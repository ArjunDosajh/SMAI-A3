{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Analysis and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  Id  \n",
       "0      9.4        5   0  \n",
       "1      9.8        5   1  \n",
       "2      9.8        5   2  \n",
       "3      9.8        6   3  \n",
       "4      9.4        5   4  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "wine_dataset = pd.read_csv('WineQT.csv')\n",
    "wine_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "      <td>1143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.311111</td>\n",
       "      <td>0.531339</td>\n",
       "      <td>0.268364</td>\n",
       "      <td>2.532152</td>\n",
       "      <td>0.086933</td>\n",
       "      <td>15.615486</td>\n",
       "      <td>45.914698</td>\n",
       "      <td>0.996730</td>\n",
       "      <td>3.311015</td>\n",
       "      <td>0.657708</td>\n",
       "      <td>10.442111</td>\n",
       "      <td>5.657043</td>\n",
       "      <td>804.969379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.747595</td>\n",
       "      <td>0.179633</td>\n",
       "      <td>0.196686</td>\n",
       "      <td>1.355917</td>\n",
       "      <td>0.047267</td>\n",
       "      <td>10.250486</td>\n",
       "      <td>32.782130</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.156664</td>\n",
       "      <td>0.170399</td>\n",
       "      <td>1.082196</td>\n",
       "      <td>0.805824</td>\n",
       "      <td>463.997116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>2.740000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.100000</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.995570</td>\n",
       "      <td>3.205000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>411.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.079000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>0.996680</td>\n",
       "      <td>3.310000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>10.200000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>794.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.090000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.997845</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>11.100000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1209.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.900000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1.003690</td>\n",
       "      <td>4.010000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>14.900000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1597.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count    1143.000000       1143.000000  1143.000000     1143.000000   \n",
       "mean        8.311111          0.531339     0.268364        2.532152   \n",
       "std         1.747595          0.179633     0.196686        1.355917   \n",
       "min         4.600000          0.120000     0.000000        0.900000   \n",
       "25%         7.100000          0.392500     0.090000        1.900000   \n",
       "50%         7.900000          0.520000     0.250000        2.200000   \n",
       "75%         9.100000          0.640000     0.420000        2.600000   \n",
       "max        15.900000          1.580000     1.000000       15.500000   \n",
       "\n",
       "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
       "count  1143.000000          1143.000000           1143.000000  1143.000000   \n",
       "mean      0.086933            15.615486             45.914698     0.996730   \n",
       "std       0.047267            10.250486             32.782130     0.001925   \n",
       "min       0.012000             1.000000              6.000000     0.990070   \n",
       "25%       0.070000             7.000000             21.000000     0.995570   \n",
       "50%       0.079000            13.000000             37.000000     0.996680   \n",
       "75%       0.090000            21.000000             61.000000     0.997845   \n",
       "max       0.611000            68.000000            289.000000     1.003690   \n",
       "\n",
       "                pH    sulphates      alcohol      quality           Id  \n",
       "count  1143.000000  1143.000000  1143.000000  1143.000000  1143.000000  \n",
       "mean      3.311015     0.657708    10.442111     5.657043   804.969379  \n",
       "std       0.156664     0.170399     1.082196     0.805824   463.997116  \n",
       "min       2.740000     0.330000     8.400000     3.000000     0.000000  \n",
       "25%       3.205000     0.550000     9.500000     5.000000   411.000000  \n",
       "50%       3.310000     0.620000    10.200000     6.000000   794.000000  \n",
       "75%       3.400000     0.730000    11.100000     6.000000  1209.500000  \n",
       "max       4.010000     2.000000    14.900000     8.000000  1597.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_dataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many distinct values of quality are there in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_dataset['quality'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "hovertemplate": "quality=%{label}<extra></extra>",
         "labels": [
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          7,
          7,
          5,
          5,
          5,
          7,
          6,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          7,
          5,
          4,
          6,
          5,
          4,
          5,
          5,
          6,
          6,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          4,
          5,
          6,
          5,
          4,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          5,
          5,
          6,
          5,
          4,
          5,
          5,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          6,
          6,
          5,
          6,
          5,
          5,
          5,
          5,
          7,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          6,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          4,
          6,
          5,
          5,
          5,
          5,
          4,
          6,
          4,
          6,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          4,
          7,
          6,
          7,
          7,
          5,
          6,
          6,
          5,
          6,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          6,
          6,
          6,
          7,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          7,
          7,
          6,
          5,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          7,
          5,
          4,
          5,
          5,
          5,
          4,
          8,
          6,
          6,
          6,
          6,
          6,
          6,
          8,
          7,
          6,
          7,
          7,
          5,
          5,
          6,
          6,
          7,
          5,
          7,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          5,
          5,
          7,
          6,
          5,
          6,
          6,
          7,
          5,
          6,
          5,
          7,
          7,
          6,
          5,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          6,
          6,
          5,
          7,
          7,
          6,
          5,
          6,
          5,
          5,
          7,
          7,
          5,
          7,
          6,
          6,
          6,
          7,
          6,
          6,
          5,
          6,
          8,
          6,
          5,
          7,
          5,
          6,
          5,
          5,
          6,
          6,
          5,
          6,
          7,
          4,
          6,
          5,
          7,
          5,
          5,
          6,
          5,
          6,
          5,
          7,
          5,
          7,
          7,
          6,
          6,
          5,
          6,
          7,
          5,
          5,
          6,
          5,
          6,
          6,
          5,
          8,
          7,
          7,
          5,
          5,
          6,
          6,
          6,
          6,
          7,
          5,
          8,
          5,
          5,
          3,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          5,
          6,
          6,
          5,
          5,
          6,
          6,
          5,
          8,
          5,
          5,
          6,
          6,
          7,
          7,
          6,
          6,
          8,
          6,
          5,
          8,
          6,
          6,
          7,
          7,
          7,
          7,
          7,
          6,
          7,
          6,
          6,
          7,
          7,
          5,
          6,
          3,
          6,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          6,
          6,
          5,
          6,
          7,
          5,
          5,
          6,
          5,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          4,
          5,
          5,
          6,
          5,
          5,
          7,
          5,
          8,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          6,
          5,
          6,
          4,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          4,
          7,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          7,
          6,
          6,
          5,
          6,
          5,
          6,
          6,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          4,
          4,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          6,
          6,
          6,
          5,
          5,
          5,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          5,
          6,
          5,
          6,
          5,
          6,
          5,
          5,
          7,
          6,
          5,
          7,
          6,
          6,
          7,
          5,
          6,
          5,
          6,
          4,
          6,
          5,
          5,
          7,
          5,
          5,
          7,
          5,
          4,
          6,
          4,
          7,
          7,
          7,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          7,
          5,
          5,
          5,
          5,
          5,
          4,
          7,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          5,
          5,
          6,
          5,
          6,
          6,
          7,
          6,
          7,
          5,
          7,
          7,
          7,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          5,
          6,
          5,
          7,
          6,
          4,
          5,
          7,
          5,
          6,
          5,
          6,
          5,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          7,
          5,
          6,
          7,
          6,
          5,
          5,
          6,
          5,
          6,
          6,
          7,
          5,
          5,
          7,
          6,
          5,
          6,
          6,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          6,
          7,
          5,
          7,
          7,
          7,
          7,
          7,
          6,
          5,
          6,
          6,
          7,
          6,
          5,
          6,
          6,
          5,
          6,
          7,
          6,
          6,
          5,
          7,
          5,
          6,
          7,
          7,
          7,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          5,
          5,
          7,
          6,
          7,
          5,
          7,
          7,
          6,
          8,
          6,
          6,
          6,
          6,
          7,
          7,
          5,
          7,
          5,
          6,
          6,
          5,
          7,
          7,
          6,
          6,
          5,
          7,
          6,
          7,
          7,
          8,
          6,
          6,
          7,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          7,
          5,
          6,
          6,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          8,
          6,
          7,
          6,
          5,
          6,
          7,
          7,
          7,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          7,
          6,
          6,
          6,
          5,
          6,
          5,
          7,
          7,
          7,
          5,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          4,
          5,
          6,
          5,
          5,
          5,
          5,
          4,
          6,
          5,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          7,
          8,
          5,
          7,
          7,
          5,
          7,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          5,
          7,
          5,
          6,
          5,
          5,
          6,
          6,
          6,
          4,
          4,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          4,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          6,
          6,
          4,
          6,
          6,
          7,
          6,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          6,
          6,
          3,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          5,
          6,
          6,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          5,
          6,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          5,
          6,
          5,
          6,
          6,
          5,
          6,
          6,
          5,
          6,
          5,
          5,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          5,
          6,
          5,
          5,
          6,
          5,
          6,
          8,
          6,
          6,
          6,
          7,
          6,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          7,
          5,
          5,
          5,
          5,
          6,
          4,
          5,
          5,
          5,
          5,
          6,
          7,
          6,
          5,
          5,
          5,
          6,
          5,
          6,
          5,
          8,
          7,
          7,
          7,
          6,
          6,
          5,
          5,
          7,
          6,
          4,
          6,
          5,
          7,
          4,
          7,
          3,
          5,
          5,
          6,
          5,
          5,
          7,
          5,
          7,
          3,
          5,
          4,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          5,
          5,
          7,
          6,
          6,
          6,
          5,
          6,
          6,
          3,
          6,
          6,
          6,
          5,
          6,
          5,
          6,
          6,
          6,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          6,
          6,
          5,
          6,
          5,
          7,
          6,
          5,
          6,
          7,
          6,
          5,
          5,
          8,
          5,
          6,
          5,
          7,
          5,
          6,
          5,
          5,
          5,
          5,
          5,
          5,
          6,
          6,
          5,
          5,
          6,
          6,
          6,
          5,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          5,
          7,
          6,
          6,
          6,
          6,
          6,
          6,
          5,
          6,
          5
         ],
         "legendgroup": "",
         "name": "",
         "showlegend": true,
         "type": "pie"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.pie(wine_dataset, names='quality')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "alcohol=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x0": " ",
         "xaxis": "x",
         "y": [
          9.4,
          9.8,
          9.8,
          9.8,
          9.4,
          9.4,
          9.4,
          10,
          9.5,
          9.2,
          9.9,
          9.1,
          10.5,
          9.2,
          9.7,
          9.5,
          9.4,
          9.7,
          9.3,
          9.5,
          9.4,
          9.8,
          10.1,
          9.8,
          9.2,
          9.6,
          10.8,
          9.7,
          10.5,
          9.3,
          10.5,
          10.3,
          13.1,
          9.2,
          9.2,
          9.4,
          9.4,
          9.4,
          10.2,
          9.6,
          10,
          9.4,
          9.2,
          9.3,
          9.8,
          10.9,
          10.9,
          10.7,
          10.5,
          9.5,
          9.2,
          10.5,
          10.7,
          10.1,
          9.1,
          9.2,
          9.1,
          10.3,
          10.1,
          9.9,
          9.6,
          9.5,
          9,
          9.5,
          9.9,
          9.6,
          10.5,
          10.7,
          9.8,
          9,
          10.2,
          9,
          9.2,
          9.4,
          9.2,
          9.3,
          9.3,
          9.5,
          9.8,
          9.7,
          9.5,
          10.5,
          10,
          9,
          10.9,
          9.2,
          9.5,
          10.9,
          10.9,
          10.5,
          9.4,
          13,
          9.9,
          9.6,
          9.2,
          9.6,
          14,
          9.4,
          14,
          9.4,
          10,
          10.2,
          10.3,
          9.4,
          10.1,
          10.1,
          10.5,
          10.5,
          10.5,
          9.3,
          9.3,
          9.6,
          9.2,
          10,
          9.4,
          9.4,
          9.5,
          10.2,
          9,
          10.4,
          9.1,
          9.2,
          11.5,
          9.5,
          9.5,
          10.5,
          9.6,
          9.5,
          9.5,
          9.3,
          9.3,
          9.3,
          9.3,
          9.7,
          9.2,
          9.5,
          9.4,
          9.8,
          9.7,
          9.7,
          10.2,
          10.1,
          11.4,
          10.3,
          9.2,
          10.8,
          10.8,
          9.4,
          12.4,
          10,
          10.1,
          9.8,
          10.5,
          11,
          9.1,
          9.7,
          9.4,
          9.4,
          9.5,
          10,
          10.5,
          9.5,
          12.2,
          9.9,
          9.6,
          9,
          9,
          9.3,
          10.9,
          9.8,
          9.2,
          9.2,
          9.9,
          9.5,
          9.9,
          10,
          9.9,
          10.5,
          9.5,
          9.3,
          9.2,
          9.2,
          9.4,
          10.5,
          9.3,
          9.4,
          10,
          9.3,
          10.9,
          9.8,
          12.8,
          9.4,
          10.1,
          10.7,
          10.7,
          9.4,
          10.1,
          12.6,
          10.5,
          9.3,
          9.9,
          10.5,
          9.8,
          9.8,
          10.3,
          10.3,
          10.6,
          9.2,
          10.6,
          10.3,
          10.1,
          9.5,
          9.5,
          9.9,
          9.6,
          9.7,
          10.7,
          10.1,
          10,
          9.2,
          9.4,
          9.5,
          9.5,
          9.4,
          9.5,
          9.4,
          11,
          11.5,
          10.4,
          9.7,
          9.2,
          9.2,
          11.5,
          11.5,
          9.7,
          11,
          11.7,
          12.2,
          12.5,
          10.3,
          9.8,
          9.8,
          9.8,
          10.7,
          12,
          10,
          9.4,
          9.3,
          13,
          11.9,
          12.8,
          11,
          11.7,
          10.4,
          9.8,
          9.4,
          9.9,
          10,
          10.2,
          10,
          10,
          9,
          12,
          8.7,
          10.6,
          11,
          12,
          13.3,
          9.4,
          9.2,
          9.2,
          12.9,
          10,
          9.5,
          13,
          9.9,
          11,
          9.4,
          9.9,
          10.5,
          10.5,
          9.1,
          10.8,
          10.8,
          9.6,
          9.5,
          9.3,
          11.7,
          9.5,
          9.3,
          11.7,
          10.5,
          10.4,
          9.9,
          12.3,
          10.9,
          11,
          12.3,
          11.4,
          10.6,
          9.3,
          10.4,
          11,
          9.2,
          9.5,
          9.9,
          9.5,
          10.2,
          11.2,
          9.3,
          9.8,
          11.2,
          12.5,
          10.5,
          11.2,
          10.2,
          10.8,
          10.8,
          10,
          11.2,
          11.1,
          13.4,
          10.3,
          9.6,
          9,
          11.3,
          9.3,
          9.2,
          11.5,
          14,
          9.2,
          9.8,
          10.6,
          11.4,
          10.4,
          10.2,
          9.7,
          11,
          10.1,
          9.2,
          11.7,
          9.4,
          10,
          10,
          10.2,
          13.3,
          13.4,
          11.6,
          12.1,
          11,
          9,
          11.1,
          11,
          11.6,
          9,
          12,
          12,
          10.8,
          12.5,
          10.8,
          9.5,
          11.4,
          10.2,
          9.7,
          11.8,
          11.8,
          9.3,
          11.9,
          8.4,
          10,
          9.4,
          9.5,
          11.4,
          9.4,
          10.3,
          10.3,
          10.3,
          12.8,
          10,
          10.3,
          9.4,
          10.7,
          12,
          11.2,
          9.6,
          11,
          9.9,
          11,
          8.4,
          9.1,
          9.5,
          10.7,
          10.4,
          9.5,
          10,
          10,
          11.5,
          11.1,
          11.7,
          11.1,
          12.7,
          11.4,
          9.2,
          10.1,
          12.7,
          11.4,
          9,
          10.7,
          11.7,
          11,
          10.4,
          10,
          9.5,
          9.8,
          9.8,
          9.6,
          9.6,
          9.9,
          9.3,
          14,
          9.7,
          11.5,
          9.7,
          9,
          9.3,
          9.3,
          9.8,
          9.3,
          9.1,
          10.5,
          10.4,
          12.7,
          9.2,
          9.4,
          10,
          9.7,
          9.8,
          9.3,
          9.4,
          9.4,
          9.5,
          10.2,
          9.1,
          9.1,
          9.3,
          9.3,
          9.3,
          9.5,
          10.5,
          11.3,
          9.5,
          9.7,
          9.4,
          9.4,
          10.3,
          9.4,
          9.4,
          9.4,
          11,
          11.2,
          11.3,
          9.6,
          14.9,
          12,
          9.5,
          9.4,
          9.6,
          10.5,
          9.6,
          9.6,
          9,
          9.6,
          9.7,
          9.5,
          9.2,
          9.2,
          9.5,
          9.5,
          9.3,
          9.9,
          10,
          9.6,
          10.2,
          9.8,
          11.3,
          9.4,
          11.3,
          9.4,
          9.4,
          9.8,
          9,
          9.4,
          9.4,
          12.8,
          9.5,
          9.7,
          10.8,
          10.1,
          9.5,
          9.4,
          9.6,
          9.7,
          9.9,
          10,
          10.5,
          11.6,
          10.1,
          9.5,
          9.8,
          10,
          9.6,
          9.5,
          9.6,
          9.2,
          9.5,
          10.4,
          11.1,
          9.5,
          9.5,
          12.7,
          9.6,
          11.5,
          9.6,
          9.5,
          9.3,
          9.5,
          9.3,
          9.3,
          11.5,
          9.5,
          9.5,
          9.5,
          9,
          9.6,
          9.5,
          9.5,
          9.4,
          9.5,
          9.1,
          10.7,
          11.2,
          9.8,
          9.8,
          9.2,
          9.7,
          9.6,
          10,
          9.5,
          9.5,
          9.4,
          9.7,
          9.6,
          9.7,
          9.4,
          9.4,
          9.5,
          10,
          10.3,
          10.5,
          9.8,
          9.4,
          9.8,
          9.8,
          9.5,
          10.1,
          10.1,
          9.3,
          9.7,
          9.6,
          9.7,
          10.8,
          12.5,
          10.2,
          9.6,
          10.8,
          10.7,
          10,
          12.9,
          9.6,
          9.9,
          12.5,
          9.2,
          10.3,
          10.5,
          10.9,
          11.4,
          11.3,
          9.6,
          9.7,
          14,
          9.8,
          10.3,
          11,
          10.7,
          10.9,
          11.1,
          9.9,
          11.7,
          11.7,
          11.2,
          10.3,
          10.9,
          9.4,
          9.8,
          9.9,
          9.8,
          9.5,
          9.5,
          10.9,
          10.9,
          10.9,
          11.3,
          10.6,
          9.5,
          10.4,
          9.7,
          9.7,
          10.6,
          10,
          11.8,
          11.8,
          11.4,
          12,
          10,
          10.5,
          10.4,
          11.2,
          9.3,
          9.7,
          9.3,
          9.7,
          9.8,
          10.7,
          12.5,
          10.7,
          12.5,
          11.8,
          10.8,
          10.8,
          10.8,
          11,
          11.5,
          10.8,
          13.2,
          10.9,
          12.2,
          11.9,
          11,
          10.1,
          11,
          11.8,
          10.5,
          11.8,
          11.2,
          11,
          10.2,
          9.2,
          11.2,
          12,
          9.8,
          9.5,
          10.5,
          11.8,
          11.4,
          12.5,
          10,
          12.1,
          12,
          12.4,
          11.9,
          11.9,
          12.4,
          11.2,
          12.1,
          10.4,
          11.3,
          11.3,
          11.1,
          9.3,
          9.5,
          11.1,
          9.2,
          12.2,
          10.9,
          12.1,
          9.4,
          9.1,
          11.3,
          10.5,
          10,
          12.9,
          10.5,
          11.3,
          9.4,
          9.4,
          10.9,
          9.4,
          9.4,
          9.4,
          10.1,
          9.1,
          12.9,
          11.5,
          10.3,
          12.8,
          11.7,
          11.7,
          12,
          12.3,
          10.4,
          10,
          10,
          11.2,
          12.6,
          12.7,
          10.4,
          11.9,
          11.9,
          10.5,
          12.3,
          10.5,
          10.4,
          12.6,
          11.6,
          10.5,
          9.6,
          9.7,
          10.6,
          12.5,
          12.6,
          11.1,
          9.8,
          12.2,
          11.4,
          10.7,
          10.4,
          10.9,
          10.8,
          9.2,
          12.9,
          12.7,
          9.1,
          12.1,
          9.1,
          11.6,
          12.1,
          9.9,
          12.5,
          11.4,
          11.8,
          11.8,
          10.2,
          12.5,
          10.9,
          10.8,
          11.1,
          9.2,
          10.7,
          11.4,
          11,
          12.3,
          12.3,
          9.5,
          12,
          9.6,
          11.6,
          11.2,
          9.9,
          9.9,
          11.8,
          11.4,
          11.5,
          12,
          10.8,
          10.8,
          9.4,
          12.4,
          12,
          12,
          12.4,
          12.8,
          11.7,
          9.5,
          10.8,
          10,
          12.3,
          11,
          13.6,
          11.3,
          11.3,
          11.3,
          13.3,
          12.9,
          13.1,
          12.3,
          11.3,
          11.5,
          10,
          10.4,
          13.6,
          11.2,
          11.8,
          11.9,
          11.4,
          9.1,
          9.5,
          9.5,
          11,
          11.4,
          10,
          10.1,
          10.4,
          9.8,
          11.8,
          11.6,
          12,
          12.5,
          9.8,
          11.1,
          9.8,
          11.8,
          12.9,
          11.8,
          10,
          12.4,
          12,
          11.5,
          10.5,
          12.3,
          9.5,
          9.5,
          11.5,
          11.2,
          11.4,
          11,
          11.4,
          9.3,
          10.9,
          10.9,
          9.6,
          12.5,
          10.8,
          12.4,
          9.5,
          9.5,
          9.8,
          10.9,
          9.5,
          9.8,
          11.2,
          11.7,
          9.4,
          11,
          11,
          10,
          11,
          11.2,
          10.4,
          10.4,
          10.4,
          9.5,
          10.9,
          11.5,
          11.5,
          10.3,
          9.4,
          9.2,
          9.6,
          13.6,
          9.5,
          11.8,
          10.8,
          9.5,
          12.8,
          9.4,
          12.8,
          9.6,
          11.8,
          9.3,
          9.5,
          10.5,
          10,
          10.9,
          9.8,
          9.8,
          9.5,
          10.9,
          9.2,
          11,
          11.3,
          9.3,
          11.2,
          9.8,
          11.8,
          10.3,
          10.3,
          11.4,
          9.5,
          14,
          11.7,
          11.2,
          9.3,
          11.2,
          9.5,
          12,
          9.7,
          9.5,
          11.5,
          10.4,
          10.4,
          10.9,
          10.2,
          10.9,
          10.5,
          10.2,
          10.2,
          11,
          10.9,
          12.4,
          9.5,
          12.1,
          12.2,
          10.9,
          12.5,
          11.7,
          11.2,
          9.2,
          9.8,
          10.1,
          9.2,
          12.8,
          10.5,
          9.8,
          12.5,
          9.1,
          12.5,
          11.4,
          10.6,
          10.6,
          10.6,
          10.6,
          9.3,
          9.8,
          9.8,
          9.2,
          9.7,
          9.6,
          10,
          12.6,
          9.5,
          9.5,
          9.5,
          10.5,
          10.5,
          10.5,
          10.5,
          11,
          10.2,
          11.4,
          9.5,
          11.8,
          10.3,
          10.1,
          10.1,
          11.1,
          9.5,
          10.0333333333333,
          10.1,
          10.0333333333333,
          11.8,
          9.8,
          10.5,
          9.8,
          9.2,
          11.6,
          9.2,
          10,
          9.9,
          10.8,
          10.8,
          9.9,
          9.9,
          9.5,
          9.2,
          9.6,
          10.3,
          12.5,
          11,
          9.8,
          10.2,
          9.55,
          9.55,
          9.9,
          11.1,
          9.9,
          11.9,
          10,
          10.7,
          10.9,
          10.7,
          12.4,
          10.7,
          11.9,
          10.6,
          10.9,
          10.1,
          9.6,
          9.4,
          9.6,
          12.1,
          9.8,
          9.9,
          9.8,
          9.4,
          11.4,
          11,
          11.2,
          11,
          11.3,
          10.4,
          9.9,
          10.1,
          9,
          8.5,
          11.1,
          10.3,
          11.066666666666698,
          11.7,
          9.6,
          9.7,
          11.3,
          11.3,
          11,
          11.6,
          10.9,
          10.9,
          9,
          10.5,
          11.9,
          10.4,
          10,
          10.8,
          9.7,
          10,
          11,
          10,
          9.7,
          9.7,
          12.6,
          11.1,
          11,
          8.8,
          13.566666666666698,
          8.8,
          13.6,
          10.2,
          10.6,
          10.1,
          10.6,
          10.7,
          9.7,
          10.3,
          10.6,
          11.4,
          12.4,
          11.95,
          9.7,
          10,
          10.6,
          11.5,
          11.5,
          9.4,
          11,
          11.4,
          9.95,
          10.8,
          11.4,
          10.6,
          11.1,
          9.7,
          9.8,
          9.23333333333333,
          9.25,
          10.3,
          10.5,
          10.2,
          10.6,
          10.4,
          9.7,
          9.6,
          10.1,
          10.2,
          11.3,
          10.2,
          9.9,
          9,
          11.7,
          9.7,
          12,
          11.6,
          11.2,
          10.1,
          10.2,
          10.4,
          11.4,
          9.4,
          11.3,
          9.4,
          10.55,
          9.9,
          11,
          9.5,
          9.9,
          9.9,
          9.9,
          10.1,
          10.1,
          10.9,
          11.2,
          10.1,
          9.2,
          11.5,
          12.4,
          11.1,
          9.5,
          12.5,
          11.8,
          10.8,
          11.9,
          11.3,
          11.9,
          11.9,
          9.8,
          11.6,
          11.4,
          10.9,
          11.6,
          11.6,
          11,
          9.5,
          10.5,
          11.2,
          10.2
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Box and whisker plot of alcohol level in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "alcohol"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(wine_dataset, y='alcohol', title='Box and whisker plot of alcohol level in the wine samples')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "hovertemplate": "pH=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa"
         },
         "name": "",
         "notched": false,
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "box",
         "x0": " ",
         "xaxis": "x",
         "y": [
          3.51,
          3.2,
          3.26,
          3.16,
          3.51,
          3.51,
          3.3,
          3.39,
          3.36,
          3.28,
          3.58,
          3.26,
          3.3,
          3.04,
          3.52,
          3.17,
          3.17,
          3.43,
          3.34,
          3.28,
          3.47,
          3.38,
          3.35,
          3.17,
          3.38,
          3.4,
          3.42,
          3.23,
          3.33,
          3.26,
          3.21,
          3.3,
          3.9,
          3.25,
          3.15,
          3.4,
          3.39,
          3.2,
          3.17,
          3.04,
          3.43,
          3.41,
          3.44,
          3.21,
          3.39,
          3.41,
          3.41,
          3.44,
          3.34,
          3.31,
          3.31,
          3.54,
          3.52,
          3.38,
          3.16,
          3.41,
          3.36,
          3.44,
          3.41,
          2.93,
          3.39,
          3.14,
          3.48,
          3.23,
          2.93,
          3.39,
          3.75,
          3.45,
          3.39,
          3.3,
          3.4,
          3.3,
          3.29,
          3.33,
          3.29,
          3.08,
          3.46,
          3.19,
          3.15,
          3.32,
          3.19,
          3.07,
          3.39,
          3.3,
          3.21,
          3.49,
          3.39,
          3.53,
          3.54,
          3.42,
          3.24,
          3.63,
          3.22,
          3.19,
          3.48,
          3.19,
          3.68,
          3.34,
          3.68,
          3.17,
          3.54,
          3.42,
          3.33,
          2.74,
          3.35,
          3.35,
          3.42,
          3.42,
          3.42,
          3.48,
          3.59,
          3.2,
          3.17,
          3.33,
          3.37,
          3.37,
          3.19,
          3.34,
          3.37,
          3.47,
          3.36,
          3.29,
          3.42,
          3.35,
          3.33,
          3.58,
          3.48,
          3.19,
          3.19,
          3.12,
          3.44,
          3.54,
          3.52,
          3.26,
          3.34,
          3.2,
          3.23,
          3.57,
          3.28,
          3.28,
          3.46,
          3.11,
          3.51,
          3.22,
          3.34,
          3.2,
          3.2,
          3.22,
          3.3,
          3.35,
          3.3,
          3.24,
          3.34,
          3.14,
          3.36,
          3.39,
          3.34,
          3.15,
          3.42,
          3.28,
          3.37,
          3.04,
          3.54,
          3.37,
          3.34,
          3.32,
          3.37,
          3,
          3.14,
          3.08,
          3.07,
          3.07,
          3.61,
          3.38,
          3.61,
          3.22,
          3.47,
          3.17,
          3.23,
          3.26,
          3.22,
          3.49,
          3.06,
          3.36,
          3.29,
          3.35,
          3.34,
          3.28,
          3.08,
          3.6,
          3.35,
          3.69,
          3.28,
          3.36,
          3.36,
          3.69,
          3.28,
          3.23,
          3.38,
          3.12,
          3.25,
          3.38,
          3.31,
          3.31,
          3.1,
          3.37,
          3.34,
          3.2,
          3.34,
          3.22,
          3.41,
          3.05,
          3.05,
          3.16,
          3.67,
          3.67,
          3.38,
          3.22,
          3.51,
          3.2,
          3.36,
          3.19,
          3.19,
          3.27,
          3.32,
          3.3,
          3.39,
          3.37,
          3.3,
          3.24,
          3.16,
          3.16,
          3.05,
          3.28,
          3.16,
          3.13,
          3.34,
          3.17,
          3.35,
          3.31,
          3.11,
          3.3,
          3.3,
          3.12,
          3.02,
          3.11,
          3.35,
          3.27,
          3.18,
          3.25,
          3.55,
          3.26,
          3.24,
          3.15,
          3.17,
          3.19,
          3.37,
          3.05,
          2.99,
          3.07,
          3.07,
          3.16,
          3.2,
          3.32,
          3.32,
          3.26,
          3.2,
          3.11,
          3.21,
          3.42,
          3.43,
          3.56,
          3.06,
          3.18,
          3.22,
          3.47,
          3.18,
          3.1,
          3.47,
          3.1,
          3.15,
          3.26,
          3.24,
          3.18,
          3.05,
          3.38,
          3.27,
          3.27,
          3.26,
          3.32,
          3.26,
          3.44,
          3.24,
          3.62,
          3.52,
          3.36,
          3.15,
          3.52,
          3.49,
          3.26,
          3.24,
          3.1,
          3.15,
          3.25,
          3.16,
          3.15,
          3.16,
          3.26,
          3.17,
          3.08,
          2.88,
          2.95,
          3.57,
          3.1,
          3.22,
          3.2,
          3.1,
          3.1,
          3.44,
          3.26,
          3.5,
          3.22,
          3.37,
          3.28,
          3.25,
          3.35,
          3.26,
          2.98,
          3.16,
          3.32,
          3.17,
          3.2,
          3.05,
          3.2,
          3.15,
          3.14,
          3.28,
          3.18,
          3.19,
          3.12,
          3.15,
          3.04,
          3.17,
          3.17,
          3.34,
          3.34,
          3.32,
          3.48,
          3.44,
          3.15,
          3.43,
          3.32,
          3.15,
          3.48,
          3.43,
          3.17,
          3.17,
          3.21,
          3.16,
          3.25,
          3.17,
          3.04,
          3.18,
          3.03,
          3.09,
          3.09,
          3.31,
          3.25,
          3.16,
          3.42,
          3.22,
          3.23,
          3.39,
          3.09,
          3.41,
          3.16,
          3.16,
          3.22,
          3.28,
          3.41,
          3.09,
          3.37,
          3.2,
          3.22,
          3.26,
          3.21,
          3.12,
          3.06,
          2.86,
          3.08,
          3.45,
          3.26,
          3.12,
          3.33,
          3.19,
          3.12,
          3.74,
          2.92,
          3.07,
          2.92,
          3.3,
          3.14,
          3.08,
          3.31,
          3.3,
          3.14,
          3.32,
          3.31,
          3.57,
          3.32,
          3.14,
          3.34,
          3.3,
          3.29,
          3.14,
          3.19,
          3.19,
          2.98,
          3.26,
          3.72,
          3.35,
          3.12,
          3.35,
          3.29,
          3.27,
          3.04,
          3.2,
          3.3,
          3.17,
          3.31,
          3.32,
          3.56,
          3.39,
          2.98,
          3.32,
          3.5,
          3.03,
          3.09,
          3.27,
          3.28,
          3.13,
          3.46,
          3.36,
          3.36,
          3.27,
          3.21,
          3.27,
          3.25,
          3.32,
          3.43,
          3.27,
          3.27,
          3.24,
          3.24,
          3.18,
          3.39,
          3.39,
          3.39,
          3.32,
          3.33,
          3.16,
          2.89,
          2.98,
          3.12,
          3.08,
          3.14,
          2.89,
          2.92,
          3.32,
          3.32,
          3.31,
          3.36,
          3.14,
          3.18,
          2.94,
          2.94,
          3.2,
          3.2,
          3.08,
          3.4,
          3.48,
          3.13,
          3.21,
          3.33,
          3.37,
          3.25,
          3.37,
          3.4,
          3.3,
          3.48,
          3.03,
          3.32,
          3.31,
          3.9,
          3.47,
          3.31,
          3.11,
          3.08,
          3.47,
          3.47,
          3.32,
          3.29,
          3.37,
          3.4,
          3.37,
          3.34,
          3.06,
          3.38,
          3.28,
          3.21,
          3.22,
          3.46,
          3.22,
          3.1,
          2.94,
          3.29,
          3.43,
          3.46,
          3.46,
          3.61,
          3.17,
          3.44,
          3.39,
          3.55,
          3.48,
          3.26,
          3.5,
          3.35,
          3.45,
          3.21,
          3.13,
          3.52,
          3.3,
          3.52,
          3.52,
          3.29,
          3.39,
          3.29,
          3.09,
          3.51,
          3.6,
          3.25,
          3.25,
          3.19,
          3.23,
          3.25,
          3.31,
          3.31,
          3.31,
          3.14,
          3.55,
          3.39,
          3.55,
          3.28,
          3.27,
          3.3,
          3.43,
          3.4,
          3.36,
          3.5,
          3.31,
          3.66,
          3.55,
          3.21,
          3.18,
          3.18,
          3.09,
          3.33,
          3.23,
          3.48,
          3.38,
          3.17,
          2.99,
          3.1,
          3.24,
          3.29,
          3.23,
          3.56,
          3.24,
          3.26,
          3.27,
          3.26,
          3.22,
          3.3,
          3.09,
          3.44,
          3.21,
          3.28,
          3.34,
          3.71,
          3.61,
          3.24,
          3.4,
          3.36,
          3.38,
          3.56,
          3.38,
          3.26,
          3.26,
          3.24,
          3.45,
          3.23,
          3.28,
          3.59,
          3.5,
          3.59,
          3.28,
          3.28,
          3.47,
          3.47,
          3.47,
          3.4,
          3.15,
          3.51,
          3.24,
          3.51,
          3.51,
          3.53,
          3.43,
          3.31,
          3.41,
          3.48,
          3.22,
          3.22,
          3.34,
          3.33,
          3.43,
          3.22,
          3.53,
          3.22,
          3.53,
          3.53,
          3.42,
          3.31,
          3.42,
          3.31,
          3.4,
          3.58,
          3.58,
          3.41,
          3.39,
          3.59,
          3.43,
          3.23,
          3.18,
          3.33,
          3.27,
          3.62,
          3.38,
          3.3,
          3.38,
          3.24,
          3.38,
          3.18,
          3.47,
          3.47,
          3.2,
          3.18,
          3.3,
          3.48,
          3.45,
          3.69,
          3.39,
          3.61,
          3.19,
          3.22,
          3.27,
          3.29,
          3.26,
          3.41,
          3.41,
          3.26,
          3.31,
          3.2,
          3.36,
          3.31,
          3.47,
          3.16,
          3.27,
          3.38,
          3.16,
          3.13,
          3.2,
          3.33,
          3.3,
          3.44,
          3.15,
          3.28,
          3.32,
          3.25,
          3.34,
          3.32,
          3.45,
          3.44,
          3.16,
          3.14,
          3.16,
          3.45,
          3.45,
          3.39,
          3.12,
          3.47,
          3.44,
          3.25,
          3.36,
          3.26,
          3.26,
          3.23,
          3.25,
          3.17,
          3.23,
          3.38,
          3.22,
          3.27,
          2.89,
          3.53,
          3.2,
          3.2,
          3.35,
          3.27,
          3.32,
          3.33,
          3.41,
          3.49,
          3.32,
          3.36,
          3.2,
          3.17,
          3.22,
          3.24,
          3.33,
          3.38,
          3.36,
          3.32,
          3.31,
          3.49,
          3.27,
          3.27,
          3.03,
          3.56,
          3.38,
          3.13,
          3.21,
          3.15,
          3.19,
          3.21,
          3.14,
          3.21,
          3.3,
          3.22,
          3.28,
          3.29,
          3.4,
          3.02,
          3.31,
          3.18,
          3.2,
          3.31,
          3.15,
          3.27,
          3.01,
          3.01,
          3.42,
          3.33,
          3.12,
          3.38,
          3.29,
          3.02,
          3.02,
          2.98,
          3.35,
          3.43,
          3.33,
          3.35,
          3.35,
          3.2,
          3.11,
          3.35,
          3.35,
          3.28,
          3.41,
          3.27,
          3.36,
          3.17,
          3.25,
          3.78,
          3.29,
          3.49,
          3.38,
          3.38,
          3.38,
          3.3,
          3.52,
          3.2,
          3.45,
          3.14,
          3.51,
          3.22,
          3.18,
          3.38,
          3.37,
          3.3,
          3.38,
          3.22,
          3.14,
          3.34,
          3.41,
          3.27,
          3.3,
          3.61,
          3.43,
          3.53,
          3.28,
          3.21,
          3.39,
          3.23,
          3.46,
          3.15,
          3.23,
          3.15,
          3.33,
          3.46,
          3.14,
          3.29,
          3.32,
          3.21,
          3.32,
          3.2,
          3.27,
          3.46,
          3.46,
          3.61,
          3.58,
          3.68,
          3.27,
          3.19,
          3.29,
          3.36,
          3.36,
          3.3,
          3.28,
          3.56,
          3.52,
          3.22,
          3.52,
          3.16,
          3.15,
          3.21,
          3.16,
          3.27,
          3.35,
          3.14,
          3.4,
          3.4,
          3.35,
          3.4,
          3.45,
          3.35,
          3.35,
          3.1,
          3.29,
          3.2,
          3.28,
          3.28,
          3.07,
          3.15,
          3.02,
          3.27,
          3.68,
          3.4,
          3.37,
          3.38,
          3.4,
          3.39,
          3.26,
          3.39,
          3.38,
          3.45,
          3.1,
          3.37,
          3.49,
          3.12,
          3.4,
          3.28,
          3.45,
          3.43,
          3.4,
          3.1,
          3.32,
          3.44,
          3.02,
          3.59,
          3.15,
          3.38,
          3.38,
          3.38,
          3.1,
          3.47,
          3.7,
          3.38,
          3.5,
          3.1,
          3.24,
          3.24,
          3.28,
          3.35,
          3.24,
          3.14,
          3.37,
          3.37,
          3.33,
          3.26,
          3.39,
          3.15,
          3.3,
          3.3,
          3.36,
          3.29,
          3.62,
          3.2,
          3.35,
          3.45,
          3.5,
          3.78,
          3.6,
          3.3,
          3.12,
          3.3,
          3.29,
          3.28,
          3.33,
          3.34,
          3.26,
          4.01,
          2.9,
          4.01,
          3.18,
          3.39,
          3.39,
          3.39,
          3.39,
          3.34,
          3.29,
          3.29,
          3.26,
          3.09,
          3.18,
          3.39,
          3.38,
          3.36,
          3.36,
          3.36,
          3.36,
          3.36,
          3.36,
          3.36,
          3.09,
          3.25,
          3.52,
          3.34,
          3.32,
          3.37,
          3.36,
          3.36,
          3.6,
          3.28,
          3.07,
          3.36,
          3.07,
          3.46,
          3.24,
          3.25,
          3.27,
          3,
          3.21,
          3,
          3.11,
          3.29,
          3.36,
          3.36,
          3.3,
          3.3,
          3.19,
          3.19,
          3.3,
          3.35,
          3.58,
          3.37,
          3.17,
          3.3,
          3.31,
          3.31,
          3.28,
          3.42,
          3.25,
          3.44,
          3.23,
          3.43,
          3.22,
          3.54,
          3.27,
          3.54,
          3.5,
          3.56,
          3.22,
          3.04,
          3.2,
          3.56,
          3.2,
          3.35,
          3.16,
          3.27,
          3.16,
          3.34,
          3.39,
          3.5,
          3.3,
          3.31,
          3.33,
          3.37,
          3.26,
          3.42,
          3.18,
          3.15,
          3.53,
          3.41,
          3.32,
          3.38,
          3.16,
          3.4,
          3.23,
          3.23,
          3.33,
          3.35,
          3.21,
          3.5,
          3.41,
          3.39,
          3.32,
          3.41,
          3.59,
          3.34,
          3.41,
          3.3,
          3.52,
          3.3,
          3.31,
          2.88,
          3.43,
          3.38,
          3.38,
          3.16,
          3.54,
          3.16,
          3.54,
          3.4,
          3.39,
          3.66,
          3.39,
          3.35,
          3.37,
          3.38,
          3.52,
          3.72,
          3.39,
          3.57,
          3.26,
          3.42,
          3.35,
          3.45,
          3.45,
          3.16,
          3.51,
          3.36,
          3.55,
          3.51,
          3.36,
          3.38,
          3.28,
          3.47,
          3.44,
          3.53,
          3.53,
          3.38,
          3.32,
          3.44,
          3.42,
          3.34,
          3.33,
          3.3,
          3.31,
          3.42,
          3.42,
          3.6,
          3.21,
          3.39,
          3.42,
          3.36,
          3.57,
          3.56,
          3.17,
          3.36,
          3.36,
          3.1,
          3.24,
          3.44,
          3.51,
          3.41,
          3.44,
          3.53,
          3.54,
          3.22,
          3.21,
          3.21,
          3.21,
          3.29,
          3.29,
          3.39,
          3.34,
          3.29,
          3.34,
          3.48,
          3.37,
          3.44,
          3.33,
          3.58,
          3.26,
          3.3,
          3.54,
          3.42,
          3.36,
          3.57,
          3.33,
          3.29,
          3.34,
          3.55,
          3.32,
          3.67,
          3.42,
          3.42,
          3.45,
          3.52,
          3.57
         ],
         "y0": " ",
         "yaxis": "y"
        }
       ],
       "layout": {
        "boxmode": "group",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Box and whisker plot of pH level in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ]
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "pH"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.box(wine_dataset, y='pH', title='Box and whisker plot of pH level in the wine samples')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "fixed acidity=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          7.4,
          7.8,
          7.8,
          11.2,
          7.4,
          7.4,
          7.9,
          7.3,
          7.8,
          6.7,
          5.6,
          7.8,
          8.5,
          7.9,
          7.6,
          7.9,
          8.5,
          6.9,
          6.3,
          7.6,
          7.1,
          7.8,
          6.7,
          8.3,
          5.2,
          7.8,
          7.8,
          8.1,
          7.3,
          8.8,
          7.5,
          8.1,
          4.6,
          7.7,
          8.8,
          6.6,
          6.6,
          8.6,
          7.6,
          10.2,
          7.8,
          7.3,
          8.8,
          7.7,
          7,
          7.2,
          7.2,
          6.6,
          8,
          7.7,
          8.3,
          8.8,
          6.8,
          6.7,
          8.3,
          6.2,
          7.4,
          6.3,
          6.9,
          8.6,
          7.7,
          9.3,
          7,
          7.9,
          8.6,
          7.7,
          5,
          6.8,
          7.6,
          8.1,
          8.3,
          8.1,
          8.1,
          7.2,
          8.1,
          7.8,
          6.2,
          7.8,
          8.4,
          10.1,
          7.8,
          9.4,
          8.3,
          7.3,
          8.8,
          7.3,
          7.8,
          8.2,
          8.1,
          8,
          8,
          5.6,
          7.9,
          8.4,
          7.2,
          8.4,
          5.2,
          6.3,
          5.2,
          8.1,
          5.8,
          6.9,
          7.3,
          9.2,
          7.5,
          7.5,
          7.1,
          7.1,
          7.1,
          7.1,
          6.8,
          7.6,
          7.6,
          7.8,
          7.4,
          7.3,
          7.8,
          6.8,
          7.3,
          6.8,
          7.9,
          8,
          7.4,
          6.9,
          7.3,
          7.5,
          7,
          8.8,
          8.8,
          8.9,
          7.2,
          6.8,
          6.7,
          8.9,
          7.4,
          7.9,
          8.2,
          6.4,
          7.6,
          7.6,
          7.3,
          11.5,
          6.9,
          9.6,
          7,
          12.8,
          12.8,
          7.8,
          9.7,
          8,
          8.2,
          7.8,
          7,
          8.7,
          8.1,
          7.5,
          7.8,
          7.4,
          6.8,
          8.6,
          7.7,
          8.9,
          5.2,
          8,
          8.5,
          8.2,
          7.2,
          8.9,
          12,
          7.7,
          15,
          15,
          7.3,
          7.1,
          7.3,
          10.8,
          7.1,
          11.1,
          7.7,
          8,
          9.4,
          6.6,
          7.7,
          10,
          7.9,
          7,
          8,
          7.9,
          12.5,
          8.1,
          7.9,
          6.9,
          11.5,
          7.9,
          7.9,
          6.9,
          11.5,
          10.3,
          8.9,
          11.4,
          7.7,
          8.9,
          9.9,
          9.9,
          12,
          7.5,
          8.7,
          11.6,
          8.7,
          10.4,
          6.9,
          13.3,
          10.8,
          10.6,
          7.1,
          7.2,
          7.5,
          11.1,
          8.3,
          8.4,
          7.6,
          10.3,
          10.3,
          7.9,
          9,
          8.6,
          7.4,
          9.8,
          9.6,
          9.3,
          10,
          10,
          11.6,
          10.3,
          13.4,
          8.4,
          7.9,
          11.9,
          8.9,
          7.8,
          12.5,
          10.9,
          10.9,
          11.9,
          13.8,
          9.6,
          9.1,
          7.7,
          13.5,
          6.1,
          6.7,
          11.5,
          10.5,
          11.9,
          12.6,
          8.2,
          8.6,
          11.9,
          12.5,
          12.8,
          12.8,
          10.4,
          9.4,
          7.9,
          9.1,
          11.5,
          9.4,
          11.4,
          8.3,
          7.7,
          7.8,
          5.6,
          13.7,
          9.5,
          12,
          6.6,
          11.5,
          8.7,
          6.6,
          12.2,
          11.4,
          7.7,
          9.8,
          12,
          12.5,
          9,
          7.1,
          9.9,
          8.8,
          8.6,
          10.6,
          7,
          11.9,
          6.8,
          6.6,
          7.7,
          10.5,
          6.6,
          6.4,
          9.5,
          9.1,
          12.8,
          10.5,
          7.8,
          12.3,
          10.4,
          12.3,
          8,
          11.1,
          7,
          12.6,
          15.6,
          5.3,
          12.5,
          9.3,
          8.6,
          11.9,
          11.9,
          6.8,
          10.4,
          7,
          11.3,
          8.9,
          9.2,
          11.6,
          9.2,
          8.3,
          11.5,
          10.3,
          8.8,
          11.4,
          8.7,
          13,
          9.6,
          12.5,
          9.6,
          9.3,
          10.4,
          9.4,
          10.6,
          9.4,
          10.6,
          10.2,
          10.2,
          9.3,
          9.2,
          8.9,
          8.7,
          6.5,
          10.7,
          7.8,
          7.2,
          10.7,
          8.7,
          7.8,
          10.4,
          10.4,
          10.5,
          10.2,
          10.4,
          11.2,
          13.3,
          10,
          10.7,
          10.5,
          10.5,
          8.5,
          12.5,
          10.4,
          9.8,
          9.3,
          9.2,
          7,
          9.9,
          9.1,
          11.9,
          11.9,
          10.3,
          10,
          9.1,
          9.9,
          8.1,
          12.9,
          11.2,
          9.2,
          9.5,
          9.3,
          11.2,
          14.3,
          9.1,
          7.5,
          10.6,
          12.4,
          6.8,
          9.4,
          9.5,
          5,
          15.5,
          10.9,
          15.6,
          13,
          12.7,
          9,
          7.6,
          13,
          12.7,
          8.7,
          9.8,
          6.2,
          11.5,
          10.2,
          9.9,
          8.8,
          8.8,
          10.6,
          12.3,
          12.3,
          12,
          7.3,
          5,
          9,
          6.6,
          9,
          9.9,
          8.9,
          12.4,
          8.5,
          7.7,
          8.3,
          8.8,
          10.1,
          6.3,
          8.8,
          13.2,
          7.5,
          9.6,
          11.5,
          11.3,
          8.3,
          8.2,
          10,
          6.8,
          8.8,
          8.8,
          8.7,
          7.6,
          8.7,
          10.4,
          7.6,
          10.1,
          7.9,
          8.7,
          9.6,
          9.5,
          8.9,
          9.9,
          9.9,
          9.9,
          8.3,
          8.7,
          6.7,
          10.7,
          15.9,
          9.4,
          8.6,
          9.7,
          10.7,
          12,
          7.2,
          7.2,
          7.5,
          7.2,
          9.4,
          8.3,
          11.3,
          11.3,
          8.2,
          8.2,
          10.8,
          8.6,
          8.3,
          10.8,
          8,
          8.5,
          8.1,
          9.8,
          8.1,
          7.7,
          8.1,
          9.2,
          8.6,
          9,
          9,
          5.1,
          7,
          9.4,
          11.8,
          10.6,
          7,
          7,
          7.5,
          9.1,
          8.4,
          7,
          7.4,
          7.8,
          10.6,
          8.9,
          9.9,
          7.6,
          8.4,
          7.1,
          8.4,
          8.9,
          7.1,
          9,
          8.1,
          6.4,
          6.4,
          6.4,
          9.5,
          8.9,
          7.3,
          7,
          7.7,
          7.7,
          8.2,
          9,
          8.3,
          9.2,
          11.1,
          7.3,
          8.2,
          7.2,
          7.3,
          8.3,
          7.6,
          8.3,
          7.8,
          7.8,
          6.3,
          8.1,
          8.1,
          8.8,
          9,
          9.3,
          8.8,
          9.1,
          9.2,
          8.8,
          7.1,
          7.9,
          7.1,
          9.4,
          9.5,
          7.9,
          7.2,
          6.9,
          8.3,
          7.1,
          7,
          6.5,
          7.1,
          9.9,
          10,
          10,
          8.6,
          7.4,
          8.8,
          7.1,
          7.7,
          10.1,
          10.8,
          8.7,
          9.3,
          9.4,
          8.6,
          5.1,
          7.7,
          8.4,
          8.4,
          7.4,
          7.6,
          7.3,
          12.9,
          6.9,
          12.6,
          9.1,
          7,
          4.9,
          6.7,
          7.1,
          7.5,
          7.1,
          7.5,
          5.9,
          11.6,
          6.7,
          6.7,
          10.1,
          6.6,
          10.6,
          7.1,
          6.4,
          7.4,
          6.4,
          9.3,
          9.3,
          9.3,
          9.3,
          9.3,
          8.2,
          11.7,
          7.2,
          7.5,
          7.2,
          7.2,
          6.9,
          7.3,
          8.8,
          7.7,
          7.6,
          8.4,
          8.8,
          8.9,
          9,
          6.8,
          10.7,
          7.2,
          10.1,
          7.2,
          7.2,
          7.1,
          8.3,
          7.1,
          8.3,
          8.9,
          7.4,
          7.4,
          6.8,
          7.2,
          6.1,
          7.4,
          9.3,
          9.1,
          10,
          8.6,
          5.3,
          6.8,
          8.4,
          8.4,
          9.6,
          8.4,
          8.6,
          8.6,
          9.4,
          8.4,
          8.6,
          8.7,
          7.4,
          7.6,
          6.6,
          8.8,
          6.2,
          9.9,
          10.1,
          8.3,
          10.2,
          8.3,
          8.9,
          8.9,
          8.3,
          8.2,
          10.2,
          8.5,
          9,
          6.4,
          8.5,
          7.1,
          6.6,
          8.5,
          8.5,
          9,
          10.4,
          8.8,
          7.2,
          8.4,
          7,
          9.1,
          9.5,
          7.3,
          9.1,
          7.4,
          7.1,
          7.7,
          9.7,
          7.7,
          7.1,
          7.1,
          7.7,
          8.9,
          6.4,
          7.5,
          8.2,
          6.8,
          9.1,
          9.1,
          8.9,
          8.9,
          8.9,
          7.7,
          7.5,
          8,
          8.9,
          8,
          7,
          11.3,
          11.3,
          7,
          8.2,
          7.7,
          8.6,
          7.9,
          6.4,
          7.7,
          8.1,
          8.9,
          10.1,
          7.6,
          8.7,
          8.9,
          6.9,
          6.4,
          6.9,
          7.6,
          7.1,
          9.3,
          9.3,
          8.5,
          5.6,
          8.3,
          8.2,
          8.9,
          7.6,
          9.9,
          8.9,
          11.6,
          9.1,
          8,
          10.2,
          8.2,
          7.7,
          6.6,
          11.1,
          8,
          9.3,
          7.5,
          8,
          9.9,
          8.6,
          7.9,
          7.9,
          7.2,
          8.7,
          6.8,
          8.5,
          7.9,
          11.6,
          11.6,
          10,
          7.9,
          7,
          9.2,
          6.6,
          6.6,
          8.6,
          8.4,
          7.4,
          7.4,
          8,
          6.3,
          9.1,
          8.1,
          10.8,
          8.3,
          5.4,
          7.9,
          5,
          7,
          7,
          7,
          7.1,
          5.6,
          7.9,
          6.3,
          8.8,
          6.3,
          10,
          9.1,
          7.4,
          7.2,
          8.5,
          8,
          10.4,
          7.5,
          8.2,
          7.3,
          8.2,
          6.9,
          7,
          7.3,
          8.2,
          7.8,
          10,
          7.8,
          10,
          6.1,
          8.3,
          9.6,
          8.3,
          8.5,
          5.1,
          8.5,
          9,
          8.2,
          6.5,
          7.6,
          9.2,
          9.7,
          7.6,
          7.6,
          6.5,
          6.5,
          5.6,
          8.2,
          9.8,
          6.8,
          6.7,
          6.7,
          8.8,
          9.1,
          6.5,
          7.2,
          7,
          6.2,
          7.7,
          7.7,
          7.9,
          7.7,
          7.9,
          8.6,
          9.9,
          7.2,
          7.2,
          9.9,
          7.2,
          6.2,
          6.8,
          6.8,
          10.2,
          7.9,
          9,
          10.9,
          10.9,
          12.6,
          9.2,
          7.5,
          9,
          5.1,
          7.6,
          7.7,
          7.8,
          7.6,
          7.1,
          7.8,
          7.1,
          8.1,
          6.5,
          7.5,
          8.3,
          7.4,
          7.4,
          7.1,
          7.5,
          7.1,
          7.9,
          7.8,
          7.5,
          7,
          6.8,
          8.6,
          6.3,
          9.8,
          8.5,
          7.2,
          7.2,
          10.4,
          6.9,
          5,
          7.3,
          5.9,
          7.5,
          7.8,
          8,
          8.5,
          7,
          8,
          9.8,
          7.1,
          7.1,
          7.9,
          8.7,
          7,
          11.3,
          7,
          7,
          7.6,
          8.2,
          5.9,
          6.6,
          7.2,
          5.7,
          7.6,
          5.2,
          6.7,
          9.1,
          7.6,
          7.5,
          9.7,
          7,
          6.5,
          8,
          7.5,
          5.4,
          9.1,
          5,
          9.1,
          6.7,
          6.7,
          6.7,
          6.7,
          6.5,
          7.4,
          7.4,
          7.8,
          8.4,
          9.1,
          7.2,
          6.6,
          6,
          6,
          6,
          7.5,
          7.5,
          7.5,
          7.5,
          11.5,
          8.2,
          6.1,
          7.2,
          7.2,
          7.6,
          6.1,
          6.1,
          7.3,
          7.4,
          11.6,
          8.3,
          11.6,
          7.2,
          7.3,
          6.9,
          8,
          8.7,
          7.5,
          8.7,
          8.2,
          7.2,
          7.5,
          7.5,
          8,
          8,
          7.1,
          8,
          7.4,
          6.6,
          6,
          8,
          7.1,
          8,
          8.6,
          8.7,
          7.3,
          7.2,
          7.9,
          7.6,
          7.2,
          8,
          8.2,
          6,
          8.1,
          6,
          6.6,
          6.4,
          8.2,
          9.9,
          10,
          6.2,
          10,
          7.3,
          7.8,
          7.7,
          7.8,
          7.5,
          7,
          6.4,
          7.6,
          7.8,
          7.9,
          7.4,
          7.6,
          6.1,
          10.2,
          10,
          6.8,
          7,
          7.3,
          6.9,
          7.4,
          6.8,
          7.2,
          7.2,
          7.8,
          6.6,
          11.7,
          6.5,
          7.6,
          8.4,
          7.9,
          6.4,
          6.2,
          6.9,
          6.8,
          7.3,
          6.7,
          7.3,
          7.3,
          10,
          6.7,
          7.6,
          6.1,
          9.9,
          5.3,
          9.9,
          5.3,
          7.1,
          8.2,
          5.6,
          8.2,
          8.1,
          7,
          6.8,
          6,
          5.6,
          7.1,
          6.2,
          7.7,
          6.4,
          7,
          6.9,
          6.9,
          7.8,
          6.2,
          7.5,
          6.7,
          6.8,
          7.5,
          7.1,
          7.9,
          6.4,
          7.1,
          6.9,
          6.9,
          6.5,
          7.4,
          6.6,
          6.1,
          6.8,
          6.7,
          6.8,
          7.9,
          7.1,
          6.6,
          6.1,
          7.2,
          8,
          6.6,
          7,
          6.2,
          6.2,
          8.4,
          6.5,
          7,
          11.2,
          7.4,
          7.1,
          6.3,
          7.3,
          7,
          6.6,
          6.6,
          6.9,
          7.8,
          7.8,
          7.8,
          7.2,
          7.2,
          6.7,
          6.7,
          7.2,
          7,
          6.2,
          6.4,
          6.4,
          7.3,
          6,
          7.5,
          8,
          6.2,
          6.8,
          7.4,
          6.1,
          6.2,
          6.7,
          7.5,
          5.8,
          6.3,
          5.4,
          6.3,
          6.8,
          6.2,
          5.9,
          5.9
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of fixed acidity"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "fixed acidity"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "volatile acidity=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0.7,
          0.88,
          0.76,
          0.28,
          0.7,
          0.66,
          0.6,
          0.65,
          0.58,
          0.58,
          0.615,
          0.61,
          0.28,
          0.32,
          0.39,
          0.43,
          0.49,
          0.4,
          0.39,
          0.41,
          0.71,
          0.645,
          0.675,
          0.655,
          0.32,
          0.645,
          0.6,
          0.38,
          0.45,
          0.61,
          0.49,
          0.66,
          0.52,
          0.935,
          0.66,
          0.52,
          0.5,
          0.38,
          0.51,
          0.42,
          0.59,
          0.39,
          0.4,
          0.69,
          0.735,
          0.725,
          0.725,
          0.705,
          0.705,
          0.69,
          0.675,
          0.41,
          0.785,
          0.75,
          0.625,
          0.45,
          0.5,
          0.3,
          0.55,
          0.49,
          0.49,
          0.39,
          0.62,
          0.52,
          0.49,
          0.49,
          1.02,
          0.775,
          0.9,
          0.545,
          0.61,
          0.545,
          0.575,
          0.49,
          0.575,
          0.41,
          0.63,
          0.56,
          0.62,
          0.31,
          0.56,
          0.4,
          0.54,
          1.07,
          0.55,
          0.695,
          0.5,
          1.33,
          1.33,
          0.59,
          0.745,
          0.5,
          1.04,
          0.745,
          0.415,
          0.745,
          0.34,
          0.39,
          0.34,
          0.67,
          0.68,
          0.49,
          0.33,
          0.52,
          0.6,
          0.6,
          0.43,
          0.43,
          0.43,
          0.68,
          0.6,
          0.95,
          0.68,
          0.53,
          0.6,
          0.59,
          0.63,
          0.64,
          0.55,
          0.63,
          0.885,
          0.42,
          0.62,
          0.5,
          0.38,
          0.52,
          0.805,
          0.61,
          0.61,
          0.61,
          0.73,
          0.61,
          0.62,
          0.31,
          0.39,
          0.5,
          0.5,
          0.37,
          0.55,
          0.55,
          0.58,
          0.3,
          1.09,
          0.32,
          0.43,
          0.3,
          0.3,
          0.44,
          0.53,
          0.725,
          0.57,
          0.735,
          0.49,
          0.625,
          0.725,
          0.49,
          0.34,
          0.53,
          0.61,
          0.645,
          0.43,
          0.59,
          0.48,
          0.38,
          0.37,
          1,
          0.63,
          0.635,
          0.38,
          0.58,
          0.21,
          0.21,
          0.66,
          0.68,
          0.66,
          0.32,
          0.6,
          0.35,
          0.775,
          0.57,
          0.34,
          0.695,
          0.41,
          0.31,
          0.33,
          0.975,
          0.52,
          0.37,
          0.56,
          0.87,
          0.35,
          0.54,
          0.18,
          0.545,
          0.545,
          0.54,
          0.18,
          0.32,
          0.4,
          0.26,
          0.27,
          0.4,
          0.59,
          0.59,
          0.45,
          0.4,
          0.52,
          0.42,
          0.52,
          0.55,
          0.36,
          0.34,
          0.5,
          0.83,
          0.63,
          0.65,
          0.53,
          0.18,
          0.705,
          0.65,
          0.62,
          0.41,
          0.43,
          0.53,
          0.46,
          0.47,
          0.36,
          0.66,
          0.77,
          0.61,
          0.49,
          0.49,
          0.53,
          0.44,
          0.27,
          0.56,
          0.65,
          0.695,
          0.43,
          0.43,
          0.28,
          0.39,
          0.39,
          0.57,
          0.49,
          0.56,
          0.795,
          0.665,
          0.53,
          0.21,
          0.75,
          0.41,
          0.42,
          0.43,
          0.38,
          0.7,
          0.45,
          0.58,
          0.46,
          0.615,
          0.615,
          0.575,
          0.27,
          0.24,
          0.28,
          0.45,
          0.27,
          0.625,
          0.26,
          0.51,
          0.46,
          0.85,
          0.415,
          0.37,
          0.37,
          0.735,
          0.59,
          0.765,
          0.735,
          0.48,
          0.6,
          0.69,
          0.44,
          0.39,
          0.46,
          0.43,
          0.735,
          0.4,
          0.52,
          0.725,
          0.48,
          0.58,
          0.38,
          0.77,
          0.84,
          0.96,
          0.24,
          0.84,
          0.67,
          0.78,
          0.52,
          0.84,
          0.24,
          0.55,
          0.39,
          0.41,
          0.39,
          0.67,
          0.45,
          0.62,
          0.31,
          0.685,
          0.57,
          0.38,
          0.48,
          0.53,
          0.39,
          0.39,
          0.56,
          0.33,
          0.23,
          0.62,
          0.59,
          0.63,
          0.58,
          0.43,
          0.615,
          0.315,
          0.5,
          0.46,
          0.36,
          0.82,
          0.32,
          0.54,
          0.37,
          0.68,
          0.27,
          0.24,
          0.685,
          0.28,
          0.3,
          0.36,
          0.67,
          0.645,
          0.39,
          0.41,
          0.4,
          0.69,
          0.39,
          0.35,
          0.52,
          0.34,
          0.35,
          0.69,
          0.52,
          0.44,
          0.44,
          0.24,
          0.49,
          0.24,
          0.67,
          0.29,
          0.59,
          0.4,
          0.51,
          0.51,
          0.655,
          0.6,
          0.61,
          0.25,
          0.4,
          0.43,
          0.38,
          0.63,
          0.22,
          0.38,
          0.38,
          0.27,
          0.48,
          0.22,
          0.63,
          0.825,
          0.35,
          0.5,
          0.59,
          0.46,
          0.715,
          0.66,
          0.31,
          0.47,
          0.55,
          0.31,
          0.35,
          0.51,
          0.43,
          0.46,
          1.04,
          0.645,
          0.53,
          0.645,
          0.47,
          0.6,
          0.54,
          0.29,
          0.47,
          0.6,
          0.7,
          0.5,
          0.36,
          0.35,
          0.24,
          0.5,
          0.44,
          0.47,
          0.31,
          0.5,
          0.5,
          0.28,
          0.73,
          0.42,
          0.45,
          0.39,
          0.45,
          0.49,
          0.595,
          0.4,
          0.585,
          0.835,
          0.58,
          0.48,
          0.65,
          0.36,
          0.24,
          0.38,
          0.64,
          0.6,
          0.31,
          0.37,
          0.54,
          0.56,
          0.58,
          0.69,
          0.6,
          0.6,
          0.54,
          0.685,
          0.54,
          0.28,
          0.41,
          0.935,
          0.35,
          0.84,
          0.88,
          0.885,
          0.29,
          0.54,
          0.54,
          0.54,
          0.845,
          0.48,
          0.42,
          0.43,
          0.36,
          0.33,
          0.47,
          0.55,
          0.43,
          0.5,
          0.52,
          0.52,
          0.42,
          0.57,
          0.59,
          0.49,
          0.34,
          0.34,
          0.73,
          0.73,
          0.4,
          0.8,
          0.78,
          0.26,
          0.45,
          0.46,
          0.78,
          0.98,
          0.78,
          0.66,
          0.38,
          0.92,
          0.49,
          0.48,
          0.47,
          0.47,
          0.65,
          0.615,
          0.38,
          1.02,
          0.65,
          0.64,
          0.38,
          0.765,
          1.035,
          0.78,
          0.49,
          0.545,
          1.025,
          0.565,
          0.74,
          0.46,
          0.56,
          0.66,
          0.56,
          0.48,
          0.31,
          0.66,
          0.72,
          0.57,
          0.57,
          0.865,
          0.55,
          0.875,
          0.835,
          0.45,
          0.56,
          0.965,
          0.59,
          0.69,
          0.76,
          0.53,
          0.39,
          0.51,
          0.34,
          0.5,
          0.51,
          0.65,
          0.54,
          0.65,
          0.48,
          0.91,
          0.98,
          0.87,
          0.87,
          0.42,
          0.58,
          0.655,
          0.7,
          0.68,
          0.67,
          0.59,
          0.59,
          0.72,
          0.59,
          0.685,
          0.57,
          0.4,
          1,
          0.635,
          0.43,
          0.52,
          0.57,
          0.46,
          0.59,
          0.35,
          0.56,
          0.56,
          0.63,
          0.37,
          0.64,
          0.61,
          0.6,
          0.27,
          0.89,
          0.46,
          0.37,
          0.5,
          0.55,
          0.585,
          0.56,
          0.52,
          0.25,
          0.53,
          0.48,
          0.49,
          0.5,
          0.39,
          0.41,
          0.66,
          0.685,
          0.42,
          0.54,
          0.48,
          0.27,
          0.46,
          0.685,
          0.61,
          0.47,
          0.28,
          0.28,
          0.31,
          0.66,
          0.5,
          0.685,
          0.64,
          0.68,
          0.64,
          0.43,
          0.43,
          0.36,
          0.36,
          0.36,
          0.26,
          0.28,
          0.62,
          0.42,
          0.62,
          0.635,
          0.56,
          0.35,
          0.31,
          0.715,
          0.715,
          0.31,
          0.61,
          0.75,
          0.8,
          0.57,
          0.9,
          0.66,
          0.45,
          0.66,
          0.63,
          0.59,
          0.31,
          0.59,
          0.31,
          0.31,
          0.635,
          0.635,
          0.59,
          0.54,
          0.56,
          0.52,
          0.38,
          0.28,
          0.46,
          0.315,
          0.715,
          0.41,
          0.36,
          0.62,
          0.41,
          0.62,
          0.47,
          0.22,
          0.24,
          0.67,
          0.47,
          0.33,
          0.61,
          0.4,
          0.61,
          0.3,
          0.46,
          0.27,
          0.43,
          0.3,
          0.44,
          0.28,
          0.12,
          0.12,
          0.28,
          0.31,
          0.34,
          0.21,
          0.36,
          0.57,
          0.47,
          0.56,
          0.57,
          0.47,
          0.66,
          0.4,
          0.26,
          0.33,
          0.41,
          0.59,
          0.4,
          0.5,
          0.86,
          0.52,
          0.5,
          0.58,
          0.36,
          0.39,
          0.295,
          0.39,
          0.34,
          0.34,
          0.6,
          0.84,
          0.69,
          0.43,
          0.43,
          0.36,
          0.29,
          0.3,
          0.35,
          0.28,
          0.32,
          1.005,
          0.71,
          0.58,
          0.38,
          0.18,
          0.5,
          0.36,
          0.36,
          0.51,
          0.32,
          0.58,
          0.83,
          0.31,
          0.795,
          0.58,
          0.82,
          0.745,
          0.37,
          0.31,
          0.41,
          0.5,
          0.49,
          0.39,
          0.44,
          0.78,
          0.43,
          0.49,
          0.5,
          0.46,
          0.605,
          0.33,
          0.64,
          0.48,
          0.42,
          0.53,
          0.48,
          0.23,
          0.4,
          0.38,
          0.29,
          0.74,
          0.61,
          0.52,
          0.31,
          0.62,
          0.33,
          0.77,
          0.62,
          0.32,
          0.37,
          0.3,
          0.3,
          0.38,
          0.42,
          0.48,
          0.34,
          0.19,
          0.41,
          0.41,
          0.26,
          0.34,
          0.54,
          0.31,
          0.725,
          0.725,
          0.52,
          0.34,
          0.49,
          0.49,
          0.48,
          0.57,
          0.3,
          0.78,
          0.47,
          0.53,
          0.42,
          0.33,
          0.4,
          0.69,
          0.69,
          0.69,
          0.39,
          0.66,
          0.54,
          0.47,
          0.24,
          0.76,
          0.43,
          0.6,
          0.36,
          0.48,
          0.28,
          0.25,
          0.52,
          0.41,
          0.51,
          0.4,
          0.38,
          0.45,
          0.22,
          0.32,
          0.2,
          0.5,
          0.41,
          0.39,
          0.35,
          0.58,
          0.6,
          0.42,
          0.6,
          0.18,
          0.51,
          0.32,
          0.785,
          0.33,
          0.34,
          0.5,
          0.36,
          0.42,
          0.36,
          0.36,
          0.61,
          0.88,
          0.915,
          0.35,
          0.39,
          0.66,
          0.64,
          0.64,
          0.955,
          0.4,
          0.885,
          0.25,
          0.745,
          0.43,
          0.57,
          0.26,
          0.58,
          0.57,
          0.34,
          0.42,
          0.74,
          0.36,
          0.36,
          0.72,
          0.36,
          0.39,
          0.65,
          0.65,
          0.33,
          0.57,
          0.39,
          0.32,
          0.32,
          0.39,
          0.46,
          0.58,
          0.58,
          0.42,
          0.43,
          0.18,
          0.815,
          0.43,
          0.75,
          0.55,
          0.75,
          0.73,
          0.67,
          0.61,
          0.56,
          0.55,
          0.74,
          0.6,
          0.58,
          0.72,
          0.66,
          0.7,
          0.59,
          0.58,
          0.64,
          0.635,
          1.02,
          0.45,
          0.37,
          0.57,
          0.57,
          0.43,
          0.41,
          0.38,
          0.44,
          0.46,
          0.58,
          0.58,
          0.715,
          0.4,
          0.69,
          0.715,
          0.3,
          0.46,
          0.46,
          0.765,
          0.63,
          0.42,
          0.37,
          0.6,
          0.6,
          0.74,
          0.635,
          0.395,
          0.63,
          0.53,
          0.6,
          1.58,
          0.645,
          0.86,
          0.37,
          0.79,
          0.61,
          0.69,
          0.62,
          0.51,
          1.18,
          0.63,
          0.74,
          0.76,
          0.74,
          0.34,
          0.46,
          0.46,
          0.46,
          0.46,
          0.52,
          0.6,
          0.6,
          0.87,
          0.39,
          0.775,
          0.835,
          0.58,
          0.5,
          0.5,
          0.5,
          0.51,
          0.51,
          0.51,
          0.51,
          0.42,
          0.44,
          0.59,
          0.655,
          0.62,
          0.645,
          0.32,
          0.34,
          0.43,
          0.64,
          0.475,
          0.85,
          0.475,
          0.605,
          0.74,
          0.54,
          0.77,
          0.78,
          0.58,
          0.78,
          0.885,
          0.45,
          0.57,
          0.57,
          0.6,
          0.6,
          0.755,
          0.81,
          0.64,
          0.64,
          0.49,
          0.64,
          0.62,
          0.52,
          0.685,
          0.675,
          0.59,
          0.67,
          0.69,
          0.3,
          0.33,
          0.5,
          0.24,
          0.51,
          0.29,
          0.51,
          0.96,
          0.47,
          0.24,
          0.57,
          0.32,
          0.58,
          0.32,
          0.34,
          0.53,
          0.64,
          0.53,
          0.4,
          0.54,
          0.53,
          0.41,
          0.64,
          0.18,
          0.41,
          0.43,
          0.4,
          0.54,
          0.38,
          0.915,
          0.59,
          0.67,
          0.58,
          0.785,
          0.67,
          0.38,
          0.37,
          0.32,
          0.58,
          0.45,
          0.9,
          0.49,
          0.29,
          0.2,
          0.42,
          0.785,
          0.63,
          0.59,
          0.48,
          1.04,
          0.48,
          0.98,
          0.69,
          0.7,
          0.35,
          0.6,
          0.5,
          0.47,
          0.5,
          0.47,
          0.875,
          0.28,
          0.62,
          0.28,
          0.33,
          0.655,
          0.68,
          0.64,
          0.54,
          0.22,
          0.65,
          0.54,
          0.31,
          0.43,
          0.74,
          0.74,
          0.82,
          0.44,
          0.38,
          0.76,
          0.81,
          0.38,
          0.27,
          0.18,
          0.36,
          0.69,
          0.84,
          0.84,
          0.53,
          0.47,
          0.7,
          0.32,
          0.48,
          0.48,
          0.47,
          0.29,
          0.69,
          0.44,
          0.705,
          0.53,
          0.39,
          0.56,
          0.55,
          0.64,
          0.52,
          0.37,
          0.63,
          0.57,
          0.4,
          0.36,
          0.67,
          0.68,
          0.735,
          0.56,
          0.88,
          0.855,
          0.63,
          0.6,
          0.6,
          0.6,
          0.695,
          0.695,
          0.67,
          0.16,
          0.695,
          0.56,
          0.51,
          0.36,
          0.38,
          0.69,
          0.58,
          0.52,
          0.3,
          0.7,
          0.67,
          0.35,
          0.715,
          0.46,
          0.32,
          0.31,
          0.61,
          0.55,
          0.74,
          0.51,
          0.62,
          0.6,
          0.55,
          0.645
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of volatile acidity in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "volatile acidity"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "citric acid=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0,
          0,
          0.04,
          0.56,
          0,
          0,
          0.06,
          0,
          0.02,
          0.08,
          0,
          0.29,
          0.56,
          0.51,
          0.31,
          0.21,
          0.11,
          0.14,
          0.16,
          0.24,
          0,
          0,
          0.07,
          0.12,
          0.25,
          0,
          0.14,
          0.28,
          0.36,
          0.3,
          0.2,
          0.22,
          0.15,
          0.43,
          0.26,
          0.04,
          0.04,
          0.36,
          0.15,
          0.57,
          0.18,
          0.31,
          0.4,
          0.49,
          0.05,
          0.05,
          0.05,
          0.07,
          0.05,
          0.22,
          0.26,
          0.64,
          0,
          0.12,
          0.2,
          0.2,
          0.47,
          0.48,
          0.15,
          0.28,
          0.26,
          0.44,
          0.08,
          0.26,
          0.28,
          0.26,
          0.04,
          0,
          0.06,
          0.18,
          0.3,
          0.18,
          0.22,
          0.24,
          0.22,
          0.68,
          0.31,
          0.19,
          0.09,
          0.44,
          0.19,
          0.31,
          0.28,
          0.09,
          0.04,
          0,
          0.17,
          0,
          0,
          0.16,
          0.56,
          0.09,
          0.05,
          0.11,
          0.36,
          0.11,
          0,
          0.08,
          0,
          0.55,
          0.02,
          0.1,
          0.47,
          1,
          0.03,
          0.03,
          0.42,
          0.42,
          0.42,
          0,
          0.18,
          0.03,
          0.02,
          0.04,
          0.26,
          0.26,
          0.48,
          0.1,
          0.03,
          0.07,
          0.03,
          0.17,
          0.05,
          0.04,
          0.21,
          0.42,
          0,
          0.14,
          0.14,
          0.49,
          0.02,
          0.2,
          0.21,
          0.57,
          0.48,
          0.33,
          0.35,
          0.25,
          0.21,
          0.21,
          0.3,
          0.6,
          0.06,
          0.47,
          0.36,
          0.74,
          0.74,
          0.28,
          0.6,
          0.24,
          0.26,
          0.08,
          0.49,
          0.16,
          0.22,
          0.19,
          0.37,
          0.26,
          0.04,
          0.25,
          0.25,
          0.5,
          0.04,
          0.06,
          0.2,
          0.09,
          0,
          0.37,
          0.56,
          0.1,
          0.44,
          0.44,
          0,
          0.07,
          0,
          0.44,
          0,
          0.48,
          0.42,
          0.23,
          0.37,
          0,
          0.76,
          0.47,
          0.23,
          0.04,
          0.03,
          0.23,
          0.49,
          0,
          0.46,
          0.04,
          0.51,
          0.06,
          0.06,
          0.04,
          0.51,
          0.45,
          0.32,
          0.44,
          0.68,
          0.32,
          0.07,
          0.07,
          0.55,
          0.12,
          0.09,
          0.53,
          0.09,
          0.23,
          0.25,
          0.52,
          0.46,
          0.37,
          0.06,
          0.02,
          0.06,
          0.48,
          0.12,
          0.6,
          0.32,
          0.42,
          0.44,
          0.24,
          0.31,
          0.3,
          0.29,
          0.39,
          0.12,
          0.26,
          0.2,
          0.2,
          0.66,
          0.5,
          0.62,
          0.08,
          0.01,
          0.53,
          0.45,
          0.32,
          0.54,
          0.47,
          0.47,
          0.5,
          0.67,
          0.31,
          0,
          0,
          0.79,
          0.4,
          0.01,
          0.52,
          0.66,
          0.66,
          0.66,
          0.23,
          0.31,
          0.66,
          0.63,
          0.66,
          0.66,
          0.61,
          0.53,
          0.4,
          0.48,
          0.5,
          0.53,
          0.66,
          0.42,
          0.28,
          0.26,
          0.05,
          0.68,
          0.52,
          0.76,
          0.02,
          0.59,
          0.22,
          0.02,
          0.54,
          0.49,
          0.05,
          0.47,
          0.66,
          0.49,
          0.34,
          0.16,
          0.53,
          0.34,
          0.24,
          0.64,
          0.12,
          0.51,
          0,
          0.03,
          0.2,
          0.47,
          0.03,
          0.08,
          0.22,
          0.33,
          0.63,
          0.47,
          0.35,
          0.63,
          0.55,
          0.63,
          0.3,
          0.73,
          0.18,
          0.72,
          0.76,
          0.01,
          0.6,
          0.29,
          0.22,
          0.69,
          0.69,
          0.03,
          0.63,
          0.4,
          0.67,
          0.39,
          0.21,
          0.66,
          0.52,
          0.22,
          0.54,
          0.42,
          0.45,
          0.69,
          0.02,
          0.65,
          0.42,
          0.55,
          0.24,
          0.41,
          0.49,
          0.11,
          0.39,
          0.56,
          0.6,
          0.39,
          0.36,
          0.4,
          0.5,
          0.51,
          0.31,
          0.23,
          0.53,
          0.25,
          0.32,
          0.53,
          0.31,
          0.25,
          0.73,
          0.73,
          0.42,
          0.63,
          0.46,
          0.55,
          0.75,
          0.31,
          0.48,
          0.64,
          0.64,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.24,
          0.24,
          0.49,
          0.49,
          0.24,
          0.24,
          0.24,
          0.24,
          0.24,
          0.49,
          0.74,
          0.24,
          0.49,
          0.24,
          0.24,
          0.74,
          0.49,
          0.24,
          0.49,
          0.49,
          0.01,
          0.24,
          0.24,
          0.24,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.24,
          0.49,
          0.24,
          0.49,
          0.49,
          0.24,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.49,
          0.24,
          0.24,
          0.49,
          0.49,
          0.49,
          0.58,
          0.41,
          0.51,
          0.18,
          0,
          0.13,
          0.41,
          0.37,
          0.19,
          0.54,
          0.55,
          0,
          0.5,
          0.51,
          0.41,
          0.24,
          0.23,
          0.22,
          0,
          0.29,
          0.29,
          0.26,
          0.23,
          0.26,
          0.54,
          0.14,
          0.22,
          0.21,
          0,
          0.28,
          0.27,
          0.35,
          0.45,
          0.45,
          0.45,
          0.01,
          0.3,
          0.27,
          0.39,
          0.65,
          0.59,
          0.47,
          0.17,
          0.39,
          0.59,
          0.07,
          0.07,
          0.31,
          0.06,
          0.14,
          0.36,
          0.45,
          0.45,
          0.21,
          0.21,
          0.41,
          0.11,
          0.1,
          0.45,
          0.23,
          0.31,
          0.23,
          0.32,
          0.23,
          0.04,
          0.48,
          0.24,
          0.51,
          0.32,
          0.31,
          0.02,
          0.02,
          0.28,
          0.55,
          0.43,
          0.02,
          0.02,
          0.48,
          0.04,
          0.15,
          0.08,
          0.19,
          0.12,
          0.43,
          0.34,
          0.28,
          0.11,
          0.04,
          0,
          0.04,
          0.24,
          0.3,
          0.17,
          0.09,
          0.02,
          0.02,
          0.03,
          0.66,
          0.13,
          0.03,
          0.34,
          0.2,
          0.1,
          0,
          0,
          0.29,
          0.24,
          0.54,
          0.18,
          0.38,
          0.18,
          0.18,
          0.1,
          0.13,
          0.1,
          0.68,
          0.07,
          0.01,
          0,
          0,
          0.21,
          0.25,
          0.26,
          0,
          0.11,
          0.1,
          0.18,
          0.02,
          0.01,
          0.02,
          0.26,
          0.27,
          0.29,
          0,
          0.17,
          0.3,
          0.03,
          0,
          0.14,
          0.01,
          0.41,
          0.24,
          0.24,
          0.17,
          0.43,
          0.17,
          0.02,
          0,
          0.54,
          0.3,
          0.31,
          0.44,
          0.34,
          0.09,
          0,
          0.08,
          0.22,
          0.39,
          0.12,
          0.31,
          0.1,
          0.55,
          0.24,
          0.54,
          0.15,
          0,
          0,
          0.13,
          0.28,
          0.34,
          0.14,
          0.07,
          0.08,
          0.44,
          0.28,
          0.28,
          0.35,
          0,
          0.45,
          0.35,
          0.21,
          0.16,
          0.21,
          0.44,
          0.44,
          0.39,
          0.39,
          0.39,
          0.34,
          0.47,
          0.06,
          0.32,
          0.06,
          0.07,
          0.03,
          0.24,
          0.4,
          0.01,
          0,
          0.29,
          0.19,
          0.14,
          0.12,
          0,
          0.34,
          0.03,
          0.23,
          0.03,
          0.03,
          0.01,
          0.39,
          0.01,
          0.39,
          0.36,
          0.1,
          0.1,
          0.06,
          0.27,
          0,
          0.13,
          0.48,
          0.46,
          0.44,
          0.4,
          0.19,
          0.31,
          0.32,
          0.12,
          0.37,
          0.12,
          0.27,
          0.36,
          0.33,
          0.19,
          0.27,
          0.38,
          0.01,
          0.29,
          0.01,
          0.38,
          0.17,
          0.49,
          0.4,
          0.49,
          0.58,
          0.48,
          0.45,
          0.45,
          0.48,
          0.4,
          0.48,
          0.52,
          0.52,
          0.12,
          0.27,
          0.14,
          0.02,
          0.27,
          0.2,
          0.43,
          0.48,
          0.41,
          0.3,
          0.29,
          0.32,
          0.3,
          0.26,
          0.32,
          0.3,
          0,
          0.3,
          0.12,
          0.4,
          0.12,
          0.28,
          0.28,
          0.06,
          0.34,
          0,
          0.3,
          0.29,
          0.32,
          0.33,
          0.34,
          0.4,
          0.45,
          0.31,
          0.15,
          0,
          0.16,
          0.4,
          0.37,
          0.14,
          0.66,
          0.66,
          0.09,
          0.42,
          0.01,
          0,
          0.32,
          0,
          0.01,
          0,
          0.18,
          0.34,
          0.34,
          0.41,
          0.21,
          0.19,
          0.33,
          0,
          0,
          0.17,
          0.36,
          0.36,
          0.59,
          0.05,
          0.42,
          0.27,
          0.53,
          0.25,
          0.57,
          0.53,
          0.57,
          0.5,
          0.44,
          0.65,
          0.09,
          0.18,
          0.08,
          0.53,
          0.35,
          0.45,
          0.2,
          0.33,
          0.56,
          0.65,
          0.68,
          0.68,
          0.3,
          0.45,
          0.08,
          0.4,
          0.42,
          0.54,
          0.54,
          0.54,
          0.42,
          0.09,
          0.36,
          0.09,
          0.09,
          0.38,
          0.42,
          0.27,
          0.27,
          0.34,
          0.28,
          0.41,
          0.1,
          0.43,
          0,
          0.27,
          0.41,
          0.5,
          0.07,
          0.07,
          0.07,
          0.12,
          0,
          0.34,
          0,
          0.35,
          0,
          0.33,
          0,
          0.34,
          0.07,
          0.35,
          0.43,
          0.45,
          0.15,
          0.24,
          0.3,
          0.32,
          0.11,
          0.3,
          0.23,
          0.43,
          0.12,
          0.45,
          0.42,
          0.47,
          0.23,
          0.25,
          0.35,
          0.25,
          0.51,
          0.18,
          0.42,
          0.24,
          0.39,
          0.27,
          0.29,
          0.34,
          0.46,
          0.31,
          0.31,
          0,
          0.03,
          0,
          0.33,
          0.43,
          0.07,
          0.23,
          0.23,
          0.05,
          0.57,
          0,
          0.37,
          0.12,
          0.22,
          0.21,
          0.26,
          0.23,
          0.21,
          0.36,
          0.39,
          0.19,
          0.46,
          0.46,
          0.55,
          0.46,
          0.43,
          0.02,
          0.02,
          0.46,
          0.31,
          0.4,
          0.52,
          0.52,
          0.49,
          0.23,
          0.03,
          0.25,
          0,
          0.29,
          0.34,
          0.01,
          0.29,
          0.01,
          0,
          0.01,
          0,
          0,
          0.2,
          0.22,
          0.19,
          0.07,
          0.01,
          0.14,
          0,
          0,
          0.06,
          0.22,
          0.28,
          0,
          0.68,
          0,
          0.38,
          0.32,
          0.05,
          0.05,
          0.5,
          0.31,
          0.01,
          0.2,
          0,
          0.2,
          0.13,
          0.22,
          0.4,
          0,
          0.22,
          0.39,
          0.2,
          0.2,
          0,
          0.28,
          0.19,
          0.5,
          0.3,
          0.3,
          0,
          0.1,
          0.13,
          0,
          0.14,
          0,
          0,
          0,
          0.07,
          0.32,
          0.21,
          0.26,
          0.32,
          0.1,
          0.15,
          0.21,
          0.27,
          0,
          0.68,
          0,
          0.42,
          0.24,
          0.24,
          0.24,
          0.24,
          0.11,
          0.26,
          0.26,
          0.26,
          0.1,
          0.22,
          0,
          0.02,
          0,
          0,
          0,
          0.02,
          0.02,
          0.02,
          0.02,
          0.48,
          0.24,
          0.01,
          0.03,
          0.01,
          0.03,
          0.25,
          0.25,
          0.24,
          0.17,
          0.4,
          0.14,
          0.4,
          0.02,
          0.08,
          0.3,
          0.32,
          0.51,
          0.56,
          0.51,
          0.2,
          0.15,
          0.02,
          0.02,
          0.22,
          0.22,
          0.15,
          0.25,
          0.07,
          0.31,
          0,
          0.22,
          0.06,
          0.25,
          0.1,
          0.1,
          0.26,
          0,
          0.21,
          0.42,
          0.33,
          0.39,
          0.34,
          0,
          0.36,
          0,
          0,
          0.4,
          0.34,
          0.25,
          0.59,
          0,
          0.59,
          0.33,
          0.01,
          0.21,
          0.01,
          0.18,
          0,
          0.09,
          0.33,
          0,
          0.4,
          0.24,
          0.31,
          0.16,
          0.37,
          0.38,
          0.29,
          0,
          0.02,
          0.2,
          0.19,
          0,
          0.31,
          0.32,
          0.44,
          0.02,
          0.63,
          0,
          0.33,
          0.4,
          0.35,
          0.09,
          0,
          0.01,
          0.1,
          0.32,
          0.08,
          0.32,
          0.05,
          0.11,
          0.08,
          0.6,
          0.08,
          0.5,
          0.11,
          0.5,
          0.11,
          0.05,
          0.6,
          0.03,
          0.6,
          0.44,
          0.16,
          0.21,
          0.05,
          0.04,
          0.49,
          0.06,
          0.26,
          0.09,
          0.02,
          0.03,
          0.03,
          0.29,
          0.39,
          0.57,
          0.02,
          0.05,
          0.57,
          0.6,
          0.4,
          0.21,
          0.04,
          0.21,
          0.21,
          0.06,
          0.46,
          0.08,
          0.25,
          0.25,
          0.08,
          0.08,
          0.49,
          0.08,
          0.09,
          0.1,
          0.13,
          0.3,
          0.14,
          0.13,
          0.09,
          0.08,
          0.43,
          0.33,
          0.02,
          0.5,
          0.3,
          0,
          0.01,
          0,
          0.17,
          0.04,
          0.02,
          0.33,
          0.26,
          0.26,
          0.26,
          0.13,
          0.13,
          0.02,
          0.64,
          0.13,
          0.13,
          0.14,
          0.53,
          0.14,
          0.32,
          0.2,
          0.4,
          0.63,
          0.15,
          0.15,
          0.33,
          0.1,
          0.29,
          0.44,
          0.41,
          0.11,
          0.15,
          0.09,
          0.13,
          0.08,
          0.08,
          0.1,
          0.12
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of citric acid in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "citric acid"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "residual sugar=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          1.9,
          2.6,
          2.3,
          1.9,
          1.9,
          1.8,
          1.6,
          1.2,
          2,
          1.8,
          1.6,
          1.6,
          1.8,
          1.8,
          2.3,
          1.6,
          2.3,
          2.4,
          1.4,
          1.8,
          1.9,
          2,
          2.4,
          2.3,
          1.8,
          5.5,
          2.4,
          2.1,
          5.9,
          2.8,
          2.6,
          2.2,
          2.1,
          2.2,
          1.7,
          2.2,
          2.1,
          3,
          2.8,
          3.4,
          2.3,
          2.4,
          2.2,
          1.8,
          2,
          4.65,
          4.65,
          1.6,
          1.9,
          1.9,
          2.1,
          2.2,
          2.4,
          2,
          1.5,
          1.6,
          2,
          1.8,
          2.2,
          1.9,
          1.9,
          2.1,
          1.8,
          1.9,
          1.9,
          1.9,
          1.4,
          3,
          2.5,
          1.9,
          2.1,
          1.9,
          2.1,
          2.2,
          2.1,
          1.7,
          1.7,
          1.8,
          2.2,
          2.3,
          1.8,
          2.2,
          1.9,
          1.7,
          2.2,
          2.5,
          1.6,
          1.7,
          1.8,
          1.8,
          2,
          2.3,
          2.2,
          1.9,
          2,
          1.9,
          1.8,
          1.7,
          1.8,
          1.8,
          1.8,
          2.3,
          2.1,
          3.4,
          1.8,
          1.8,
          5.5,
          5.5,
          5.5,
          2.2,
          1.9,
          2,
          1.3,
          1.7,
          7.3,
          7.2,
          1.7,
          2.1,
          1.6,
          2.1,
          1.8,
          2,
          1.9,
          1.5,
          2,
          2.3,
          2.5,
          2.4,
          2.4,
          2,
          2.5,
          1.8,
          1.9,
          2,
          2,
          2,
          2.9,
          1.9,
          2.2,
          2.2,
          2.4,
          2,
          2.1,
          1.4,
          1.6,
          2.6,
          2.6,
          2.7,
          2,
          2.8,
          2.2,
          2.4,
          5.6,
          2,
          2.2,
          1.9,
          2,
          2,
          1.5,
          2,
          2.6,
          2,
          1.6,
          1.8,
          2.8,
          2.3,
          1.9,
          1.7,
          2.1,
          1.8,
          2.2,
          2.2,
          2,
          1.9,
          2,
          1.6,
          1.8,
          3.1,
          1.9,
          3.2,
          2.2,
          2.1,
          1.8,
          2.6,
          1.7,
          2,
          1.7,
          1.8,
          2.4,
          3.3,
          3.6,
          3,
          4,
          4,
          4,
          3,
          4,
          6.4,
          5.6,
          3.6,
          3.5,
          5.6,
          3.4,
          3.4,
          2,
          3,
          2.5,
          3.3,
          2.5,
          2.7,
          2.4,
          3.2,
          2.5,
          2.6,
          2,
          2.3,
          2.6,
          1.5,
          2.6,
          2.1,
          2.2,
          2.4,
          2.4,
          2,
          2.8,
          3,
          2.6,
          3.2,
          2.9,
          3.4,
          11,
          11,
          3.65,
          4.5,
          2.6,
          2.1,
          2.5,
          3.4,
          1.9,
          2.8,
          2.3,
          1.8,
          1.8,
          2.6,
          3,
          2.8,
          2.6,
          2.4,
          4.8,
          1.4,
          2.4,
          3,
          2.95,
          3.1,
          2.6,
          2,
          2.6,
          2.5,
          2,
          5.8,
          5.8,
          2.6,
          2.4,
          1.6,
          1.8,
          3,
          2.4,
          6.2,
          2,
          2.1,
          1.9,
          1.4,
          2.9,
          2,
          4.2,
          7.9,
          2.6,
          2.3,
          7.9,
          2.6,
          2.7,
          2.7,
          2.5,
          3,
          4.5,
          2.5,
          1.9,
          6.7,
          2.7,
          6.6,
          2.2,
          1.9,
          2,
          1.8,
          2.3,
          2,
          2.1,
          2.3,
          2.1,
          1.9,
          1.3,
          2.4,
          2.1,
          2.2,
          2.3,
          3.2,
          2.3,
          2,
          3.2,
          1.5,
          2.2,
          3.7,
          1.7,
          2.6,
          2.1,
          2,
          2.8,
          2.8,
          1.7,
          2.8,
          1.6,
          5.2,
          2.3,
          2.7,
          2.2,
          2.3,
          2.6,
          2.1,
          2,
          2.6,
          2.1,
          1.2,
          2.6,
          2.4,
          2.6,
          2.2,
          2,
          1.8,
          2.7,
          15.5,
          2.8,
          2.2,
          1.9,
          1.8,
          2.6,
          2.5,
          2.6,
          3,
          8.3,
          2.6,
          1.9,
          2.5,
          2.6,
          3,
          1.9,
          6.55,
          6.55,
          1.8,
          2.9,
          1.8,
          2.3,
          2.8,
          2.2,
          2.1,
          2.4,
          2.4,
          6.1,
          4.3,
          2.1,
          2.7,
          2.5,
          2.4,
          2.5,
          2.4,
          2.1,
          2.7,
          2.7,
          2.1,
          2.7,
          2.1,
          2.4,
          2.1,
          5.8,
          5.15,
          3.3,
          6.3,
          2.1,
          2.5,
          1.8,
          2.6,
          2,
          2.5,
          2.6,
          2.1,
          2.8,
          2.7,
          1.6,
          4.2,
          4.6,
          4.2,
          4.3,
          2.8,
          2.9,
          2.7,
          4.3,
          2.8,
          2.5,
          2.6,
          2.2,
          3.3,
          2.4,
          2.3,
          2.8,
          2.9,
          2.2,
          2.2,
          2.2,
          1.9,
          1.9,
          2,
          2.6,
          1.7,
          2.6,
          3.5,
          7.9,
          2,
          2.1,
          2.6,
          2.9,
          3.3,
          5.1,
          3.2,
          2.5,
          2.7,
          2.4,
          2.3,
          2.2,
          2.3,
          3.4,
          3.4,
          1.9,
          5.6,
          2.2,
          2.2,
          2.5,
          2.3,
          2.5,
          2.7,
          3,
          3.4,
          1.9,
          1.4,
          2.4,
          2.3,
          1.9,
          2.3,
          2.3,
          2.3,
          2.2,
          2.8,
          8.6,
          2.2,
          7.5,
          2.8,
          2.4,
          2.9,
          2.2,
          1.4,
          1.4,
          1.4,
          1.6,
          1.6,
          2,
          1.8,
          2,
          2,
          1.7,
          1.7,
          2.2,
          2.3,
          2.6,
          3.3,
          2.2,
          2.25,
          2.6,
          2.3,
          2.6,
          1.6,
          1.8,
          2.6,
          2,
          2.8,
          2.7,
          1.3,
          2.1,
          3.2,
          2.1,
          2.9,
          2.1,
          2.1,
          2.6,
          1.6,
          6,
          2,
          3,
          2.5,
          2.8,
          3,
          2.6,
          2.6,
          2,
          3.9,
          2,
          2.85,
          2.2,
          3,
          2.8,
          1.8,
          1.8,
          3.2,
          2.3,
          3.45,
          2.1,
          2.7,
          2,
          2.1,
          2.5,
          2.4,
          4.2,
          2.6,
          2.7,
          2.1,
          2.5,
          2.1,
          2.1,
          2.9,
          2.5,
          2.9,
          1.7,
          1.9,
          2,
          2.2,
          2.2,
          2.5,
          2.8,
          2,
          1.7,
          2.8,
          3,
          2.9,
          2.3,
          1.9,
          2.3,
          2.4,
          2.3,
          1.8,
          3,
          2.4,
          3.4,
          2.6,
          2,
          2.4,
          2.5,
          2.3,
          2.2,
          2.2,
          2.9,
          2.6,
          2.9,
          2.5,
          2.6,
          2.3,
          2.6,
          2.5,
          1.6,
          3.6,
          3.3,
          1.7,
          2.5,
          2.7,
          2,
          1.9,
          2.8,
          2.6,
          2.8,
          2.1,
          2.8,
          3.2,
          1.9,
          2.1,
          2,
          2.8,
          2.3,
          2.8,
          2.5,
          2.1,
          1.6,
          2.4,
          2.4,
          1.6,
          3,
          2.6,
          2,
          1.8,
          1.8,
          1.8,
          1.9,
          1.9,
          1.5,
          1.5,
          1.5,
          2.5,
          1.7,
          2.7,
          2.7,
          2.5,
          2.6,
          1.5,
          2,
          2.8,
          2.1,
          2.1,
          3.1,
          4,
          2.5,
          2.4,
          2.5,
          6.6,
          2.3,
          1.9,
          2.3,
          2.2,
          2.3,
          2.4,
          2.3,
          2.4,
          2.6,
          2.4,
          2.4,
          6,
          2.6,
          2.2,
          2.4,
          3.8,
          9,
          2.9,
          2.2,
          1.5,
          8.8,
          2.2,
          1.8,
          2.3,
          1.8,
          2.3,
          1.9,
          2.3,
          2.2,
          2.3,
          3.3,
          2,
          1.9,
          1.9,
          2.3,
          1.6,
          5,
          2.6,
          3.8,
          4.1,
          2.1,
          1.8,
          1.8,
          2.1,
          2.2,
          2.1,
          1.9,
          2.1,
          2.3,
          1.9,
          1.6,
          2.1,
          1.9,
          2.1,
          2.4,
          1.9,
          5.9,
          2.1,
          2.6,
          3.6,
          1.9,
          1.9,
          2.1,
          1.9,
          2,
          1.6,
          1.7,
          1.5,
          1.7,
          2,
          2,
          2,
          1.4,
          1.65,
          2.2,
          1.6,
          1.8,
          2.05,
          2,
          3.6,
          1.7,
          2,
          2.1,
          1.6,
          2,
          2.2,
          0.9,
          1.8,
          2.4,
          2.4,
          2.1,
          2.3,
          1.8,
          2.8,
          1.9,
          2.2,
          1.8,
          4.1,
          2.5,
          2.4,
          2.5,
          6.2,
          2.2,
          1.7,
          3.3,
          1.4,
          1.7,
          1.8,
          1.7,
          1.8,
          1.4,
          2.4,
          2.3,
          2,
          4,
          3.9,
          2.4,
          4,
          1.8,
          1.8,
          1.9,
          2.4,
          2,
          2.4,
          2.4,
          2.2,
          2.8,
          1.5,
          8.1,
          2.7,
          2,
          6.4,
          8.3,
          8.3,
          1.8,
          2.4,
          1.8,
          4.7,
          1.6,
          1.5,
          1.5,
          1.9,
          2,
          2,
          2.2,
          5.5,
          5.5,
          1.5,
          2.1,
          2.1,
          2.1,
          2.2,
          2.1,
          2,
          3.3,
          2.1,
          1.4,
          2,
          1.5,
          4.3,
          2.5,
          2.5,
          2.5,
          2.1,
          2.5,
          2.5,
          1.4,
          1.7,
          2.9,
          2.7,
          1.9,
          1.8,
          5.5,
          1.7,
          1.7,
          2,
          3.7,
          2,
          1.7,
          2.5,
          2.4,
          1.8,
          2.3,
          2.5,
          1.8,
          6.2,
          2,
          2,
          2.5,
          2.2,
          2.1,
          2.2,
          1.75,
          2.1,
          2.3,
          1.7,
          2.5,
          2.8,
          2.3,
          1.6,
          2.1,
          1.7,
          1.7,
          2.2,
          5.6,
          2.1,
          2.4,
          1.65,
          1.6,
          2.1,
          2.1,
          1.8,
          4.6,
          2.3,
          2.5,
          1.8,
          1.8,
          1.5,
          2,
          2.3,
          1.5,
          1.9,
          1.8,
          5.8,
          2.1,
          2.1,
          1.7,
          2.1,
          2,
          2.1,
          2.1,
          1.9,
          2,
          1.3,
          1.8,
          1.8,
          2.5,
          2.6,
          4.1,
          2,
          1.8,
          2.1,
          2.7,
          2.6,
          2.1,
          2.2,
          1.7,
          2.2,
          2.5,
          4.3,
          1.7,
          2.4,
          1.8,
          1.7,
          2.3,
          2.2,
          1.8,
          1.4,
          1.9,
          1.8,
          4.8,
          2.7,
          1.8,
          2,
          2.5,
          1.8,
          2.3,
          2.3,
          2.3,
          2,
          1.6,
          1.6,
          1.9,
          2,
          2.1,
          2.3,
          6.3,
          1.9,
          2.3,
          1.7,
          1.9,
          1.9,
          2,
          2.7,
          2.3,
          1.8,
          4.5,
          4.5,
          1.9,
          2.1,
          2.4,
          4.3,
          2.1,
          1.4,
          2.1,
          2.15,
          2,
          2.1,
          2.3,
          1.9,
          2.5,
          1.4,
          3,
          1.9,
          2,
          1.2,
          1.7,
          1.2,
          1.8,
          1.7,
          1.7,
          1.7,
          1.7,
          1.8,
          2.1,
          2.1,
          3.8,
          1.7,
          2.2,
          2,
          2.4,
          1.4,
          1.4,
          1.4,
          1.7,
          1.7,
          1.7,
          1.7,
          2.6,
          2.3,
          2.1,
          1.8,
          2.3,
          1.9,
          1.8,
          1.8,
          2.5,
          5.4,
          1.4,
          2.5,
          1.4,
          1.9,
          1.7,
          2.2,
          2.1,
          1.7,
          3.1,
          1.7,
          1.4,
          2,
          2.6,
          2.6,
          2.1,
          2.1,
          1.8,
          3.4,
          1.8,
          6.1,
          2.3,
          2.4,
          1.3,
          2,
          1.6,
          1.6,
          2,
          2.2,
          2.1,
          2,
          1.7,
          2.6,
          5.1,
          2.1,
          2.2,
          2.1,
          1.8,
          2.4,
          5.1,
          2,
          2.2,
          1.6,
          2.2,
          2.5,
          1.6,
          2.2,
          1.6,
          1.6,
          2.1,
          3.9,
          2.5,
          1.9,
          2.2,
          1.8,
          2.1,
          1.8,
          15.4,
          1.6,
          4.8,
          1.7,
          2.2,
          1.75,
          5.2,
          1.9,
          2,
          2,
          2.7,
          2,
          2.2,
          1.6,
          1.9,
          1.7,
          1.7,
          2.3,
          2.1,
          2.4,
          1.7,
          2.1,
          2.3,
          2.1,
          2.1,
          1.4,
          3.75,
          2.6,
          1.8,
          13.8,
          2.2,
          13.8,
          2.2,
          5.7,
          3,
          1.5,
          3,
          1.5,
          2.1,
          2.1,
          1.9,
          1.7,
          1.8,
          1.6,
          1.9,
          1.4,
          1.9,
          2.3,
          2.3,
          4.3,
          2.5,
          2.3,
          1.8,
          2,
          2.3,
          2.1,
          1.8,
          2.2,
          2.1,
          4.1,
          4.1,
          2,
          2.2,
          2.6,
          2.3,
          2,
          2.1,
          2.2,
          2.2,
          2.1,
          2.2,
          2.8,
          2,
          1.9,
          2.4,
          2.2,
          2.5,
          4.4,
          2.3,
          1.8,
          2,
          2,
          1.8,
          2.3,
          3.7,
          2.2,
          1.7,
          2.2,
          2.4,
          6.7,
          2,
          2,
          2,
          2,
          2,
          1.9,
          2.1,
          2,
          1.6,
          1.9,
          2.2,
          2.2,
          2.2,
          2.4,
          2.2,
          1.6,
          5.1,
          1.8,
          2.4,
          2.6,
          2.1,
          2.4,
          2.4,
          1.8,
          1.8,
          1.7,
          2.3,
          1.9,
          2,
          2.2,
          2
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of residual sugar in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "residual sugar"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "chlorides=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0.076,
          0.098,
          0.092,
          0.075,
          0.076,
          0.075,
          0.069,
          0.065,
          0.073,
          0.0969999999999999,
          0.089,
          0.114,
          0.092,
          0.341,
          0.0819999999999999,
          0.106,
          0.084,
          0.085,
          0.08,
          0.08,
          0.08,
          0.0819999999999999,
          0.089,
          0.083,
          0.103,
          0.086,
          0.086,
          0.066,
          0.074,
          0.088,
          0.332,
          0.069,
          0.054,
          0.114,
          0.074,
          0.069,
          0.068,
          0.081,
          0.11,
          0.07,
          0.076,
          0.074,
          0.079,
          0.115,
          0.081,
          0.086,
          0.086,
          0.076,
          0.074,
          0.084,
          0.084,
          0.093,
          0.104,
          0.086,
          0.08,
          0.069,
          0.086,
          0.069,
          0.076,
          0.11,
          0.062,
          0.107,
          0.076,
          0.079,
          0.11,
          0.062,
          0.045,
          0.102,
          0.079,
          0.08,
          0.084,
          0.08,
          0.077,
          0.07,
          0.077,
          0.467,
          0.088,
          0.104,
          0.084,
          0.08,
          0.104,
          0.09,
          0.077,
          0.178,
          0.119,
          0.075,
          0.0819999999999999,
          0.081,
          0.0819999999999999,
          0.065,
          0.118,
          0.049,
          0.084,
          0.09,
          0.081,
          0.09,
          0.05,
          0.066,
          0.05,
          0.1169999999999999,
          0.087,
          0.074,
          0.077,
          0.61,
          0.095,
          0.095,
          0.071,
          0.07,
          0.071,
          0.073,
          0.079,
          0.09,
          0.072,
          0.076,
          0.07,
          0.07,
          0.1,
          0.085,
          0.072,
          0.089,
          0.0579999999999999,
          0.073,
          0.068,
          0.085,
          0.08,
          0.087,
          0.068,
          0.067,
          0.067,
          0.27,
          0.076,
          0.077,
          0.079,
          0.111,
          0.0819999999999999,
          0.084,
          0.077,
          0.074,
          0.071,
          0.071,
          0.074,
          0.067,
          0.061,
          0.0559999999999999,
          0.089,
          0.095,
          0.095,
          0.1,
          0.039,
          0.083,
          0.06,
          0.092,
          0.06,
          0.1009999999999999,
          0.072,
          0.076,
          0.0819999999999999,
          0.1009999999999999,
          0.057,
          0.083,
          0.073,
          0.337,
          0.054,
          0.078,
          0.09,
          0.065,
          0.0969999999999999,
          0.263,
          0.093,
          0.102,
          0.075,
          0.075,
          0.084,
          0.075,
          0.084,
          0.063,
          0.074,
          0.09,
          0.092,
          0.073,
          0.075,
          0.075,
          0.611,
          0.085,
          0.077,
          0.087,
          0.07,
          0.077,
          0.064,
          0.096,
          0.078,
          0.077,
          0.104,
          0.087,
          0.087,
          0.077,
          0.104,
          0.073,
          0.087,
          0.071,
          0.358,
          0.087,
          0.102,
          0.102,
          0.073,
          0.092,
          0.091,
          0.105,
          0.091,
          0.091,
          0.098,
          0.094,
          0.073,
          0.086,
          0.083,
          0.094,
          0.086,
          0.068,
          0.092,
          0.1119999999999999,
          0.0819999999999999,
          0.213,
          0.214,
          0.072,
          0.093,
          0.076,
          0.087,
          0.083,
          0.0819999999999999,
          0.09,
          0.071,
          0.071,
          0.121,
          0.107,
          0.0819999999999999,
          0.105,
          0.078,
          0.128,
          0.052,
          0.08,
          0.0819999999999999,
          0.118,
          0.118,
          0.0819999999999999,
          0.093,
          0.089,
          0.096,
          0.09,
          0.12,
          0.066,
          0.078,
          0.08,
          0.1159999999999999,
          0.109,
          0.088,
          0.099,
          0.086,
          0.072,
          0.071,
          0.083,
          0.083,
          0.076,
          0.074,
          0.0559999999999999,
          0.067,
          0.078,
          0.074,
          0.088,
          0.08,
          0.087,
          0.088,
          0.045,
          0.085,
          0.0819999999999999,
          0.066,
          0.122,
          0.087,
          0.064,
          0.122,
          0.085,
          0.085,
          0.075,
          0.063,
          0.093,
          0.07,
          0.08,
          0.1,
          0.0969999999999999,
          0.087,
          0.1169999999999999,
          0.111,
          0.091,
          0.121,
          0.066,
          0.059,
          0.047,
          0.066,
          0.059,
          0.045,
          0.077,
          0.07,
          0.088,
          0.066,
          0.074,
          0.091,
          0.076,
          0.091,
          0.06,
          0.066,
          0.062,
          0.072,
          0.1,
          0.054,
          0.081,
          0.127,
          0.1,
          0.095,
          0.095,
          0.084,
          0.084,
          0.063,
          0.086,
          0.095,
          0.0969999999999999,
          0.074,
          0.083,
          0.087,
          0.084,
          0.069,
          0.065,
          0.09,
          0.07,
          0.093,
          0.081,
          0.083,
          0.087,
          0.091,
          0.075,
          0.077,
          0.069,
          0.08,
          0.152,
          0.054,
          0.053,
          0.073,
          0.055,
          0.052,
          0.086,
          0.051,
          0.07,
          0.081,
          0.09,
          0.07,
          0.086,
          0.081,
          0.074,
          0.074,
          0.077,
          0.072,
          0.075,
          0.084,
          0.084,
          0.09,
          0.125,
          0.107,
          0.107,
          0.122,
          0.1,
          0.2,
          0.088,
          0.085,
          0.086,
          0.0969999999999999,
          0.077,
          0.078,
          0.098,
          0.098,
          0.072,
          0.102,
          0.078,
          0.077,
          0.084,
          0.066,
          0.1,
          0.1009999999999999,
          0.064,
          0.07,
          0.085,
          0.075,
          0.094,
          0.078,
          0.067,
          0.079,
          0.074,
          0.092,
          0.092,
          0.05,
          0.095,
          0.118,
          0.095,
          0.085,
          0.075,
          0.094,
          0.092,
          0.085,
          0.075,
          0.226,
          0.25,
          0.095,
          0.07,
          0.075,
          0.103,
          0.083,
          0.085,
          0.063,
          0.089,
          0.089,
          0.074,
          0.108,
          0.06,
          0.084,
          0.07,
          0.084,
          0.094,
          0.086,
          0.059,
          0.078,
          0.081,
          0.096,
          0.092,
          0.11,
          0.075,
          0.083,
          0.081,
          0.077,
          0.079,
          0.079,
          0.088,
          0.076,
          0.078,
          0.08,
          0.124,
          0.098,
          0.098,
          0.0969999999999999,
          0.111,
          0.0969999999999999,
          0.105,
          0.087,
          0.105,
          0.073,
          0.065,
          0.086,
          0.084,
          0.067,
          0.071,
          0.071,
          0.071,
          0.07,
          0.066,
          0.068,
          0.106,
          0.096,
          0.079,
          0.074,
          0.087,
          0.106,
          0.073,
          0.074,
          0.074,
          0.08,
          0.076,
          0.084,
          0.222,
          0.0819999999999999,
          0.0819999999999999,
          0.074,
          0.074,
          0.084,
          0.084,
          0.081,
          0.06,
          0.094,
          0.078,
          0.059,
          0.078,
          0.059,
          0.039,
          0.157,
          0.087,
          0.422,
          0.084,
          0.084,
          0.034,
          0.066,
          0.087,
          0.071,
          0.076,
          0.066,
          0.067,
          0.073,
          0.078,
          0.073,
          0.093,
          0.077,
          0.068,
          0.08,
          0.093,
          0.078,
          0.079,
          0.0819999999999999,
          0.086,
          0.0819999999999999,
          0.094,
          0.053,
          0.077,
          0.084,
          0.067,
          0.067,
          0.071,
          0.387,
          0.088,
          0.092,
          0.0819999999999999,
          0.075,
          0.1119999999999999,
          0.093,
          0.088,
          0.075,
          0.078,
          0.095,
          0.07,
          0.08,
          0.071,
          0.07,
          0.089,
          0.0969999999999999,
          0.089,
          0.415,
          0.0579999999999999,
          0.057,
          0.084,
          0.084,
          0.092,
          0.075,
          0.096,
          0.069,
          0.093,
          0.091,
          0.089,
          0.0819999999999999,
          0.076,
          0.0819999999999999,
          0.0819999999999999,
          0.0819999999999999,
          0.157,
          0.102,
          0.241,
          0.079,
          0.076,
          0.19,
          0.114,
          0.077,
          0.083,
          0.079,
          0.079,
          0.099,
          0.0819999999999999,
          0.084,
          0.081,
          0.055,
          0.065,
          0.132,
          0.126,
          0.038,
          0.0819999999999999,
          0.068,
          0.044,
          0.114,
          0.084,
          0.0409999999999999,
          0.165,
          0.07,
          0.068,
          0.072,
          0.102,
          0.103,
          0.0969999999999999,
          0.099,
          0.048,
          0.076,
          0.068,
          0.05,
          0.076,
          0.0579999999999999,
          0.071,
          0.147,
          0.012,
          0.012,
          0.075,
          0.115,
          0.119,
          0.088,
          0.081,
          0.078,
          0.081,
          0.085,
          0.085,
          0.08,
          0.08,
          0.08,
          0.073,
          0.054,
          0.077,
          0.067,
          0.078,
          0.077,
          0.086,
          0.067,
          0.109,
          0.064,
          0.068,
          0.1939999999999999,
          0.094,
          0.086,
          0.083,
          0.072,
          0.1119999999999999,
          0.078,
          0.0819999999999999,
          0.078,
          0.08,
          0.08,
          0.078,
          0.08,
          0.078,
          0.0559999999999999,
          0.08,
          0.08,
          0.06,
          0.084,
          0.079,
          0.078,
          0.132,
          0.114,
          0.065,
          0.079,
          0.161,
          0.084,
          0.081,
          0.072,
          0.091,
          0.072,
          0.055,
          0.064,
          0.061,
          0.093,
          0.055,
          0.063,
          0.074,
          0.078,
          0.08,
          0.06,
          0.073,
          0.0819999999999999,
          0.092,
          0.09,
          0.092,
          0.093,
          0.075,
          0.075,
          0.093,
          0.0579999999999999,
          0.052,
          0.09,
          0.111,
          0.12,
          0.0579999999999999,
          0.078,
          0.115,
          0.0579999999999999,
          0.0969999999999999,
          0.068,
          0.066,
          0.073,
          0.083,
          0.109,
          0.061,
          0.065,
          0.079,
          0.07,
          0.065,
          0.064,
          0.08,
          0.0969999999999999,
          0.073,
          0.0969999999999999,
          0.0819999999999999,
          0.0819999999999999,
          0.079,
          0.05,
          0.055,
          0.062,
          0.081,
          0.067,
          0.063,
          0.064,
          0.11,
          0.067,
          0.088,
          0.102,
          0.092,
          0.12,
          0.068,
          0.049,
          0.078,
          0.123,
          0.123,
          0.062,
          0.098,
          0.088,
          0.095,
          0.066,
          0.065,
          0.088,
          0.095,
          0.077,
          0.085,
          0.0819999999999999,
          0.078,
          0.088,
          0.079,
          0.046,
          0.07,
          0.076,
          0.0819999999999999,
          0.081,
          0.084,
          0.414,
          0.073,
          0.07,
          0.095,
          0.1009999999999999,
          0.104,
          0.093,
          0.1009999999999999,
          0.074,
          0.071,
          0.098,
          0.075,
          0.067,
          0.083,
          0.07,
          0.06,
          0.086,
          0.057,
          0.098,
          0.088,
          0.073,
          0.08,
          0.05,
          0.05,
          0.073,
          0.072,
          0.074,
          0.055,
          0.057,
          0.095,
          0.095,
          0.083,
          0.086,
          0.081,
          0.079,
          0.1169999999999999,
          0.1169999999999999,
          0.096,
          0.072,
          0.071,
          0.071,
          0.073,
          0.048,
          0.068,
          0.09,
          0.171,
          0.07,
          0.092,
          0.0559999999999999,
          0.046,
          0.091,
          0.091,
          0.091,
          0.065,
          0.066,
          0.076,
          0.055,
          0.055,
          0.072,
          0.095,
          0.0579999999999999,
          0.075,
          0.089,
          0.061,
          0.067,
          0.08,
          0.104,
          0.079,
          0.08,
          0.08,
          0.043,
          0.065,
          0.066,
          0.076,
          0.178,
          0.071,
          0.086,
          0.061,
          0.044,
          0.118,
          0.083,
          0.118,
          0.071,
          0.042,
          0.075,
          0.078,
          0.074,
          0.067,
          0.086,
          0.062,
          0.074,
          0.079,
          0.079,
          0.095,
          0.079,
          0.0409999999999999,
          0.076,
          0.068,
          0.07,
          0.08,
          0.08,
          0.075,
          0.08,
          0.166,
          0.063,
          0.114,
          0.078,
          0.069,
          0.052,
          0.076,
          0.069,
          0.065,
          0.068,
          0.111,
          0.074,
          0.074,
          0.136,
          0.074,
          0.071,
          0.078,
          0.078,
          0.081,
          0.079,
          0.044,
          0.132,
          0.132,
          0.08,
          0.091,
          0.08,
          0.104,
          0.044,
          0.075,
          0.066,
          0.074,
          0.075,
          0.059,
          0.07,
          0.059,
          0.081,
          0.057,
          0.076,
          0.0819999999999999,
          0.0819999999999999,
          0.086,
          0.079,
          0.077,
          0.123,
          0.096,
          0.079,
          0.0819999999999999,
          0.085,
          0.123,
          0.4029999999999999,
          0.083,
          0.081,
          0.066,
          0.081,
          0.081,
          0.068,
          0.079,
          0.048,
          0.049,
          0.077,
          0.073,
          0.102,
          0.075,
          0.05,
          0.114,
          0.075,
          0.062,
          0.077,
          0.077,
          0.084,
          0.096,
          0.071,
          0.09,
          0.068,
          0.068,
          0.1,
          0.073,
          0.0559999999999999,
          0.093,
          0.064,
          0.063,
          0.1369999999999999,
          0.08,
          0.1,
          0.064,
          0.087,
          0.073,
          0.088,
          0.071,
          0.064,
          0.083,
          0.083,
          0.0409999999999999,
          0.414,
          0.0409999999999999,
          0.0579999999999999,
          0.077,
          0.077,
          0.077,
          0.077,
          0.073,
          0.083,
          0.083,
          0.107,
          0.075,
          0.079,
          0.166,
          0.069,
          0.057,
          0.057,
          0.057,
          0.084,
          0.084,
          0.084,
          0.084,
          0.077,
          0.063,
          0.0559999999999999,
          0.078,
          0.065,
          0.086,
          0.086,
          0.084,
          0.078,
          0.168,
          0.091,
          0.093,
          0.091,
          0.096,
          0.094,
          0.088,
          0.079,
          0.415,
          0.153,
          0.415,
          0.086,
          0.078,
          0.077,
          0.077,
          0.08,
          0.08,
          0.107,
          0.076,
          0.1,
          0.083,
          0.068,
          0.094,
          0.07,
          0.078,
          0.092,
          0.09,
          0.08,
          0.068,
          0.08,
          0.052,
          0.061,
          0.0819999999999999,
          0.062,
          0.064,
          0.048,
          0.064,
          0.0819999999999999,
          0.071,
          0.062,
          0.104,
          0.077,
          0.065,
          0.077,
          0.064,
          0.077,
          0.077,
          0.077,
          0.079,
          0.079,
          0.123,
          0.078,
          0.072,
          0.049,
          0.066,
          0.069,
          0.069,
          0.214,
          0.1689999999999999,
          0.07,
          0.052,
          0.072,
          0.0579999999999999,
          0.094,
          0.08,
          0.0559999999999999,
          0.062,
          0.104,
          0.062,
          0.073,
          0.052,
          0.074,
          0.067,
          0.054,
          0.054,
          0.06,
          0.076,
          0.063,
          0.062,
          0.067,
          0.062,
          0.061,
          0.084,
          0.067,
          0.073,
          0.071,
          0.205,
          0.048,
          0.205,
          0.048,
          0.0819999999999999,
          0.104,
          0.08,
          0.104,
          0.042,
          0.074,
          0.07,
          0.066,
          0.049,
          0.039,
          0.05,
          0.089,
          0.066,
          0.08,
          0.054,
          0.054,
          0.083,
          0.077,
          0.106,
          0.078,
          0.07,
          0.106,
          0.074,
          0.062,
          0.047,
          0.068,
          0.074,
          0.074,
          0.063,
          0.114,
          0.106,
          0.071,
          0.076,
          0.064,
          0.064,
          0.096,
          0.063,
          0.063,
          0.081,
          0.0579999999999999,
          0.074,
          0.064,
          0.075,
          0.081,
          0.071,
          0.063,
          0.059,
          0.072,
          0.099,
          0.074,
          0.083,
          0.103,
          0.08,
          0.065,
          0.066,
          0.062,
          0.235,
          0.08,
          0.08,
          0.08,
          0.076,
          0.076,
          0.061,
          0.059,
          0.076,
          0.077,
          0.0559999999999999,
          0.23,
          0.038,
          0.069,
          0.075,
          0.06,
          0.081,
          0.076,
          0.118,
          0.068,
          0.053,
          0.074,
          0.061,
          0.065,
          0.066,
          0.077,
          0.089,
          0.076,
          0.068,
          0.09,
          0.062,
          0.075
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of chlorides in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "chlorides"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "free sulfur dioxide=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          11,
          25,
          15,
          17,
          11,
          13,
          15,
          15,
          9,
          15,
          16,
          9,
          35,
          17,
          23,
          10,
          9,
          21,
          11,
          4,
          14,
          8,
          17,
          15,
          13,
          5,
          3,
          13,
          12,
          17,
          8,
          9,
          8,
          22,
          4,
          8,
          6,
          30,
          33,
          4,
          17,
          9,
          19,
          20,
          13,
          4,
          4,
          6,
          8,
          18,
          11,
          9,
          14,
          12,
          27,
          3,
          21,
          18,
          19,
          20,
          9,
          34,
          8,
          42,
          20,
          9,
          41,
          8,
          5,
          13,
          11,
          13,
          12,
          5,
          12,
          18,
          15,
          12,
          11,
          22,
          12,
          13,
          11,
          10,
          14,
          3,
          21,
          3,
          3,
          3,
          30,
          17,
          13,
          16,
          13,
          16,
          27,
          3,
          27,
          32,
          21,
          12,
          5,
          32,
          25,
          25,
          28,
          29,
          28,
          12,
          18,
          7,
          9,
          17,
          36,
          35,
          14,
          18,
          17,
          11,
          4,
          6,
          24,
          19,
          7,
          8,
          7,
          10,
          10,
          23,
          16,
          11,
          8,
          26,
          14,
          15,
          21,
          21,
          7,
          7,
          15,
          12,
          12,
          9,
          14,
          9,
          9,
          18,
          5,
          10,
          28,
          10,
          26,
          13,
          11,
          10,
          24,
          16,
          5,
          8,
          29,
          27,
          19,
          12,
          18,
          7,
          14,
          5,
          6,
          28,
          10,
          10,
          6,
          16,
          6,
          16,
          16,
          5,
          8,
          17,
          5,
          12,
          8,
          14,
          18,
          12,
          10,
          23,
          5,
          26,
          15,
          7,
          4,
          27,
          27,
          7,
          4,
          5,
          10,
          6,
          5,
          10,
          32,
          32,
          25,
          29,
          20,
          33,
          20,
          18,
          5,
          17,
          5,
          26,
          8,
          5,
          20,
          7,
          12,
          12,
          7,
          6,
          5,
          15,
          19,
          30,
          26,
          21,
          30,
          25,
          13,
          13,
          6,
          5,
          6,
          16,
          17,
          7,
          6,
          29,
          12,
          6,
          6,
          6,
          6,
          15,
          11,
          8,
          23,
          40.5,
          17,
          29,
          12,
          10,
          10,
          14,
          21,
          6,
          6,
          7,
          7,
          11,
          6,
          11,
          26,
          19,
          6,
          6,
          11,
          23,
          23,
          12,
          17,
          6,
          7,
          68,
          13,
          9,
          68,
          19,
          10,
          15,
          9,
          12,
          26,
          26,
          15,
          6,
          24,
          31,
          6,
          34,
          7,
          34,
          32,
          15,
          6,
          32,
          19,
          6,
          9,
          13,
          6,
          21,
          6,
          22,
          6,
          38,
          6,
          7,
          6,
          6,
          5,
          31,
          6,
          7,
          17,
          17,
          18,
          5,
          21,
          6,
          5,
          29,
          10,
          14,
          6,
          5,
          21,
          7,
          6,
          36,
          15,
          25,
          25,
          5,
          6,
          6,
          6,
          6,
          6,
          7,
          6,
          5,
          10,
          12,
          13,
          23,
          28,
          5,
          14,
          43,
          5,
          23,
          14,
          38,
          38,
          6,
          10,
          6,
          6,
          23,
          26,
          15,
          6,
          6,
          34,
          5,
          5,
          15,
          38,
          23,
          33,
          6,
          1,
          12,
          12,
          15,
          13,
          1,
          6,
          5,
          5,
          5,
          20,
          5,
          5,
          16,
          6,
          38,
          10,
          6,
          27,
          9,
          14,
          14,
          32,
          10,
          10,
          10,
          6,
          5,
          41,
          25,
          6,
          5,
          5,
          5,
          19,
          10,
          10,
          6,
          18,
          17,
          18,
          5,
          5,
          10,
          18,
          19,
          21,
          23,
          21,
          9,
          30,
          6,
          5,
          6,
          14,
          26,
          11,
          15,
          25,
          5,
          18,
          28,
          14,
          6,
          16,
          14,
          9,
          21,
          5,
          5,
          7,
          20,
          7,
          5,
          21,
          11,
          46,
          24,
          30,
          31,
          25,
          16,
          16,
          16,
          5,
          10,
          24,
          8,
          22,
          9,
          7,
          20,
          8,
          23,
          5,
          5,
          15,
          9,
          25,
          6,
          6,
          6,
          5,
          5,
          7,
          12,
          45,
          20,
          16,
          32,
          5,
          35,
          5,
          4,
          5,
          12,
          16,
          21,
          24,
          18,
          8,
          18,
          5,
          26,
          8,
          9,
          22,
          4,
          11,
          10,
          16,
          11,
          21,
          16,
          21,
          12,
          10,
          17,
          10,
          35,
          36,
          5,
          18,
          4,
          4,
          27,
          12,
          4,
          10,
          16,
          9,
          11,
          19,
          19,
          12,
          28,
          21,
          12,
          12,
          12,
          12,
          17,
          24,
          17,
          14,
          22,
          15,
          10,
          10,
          33,
          9,
          5,
          8,
          11,
          12,
          12,
          24,
          7,
          24,
          23,
          23,
          1,
          7,
          6,
          7,
          21,
          12,
          9,
          20,
          11,
          19,
          19,
          21,
          18,
          25,
          17,
          7,
          7,
          7,
          24,
          21,
          5,
          8,
          14,
          14,
          4,
          4,
          4,
          4,
          4,
          7,
          4,
          19,
          9,
          9,
          16,
          15,
          6,
          4,
          15,
          5,
          16,
          36,
          36,
          36,
          9,
          21,
          34,
          9,
          14,
          12,
          14,
          9,
          9,
          41,
          41,
          41,
          16,
          17,
          15,
          7,
          17,
          16,
          36,
          28,
          7,
          31,
          30,
          14,
          30,
          9,
          8,
          32,
          23,
          16,
          10,
          16,
          17,
          27,
          17,
          27,
          17,
          10,
          16,
          16,
          11,
          12,
          6,
          34,
          3,
          3,
          4,
          3,
          7,
          26,
          32,
          38,
          10,
          38,
          14,
          53,
          52,
          11,
          14,
          10,
          13,
          29,
          8,
          19,
          7,
          9,
          13,
          11,
          11,
          6,
          10,
          10,
          6,
          6,
          5,
          9,
          5,
          25,
          18,
          7,
          6,
          18,
          23,
          29,
          6,
          7,
          35,
          31,
          9,
          8,
          13,
          51,
          8,
          7,
          35,
          19,
          14,
          19,
          31,
          31,
          19,
          4,
          7,
          6,
          27,
          4,
          13,
          12,
          12,
          7,
          12,
          11,
          22,
          3,
          12,
          36,
          10,
          3,
          3,
          4,
          3,
          12,
          17,
          14,
          28,
          12,
          5,
          15,
          5,
          26,
          25,
          21,
          13,
          12,
          32,
          33,
          27,
          3,
          6,
          16,
          19,
          9,
          5,
          3,
          28,
          30,
          3,
          3,
          7,
          6,
          6,
          5,
          6,
          13,
          3,
          28,
          19,
          30,
          16,
          3,
          3,
          37.5,
          37.5,
          31,
          32,
          40,
          3,
          18,
          22,
          22,
          42,
          8,
          10,
          11,
          9,
          9,
          5,
          23,
          14,
          14,
          16,
          13,
          10,
          4,
          27,
          6,
          23,
          6,
          29,
          15,
          15,
          15,
          14,
          7,
          8,
          27,
          13,
          26,
          28,
          5,
          18,
          10,
          6,
          22,
          6,
          29,
          16,
          33,
          24,
          6,
          16,
          35,
          31,
          6,
          6,
          9,
          6,
          16,
          9,
          17,
          9,
          45,
          16,
          12,
          10,
          29,
          8,
          5,
          5,
          5,
          26,
          26,
          48,
          23,
          17,
          11,
          5,
          16,
          11,
          11,
          5,
          6,
          6,
          11,
          15,
          21,
          4,
          19,
          23,
          4,
          5,
          6,
          33,
          24,
          24,
          24,
          24,
          14,
          8,
          8,
          6,
          10,
          25,
          17,
          17,
          8,
          18,
          27,
          8,
          18,
          19,
          15,
          48,
          19,
          11,
          7,
          11,
          12,
          11,
          36,
          10,
          15,
          15,
          24,
          27,
          6,
          6,
          20,
          43,
          12,
          15,
          19,
          17,
          34,
          26,
          16,
          16,
          13,
          21,
          26,
          24,
          25,
          34,
          17,
          13,
          3,
          3,
          13,
          3,
          28,
          28,
          9,
          17,
          18,
          20,
          20,
          20,
          6,
          25,
          14,
          51,
          15,
          11,
          5,
          15,
          20,
          4,
          21,
          24,
          22,
          27,
          12,
          14,
          17,
          16,
          18,
          16,
          9,
          18,
          18,
          18,
          18,
          13,
          17,
          17,
          31,
          6,
          12,
          4,
          19,
          15,
          15,
          15,
          13,
          13,
          13,
          13,
          8,
          10,
          5,
          7,
          8,
          14,
          5,
          4,
          27,
          52,
          6,
          13,
          6,
          10,
          10,
          9,
          16,
          12,
          5,
          12,
          7,
          10,
          11,
          11,
          25,
          25,
          20,
          34,
          8,
          7,
          15,
          5,
          5,
          19,
          3,
          4,
          17,
          10,
          33,
          6,
          3,
          12,
          8,
          40,
          35,
          40,
          5,
          8,
          8,
          12,
          3,
          8,
          3,
          21,
          3,
          32,
          3,
          24,
          39,
          14,
          6,
          27,
          38,
          18,
          13,
          11,
          55,
          27,
          15,
          3,
          31,
          8,
          19,
          22,
          15,
          15,
          8,
          37,
          7,
          9,
          27,
          8,
          7,
          34,
          6,
          14,
          34,
          31,
          19,
          31,
          20,
          8,
          8,
          23,
          14,
          48,
          16,
          48,
          16,
          3,
          10,
          6,
          10,
          6,
          8,
          9,
          9,
          5,
          8,
          6,
          23,
          15,
          15,
          7,
          7,
          21,
          6,
          5,
          6,
          6,
          5,
          17,
          7,
          26,
          19,
          16,
          16,
          29,
          7,
          14,
          23,
          29,
          18,
          18,
          21,
          42,
          9,
          13,
          18,
          32,
          13,
          15,
          15,
          11,
          12,
          16,
          17,
          19,
          17,
          18,
          32,
          18,
          15,
          12,
          15,
          66,
          31,
          31,
          31,
          12,
          12,
          26,
          24,
          12,
          25,
          15,
          19,
          15,
          35,
          15,
          12,
          16,
          13,
          13,
          9,
          13,
          32,
          24,
          34,
          18,
          26,
          16,
          29,
          28,
          32,
          39,
          32
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of free sulfur dioxide in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "free sulfur dioxide"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "total sulfur dioxide=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          34,
          67,
          54,
          60,
          34,
          40,
          59,
          21,
          18,
          65,
          59,
          29,
          103,
          56,
          71,
          37,
          67,
          40,
          23,
          11,
          35,
          16,
          82,
          113,
          50,
          18,
          15,
          30,
          87,
          46,
          14,
          23,
          65,
          114,
          23,
          15,
          14,
          119,
          73,
          10,
          54,
          46,
          52,
          112,
          54,
          11,
          11,
          15,
          19,
          94,
          43,
          42,
          30,
          80,
          119,
          15,
          73,
          61,
          40,
          136,
          31,
          125,
          24,
          140,
          136,
          31,
          85,
          23,
          10,
          35,
          50,
          35,
          65,
          36,
          65,
          69,
          64,
          47,
          108,
          46,
          47,
          62,
          40,
          89,
          56,
          13,
          102,
          12,
          12,
          16,
          134,
          99,
          29,
          63,
          45,
          63,
          63,
          20,
          63,
          141,
          94,
          30,
          11,
          69,
          99,
          99,
          128,
          129,
          128,
          22,
          86,
          20,
          20,
          31,
          121,
          121,
          96,
          101,
          42,
          44,
          8,
          18,
          42,
          49,
          35,
          38,
          20,
          42,
          42,
          110,
          42,
          65,
          62,
          85,
          67,
          143,
          127,
          49,
          28,
          28,
          55,
          27,
          31,
          24,
          37,
          28,
          28,
          95,
          19,
          62,
          65,
          41,
          121,
          49,
          41,
          44,
          58,
          72,
          10,
          28,
          63,
          81,
          106,
          49,
          58,
          37,
          38,
          62,
          24,
          109,
          24,
          24,
          23,
          51,
          23,
          37,
          34,
          21,
          86,
          119,
          13,
          56,
          45,
          33,
          45,
          67,
          35,
          49,
          27,
          61,
          37,
          27,
          23,
          61,
          61,
          27,
          23,
          13,
          47,
          19,
          10,
          47,
          71,
          71,
          49,
          53,
          49,
          98,
          49,
          48,
          16,
          53,
          27,
          70,
          29,
          31,
          44,
          15,
          28,
          90,
          54,
          14,
          12,
          105,
          98,
          135,
          72,
          59,
          74,
          87,
          50,
          50,
          14,
          13,
          21,
          44,
          38,
          21,
          16,
          58,
          29,
          14,
          14,
          32,
          15,
          46,
          26,
          19,
          77,
          165,
          32,
          55,
          29,
          23,
          41,
          81,
          50,
          37,
          15,
          42,
          42,
          24,
          18,
          25,
          46,
          47,
          18,
          24,
          27,
          54,
          53,
          88,
          43,
          26,
          38,
          124,
          49,
          42,
          124,
          64,
          41,
          27,
          28,
          30,
          49,
          86,
          77,
          19,
          122,
          134,
          20,
          124,
          20,
          52,
          48,
          60,
          24,
          48,
          48,
          32,
          30,
          35,
          24,
          66,
          18,
          54,
          18,
          62,
          22,
          50,
          29,
          43,
          27,
          72,
          16,
          27,
          35,
          35,
          35,
          22,
          67,
          19,
          22,
          65,
          47,
          23,
          19,
          15,
          51,
          18,
          21,
          48,
          47,
          52,
          68,
          28,
          16,
          20,
          31,
          23,
          17,
          18,
          17,
          14,
          26,
          25,
          27,
          81,
          91,
          16,
          38,
          113,
          16,
          81,
          38,
          76,
          76,
          22,
          26,
          21,
          13,
          43,
          62,
          49,
          15,
          15,
          151,
          14,
          16,
          33,
          142,
          116,
          85,
          33,
          28,
          42,
          42,
          33,
          32,
          28,
          33,
          13,
          35,
          17,
          47,
          17,
          20,
          53,
          15,
          106,
          28,
          21,
          69,
          25,
          45,
          44,
          96,
          23,
          17,
          23,
          47,
          19,
          110,
          60,
          47,
          19,
          15,
          20,
          42,
          37,
          28,
          14,
          111,
          110,
          40,
          14,
          14,
          21,
          102,
          50,
          75,
          149,
          75,
          43,
          109,
          24,
          30,
          14,
          63,
          52,
          65,
          39,
          57,
          16,
          29,
          71,
          28,
          16,
          112,
          104,
          32,
          58,
          15,
          15,
          31,
          84,
          31,
          19,
          43,
          86,
          102,
          33,
          147,
          145,
          57,
          40,
          40,
          40,
          14,
          28,
          148,
          32,
          71,
          30,
          29,
          53,
          32,
          42,
          20,
          20,
          42,
          27,
          48,
          16,
          15,
          15,
          13,
          13,
          17,
          31,
          87,
          49,
          29,
          58,
          15,
          152,
          15,
          9,
          17,
          93,
          62,
          122,
          125,
          44,
          25,
          72,
          19,
          88,
          25,
          23,
          84,
          14,
          54,
          19,
          37,
          35,
          84,
          112,
          77,
          49,
          22,
          45,
          22,
          106,
          127,
          13,
          49,
          11,
          11,
          58,
          37,
          14,
          19,
          72,
          39,
          22,
          58,
          38,
          16,
          139,
          101,
          28,
          57,
          31,
          28,
          40,
          66,
          40,
          32,
          47,
          33,
          31,
          31,
          88,
          104,
          35,
          19,
          44,
          48,
          74,
          94,
          32,
          94,
          143,
          144,
          44,
          16,
          18,
          34,
          92,
          45,
          37,
          85,
          61,
          58,
          58,
          119,
          82,
          130,
          87,
          13,
          26,
          60,
          64,
          42,
          14,
          17,
          86,
          46,
          18,
          10,
          12,
          15,
          14,
          24,
          7,
          41,
          59,
          22,
          42,
          36,
          16,
          8,
          37,
          9,
          24,
          51,
          100,
          100,
          28,
          31,
          68,
          92,
          31,
          39,
          31,
          22,
          22,
          55,
          55,
          55,
          47,
          32,
          85,
          25,
          84,
          86,
          46,
          48,
          16,
          43,
          35,
          26,
          69,
          30,
          28,
          64,
          99,
          86,
          18,
          86,
          88,
          43,
          43,
          43,
          43,
          39,
          33,
          33,
          18,
          78,
          9,
          61,
          11,
          9,
          8,
          6,
          62,
          45,
          79,
          46,
          23,
          46,
          28,
          77,
          73,
          75,
          28,
          19,
          38,
          66,
          25,
          72,
          11,
          17,
          52,
          24,
          24,
          12,
          21,
          21,
          12,
          10,
          9,
          23,
          10,
          36,
          38,
          18,
          16,
          38,
          113,
          46,
          10,
          13,
          72,
          119,
          29,
          17,
          28,
          70,
          17,
          11,
          70,
          27,
          21,
          27,
          68,
          68,
          41,
          10,
          12,
          12,
          45,
          8,
          27,
          25,
          24,
          12,
          19,
          32,
          31,
          7,
          28,
          109,
          23,
          8,
          8,
          9,
          9,
          18,
          43,
          36,
          52,
          18,
          14,
          48,
          17,
          35,
          42,
          39,
          26,
          53,
          38,
          45,
          51,
          14,
          17,
          45,
          25,
          20,
          77,
          10,
          90,
          52,
          10,
          8,
          16,
          15,
          17,
          10,
          20,
          26,
          10,
          52,
          37,
          92,
          37,
          8,
          8,
          278,
          289,
          70,
          59,
          64,
          9,
          30,
          41,
          41,
          74,
          19,
          16,
          31,
          17,
          17,
          18,
          36,
          25,
          25,
          25,
          49,
          24,
          13,
          66,
          14,
          55,
          35,
          80,
          21,
          21,
          21,
          24,
          15,
          17,
          33,
          27,
          52,
          89,
          10,
          38,
          18,
          15,
          50,
          13,
          94,
          86,
          79,
          71,
          12,
          20,
          70,
          51,
          21,
          14,
          21,
          11,
          70,
          38,
          38,
          38,
          88,
          101,
          19,
          21,
          48,
          44,
          14,
          12,
          16,
          65,
          65,
          59,
          47,
          78,
          47,
          11,
          61,
          119,
          119,
          19,
          20,
          12,
          41,
          64,
          56,
          9,
          77,
          94,
          9,
          10,
          12,
          76,
          44,
          44,
          52,
          44,
          24,
          15,
          15,
          9,
          79,
          50,
          44,
          44,
          20,
          77,
          46,
          21,
          88,
          66,
          58,
          90,
          66,
          18,
          17,
          18,
          24,
          20,
          60,
          86,
          34,
          48,
          37,
          60,
          14,
          13,
          35,
          60,
          69,
          33,
          56,
          24,
          66,
          51,
          36,
          36,
          19,
          51,
          60,
          64,
          44,
          44,
          36,
          81,
          10,
          10,
          81,
          9,
          54,
          54,
          22,
          69,
          36,
          47,
          110,
          110,
          12,
          60,
          28,
          77.5,
          29,
          18,
          9,
          28,
          57,
          15,
          68,
          88,
          91,
          63,
          27,
          41,
          91,
          46,
          64,
          46,
          18,
          34,
          34,
          34,
          34,
          38,
          91,
          91,
          67,
          25,
          48,
          11,
          40,
          26,
          26,
          26,
          31,
          31,
          31,
          31,
          20,
          28,
          13,
          12,
          46,
          57,
          32,
          28,
          67,
          98,
          28,
          54,
          28,
          31,
          45,
          105,
          74,
          66,
          14,
          66,
          31,
          28,
          35,
          35,
          105,
          105,
          84,
          85,
          23,
          49,
          33,
          33,
          12,
          59,
          12,
          11,
          104,
          24,
          141,
          24,
          13,
          46,
          22,
          54,
          53,
          54,
          16,
          19,
          22,
          89,
          15,
          18,
          15,
          37,
          19,
          133,
          19,
          58,
          55,
          31,
          23,
          55,
          67,
          47,
          74,
          25,
          95,
          90,
          39,
          8,
          92,
          22,
          98,
          39,
          29,
          28,
          17,
          53,
          23,
          17,
          85,
          20,
          15,
          64,
          13,
          39,
          53,
          54,
          32,
          54,
          49,
          24,
          16,
          44,
          45,
          82,
          89,
          82,
          89,
          14,
          22,
          13,
          22,
          12,
          25,
          23,
          17,
          13,
          18,
          18,
          147,
          28,
          28,
          16,
          16,
          64,
          14,
          12,
          12,
          14,
          12,
          25,
          20,
          48,
          27,
          65,
          65,
          44,
          20,
          27,
          58,
          61,
          34,
          38,
          59,
          52,
          18,
          28,
          22,
          84,
          29,
          35,
          26,
          32,
          19,
          28,
          26,
          50,
          24,
          27,
          54,
          28,
          24,
          20,
          23,
          115,
          131,
          131,
          131,
          20,
          20,
          42,
          52,
          20,
          42,
          34,
          35,
          25,
          104,
          50,
          20,
          29,
          27,
          20,
          26,
          27,
          98,
          34,
          60,
          28,
          35,
          26,
          40,
          38,
          44,
          51,
          44
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of total sulfur dioxide in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "total sulfur dioxide"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "sulphates=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0.56,
          0.68,
          0.65,
          0.58,
          0.56,
          0.56,
          0.46,
          0.47,
          0.57,
          0.54,
          0.52,
          1.56,
          0.75,
          1.08,
          0.65,
          0.91,
          0.53,
          0.63,
          0.56,
          0.59,
          0.55,
          0.59,
          0.54,
          0.66,
          0.55,
          0.55,
          0.6,
          0.73,
          0.83,
          0.51,
          0.9,
          1.2,
          0.56,
          0.73,
          0.74,
          0.63,
          0.64,
          0.56,
          0.63,
          0.63,
          0.59,
          0.54,
          0.64,
          0.71,
          0.57,
          0.39,
          0.39,
          0.58,
          0.95,
          0.48,
          0.53,
          0.66,
          0.55,
          0.52,
          1.12,
          0.56,
          0.57,
          0.78,
          0.59,
          1.95,
          0.64,
          1.22,
          0.53,
          0.54,
          1.95,
          0.64,
          0.48,
          0.56,
          0.56,
          0.59,
          0.61,
          0.59,
          0.51,
          0.48,
          0.51,
          1.31,
          0.79,
          0.93,
          0.66,
          0.67,
          0.93,
          0.63,
          0.61,
          0.57,
          0.6,
          0.52,
          0.48,
          0.49,
          0.48,
          0.92,
          0.66,
          0.63,
          0.55,
          0.82,
          0.64,
          0.82,
          0.79,
          0.58,
          0.79,
          0.62,
          0.52,
          0.58,
          0.53,
          2,
          0.54,
          0.54,
          0.71,
          0.72,
          0.71,
          0.5,
          0.57,
          0.56,
          1.08,
          0.56,
          0.49,
          0.49,
          0.62,
          0.52,
          0.48,
          0.55,
          0.33,
          0.61,
          0.57,
          0.78,
          0.47,
          0.61,
          0.56,
          0.59,
          0.59,
          1.02,
          0.52,
          0.58,
          0.58,
          0.53,
          0.55,
          0.55,
          0.62,
          0.62,
          0.55,
          0.55,
          0.59,
          0.97,
          0.43,
          0.82,
          0.56,
          0.77,
          0.77,
          0.67,
          0.86,
          0.56,
          0.43,
          0.71,
          0.76,
          0.57,
          0.55,
          0.54,
          0.59,
          0.57,
          0.6,
          0.6,
          0.58,
          1.61,
          0.62,
          0.52,
          0.7,
          0.55,
          0.58,
          1.09,
          0.71,
          0.49,
          0.84,
          0.84,
          0.96,
          0.52,
          0.96,
          0.78,
          0.7,
          0.53,
          0.59,
          0.57,
          0.62,
          0.67,
          1.26,
          0.8,
          0.65,
          0.6,
          0.57,
          0.67,
          0.87,
          0.72,
          0.86,
          0.91,
          0.97,
          0.67,
          0.67,
          0.91,
          0.97,
          0.82,
          0.77,
          0.82,
          1.08,
          0.77,
          0.71,
          0.71,
          0.76,
          0.7,
          0.86,
          0.95,
          0.86,
          0.64,
          0.6,
          0.81,
          0.64,
          0.52,
          0.73,
          0.8,
          0.59,
          0.64,
          0.72,
          0.52,
          0.52,
          0.62,
          0.63,
          0.54,
          0.63,
          0.53,
          0.68,
          0.71,
          0.64,
          0.62,
          0.69,
          0.69,
          0.74,
          0.83,
          0.67,
          0.52,
          0.74,
          0.84,
          0.7,
          0.64,
          1.36,
          0.75,
          0.75,
          0.78,
          0.93,
          0.92,
          0.83,
          0.73,
          0.77,
          0.59,
          0.61,
          0.88,
          0.75,
          0.85,
          0.68,
          0.7,
          0.91,
          0.56,
          0.87,
          0.73,
          0.73,
          0.69,
          1.13,
          0.87,
          1.04,
          1.11,
          1.13,
          0.99,
          0.8,
          0.74,
          0.74,
          0.82,
          0.8,
          0.51,
          0.6,
          0.53,
          0.65,
          0.55,
          0.53,
          0.61,
          0.63,
          0.61,
          0.65,
          0.63,
          0.57,
          0.62,
          0.64,
          0.82,
          0.61,
          1.07,
          0.66,
          0.48,
          0.76,
          0.68,
          0.56,
          0.44,
          0.9,
          0.56,
          0.49,
          0.56,
          0.6,
          0.6,
          0.9,
          0.56,
          0.49,
          0.89,
          0.49,
          0.56,
          0.66,
          0.6,
          0.82,
          0.68,
          0.84,
          0.73,
          0.72,
          0.56,
          0.61,
          0.61,
          0.63,
          0.74,
          0.63,
          0.69,
          0.58,
          0.58,
          0.57,
          0.61,
          0.61,
          0.7,
          0.72,
          0.79,
          0.62,
          0.58,
          0.61,
          0.71,
          0.82,
          0.6,
          0.7,
          1.06,
          0.7,
          0.66,
          0.92,
          1.06,
          0.47,
          0.42,
          0.75,
          0.79,
          0.9,
          0.74,
          0.55,
          0.65,
          0.65,
          0.79,
          0.65,
          0.74,
          0.65,
          0.85,
          0.85,
          1.05,
          0.78,
          1.02,
          0.71,
          0.68,
          0.63,
          0.81,
          0.66,
          0.66,
          1.14,
          0.74,
          0.63,
          0.9,
          0.55,
          0.64,
          0.77,
          0.57,
          0.87,
          0.61,
          0.61,
          0.66,
          0.56,
          0.87,
          0.57,
          0.77,
          0.66,
          0.62,
          0.67,
          0.73,
          0.59,
          0.72,
          0.79,
          0.59,
          0.78,
          0.86,
          0.75,
          0.56,
          0.73,
          0.74,
          0.62,
          0.74,
          0.56,
          0.74,
          0.68,
          0.57,
          0.61,
          0.61,
          0.68,
          0.57,
          0.6,
          0.79,
          0.57,
          0.91,
          0.61,
          0.52,
          0.6,
          0.6,
          0.51,
          0.44,
          0.44,
          0.66,
          0.59,
          0.74,
          0.57,
          0.5,
          0.57,
          0.58,
          0.57,
          0.6,
          0.48,
          0.52,
          0.62,
          0.53,
          0.64,
          0.52,
          0.54,
          0.54,
          0.6,
          0.57,
          0.93,
          0.8,
          0.61,
          0.62,
          0.55,
          0.72,
          0.49,
          0.49,
          0.6,
          0.61,
          0.6,
          0.63,
          0.57,
          0.64,
          0.58,
          0.55,
          0.53,
          0.53,
          1.36,
          0.62,
          0.62,
          0.62,
          0.58,
          0.67,
          0.57,
          0.5,
          0.84,
          0.54,
          0.46,
          0.61,
          0.5,
          0.68,
          0.81,
          0.81,
          0.64,
          0.7,
          0.56,
          0.6,
          0.66,
          0.66,
          0.52,
          0.52,
          0.67,
          0.48,
          0.53,
          0.54,
          0.49,
          0.54,
          0.56,
          0.48,
          0.56,
          0.47,
          1.05,
          0.54,
          1.17,
          0.62,
          0.61,
          0.62,
          0.67,
          0.53,
          0.62,
          0.57,
          0.67,
          0.67,
          0.7,
          0.54,
          0.49,
          0.47,
          0.51,
          0.61,
          0.57,
          0.61,
          0.51,
          0.57,
          0.44,
          0.54,
          0.44,
          0.53,
          1.62,
          0.55,
          0.72,
          0.68,
          0.68,
          0.49,
          0.67,
          0.52,
          0.47,
          0.6,
          0.62,
          0.5,
          0.65,
          0.6,
          0.68,
          0.57,
          0.51,
          0.73,
          0.47,
          0.72,
          0.73,
          0.55,
          0.61,
          0.55,
          1.06,
          0.43,
          0.46,
          0.5,
          0.5,
          0.52,
          0.57,
          0.42,
          0.53,
          0.55,
          0.54,
          0.54,
          0.53,
          0.54,
          0.53,
          0.55,
          0.55,
          0.92,
          0.46,
          0.59,
          0.61,
          0.6,
          0.6,
          0.65,
          0.59,
          0.5,
          0.56,
          0.56,
          0.52,
          0.68,
          0.54,
          0.6,
          0.56,
          0.53,
          1.18,
          0.74,
          0.81,
          0.52,
          0.44,
          0.94,
          0.66,
          0.57,
          0.71,
          0.86,
          0.55,
          0.47,
          0.68,
          0.58,
          0.76,
          0.54,
          0.6,
          0.74,
          0.64,
          0.53,
          0.64,
          0.49,
          0.55,
          0.77,
          0.86,
          0.39,
          0.39,
          0.83,
          0.63,
          0.72,
          0.62,
          0.66,
          0.7,
          0.66,
          0.55,
          0.55,
          0.73,
          0.73,
          0.73,
          0.78,
          0.67,
          0.54,
          0.44,
          0.53,
          0.54,
          0.57,
          0.54,
          0.79,
          0.57,
          0.65,
          0.78,
          0.5,
          0.64,
          0.65,
          0.56,
          0.68,
          0.57,
          0.65,
          0.57,
          0.58,
          0.58,
          0.77,
          0.58,
          0.77,
          0.69,
          0.69,
          0.69,
          0.59,
          0.71,
          0.54,
          0.59,
          0.57,
          0.6,
          0.62,
          0.67,
          0.61,
          0.64,
          0.72,
          0.89,
          0.56,
          0.89,
          0.8,
          0.87,
          0.9,
          0.59,
          0.8,
          0.73,
          0.65,
          0.59,
          0.73,
          0.72,
          0.54,
          0.52,
          0.64,
          0.64,
          0.99,
          0.62,
          0.76,
          0.76,
          0.62,
          0.68,
          0.69,
          0.67,
          0.62,
          0.71,
          0.85,
          0.62,
          0.69,
          0.85,
          0.48,
          0.6,
          0.87,
          0.62,
          0.52,
          0.5,
          0.49,
          0.71,
          0.62,
          0.82,
          0.71,
          0.58,
          0.5,
          0.49,
          0.51,
          0.49,
          0.48,
          0.48,
          0.62,
          0.48,
          0.53,
          0.72,
          0.54,
          0.55,
          0.84,
          0.84,
          0.7,
          0.55,
          0.55,
          0.48,
          0.58,
          0.58,
          0.75,
          0.44,
          0.61,
          0.53,
          0.53,
          0.54,
          0.55,
          0.56,
          0.6,
          0.56,
          0.52,
          0.56,
          0.53,
          0.47,
          0.65,
          0.59,
          0.77,
          0.83,
          0.64,
          0.62,
          0.58,
          0.62,
          0.64,
          0.78,
          0.77,
          1.34,
          0.55,
          0.77,
          0.62,
          0.59,
          0.57,
          0.76,
          0.59,
          0.7,
          0.69,
          0.64,
          0.63,
          0.57,
          0.6,
          0.72,
          0.83,
          0.62,
          0.89,
          0.58,
          0.58,
          0.73,
          0.58,
          0.51,
          0.51,
          0.59,
          0.77,
          0.49,
          0.66,
          0.69,
          0.76,
          0.76,
          0.63,
          0.6,
          0.59,
          0.86,
          0.49,
          0.49,
          0.52,
          0.78,
          0.63,
          0.63,
          0.66,
          0.6,
          0.85,
          0.49,
          0.76,
          0.64,
          0.64,
          0.71,
          0.66,
          0.6,
          0.6,
          0.6,
          0.53,
          0.58,
          0.72,
          0.48,
          0.59,
          0.6,
          0.68,
          0.63,
          0.88,
          0.68,
          0.74,
          0.6,
          0.76,
          0.58,
          0.64,
          0.65,
          0.85,
          0.65,
          0.82,
          0.62,
          0.81,
          0.87,
          0.49,
          0.66,
          0.52,
          0.65,
          0.53,
          0.66,
          0.53,
          0.76,
          0.87,
          0.71,
          0.67,
          0.88,
          0.56,
          0.62,
          0.67,
          0.74,
          0.62,
          0.62,
          0.7,
          0.5,
          0.73,
          0.81,
          0.46,
          0.6,
          0.7,
          0.7,
          0.44,
          0.57,
          0.51,
          0.8,
          0.59,
          0.6,
          0.54,
          0.79,
          0.58,
          0.54,
          0.54,
          0.69,
          0.55,
          0.85,
          0.85,
          0.94,
          0.85,
          0.87,
          0.62,
          0.62,
          0.48,
          0.69,
          0.83,
          0.77,
          0.77,
          0.82,
          0.51,
          0.47,
          0.72,
          0.73,
          0.64,
          0.78,
          0.62,
          0.64,
          0.4,
          0.64,
          0.4,
          0.46,
          0.56,
          0.4,
          0.62,
          0.68,
          0.48,
          0.61,
          0.59,
          0.58,
          0.58,
          0.69,
          0.42,
          0.7,
          0.63,
          1.15,
          0.55,
          0.58,
          0.72,
          0.6,
          0.6,
          0.87,
          0.55,
          0.75,
          0.57,
          0.53,
          0.43,
          0.53,
          0.54,
          0.56,
          0.6,
          0.54,
          0.57,
          0.64,
          0.64,
          0.68,
          0.63,
          0.56,
          0.57,
          1.17,
          1.17,
          0.59,
          0.75,
          0.67,
          0.45,
          0.61,
          0.56,
          0.4,
          0.61,
          0.74,
          0.8,
          0.44,
          0.53,
          0.62,
          0.61,
          0.59,
          0.47,
          0.58,
          0.59,
          1.33,
          0.59,
          0.55,
          0.6,
          0.6,
          0.6,
          0.6,
          0.52,
          0.56,
          0.56,
          0.46,
          0.43,
          0.51,
          0.52,
          0.66,
          0.45,
          0.45,
          0.45,
          0.54,
          0.54,
          0.54,
          0.54,
          0.53,
          0.53,
          0.56,
          0.39,
          0.51,
          0.46,
          0.44,
          0.44,
          0.59,
          0.5,
          0.65,
          0.54,
          0.65,
          0.53,
          0.5,
          1.18,
          0.5,
          1.17,
          1.03,
          1.17,
          0.46,
          0.51,
          0.62,
          0.62,
          0.49,
          0.49,
          0.5,
          0.42,
          0.58,
          0.68,
          0.59,
          0.58,
          0.48,
          0.48,
          0.65,
          0.65,
          0.52,
          0.72,
          0.51,
          0.82,
          1.1,
          0.62,
          0.94,
          0.93,
          1.01,
          0.93,
          0.44,
          0.73,
          0.94,
          0.9,
          0.78,
          0.84,
          0.78,
          0.77,
          0.46,
          0.45,
          0.46,
          0.58,
          0.84,
          0.67,
          0.58,
          0.63,
          0.93,
          0.62,
          0.54,
          0.74,
          0.77,
          0.65,
          0.54,
          0.47,
          0.68,
          0.49,
          0.52,
          0.74,
          0.76,
          0.73,
          0.78,
          0.76,
          0.69,
          0.63,
          0.58,
          0.6,
          0.8,
          0.68,
          0.61,
          0.53,
          0.67,
          0.65,
          0.57,
          0.65,
          0.55,
          0.47,
          0.52,
          0.79,
          0.54,
          0.75,
          0.88,
          0.75,
          0.88,
          0.52,
          0.68,
          0.62,
          0.68,
          0.61,
          0.55,
          0.6,
          0.78,
          0.58,
          0.56,
          0.54,
          0.59,
          0.7,
          0.81,
          0.63,
          0.63,
          0.53,
          0.69,
          0.55,
          0.63,
          0.66,
          0.55,
          0.72,
          0.7,
          0.77,
          0.67,
          0.72,
          0.72,
          0.83,
          0.63,
          0.58,
          0.97,
          0.6,
          0.64,
          0.65,
          0.67,
          0.6,
          0.69,
          0.66,
          0.68,
          0.61,
          0.62,
          0.59,
          0.63,
          0.63,
          0.81,
          0.64,
          0.61,
          0.58,
          0.7,
          0.54,
          0.66,
          0.6,
          0.68,
          0.56,
          0.6,
          0.56,
          0.52,
          0.52,
          0.52,
          0.54,
          0.54,
          0.82,
          0.71,
          0.54,
          0.59,
          0.57,
          0.93,
          0.65,
          0.51,
          0.67,
          0.64,
          0.78,
          0.6,
          0.67,
          0.6,
          0.5,
          0.62,
          0.8,
          0.85,
          0.66,
          0.82,
          0.56,
          0.75,
          0.82,
          0.58,
          0.76,
          0.71
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of sulphates in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "sulphates"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "density=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "",
         "offsetgroup": "",
         "orientation": "v",
         "showlegend": false,
         "type": "histogram",
         "x": [
          0.9978,
          0.9968,
          0.997,
          0.998,
          0.9978,
          0.9978,
          0.9964,
          0.9946,
          0.9968,
          0.9959,
          0.9943,
          0.9974,
          0.9969,
          0.9969,
          0.9982,
          0.9966,
          0.9968,
          0.9968,
          0.9955,
          0.9962,
          0.9972,
          0.9964,
          0.9958,
          0.9966,
          0.9957,
          0.9986,
          0.9975,
          0.9968,
          0.9978,
          0.9976,
          0.9968,
          0.9968,
          0.9934,
          0.997,
          0.9971,
          0.9956,
          0.9955,
          0.997,
          0.9955,
          0.9971,
          0.9975,
          0.9962,
          0.998,
          0.9968,
          0.9966,
          0.9962,
          0.9962,
          0.9962,
          0.9962,
          0.9961,
          0.9976,
          0.9986,
          0.9966,
          0.9958,
          0.9972,
          0.9958,
          0.997,
          0.9959,
          0.9961,
          0.9972,
          0.9966,
          0.9978,
          0.9978,
          0.9964,
          0.9972,
          0.9966,
          0.9938,
          0.9965,
          0.9967,
          0.9972,
          0.9972,
          0.9972,
          0.9967,
          0.996,
          0.9967,
          0.9973,
          0.9969,
          0.9964,
          0.9964,
          0.9988,
          0.9964,
          0.9966,
          0.9978,
          0.9962,
          0.9962,
          0.998,
          0.996,
          0.9964,
          0.9964,
          0.9962,
          0.9968,
          0.9937,
          0.9959,
          0.9965,
          0.9972,
          0.9965,
          0.9916,
          0.9954,
          0.9916,
          0.9968,
          0.9944,
          0.9959,
          0.9958,
          0.9996,
          0.995,
          0.995,
          0.9973,
          0.9973,
          0.9973,
          0.9969,
          0.9968,
          0.9959,
          0.9965,
          0.9964,
          0.9982,
          0.9981,
          0.9961,
          0.9956,
          0.9956,
          0.9953,
          0.9972,
          0.9972,
          0.9961,
          0.9958,
          0.9961,
          0.9972,
          0.9969,
          0.9969,
          0.9969,
          0.9972,
          0.9972,
          0.9971,
          0.997,
          0.9971,
          0.9972,
          0.9968,
          0.9976,
          0.9974,
          0.9964,
          0.9964,
          0.9968,
          0.9981,
          0.9948,
          0.99695,
          0.99615,
          0.9994,
          0.9994,
          0.9966,
          0.99585,
          0.99685,
          0.9959,
          0.9974,
          0.9974,
          0.9962,
          0.9967,
          0.9957,
          0.9964,
          0.9957,
          0.99525,
          0.99815,
          0.99615,
          0.9964,
          0.9927,
          0.99625,
          0.998,
          0.99685,
          0.99675,
          0.9971,
          0.99925,
          0.99565,
          1.00005,
          1.00005,
          0.9983,
          0.99685,
          0.9983,
          0.9985,
          0.9972,
          0.9986,
          0.9959,
          0.99675,
          0.998,
          0.9968,
          0.9968,
          0.99965,
          0.99625,
          0.99565,
          0.99575,
          0.9963,
          0.9999,
          1.00025,
          0.9973,
          0.9987,
          0.9996,
          0.9965,
          0.9965,
          0.9987,
          0.9996,
          0.9976,
          0.9991,
          0.9986,
          0.9972,
          0.9991,
          1.00015,
          1.00015,
          0.9997,
          0.9967,
          0.9976,
          1.001,
          0.9976,
          0.9994,
          0.9964,
          1.0014,
          1.0001,
          0.9981,
          0.99855,
          0.9993,
          0.9965,
          0.9973,
          0.9994,
          0.9973,
          0.9966,
          0.9994,
          0.9994,
          0.996,
          0.99815,
          0.9976,
          0.99645,
          0.9989,
          0.99865,
          0.99975,
          1.0015,
          1.0015,
          0.9978,
          0.998,
          1.0002,
          0.9958,
          0.9963,
          0.9992,
          0.9948,
          0.9974,
          0.9997,
          0.9982,
          0.9982,
          1.0006,
          0.9986,
          0.9979,
          0.9994,
          0.9974,
          1.0018,
          0.9912,
          0.9955,
          1.0001,
          0.997,
          1,
          1.001,
          0.9973,
          0.9982,
          0.9992,
          0.9988,
          1.0022,
          1.0022,
          1,
          0.9962,
          0.9967,
          0.9967,
          1.0003,
          0.9962,
          0.9988,
          0.9974,
          0.998,
          0.9981,
          0.9924,
          1.0014,
          0.998,
          1.0004,
          0.9994,
          0.9988,
          0.9963,
          0.9994,
          1,
          0.9994,
          0.9974,
          0.9981,
          0.9996,
          0.9981,
          0.9987,
          0.9966,
          0.9986,
          0.9982,
          1.0014,
          0.997,
          0.9956,
          0.9996,
          0.9976,
          0.9952,
          0.9955,
          0.9978,
          0.9952,
          0.9949,
          0.9988,
          0.9978,
          0.9997,
          0.9978,
          0.9974,
          1.0004,
          0.9996,
          1.0004,
          0.9958,
          0.9986,
          0.9951,
          0.9987,
          1.0032,
          0.9934,
          0.9996,
          0.9968,
          0.9967,
          0.9994,
          0.9994,
          0.9968,
          0.9998,
          0.9952,
          0.9988,
          0.9986,
          0.9988,
          1.0008,
          0.9976,
          0.9982,
          0.9987,
          0.9982,
          0.9947,
          1,
          0.9952,
          0.9996,
          0.997,
          0.9995,
          0.9988,
          0.998,
          0.9977,
          0.9984,
          1.0026,
          0.9964,
          0.9986,
          0.9976,
          0.9982,
          0.9984,
          0.9952,
          0.995,
          1.0002,
          0.9952,
          0.9972,
          0.9984,
          0.9966,
          0.9972,
          1.0002,
          0.9984,
          0.999,
          0.999,
          0.9976,
          0.9968,
          0.9976,
          1,
          0.9986,
          0.9994,
          0.998,
          0.9973,
          0.9973,
          1.001,
          1.001,
          0.9994,
          0.9982,
          0.9978,
          0.9976,
          0.9962,
          0.9974,
          0.999,
          1.0004,
          1.0004,
          0.9956,
          1,
          0.999,
          0.9974,
          0.9972,
          1.0014,
          0.9996,
          0.9988,
          0.9988,
          0.9966,
          0.9993,
          1.0008,
          0.9982,
          0.9983,
          0.9987,
          0.9994,
          0.9958,
          0.998,
          0.998,
          0.9934,
          1.00315,
          1.0002,
          1.00315,
          1.0021,
          0.9994,
          0.9982,
          0.9971,
          1.0021,
          0.9994,
          0.9991,
          0.999,
          0.9946,
          1.0003,
          0.9978,
          0.9978,
          0.9982,
          0.9982,
          0.9976,
          1.0002,
          1.0002,
          0.9976,
          0.9967,
          0.9917,
          0.9987,
          0.9922,
          0.9987,
          1.0004,
          0.9998,
          0.9994,
          0.9967,
          0.9975,
          0.9984,
          0.9982,
          1.0026,
          0.9956,
          0.9983,
          1.0006,
          0.9965,
          0.9997,
          0.9982,
          0.9988,
          0.9976,
          0.9976,
          0.9974,
          0.9997,
          0.9988,
          0.9988,
          0.9976,
          0.9964,
          0.9976,
          0.9988,
          0.9964,
          1.001,
          0.9964,
          0.9954,
          0.9979,
          0.9978,
          0.997,
          0.9991,
          0.9991,
          0.9991,
          0.9967,
          0.9964,
          0.9948,
          0.9986,
          0.9976,
          0.9976,
          0.9979,
          1.0004,
          0.9986,
          0.998,
          0.9973,
          0.9973,
          0.9978,
          0.9972,
          0.9981,
          0.998,
          0.9988,
          0.9988,
          0.9968,
          0.9968,
          0.9984,
          0.9979,
          0.9983,
          0.9972,
          0.9962,
          0.998,
          0.997,
          0.998,
          0.997,
          0.9962,
          0.9976,
          0.9998,
          0.9979,
          0.9984,
          0.9984,
          0.9921,
          0.9972,
          1.0001,
          0.9986,
          0.9984,
          0.9972,
          0.997,
          0.9972,
          0.998,
          0.999,
          0.9956,
          0.9966,
          0.996,
          0.9985,
          0.9998,
          0.998,
          0.9968,
          0.9976,
          0.9976,
          0.9976,
          0.9982,
          0.9965,
          0.9976,
          0.9994,
          0.997,
          0.997,
          0.995,
          0.9982,
          0.9994,
          0.9966,
          0.998,
          0.9987,
          0.9963,
          1.0002,
          0.999,
          0.9965,
          0.99788,
          1.0001,
          0.99768,
          0.9978,
          0.99761,
          0.99768,
          0.99803,
          0.99785,
          0.99803,
          0.99656,
          0.99525,
          0.99488,
          0.99656,
          0.99656,
          0.99823,
          0.99779,
          0.99738,
          0.99701,
          0.99888,
          0.99888,
          0.99738,
          0.99744,
          0.99668,
          0.99744,
          0.9978,
          0.99782,
          0.9973,
          0.99586,
          0.9961,
          0.99788,
          0.99745,
          0.99676,
          0.99732,
          0.99746,
          0.9982,
          0.9991,
          0.9991,
          0.998,
          0.99708,
          0.99818,
          0.99745,
          0.99639,
          0.99531,
          0.99786,
          0.99746,
          0.99526,
          0.9987,
          0.99735,
          0.99264,
          0.9971,
          0.99682,
          0.99386,
          0.99702,
          0.99693,
          0.99562,
          1.00012,
          0.99462,
          0.99939,
          0.99976,
          0.99606,
          0.99154,
          0.9973,
          0.99682,
          0.9951,
          0.99624,
          0.99632,
          0.99376,
          0.99836,
          0.99064,
          0.99064,
          0.99672,
          0.99629,
          0.99708,
          0.9963,
          0.99689,
          0.9977,
          0.99689,
          0.99708,
          0.99708,
          0.99652,
          0.99652,
          0.99652,
          0.99594,
          0.99686,
          0.99746,
          0.99628,
          0.99746,
          0.99748,
          0.99522,
          0.99576,
          0.99614,
          0.99371,
          0.99533,
          0.99536,
          0.99787,
          0.99824,
          0.99836,
          0.99491,
          1.00289,
          0.99743,
          0.99774,
          0.99743,
          0.99745,
          0.9955,
          0.99444,
          0.9955,
          0.99444,
          0.99562,
          0.99736,
          0.99736,
          0.9962,
          0.9964,
          0.9948,
          0.99528,
          0.99577,
          0.99901,
          0.99674,
          0.99512,
          0.99395,
          0.99824,
          0.9964,
          0.99504,
          0.99786,
          0.99504,
          0.99516,
          0.99604,
          0.99786,
          0.99736,
          0.99516,
          0.99468,
          0.99748,
          0.9971,
          0.99746,
          0.99543,
          0.99425,
          0.99484,
          0.99834,
          0.99498,
          0.99745,
          0.99408,
          0.99552,
          0.99552,
          0.99408,
          0.99536,
          0.99458,
          0.99648,
          0.99568,
          0.99519,
          0.99518,
          0.99592,
          0.99654,
          0.99518,
          0.99733,
          0.9943,
          0.99724,
          0.99658,
          0.997,
          0.99801,
          0.99416,
          0.99774,
          0.99712,
          0.99418,
          0.99774,
          0.99562,
          0.99693,
          0.99596,
          0.99556,
          0.99596,
          0.99694,
          0.99694,
          0.99697,
          0.99554,
          0.99162,
          0.99495,
          0.99603,
          0.9928,
          0.99516,
          0.99516,
          0.99549,
          0.99354,
          0.9957,
          0.99604,
          0.99635,
          0.99454,
          0.99486,
          0.99007,
          0.99636,
          0.99642,
          0.99642,
          0.99584,
          0.99506,
          0.99568,
          0.99822,
          0.99364,
          0.99378,
          0.99568,
          0.99854,
          0.99739,
          0.99683,
          0.99356,
          0.9953,
          0.99692,
          0.99547,
          0.99294,
          0.99438,
          0.99612,
          0.99634,
          0.99702,
          0.99704,
          0.99702,
          0.99258,
          0.99426,
          0.99747,
          0.99586,
          0.99784,
          0.9971,
          0.99586,
          0.9981,
          0.99462,
          0.9956,
          0.99565,
          0.99418,
          0.9963,
          0.99358,
          0.99572,
          0.997,
          0.99498,
          0.99892,
          0.9972,
          0.99534,
          0.99817,
          0.99316,
          0.99316,
          0.99685,
          0.99617,
          0.99529,
          0.99738,
          0.994,
          0.99735,
          0.99735,
          0.99451,
          0.99546,
          0.99479,
          0.99615,
          0.99655,
          0.99655,
          0.99666,
          0.99392,
          0.99388,
          0.99388,
          0.9936,
          0.99374,
          0.99523,
          0.99855,
          0.9982,
          0.99593,
          0.99471,
          0.99396,
          0.9902,
          0.99572,
          0.99572,
          0.99572,
          0.99252,
          0.99256,
          0.99235,
          0.9922,
          0.99394,
          0.99379,
          0.9984,
          0.9977,
          0.9933,
          0.99684,
          0.99524,
          0.9946,
          0.99774,
          0.99786,
          0.99764,
          0.9969,
          0.99624,
          0.99354,
          0.99672,
          0.99588,
          0.99672,
          0.996,
          0.99702,
          0.99526,
          0.99585,
          0.99352,
          0.99616,
          0.99622,
          0.99616,
          0.99524,
          0.9924,
          0.99434,
          0.99692,
          0.99528,
          0.99384,
          0.99502,
          0.99667,
          0.99649,
          0.99716,
          0.99716,
          0.99541,
          0.99572,
          0.99346,
          0.99599,
          0.99478,
          0.99572,
          0.99538,
          0.99538,
          0.99616,
          0.99652,
          0.99551,
          0.99439,
          0.99588,
          0.99633,
          0.99458,
          0.9951,
          0.99686,
          0.99458,
          0.99419,
          0.99516,
          0.99878,
          0.99534,
          0.99534,
          0.99752,
          0.99534,
          0.99428,
          0.99498,
          0.99498,
          0.99628,
          0.99677,
          0.99478,
          0.99734,
          0.99734,
          0.9992,
          0.99922,
          0.99592,
          0.99769,
          0.99157,
          0.99718,
          0.9947,
          0.99621,
          0.99718,
          0.99242,
          0.99659,
          0.99242,
          0.99798,
          0.99488,
          0.99494,
          0.9983,
          0.99655,
          0.99502,
          0.99514,
          0.9963,
          0.99627,
          0.99569,
          0.99628,
          0.99499,
          0.99633,
          0.99538,
          0.99632,
          0.99437,
          0.99726,
          0.99456,
          0.99564,
          0.99564,
          0.996,
          0.99668,
          0.99084,
          0.9935,
          0.99385,
          0.99494,
          0.9944,
          0.99688,
          0.99566,
          0.99636,
          0.99688,
          0.9948,
          0.9956,
          0.9956,
          0.99619,
          0.99734,
          0.99476,
          0.99734,
          0.99914,
          0.99914,
          0.99521,
          0.99638,
          0.99362,
          0.99558,
          0.99323,
          0.99191,
          0.99476,
          0.99444,
          0.99598,
          0.99576,
          0.9955,
          0.99612,
          0.9979,
          0.996,
          0.9929,
          0.99532,
          0.99616,
          0.99258,
          0.99652,
          0.99258,
          0.99392,
          0.9948,
          0.9948,
          0.9948,
          0.9948,
          0.9955,
          0.99616,
          0.99616,
          0.99668,
          0.99581,
          0.9976,
          0.99608,
          0.99387,
          0.99448,
          0.99448,
          0.99448,
          0.99538,
          0.99538,
          0.99538,
          0.99538,
          0.99852,
          0.99613,
          0.99472,
          0.99587,
          0.99332,
          0.9969,
          0.99464,
          0.99464,
          0.99648,
          0.99736,
          0.99704,
          0.99724,
          0.99704,
          0.995,
          0.99576,
          0.99725,
          0.99656,
          0.99623,
          0.99476,
          0.99623,
          0.9946,
          0.99609,
          0.99557,
          0.99557,
          0.99613,
          0.99613,
          0.99593,
          0.99668,
          0.9961,
          0.99718,
          0.99292,
          0.99612,
          0.9942,
          0.99612,
          0.99745,
          0.99745,
          0.99584,
          0.9956,
          0.9962,
          0.9963,
          0.996,
          0.9985,
          0.9974,
          0.995,
          0.995,
          0.995,
          0.9936,
          0.9963,
          0.9974,
          0.9963,
          0.9994,
          0.9966,
          0.9994,
          0.9952,
          0.995,
          0.9956,
          0.995,
          0.9965,
          0.9956,
          0.9968,
          0.9957,
          0.9962,
          0.996,
          0.9956,
          0.9958,
          0.9955,
          1.00369,
          0.99914,
          0.99577,
          0.996,
          0.99566,
          0.99322,
          0.99713,
          0.99701,
          0.99472,
          0.9947,
          0.99732,
          0.99374,
          0.99974,
          0.99467,
          0.99706,
          0.99603,
          0.99458,
          0.99724,
          0.99664,
          0.99522,
          0.9958,
          0.99728,
          0.99648,
          0.99728,
          0.99705,
          0.99578,
          0.99334,
          0.99656,
          0.99336,
          1.00242,
          0.99182,
          1.00242,
          0.99182,
          0.99808,
          0.99828,
          0.99498,
          0.99828,
          0.99542,
          0.99606,
          0.99546,
          0.99496,
          0.9942,
          0.99344,
          0.99348,
          0.99636,
          0.99459,
          0.99492,
          0.99508,
          0.99508,
          0.99642,
          0.99555,
          0.99605,
          0.996,
          0.99562,
          0.99605,
          0.99814,
          0.9941,
          0.99661,
          0.99712,
          0.99842,
          0.99842,
          0.99489,
          0.99647,
          0.99665,
          0.99633,
          0.9953,
          0.99552,
          0.99553,
          0.99714,
          0.99608,
          0.99444,
          0.99631,
          0.99573,
          0.99717,
          0.99397,
          0.9959,
          0.99538,
          0.99646,
          0.9955,
          0.99531,
          0.99575,
          0.99783,
          0.99419,
          0.99768,
          0.99586,
          0.99765,
          0.99514,
          0.99636,
          0.99627,
          0.99787,
          0.99622,
          0.99622,
          0.99622,
          0.99546,
          0.99546,
          0.99489,
          0.99494,
          0.99546,
          0.99629,
          0.99396,
          0.9934,
          0.99514,
          0.99632,
          0.99467,
          0.99474,
          0.99588,
          0.99622,
          0.9954,
          0.9947,
          0.99362,
          0.99578,
          0.99484,
          0.99492,
          0.99483,
          0.99314,
          0.99402,
          0.99574,
          0.99651,
          0.9949,
          0.99512,
          0.99547
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Distribution of density in the wine samples"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "density"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "count"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.histogram(wine_dataset, x='fixed acidity', title='Distribution of fixed acidity')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='volatile acidity', title='Distribution of volatile acidity in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='citric acid', title='Distribution of citric acid in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='residual sugar', title='Distribution of residual sugar in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='chlorides', title='Distribution of chlorides in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='free sulfur dioxide', title='Distribution of free sulfur dioxide in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='total sulfur dioxide', title='Distribution of total sulfur dioxide in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='sulphates', title='Distribution of sulphates in the wine samples')\n",
    "fig.show()\n",
    "\n",
    "fig = px.histogram(wine_dataset, x='density', title='Distribution of density in the wine samples')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set = 925\n",
      "Size of validation set = 103\n",
      "Size of test set = 115\n"
     ]
    }
   ],
   "source": [
    "X = wine_dataset.drop('quality', axis=1)\n",
    "y = wine_dataset['quality']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=52)\n",
    "\n",
    "print(f\"Size of training set = {len(X_train)}\\nSize of validation set = {len(X_val)}\\nSize of test set = {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 4 3 2 2 3 3 3 3 2 0 4 2 3 2 4 2 3 1 2 3 3 3 2 3 3 3 2 2 3 2 3 2 2 4 1\n",
      " 3 2 3 3 2 2 3 3 3 2 3 3 2 2 4 2 3 3 2 2 2 3 3 3 3 2 4 3 3 2 2 2 2 3 2 4 2\n",
      " 2 3 2 2 4 2 3 2 4 3 2 3 2 3 1 3 2 2 4 3 2 3 3 2 3 1]\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_train -= 3 # To make the range of values from 0 to 5\n",
    "print(y_train[:100])\n",
    "\n",
    "X_val = X_val.to_numpy()\n",
    "y_val = y_val.to_numpy()\n",
    "y_val -= 3 # To make the range of values from 0 to 5\n",
    "\n",
    "X_test = X_test.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "y_test -= 3 # To make the range of values from 0 to 5\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)\n",
    "X_test = scaler.fit_transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((925, 12), (925,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33marjundosajh100\u001b[0m (\u001b[33marjundosajh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(y, n_classes):\n",
    "        return np.eye(n_classes)[y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultinomialLogisticRegression:\n",
    "    def __init__(self, learning_rate, epochs, X_train, y_train, X_val, y_val):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.X_train = X_train\n",
    "        self.X_val = X_val\n",
    "        self.y_train = self.one_hot_encode(y_train, len(np.unique(y_train)))\n",
    "        self.y_val = self.one_hot_encode(y_val, len(np.unique(y_val)))\n",
    "\n",
    "    def one_hot_encode(self, y, n_classes):\n",
    "        return np.eye(n_classes)[y]\n",
    "    \n",
    "    def softmax(self, z):\n",
    "        exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
    "        softmax_scores = exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "        return softmax_scores\n",
    "    \n",
    "    def accuracy(self, y_true, y_pred):\n",
    "        y_true_class = np.argmax(y_true, axis=1)\n",
    "        y_pred_class = np.argmax(y_pred, axis=1)\n",
    "        return np.mean(y_true_class == y_pred_class)\n",
    "\n",
    "\n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        n_samples = y_true.shape[0]\n",
    "        epsilon = 1e-15  # Add a smoothing factor\n",
    "        y_pred = np.clip(y_pred, epsilon, 1. - epsilon)  # Ensure predictions are within [epsilon, 1-epsilon]\n",
    "        logp = - np.log(y_pred[np.arange(n_samples), y_true.argmax(axis=1)])\n",
    "        loss = np.sum(logp) / n_samples\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def gradient_descent(self, X, y, y_pred):\n",
    "        m = X.shape[0]\n",
    "        gradient = np.dot(X.T, (y_pred - y)) / m\n",
    "        self.weights = self.weights - self.lr * gradient\n",
    "\n",
    "    def train(self):\n",
    "        num_features = self.X_train.shape[1]\n",
    "        num_classes = self.y_train.shape[1]\n",
    "        self.weights = np.zeros((num_features, num_classes))\n",
    "        train_loss_array = np.array([])\n",
    "        val_loss_array = np.array([])\n",
    "        # self.weights = np.random.randn(num_features, num_classes) * 0.01 # weights are small random numbers\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            linear_model_train = np.dot(self.X_train, self.weights)\n",
    "            linear_model_val = np.dot(self.X_val, self.weights)\n",
    "\n",
    "            y_train_pred = self.softmax(linear_model_train)\n",
    "            y_val_pred = self.softmax(linear_model_val)\n",
    "\n",
    "            train_loss = self.cross_entropy_loss(self.y_train, y_train_pred)\n",
    "            val_loss = self.cross_entropy_loss(self.y_val, y_val_pred)\n",
    "\n",
    "            train_loss_array = np.append(train_loss_array, train_loss)\n",
    "            val_loss_array = np.append(val_loss_array, val_loss)\n",
    "\n",
    "            train_acc = self.accuracy(self.y_train, y_train_pred)\n",
    "            val_acc = self.accuracy(self.y_val, y_val_pred)\n",
    "            \n",
    "            self.gradient_descent(self.X_train, self.y_train, y_train_pred)\n",
    "\n",
    "            # wandb.log({\n",
    "            #     'epoch': _,\n",
    "            #     'train_loss': train_loss,\n",
    "            #     'val_loss': val_loss,\n",
    "            #     'train_accuracy': train_acc,\n",
    "            #     'val_accuracy': val_acc\n",
    "            # })\n",
    "\n",
    "            if _ % 10 == 0:\n",
    "                print(f'Epoch: {_}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc*100:.4f}%')\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights)\n",
    "        y_pred = self.softmax(linear_model)\n",
    "        return np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9mjqn0my) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▂▃▄▄▅▆▆▅▅▅▅▅▅▆▆▇▇▇▇██▇▇▇▇▇▇█████████▇▇▇</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▁▂▃▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▄▆▆▇█████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>999</td></tr><tr><td>train_accuracy</td><td>0.56865</td></tr><tr><td>train_loss</td><td>1.41101</td></tr><tr><td>val_accuracy</td><td>0.59223</td></tr><tr><td>val_loss</td><td>1.34843</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">faithful-salad-1</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203%20sample%20run/runs/9mjqn0my' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203%20sample%20run/runs/9mjqn0my</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_184319-9mjqn0my/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:9mjqn0my). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_184927-grxnd1ks</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/grxnd1ks' target=\"_blank\">laced-universe-1</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/grxnd1ks' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/grxnd1ks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/grxnd1ks?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x155067f90>"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='SMAI-Assignment 3', config={\n",
    "    'Model': 'Multinomial Logistic Regression',\n",
    "    'Epochs': 10000\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.6603, Train Accuracy: 51.7838%\n",
      "Epoch: 20, Train Loss: 1.5855, Train Accuracy: 52.4324%\n",
      "Epoch: 30, Train Loss: 1.5405, Train Accuracy: 53.1892%\n",
      "Epoch: 40, Train Loss: 1.5116, Train Accuracy: 52.9730%\n",
      "Epoch: 50, Train Loss: 1.4920, Train Accuracy: 53.2973%\n",
      "Epoch: 60, Train Loss: 1.4781, Train Accuracy: 53.5135%\n",
      "Epoch: 70, Train Loss: 1.4679, Train Accuracy: 53.9459%\n",
      "Epoch: 80, Train Loss: 1.4602, Train Accuracy: 53.9459%\n",
      "Epoch: 90, Train Loss: 1.4541, Train Accuracy: 54.3784%\n",
      "Epoch: 100, Train Loss: 1.4492, Train Accuracy: 54.3784%\n",
      "Epoch: 110, Train Loss: 1.4453, Train Accuracy: 54.4865%\n",
      "Epoch: 120, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 130, Train Loss: 1.4391, Train Accuracy: 55.0270%\n",
      "Epoch: 140, Train Loss: 1.4367, Train Accuracy: 55.2432%\n",
      "Epoch: 150, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 160, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 170, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 180, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 190, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 200, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 210, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 220, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 230, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 240, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 250, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 260, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 270, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 280, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 290, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 300, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 310, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 320, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 330, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 340, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 350, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 360, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 370, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 380, Train Loss: 1.4169, Train Accuracy: 56.0000%\n",
      "Epoch: 390, Train Loss: 1.4167, Train Accuracy: 56.0000%\n",
      "Epoch: 400, Train Loss: 1.4164, Train Accuracy: 56.2162%\n",
      "Epoch: 410, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 420, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 430, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 440, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 450, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 460, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 470, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 480, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 490, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 500, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 510, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 520, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 530, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 540, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 550, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 560, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 570, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 580, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 590, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 600, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 610, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 620, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 630, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 640, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 650, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 660, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 670, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 680, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 690, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 700, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 710, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 720, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 730, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 740, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 750, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 760, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 770, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 780, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 790, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 800, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 810, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 820, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 830, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 840, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 850, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 860, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 870, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 880, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 890, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 900, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 910, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 920, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 930, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 940, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 950, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 960, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 970, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 980, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 990, Train Loss: 1.4110, Train Accuracy: 56.8649%\n"
     ]
    }
   ],
   "source": [
    "model_0 = MultinomialLogisticRegression(learning_rate=0.1, epochs=1000, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "model_0.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00         1\n",
      "           1       0.00      0.00      1.00         3\n",
      "           2       0.66      0.77      0.71        43\n",
      "           3       0.74      0.45      0.56        44\n",
      "           4       0.38      0.73      0.50        11\n",
      "           5       0.00      0.00      1.00         1\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       103\n",
      "   macro avg       0.46      0.32      0.63       103\n",
      "weighted avg       0.64      0.59      0.63       103\n",
      " samples avg       0.59      0.59      1.00       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n",
      "wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = model_0.predict(X_val)\n",
    "y_val_one_hot = one_hot_encode(y_val, 6)\n",
    "y_pred_val_one_hot = one_hot_encode(y_pred_val, 6)\n",
    "print(\"Validation Classification Report\")\n",
    "print(classification_report(y_val_one_hot, y_pred_val_one_hot, zero_division=1)) # zero division is set to 1 because some classes are never predicted by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190106-ytqgotmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/ytqgotmm' target=\"_blank\">Logistic Regression lr=0.1</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/ytqgotmm' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/ytqgotmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.6603, Train Accuracy: 51.7838%\n",
      "Epoch: 20, Train Loss: 1.5855, Train Accuracy: 52.4324%\n",
      "Epoch: 30, Train Loss: 1.5405, Train Accuracy: 53.1892%\n",
      "Epoch: 40, Train Loss: 1.5116, Train Accuracy: 52.9730%\n",
      "Epoch: 50, Train Loss: 1.4920, Train Accuracy: 53.2973%\n",
      "Epoch: 60, Train Loss: 1.4781, Train Accuracy: 53.5135%\n",
      "Epoch: 70, Train Loss: 1.4679, Train Accuracy: 53.9459%\n",
      "Epoch: 80, Train Loss: 1.4602, Train Accuracy: 53.9459%\n",
      "Epoch: 90, Train Loss: 1.4541, Train Accuracy: 54.3784%\n",
      "Epoch: 100, Train Loss: 1.4492, Train Accuracy: 54.3784%\n",
      "Epoch: 110, Train Loss: 1.4453, Train Accuracy: 54.4865%\n",
      "Epoch: 120, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 130, Train Loss: 1.4391, Train Accuracy: 55.0270%\n",
      "Epoch: 140, Train Loss: 1.4367, Train Accuracy: 55.2432%\n",
      "Epoch: 150, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 160, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 170, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 180, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 190, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 200, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 210, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 220, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 230, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 240, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 250, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 260, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 270, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 280, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 290, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 300, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 310, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 320, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 330, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 340, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 350, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 360, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 370, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 380, Train Loss: 1.4169, Train Accuracy: 56.0000%\n",
      "Epoch: 390, Train Loss: 1.4167, Train Accuracy: 56.0000%\n",
      "Epoch: 400, Train Loss: 1.4164, Train Accuracy: 56.2162%\n",
      "Epoch: 410, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 420, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 430, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 440, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 450, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 460, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 470, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 480, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 490, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 500, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 510, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 520, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 530, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 540, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 550, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 560, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 570, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 580, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 590, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 600, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 610, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 620, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 630, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 640, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 650, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 660, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 670, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 680, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 690, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 700, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 710, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 720, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 730, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 740, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 750, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 760, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 770, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 780, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 790, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 800, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 810, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 820, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 830, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 840, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 850, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 860, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 870, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 880, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 890, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 900, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 910, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 920, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 930, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 940, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 950, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 960, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 970, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 980, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 990, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 1000, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 1010, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 1020, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 1030, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 1040, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 1050, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 1060, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 1070, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 1080, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 1090, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 1100, Train Loss: 1.4108, Train Accuracy: 57.0811%\n",
      "Epoch: 1110, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 1120, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 1130, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 1140, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 1150, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 1160, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 1170, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 1180, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1190, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1200, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1210, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1220, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1230, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1240, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 1250, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 1260, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 1270, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 1280, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 1290, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 1300, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 1310, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 1320, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 1330, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 1340, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 1350, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 1360, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 1370, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 1380, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 1390, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 1400, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 1410, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 1420, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 1430, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 1440, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 1450, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1460, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1470, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1480, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1490, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1500, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1510, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 1520, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 1530, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 1540, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 1550, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 1560, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 1570, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1580, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1590, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1600, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1610, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1620, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1630, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1640, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1650, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 1660, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1670, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1680, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1690, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1700, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1710, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1720, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1730, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1740, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1750, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1760, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1770, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1780, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1790, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1800, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1810, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1820, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1830, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 1840, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1850, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1860, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1870, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1880, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1890, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1900, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1910, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1920, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 1930, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1940, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1950, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1960, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1970, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1980, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1990, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 2000, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 2010, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 2020, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 2030, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2040, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2050, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2060, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2070, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2080, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 2090, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2100, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2110, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2120, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2130, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2140, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2150, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2160, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2170, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2180, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2190, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2200, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2210, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2220, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2230, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2240, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2250, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2260, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2270, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2280, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2290, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2300, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2310, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2320, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2330, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2340, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2350, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2360, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2370, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2380, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2390, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2400, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2410, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2420, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2430, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2440, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2450, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2460, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2470, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2480, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2490, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2500, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2510, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 2520, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 2530, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 2540, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 2550, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2560, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2570, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2580, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2590, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2600, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2610, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2620, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2630, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2640, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2650, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2660, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2670, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2680, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2690, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2700, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2710, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2720, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2730, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2740, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2750, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2760, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2770, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2780, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2790, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2800, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2810, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2820, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2830, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2840, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2850, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2860, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2870, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2880, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2890, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2900, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2910, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2920, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2930, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2940, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2950, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2960, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2970, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2980, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2990, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3000, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3010, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3020, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3030, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3040, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3050, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3060, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3070, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3080, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3090, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3100, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3110, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3120, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3130, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3140, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3150, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3160, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3170, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3180, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3190, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3200, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3210, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3220, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3230, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3240, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3250, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3260, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3270, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3280, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3290, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3300, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3310, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3320, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3330, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3340, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3350, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3360, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3370, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3380, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3390, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3400, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3410, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3420, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3430, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3440, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3450, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3460, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3470, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3480, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3490, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3500, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3510, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3520, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3530, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3540, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3550, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3560, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 3570, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3580, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3590, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3600, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3610, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3620, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3630, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3640, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3650, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3660, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3670, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3680, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3690, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3700, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3710, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3720, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3730, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3740, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3750, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3760, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3770, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3780, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3790, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3800, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3810, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3820, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3830, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3840, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3850, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3860, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3870, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3880, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3890, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3900, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3910, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3920, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3930, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3940, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3950, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3960, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3970, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3980, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 3990, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 4000, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 4010, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 4020, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4030, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4040, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4050, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4060, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4070, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4080, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4090, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4100, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4110, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4120, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4130, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4140, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4150, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4160, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4170, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4180, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4190, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4200, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4210, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 4220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ytqgotmm) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▇█▇█▇▇▆▆▆▆▆▆▇▇▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>train_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▆▆▆▆▆▇███████████████████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56757</td></tr><tr><td>train_loss</td><td>1.40974</td></tr><tr><td>val_accuracy</td><td>0.61165</td></tr><tr><td>val_loss</td><td>1.34033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.1</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/ytqgotmm' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/ytqgotmm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190106-ytqgotmm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ytqgotmm). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190119-slksf98y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/slksf98y' target=\"_blank\">Logistic Regression lr=0.01</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/slksf98y' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/slksf98y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7750, Train Accuracy: 51.6757%\n",
      "Epoch: 20, Train Loss: 1.7593, Train Accuracy: 51.6757%\n",
      "Epoch: 30, Train Loss: 1.7444, Train Accuracy: 51.6757%\n",
      "Epoch: 40, Train Loss: 1.7305, Train Accuracy: 51.6757%\n",
      "Epoch: 50, Train Loss: 1.7173, Train Accuracy: 51.6757%\n",
      "Epoch: 60, Train Loss: 1.7048, Train Accuracy: 51.8919%\n",
      "Epoch: 70, Train Loss: 1.6930, Train Accuracy: 51.6757%\n",
      "Epoch: 80, Train Loss: 1.6819, Train Accuracy: 51.6757%\n",
      "Epoch: 90, Train Loss: 1.6714, Train Accuracy: 51.6757%\n",
      "Epoch: 100, Train Loss: 1.6615, Train Accuracy: 52.0000%\n",
      "Epoch: 110, Train Loss: 1.6521, Train Accuracy: 52.2162%\n",
      "Epoch: 120, Train Loss: 1.6433, Train Accuracy: 52.4324%\n",
      "Epoch: 130, Train Loss: 1.6348, Train Accuracy: 52.4324%\n",
      "Epoch: 140, Train Loss: 1.6269, Train Accuracy: 52.6486%\n",
      "Epoch: 150, Train Loss: 1.6193, Train Accuracy: 52.5405%\n",
      "Epoch: 160, Train Loss: 1.6121, Train Accuracy: 52.6486%\n",
      "Epoch: 170, Train Loss: 1.6053, Train Accuracy: 52.6486%\n",
      "Epoch: 180, Train Loss: 1.5989, Train Accuracy: 52.8649%\n",
      "Epoch: 190, Train Loss: 1.5927, Train Accuracy: 52.7568%\n",
      "Epoch: 200, Train Loss: 1.5869, Train Accuracy: 52.5405%\n",
      "Epoch: 210, Train Loss: 1.5813, Train Accuracy: 52.7568%\n",
      "Epoch: 220, Train Loss: 1.5760, Train Accuracy: 52.7568%\n",
      "Epoch: 230, Train Loss: 1.5710, Train Accuracy: 52.7568%\n",
      "Epoch: 240, Train Loss: 1.5662, Train Accuracy: 52.7568%\n",
      "Epoch: 250, Train Loss: 1.5616, Train Accuracy: 52.7568%\n",
      "Epoch: 260, Train Loss: 1.5572, Train Accuracy: 52.7568%\n",
      "Epoch: 270, Train Loss: 1.5531, Train Accuracy: 52.8649%\n",
      "Epoch: 280, Train Loss: 1.5491, Train Accuracy: 52.9730%\n",
      "Epoch: 290, Train Loss: 1.5453, Train Accuracy: 53.0811%\n",
      "Epoch: 300, Train Loss: 1.5416, Train Accuracy: 53.2973%\n",
      "Epoch: 310, Train Loss: 1.5381, Train Accuracy: 52.8649%\n",
      "Epoch: 320, Train Loss: 1.5348, Train Accuracy: 52.8649%\n",
      "Epoch: 330, Train Loss: 1.5316, Train Accuracy: 52.8649%\n",
      "Epoch: 340, Train Loss: 1.5285, Train Accuracy: 52.9730%\n",
      "Epoch: 350, Train Loss: 1.5256, Train Accuracy: 52.9730%\n",
      "Epoch: 360, Train Loss: 1.5227, Train Accuracy: 52.9730%\n",
      "Epoch: 370, Train Loss: 1.5200, Train Accuracy: 52.9730%\n",
      "Epoch: 380, Train Loss: 1.5174, Train Accuracy: 53.0811%\n",
      "Epoch: 390, Train Loss: 1.5149, Train Accuracy: 53.0811%\n",
      "Epoch: 400, Train Loss: 1.5125, Train Accuracy: 53.0811%\n",
      "Epoch: 410, Train Loss: 1.5102, Train Accuracy: 53.0811%\n",
      "Epoch: 420, Train Loss: 1.5079, Train Accuracy: 52.9730%\n",
      "Epoch: 430, Train Loss: 1.5058, Train Accuracy: 53.0811%\n",
      "Epoch: 440, Train Loss: 1.5037, Train Accuracy: 53.1892%\n",
      "Epoch: 450, Train Loss: 1.5017, Train Accuracy: 53.4054%\n",
      "Epoch: 460, Train Loss: 1.4998, Train Accuracy: 53.4054%\n",
      "Epoch: 470, Train Loss: 1.4979, Train Accuracy: 53.4054%\n",
      "Epoch: 480, Train Loss: 1.4961, Train Accuracy: 53.4054%\n",
      "Epoch: 490, Train Loss: 1.4944, Train Accuracy: 53.2973%\n",
      "Epoch: 500, Train Loss: 1.4927, Train Accuracy: 53.2973%\n",
      "Epoch: 510, Train Loss: 1.4911, Train Accuracy: 53.4054%\n",
      "Epoch: 520, Train Loss: 1.4895, Train Accuracy: 53.5135%\n",
      "Epoch: 530, Train Loss: 1.4880, Train Accuracy: 53.5135%\n",
      "Epoch: 540, Train Loss: 1.4866, Train Accuracy: 53.5135%\n",
      "Epoch: 550, Train Loss: 1.4852, Train Accuracy: 53.5135%\n",
      "Epoch: 560, Train Loss: 1.4838, Train Accuracy: 53.6216%\n",
      "Epoch: 570, Train Loss: 1.4825, Train Accuracy: 53.5135%\n",
      "Epoch: 580, Train Loss: 1.4812, Train Accuracy: 53.5135%\n",
      "Epoch: 590, Train Loss: 1.4799, Train Accuracy: 53.5135%\n",
      "Epoch: 600, Train Loss: 1.4787, Train Accuracy: 53.5135%\n",
      "Epoch: 610, Train Loss: 1.4775, Train Accuracy: 53.6216%\n",
      "Epoch: 620, Train Loss: 1.4764, Train Accuracy: 53.6216%\n",
      "Epoch: 630, Train Loss: 1.4753, Train Accuracy: 53.6216%\n",
      "Epoch: 640, Train Loss: 1.4742, Train Accuracy: 53.6216%\n",
      "Epoch: 650, Train Loss: 1.4732, Train Accuracy: 53.6216%\n",
      "Epoch: 660, Train Loss: 1.4722, Train Accuracy: 53.7297%\n",
      "Epoch: 670, Train Loss: 1.4712, Train Accuracy: 53.7297%\n",
      "Epoch: 680, Train Loss: 1.4702, Train Accuracy: 53.7297%\n",
      "Epoch: 690, Train Loss: 1.4693, Train Accuracy: 53.9459%\n",
      "Epoch: 700, Train Loss: 1.4684, Train Accuracy: 53.9459%\n",
      "Epoch: 710, Train Loss: 1.4675, Train Accuracy: 53.9459%\n",
      "Epoch: 720, Train Loss: 1.4667, Train Accuracy: 53.9459%\n",
      "Epoch: 730, Train Loss: 1.4658, Train Accuracy: 53.8378%\n",
      "Epoch: 740, Train Loss: 1.4650, Train Accuracy: 53.8378%\n",
      "Epoch: 750, Train Loss: 1.4642, Train Accuracy: 53.7297%\n",
      "Epoch: 760, Train Loss: 1.4634, Train Accuracy: 53.7297%\n",
      "Epoch: 770, Train Loss: 1.4627, Train Accuracy: 53.7297%\n",
      "Epoch: 780, Train Loss: 1.4620, Train Accuracy: 53.7297%\n",
      "Epoch: 790, Train Loss: 1.4612, Train Accuracy: 53.8378%\n",
      "Epoch: 800, Train Loss: 1.4605, Train Accuracy: 53.9459%\n",
      "Epoch: 810, Train Loss: 1.4599, Train Accuracy: 53.9459%\n",
      "Epoch: 820, Train Loss: 1.4592, Train Accuracy: 53.9459%\n",
      "Epoch: 830, Train Loss: 1.4585, Train Accuracy: 54.0541%\n",
      "Epoch: 840, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 850, Train Loss: 1.4573, Train Accuracy: 54.1622%\n",
      "Epoch: 860, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 870, Train Loss: 1.4561, Train Accuracy: 54.1622%\n",
      "Epoch: 880, Train Loss: 1.4555, Train Accuracy: 54.1622%\n",
      "Epoch: 890, Train Loss: 1.4550, Train Accuracy: 54.1622%\n",
      "Epoch: 900, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 910, Train Loss: 1.4539, Train Accuracy: 54.5946%\n",
      "Epoch: 920, Train Loss: 1.4533, Train Accuracy: 54.7027%\n",
      "Epoch: 930, Train Loss: 1.4528, Train Accuracy: 54.7027%\n",
      "Epoch: 940, Train Loss: 1.4523, Train Accuracy: 54.7027%\n",
      "Epoch: 950, Train Loss: 1.4518, Train Accuracy: 54.5946%\n",
      "Epoch: 960, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 970, Train Loss: 1.4508, Train Accuracy: 54.5946%\n",
      "Epoch: 980, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 990, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 1000, Train Loss: 1.4495, Train Accuracy: 54.3784%\n",
      "Epoch: 1010, Train Loss: 1.4490, Train Accuracy: 54.2703%\n",
      "Epoch: 1020, Train Loss: 1.4486, Train Accuracy: 54.3784%\n",
      "Epoch: 1030, Train Loss: 1.4482, Train Accuracy: 54.3784%\n",
      "Epoch: 1040, Train Loss: 1.4478, Train Accuracy: 54.3784%\n",
      "Epoch: 1050, Train Loss: 1.4474, Train Accuracy: 54.3784%\n",
      "Epoch: 1060, Train Loss: 1.4470, Train Accuracy: 54.3784%\n",
      "Epoch: 1070, Train Loss: 1.4466, Train Accuracy: 54.3784%\n",
      "Epoch: 1080, Train Loss: 1.4462, Train Accuracy: 54.4865%\n",
      "Epoch: 1090, Train Loss: 1.4458, Train Accuracy: 54.4865%\n",
      "Epoch: 1100, Train Loss: 1.4455, Train Accuracy: 54.4865%\n",
      "Epoch: 1110, Train Loss: 1.4451, Train Accuracy: 54.4865%\n",
      "Epoch: 1120, Train Loss: 1.4447, Train Accuracy: 54.4865%\n",
      "Epoch: 1130, Train Loss: 1.4444, Train Accuracy: 54.4865%\n",
      "Epoch: 1140, Train Loss: 1.4440, Train Accuracy: 54.5946%\n",
      "Epoch: 1150, Train Loss: 1.4437, Train Accuracy: 54.5946%\n",
      "Epoch: 1160, Train Loss: 1.4434, Train Accuracy: 54.7027%\n",
      "Epoch: 1170, Train Loss: 1.4431, Train Accuracy: 54.9189%\n",
      "Epoch: 1180, Train Loss: 1.4427, Train Accuracy: 54.9189%\n",
      "Epoch: 1190, Train Loss: 1.4424, Train Accuracy: 54.8108%\n",
      "Epoch: 1200, Train Loss: 1.4421, Train Accuracy: 55.0270%\n",
      "Epoch: 1210, Train Loss: 1.4418, Train Accuracy: 55.1351%\n",
      "Epoch: 1220, Train Loss: 1.4415, Train Accuracy: 55.1351%\n",
      "Epoch: 1230, Train Loss: 1.4412, Train Accuracy: 54.9189%\n",
      "Epoch: 1240, Train Loss: 1.4409, Train Accuracy: 54.9189%\n",
      "Epoch: 1250, Train Loss: 1.4406, Train Accuracy: 54.9189%\n",
      "Epoch: 1260, Train Loss: 1.4404, Train Accuracy: 54.9189%\n",
      "Epoch: 1270, Train Loss: 1.4401, Train Accuracy: 54.9189%\n",
      "Epoch: 1280, Train Loss: 1.4398, Train Accuracy: 54.9189%\n",
      "Epoch: 1290, Train Loss: 1.4395, Train Accuracy: 54.9189%\n",
      "Epoch: 1300, Train Loss: 1.4393, Train Accuracy: 55.0270%\n",
      "Epoch: 1310, Train Loss: 1.4390, Train Accuracy: 55.0270%\n",
      "Epoch: 1320, Train Loss: 1.4388, Train Accuracy: 55.0270%\n",
      "Epoch: 1330, Train Loss: 1.4385, Train Accuracy: 54.9189%\n",
      "Epoch: 1340, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 1350, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 1360, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 1370, Train Loss: 1.4376, Train Accuracy: 55.1351%\n",
      "Epoch: 1380, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 1390, Train Loss: 1.4371, Train Accuracy: 55.2432%\n",
      "Epoch: 1400, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 1410, Train Loss: 1.4366, Train Accuracy: 55.1351%\n",
      "Epoch: 1420, Train Loss: 1.4364, Train Accuracy: 55.1351%\n",
      "Epoch: 1430, Train Loss: 1.4362, Train Accuracy: 55.1351%\n",
      "Epoch: 1440, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 1450, Train Loss: 1.4358, Train Accuracy: 55.1351%\n",
      "Epoch: 1460, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 1470, Train Loss: 1.4354, Train Accuracy: 55.0270%\n",
      "Epoch: 1480, Train Loss: 1.4352, Train Accuracy: 55.1351%\n",
      "Epoch: 1490, Train Loss: 1.4350, Train Accuracy: 55.3514%\n",
      "Epoch: 1500, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 1510, Train Loss: 1.4346, Train Accuracy: 55.3514%\n",
      "Epoch: 1520, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 1530, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 1540, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 1550, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 1560, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 1570, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 1580, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 1590, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 1600, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 1610, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 1620, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 1630, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 1640, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 1650, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 1660, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 1670, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 1680, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 1690, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 1700, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 1710, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 1720, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 1730, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 1740, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 1750, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 1760, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 1770, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 1780, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 1790, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 1800, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 1810, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 1820, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 1830, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 1840, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 1850, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 1860, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 1870, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 1880, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 1890, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 1900, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 1910, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 1920, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 1930, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 1940, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 1950, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 1960, Train Loss: 1.4279, Train Accuracy: 55.2432%\n",
      "Epoch: 1970, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 1980, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 1990, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 2000, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 2010, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 2020, Train Loss: 1.4272, Train Accuracy: 55.4595%\n",
      "Epoch: 2030, Train Loss: 1.4271, Train Accuracy: 55.4595%\n",
      "Epoch: 2040, Train Loss: 1.4270, Train Accuracy: 55.3514%\n",
      "Epoch: 2050, Train Loss: 1.4269, Train Accuracy: 55.3514%\n",
      "Epoch: 2060, Train Loss: 1.4268, Train Accuracy: 55.3514%\n",
      "Epoch: 2070, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 2080, Train Loss: 1.4266, Train Accuracy: 55.3514%\n",
      "Epoch: 2090, Train Loss: 1.4265, Train Accuracy: 55.3514%\n",
      "Epoch: 2100, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 2110, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 2120, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 2130, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 2140, Train Loss: 1.4260, Train Accuracy: 55.3514%\n",
      "Epoch: 2150, Train Loss: 1.4259, Train Accuracy: 55.3514%\n",
      "Epoch: 2160, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 2170, Train Loss: 1.4257, Train Accuracy: 55.3514%\n",
      "Epoch: 2180, Train Loss: 1.4256, Train Accuracy: 55.3514%\n",
      "Epoch: 2190, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 2200, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 2210, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 2220, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 2230, Train Loss: 1.4251, Train Accuracy: 55.3514%\n",
      "Epoch: 2240, Train Loss: 1.4251, Train Accuracy: 55.2432%\n",
      "Epoch: 2250, Train Loss: 1.4250, Train Accuracy: 55.2432%\n",
      "Epoch: 2260, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 2270, Train Loss: 1.4248, Train Accuracy: 55.2432%\n",
      "Epoch: 2280, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 2290, Train Loss: 1.4246, Train Accuracy: 55.2432%\n",
      "Epoch: 2300, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 2310, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 2320, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 2330, Train Loss: 1.4243, Train Accuracy: 55.1351%\n",
      "Epoch: 2340, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 2350, Train Loss: 1.4241, Train Accuracy: 55.1351%\n",
      "Epoch: 2360, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 2370, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 2380, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 2390, Train Loss: 1.4238, Train Accuracy: 55.0270%\n",
      "Epoch: 2400, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 2410, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 2420, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 2430, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 2440, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 2450, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 2460, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 2470, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 2480, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 2490, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 2500, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 2510, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 2520, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 2530, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 2540, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 2550, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 2560, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 2570, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 2580, Train Loss: 1.4224, Train Accuracy: 55.0270%\n",
      "Epoch: 2590, Train Loss: 1.4224, Train Accuracy: 55.1351%\n",
      "Epoch: 2600, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 2610, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 2620, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 2630, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 2640, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 2650, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 2660, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 2670, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 2680, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 2690, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 2700, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 2710, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 2720, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 2730, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 2740, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 2750, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 2760, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 2770, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 2780, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 2790, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 2800, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 2810, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 2820, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 2830, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 2840, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 2850, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 2860, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 2870, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 2880, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 2890, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 2900, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 2910, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 2920, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 2930, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 2940, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 2950, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 2960, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 2970, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 2980, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 2990, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 3000, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 3010, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 3020, Train Loss: 1.4199, Train Accuracy: 55.2432%\n",
      "Epoch: 3030, Train Loss: 1.4199, Train Accuracy: 55.2432%\n",
      "Epoch: 3040, Train Loss: 1.4198, Train Accuracy: 55.2432%\n",
      "Epoch: 3050, Train Loss: 1.4198, Train Accuracy: 55.2432%\n",
      "Epoch: 3060, Train Loss: 1.4197, Train Accuracy: 55.2432%\n",
      "Epoch: 3070, Train Loss: 1.4197, Train Accuracy: 55.2432%\n",
      "Epoch: 3080, Train Loss: 1.4197, Train Accuracy: 55.2432%\n",
      "Epoch: 3090, Train Loss: 1.4196, Train Accuracy: 55.2432%\n",
      "Epoch: 3100, Train Loss: 1.4196, Train Accuracy: 55.2432%\n",
      "Epoch: 3110, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 3120, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 3130, Train Loss: 1.4194, Train Accuracy: 55.2432%\n",
      "Epoch: 3140, Train Loss: 1.4194, Train Accuracy: 55.2432%\n",
      "Epoch: 3150, Train Loss: 1.4193, Train Accuracy: 55.2432%\n",
      "Epoch: 3160, Train Loss: 1.4193, Train Accuracy: 55.2432%\n",
      "Epoch: 3170, Train Loss: 1.4192, Train Accuracy: 55.3514%\n",
      "Epoch: 3180, Train Loss: 1.4192, Train Accuracy: 55.3514%\n",
      "Epoch: 3190, Train Loss: 1.4192, Train Accuracy: 55.3514%\n",
      "Epoch: 3200, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 3210, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 3220, Train Loss: 1.4190, Train Accuracy: 55.3514%\n",
      "Epoch: 3230, Train Loss: 1.4190, Train Accuracy: 55.3514%\n",
      "Epoch: 3240, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 3250, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 3260, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 3270, Train Loss: 1.4188, Train Accuracy: 55.3514%\n",
      "Epoch: 3280, Train Loss: 1.4188, Train Accuracy: 55.3514%\n",
      "Epoch: 3290, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 3300, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 3310, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 3320, Train Loss: 1.4186, Train Accuracy: 55.3514%\n",
      "Epoch: 3330, Train Loss: 1.4186, Train Accuracy: 55.3514%\n",
      "Epoch: 3340, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 3350, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 3360, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 3370, Train Loss: 1.4184, Train Accuracy: 55.3514%\n",
      "Epoch: 3380, Train Loss: 1.4184, Train Accuracy: 55.3514%\n",
      "Epoch: 3390, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 3400, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 3410, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 3420, Train Loss: 1.4182, Train Accuracy: 55.4595%\n",
      "Epoch: 3430, Train Loss: 1.4182, Train Accuracy: 55.3514%\n",
      "Epoch: 3440, Train Loss: 1.4182, Train Accuracy: 55.3514%\n",
      "Epoch: 3450, Train Loss: 1.4181, Train Accuracy: 55.4595%\n",
      "Epoch: 3460, Train Loss: 1.4181, Train Accuracy: 55.4595%\n",
      "Epoch: 3470, Train Loss: 1.4180, Train Accuracy: 55.4595%\n",
      "Epoch: 3480, Train Loss: 1.4180, Train Accuracy: 55.4595%\n",
      "Epoch: 3490, Train Loss: 1.4180, Train Accuracy: 55.4595%\n",
      "Epoch: 3500, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 3510, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 3520, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 3530, Train Loss: 1.4178, Train Accuracy: 55.4595%\n",
      "Epoch: 3540, Train Loss: 1.4178, Train Accuracy: 55.4595%\n",
      "Epoch: 3550, Train Loss: 1.4178, Train Accuracy: 55.6757%\n",
      "Epoch: 3560, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 3570, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 3580, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 3590, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 3600, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 3610, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 3620, Train Loss: 1.4175, Train Accuracy: 55.6757%\n",
      "Epoch: 3630, Train Loss: 1.4175, Train Accuracy: 55.7838%\n",
      "Epoch: 3640, Train Loss: 1.4175, Train Accuracy: 55.7838%\n",
      "Epoch: 3650, Train Loss: 1.4174, Train Accuracy: 55.7838%\n",
      "Epoch: 3660, Train Loss: 1.4174, Train Accuracy: 55.7838%\n",
      "Epoch: 3670, Train Loss: 1.4174, Train Accuracy: 55.8919%\n",
      "Epoch: 3680, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 3690, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 3700, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 3710, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 3720, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 3730, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 3740, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 3750, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 3760, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 3770, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 3780, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 3790, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 3800, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 3810, Train Loss: 1.4169, Train Accuracy: 56.0000%\n",
      "Epoch: 3820, Train Loss: 1.4169, Train Accuracy: 56.0000%\n",
      "Epoch: 3830, Train Loss: 1.4169, Train Accuracy: 55.8919%\n",
      "Epoch: 3840, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 3850, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 3860, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 3870, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 3880, Train Loss: 1.4167, Train Accuracy: 55.8919%\n",
      "Epoch: 3890, Train Loss: 1.4167, Train Accuracy: 55.8919%\n",
      "Epoch: 3900, Train Loss: 1.4167, Train Accuracy: 56.0000%\n",
      "Epoch: 3910, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 3920, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 3930, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 3940, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 3950, Train Loss: 1.4165, Train Accuracy: 56.0000%\n",
      "Epoch: 3960, Train Loss: 1.4165, Train Accuracy: 56.1081%\n",
      "Epoch: 3970, Train Loss: 1.4165, Train Accuracy: 56.1081%\n",
      "Epoch: 3980, Train Loss: 1.4164, Train Accuracy: 56.1081%\n",
      "Epoch: 3990, Train Loss: 1.4164, Train Accuracy: 56.1081%\n",
      "Epoch: 4000, Train Loss: 1.4164, Train Accuracy: 56.1081%\n",
      "Epoch: 4010, Train Loss: 1.4164, Train Accuracy: 56.2162%\n",
      "Epoch: 4020, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 4030, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 4040, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 4050, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 4060, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 4070, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 4080, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 4090, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 4100, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 4110, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 4120, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 4130, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 4140, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 4150, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 4160, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 4170, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 4180, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 4190, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 4200, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 4210, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 4220, Train Loss: 1.4158, Train Accuracy: 56.2162%\n",
      "Epoch: 4230, Train Loss: 1.4158, Train Accuracy: 56.3243%\n",
      "Epoch: 4240, Train Loss: 1.4158, Train Accuracy: 56.4324%\n",
      "Epoch: 4250, Train Loss: 1.4158, Train Accuracy: 56.4324%\n",
      "Epoch: 4260, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 4270, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 4280, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 4290, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 4300, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 4310, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 4320, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 4330, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 4340, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 4350, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 4360, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 4370, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 4380, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 4390, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 4400, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 4410, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 4420, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 4430, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 4440, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 4450, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 4460, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 4470, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 4480, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 4490, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 4500, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 4510, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 4520, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 4530, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 4540, Train Loss: 1.4151, Train Accuracy: 56.4324%\n",
      "Epoch: 4550, Train Loss: 1.4151, Train Accuracy: 56.5405%\n",
      "Epoch: 4560, Train Loss: 1.4151, Train Accuracy: 56.5405%\n",
      "Epoch: 4570, Train Loss: 1.4151, Train Accuracy: 56.5405%\n",
      "Epoch: 4580, Train Loss: 1.4151, Train Accuracy: 56.6486%\n",
      "Epoch: 4590, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4600, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4610, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4620, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4630, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4640, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 4650, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 4660, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 4670, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 4680, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 4690, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 4700, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4710, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4720, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4730, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4740, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4750, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 4760, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 4770, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 4780, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 4790, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 4800, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 4810, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4820, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4830, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4840, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4850, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4860, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 4870, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 4880, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 4890, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 4900, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 4910, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 4920, Train Loss: 1.4145, Train Accuracy: 56.7568%\n",
      "Epoch: 4930, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 4940, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 4950, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 4960, Train Loss: 1.4144, Train Accuracy: 56.6486%\n",
      "Epoch: 4970, Train Loss: 1.4144, Train Accuracy: 56.6486%\n",
      "Epoch: 4980, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 4990, Train Loss: 1.4143, Train Accuracy: 56.7568%\n",
      "Epoch: 5000, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 5010, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 5020, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 5030, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 5040, Train Loss: 1.4143, Train Accuracy: 56.9730%\n",
      "Epoch: 5050, Train Loss: 1.4143, Train Accuracy: 56.9730%\n",
      "Epoch: 5060, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5070, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5080, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5090, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5100, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5110, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 5120, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5130, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5140, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5150, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5160, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5170, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 5180, Train Loss: 1.4141, Train Accuracy: 57.0811%\n",
      "Epoch: 5190, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5200, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5210, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5220, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5230, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5240, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5250, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 5260, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 5270, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 5280, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 5290, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 5300, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 5310, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 5320, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 5330, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5340, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5350, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5360, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5370, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5380, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5390, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5400, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 5410, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5420, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5430, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5440, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5450, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5460, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5470, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5480, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 5490, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 5500, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 5510, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 5520, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 5530, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 5540, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 5550, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 5560, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 5570, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5580, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5590, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5600, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5610, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5620, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5630, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5640, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 5650, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5660, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5670, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5680, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5690, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5700, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5710, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5720, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5730, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 5740, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5750, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5760, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5770, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5780, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5790, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5800, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5810, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5820, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 5830, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5840, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5850, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5860, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5870, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5880, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5890, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5900, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5910, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 5920, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5930, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5940, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5950, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5960, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5970, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5980, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 5990, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 6000, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 6010, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 6020, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6030, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6040, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6050, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6060, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6070, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6080, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6090, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6100, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6110, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6120, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 6130, Train Loss: 1.4129, Train Accuracy: 56.7568%\n",
      "Epoch: 6140, Train Loss: 1.4129, Train Accuracy: 56.7568%\n",
      "Epoch: 6150, Train Loss: 1.4129, Train Accuracy: 56.7568%\n",
      "Epoch: 6160, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6170, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6180, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6190, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6200, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6210, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6220, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 6230, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6240, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6250, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6260, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6270, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6280, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6290, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 6300, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 6310, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 6320, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 6330, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 6340, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 6350, Train Loss: 1.4127, Train Accuracy: 56.7568%\n",
      "Epoch: 6360, Train Loss: 1.4127, Train Accuracy: 56.7568%\n",
      "Epoch: 6370, Train Loss: 1.4127, Train Accuracy: 56.7568%\n",
      "Epoch: 6380, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6390, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6400, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6410, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6420, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6430, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6440, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6450, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6460, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 6470, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6480, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6490, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6500, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6510, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6520, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6530, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6540, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6550, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6560, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6570, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6580, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 6590, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6600, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6610, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6620, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6630, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6640, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6650, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6660, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6670, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6680, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6690, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6700, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6710, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 6720, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6730, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6740, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6750, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6760, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6770, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6780, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6790, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6800, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6810, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6820, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6830, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6840, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6850, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 6860, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6870, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6880, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6890, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6900, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6910, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6920, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6930, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6940, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6950, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6960, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6970, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6980, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 6990, Train Loss: 1.4123, Train Accuracy: 56.9730%\n",
      "Epoch: 7000, Train Loss: 1.4123, Train Accuracy: 56.9730%\n",
      "Epoch: 7010, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7020, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7030, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7040, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7050, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7060, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7070, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7080, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7090, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7100, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7110, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7120, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7130, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7140, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7150, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 7160, Train Loss: 1.4121, Train Accuracy: 56.9730%\n",
      "Epoch: 7170, Train Loss: 1.4121, Train Accuracy: 56.9730%\n",
      "Epoch: 7180, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7190, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7200, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7210, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7220, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7230, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7240, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7250, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7260, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7270, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7280, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7290, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7300, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7310, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7320, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 7330, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7340, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7350, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7360, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7370, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7380, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7390, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7400, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7410, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 7420, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7430, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7440, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7450, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7460, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7470, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7480, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7490, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 7500, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7510, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7520, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7530, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7540, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7550, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7560, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7570, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7580, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7590, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7600, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7610, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7620, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7630, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7640, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7650, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7660, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7670, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7680, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 7690, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7700, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7710, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7720, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7730, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7740, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7750, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7760, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7770, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7780, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7790, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7800, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7810, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7820, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7830, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7840, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7850, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7860, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7870, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7880, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 7890, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7900, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7910, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7920, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7930, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7940, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7950, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7960, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7970, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7980, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 7990, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8000, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8010, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8020, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8030, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8040, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8050, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8060, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8070, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8080, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8090, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8100, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 8110, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8120, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8130, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8140, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8150, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8160, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8170, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8180, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 8190, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8200, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8210, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8220, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8230, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8240, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8250, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8260, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8270, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8280, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8290, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8300, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8310, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8320, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8330, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 8340, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8350, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8360, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8370, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8380, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8390, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8400, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8410, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8420, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 8430, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8440, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8450, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8460, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8470, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8480, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8490, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8500, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8510, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8520, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8530, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8540, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8550, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8560, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8570, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8580, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 8590, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8600, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8610, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8620, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8630, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8640, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8650, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8660, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8670, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8680, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8690, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8700, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8710, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8720, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8730, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8740, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8750, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8760, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8770, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 8780, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8790, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8800, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8810, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8820, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8830, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8840, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8850, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8860, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 8870, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8880, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8890, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8900, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8910, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8920, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8930, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8940, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8950, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8960, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8970, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8980, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 8990, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9000, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9010, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9020, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9030, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9040, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9050, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9060, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9070, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9080, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9090, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9100, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9110, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9120, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9130, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9140, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9150, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9160, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 9170, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9180, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9190, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9200, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9210, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9220, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9230, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9240, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9250, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9260, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9270, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9280, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9290, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9300, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9310, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9320, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9330, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9340, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9350, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9360, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9370, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9380, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 9390, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9400, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9410, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9420, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9430, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9440, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9450, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9460, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9470, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9480, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9490, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 9500, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9510, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9520, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9530, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9540, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9550, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9560, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9570, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9580, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9590, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9600, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9610, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9620, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9630, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9640, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9650, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9660, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9670, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9680, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9690, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9700, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9710, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9720, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9730, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9740, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9750, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9760, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9770, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9780, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9790, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9800, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9810, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9820, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9830, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9840, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9850, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 9860, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9870, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9880, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9890, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9900, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9910, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9920, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9930, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9940, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9950, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9960, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9970, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9980, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 9990, Train Loss: 1.4110, Train Accuracy: 56.8649%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:slksf98y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▄▅▅▅▅▅▅▅▅▅▆▆▆▇▇▇██▇▇▇▇▇▇█████████▇▇▇</td></tr><tr><td>train_loss</td><td>█▆▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▁▂▃▂▂▂▃▃▃▄▄▄▄▄▄▄▄▄▄▆▆▇█████████████████</td></tr><tr><td>val_loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56865</td></tr><tr><td>train_loss</td><td>1.41101</td></tr><tr><td>val_accuracy</td><td>0.59223</td></tr><tr><td>val_loss</td><td>1.34843</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.01</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/slksf98y' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/slksf98y</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190119-slksf98y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:slksf98y). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190138-opycsgqr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/opycsgqr' target=\"_blank\">Logistic Regression lr=0.001</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/opycsgqr' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/opycsgqr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7900, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7883, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7866, Train Accuracy: 51.5676%\n",
      "Epoch: 40, Train Loss: 1.7850, Train Accuracy: 51.5676%\n",
      "Epoch: 50, Train Loss: 1.7833, Train Accuracy: 51.5676%\n",
      "Epoch: 60, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 70, Train Loss: 1.7800, Train Accuracy: 51.5676%\n",
      "Epoch: 80, Train Loss: 1.7783, Train Accuracy: 51.5676%\n",
      "Epoch: 90, Train Loss: 1.7767, Train Accuracy: 51.6757%\n",
      "Epoch: 100, Train Loss: 1.7751, Train Accuracy: 51.6757%\n",
      "Epoch: 110, Train Loss: 1.7734, Train Accuracy: 51.6757%\n",
      "Epoch: 120, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 130, Train Loss: 1.7702, Train Accuracy: 51.6757%\n",
      "Epoch: 140, Train Loss: 1.7687, Train Accuracy: 51.6757%\n",
      "Epoch: 150, Train Loss: 1.7671, Train Accuracy: 51.6757%\n",
      "Epoch: 160, Train Loss: 1.7655, Train Accuracy: 51.6757%\n",
      "Epoch: 170, Train Loss: 1.7640, Train Accuracy: 51.6757%\n",
      "Epoch: 180, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 190, Train Loss: 1.7609, Train Accuracy: 51.6757%\n",
      "Epoch: 200, Train Loss: 1.7593, Train Accuracy: 51.6757%\n",
      "Epoch: 210, Train Loss: 1.7578, Train Accuracy: 51.6757%\n",
      "Epoch: 220, Train Loss: 1.7563, Train Accuracy: 51.6757%\n",
      "Epoch: 230, Train Loss: 1.7548, Train Accuracy: 51.6757%\n",
      "Epoch: 240, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 250, Train Loss: 1.7518, Train Accuracy: 51.6757%\n",
      "Epoch: 260, Train Loss: 1.7503, Train Accuracy: 51.6757%\n",
      "Epoch: 270, Train Loss: 1.7489, Train Accuracy: 51.6757%\n",
      "Epoch: 280, Train Loss: 1.7474, Train Accuracy: 51.6757%\n",
      "Epoch: 290, Train Loss: 1.7459, Train Accuracy: 51.6757%\n",
      "Epoch: 300, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 310, Train Loss: 1.7431, Train Accuracy: 51.6757%\n",
      "Epoch: 320, Train Loss: 1.7416, Train Accuracy: 51.6757%\n",
      "Epoch: 330, Train Loss: 1.7402, Train Accuracy: 51.6757%\n",
      "Epoch: 340, Train Loss: 1.7388, Train Accuracy: 51.6757%\n",
      "Epoch: 350, Train Loss: 1.7374, Train Accuracy: 51.6757%\n",
      "Epoch: 360, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 370, Train Loss: 1.7346, Train Accuracy: 51.6757%\n",
      "Epoch: 380, Train Loss: 1.7333, Train Accuracy: 51.6757%\n",
      "Epoch: 390, Train Loss: 1.7319, Train Accuracy: 51.6757%\n",
      "Epoch: 400, Train Loss: 1.7305, Train Accuracy: 51.6757%\n",
      "Epoch: 410, Train Loss: 1.7292, Train Accuracy: 51.6757%\n",
      "Epoch: 420, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 430, Train Loss: 1.7265, Train Accuracy: 51.6757%\n",
      "Epoch: 440, Train Loss: 1.7252, Train Accuracy: 51.6757%\n",
      "Epoch: 450, Train Loss: 1.7238, Train Accuracy: 51.6757%\n",
      "Epoch: 460, Train Loss: 1.7225, Train Accuracy: 51.6757%\n",
      "Epoch: 470, Train Loss: 1.7212, Train Accuracy: 51.6757%\n",
      "Epoch: 480, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 490, Train Loss: 1.7186, Train Accuracy: 51.6757%\n",
      "Epoch: 500, Train Loss: 1.7173, Train Accuracy: 51.6757%\n",
      "Epoch: 510, Train Loss: 1.7161, Train Accuracy: 51.6757%\n",
      "Epoch: 520, Train Loss: 1.7148, Train Accuracy: 51.6757%\n",
      "Epoch: 530, Train Loss: 1.7135, Train Accuracy: 51.6757%\n",
      "Epoch: 540, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 550, Train Loss: 1.7110, Train Accuracy: 51.6757%\n",
      "Epoch: 560, Train Loss: 1.7098, Train Accuracy: 51.7838%\n",
      "Epoch: 570, Train Loss: 1.7086, Train Accuracy: 51.7838%\n",
      "Epoch: 580, Train Loss: 1.7073, Train Accuracy: 51.7838%\n",
      "Epoch: 590, Train Loss: 1.7061, Train Accuracy: 51.8919%\n",
      "Epoch: 600, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 610, Train Loss: 1.7037, Train Accuracy: 51.8919%\n",
      "Epoch: 620, Train Loss: 1.7025, Train Accuracy: 51.8919%\n",
      "Epoch: 630, Train Loss: 1.7013, Train Accuracy: 51.8919%\n",
      "Epoch: 640, Train Loss: 1.7001, Train Accuracy: 51.8919%\n",
      "Epoch: 650, Train Loss: 1.6989, Train Accuracy: 51.8919%\n",
      "Epoch: 660, Train Loss: 1.6978, Train Accuracy: 51.7838%\n",
      "Epoch: 670, Train Loss: 1.6966, Train Accuracy: 51.7838%\n",
      "Epoch: 680, Train Loss: 1.6954, Train Accuracy: 51.7838%\n",
      "Epoch: 690, Train Loss: 1.6943, Train Accuracy: 51.6757%\n",
      "Epoch: 700, Train Loss: 1.6932, Train Accuracy: 51.6757%\n",
      "Epoch: 710, Train Loss: 1.6920, Train Accuracy: 51.6757%\n",
      "Epoch: 720, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 730, Train Loss: 1.6898, Train Accuracy: 51.6757%\n",
      "Epoch: 740, Train Loss: 1.6886, Train Accuracy: 51.6757%\n",
      "Epoch: 750, Train Loss: 1.6875, Train Accuracy: 51.6757%\n",
      "Epoch: 760, Train Loss: 1.6864, Train Accuracy: 51.5676%\n",
      "Epoch: 770, Train Loss: 1.6853, Train Accuracy: 51.6757%\n",
      "Epoch: 780, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 790, Train Loss: 1.6831, Train Accuracy: 51.6757%\n",
      "Epoch: 800, Train Loss: 1.6821, Train Accuracy: 51.6757%\n",
      "Epoch: 810, Train Loss: 1.6810, Train Accuracy: 51.6757%\n",
      "Epoch: 820, Train Loss: 1.6799, Train Accuracy: 51.6757%\n",
      "Epoch: 830, Train Loss: 1.6788, Train Accuracy: 51.6757%\n",
      "Epoch: 840, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 850, Train Loss: 1.6767, Train Accuracy: 51.6757%\n",
      "Epoch: 860, Train Loss: 1.6757, Train Accuracy: 51.6757%\n",
      "Epoch: 870, Train Loss: 1.6747, Train Accuracy: 51.6757%\n",
      "Epoch: 880, Train Loss: 1.6736, Train Accuracy: 51.6757%\n",
      "Epoch: 890, Train Loss: 1.6726, Train Accuracy: 51.6757%\n",
      "Epoch: 900, Train Loss: 1.6716, Train Accuracy: 51.7838%\n",
      "Epoch: 910, Train Loss: 1.6706, Train Accuracy: 51.7838%\n",
      "Epoch: 920, Train Loss: 1.6695, Train Accuracy: 51.7838%\n",
      "Epoch: 930, Train Loss: 1.6685, Train Accuracy: 51.7838%\n",
      "Epoch: 940, Train Loss: 1.6675, Train Accuracy: 51.7838%\n",
      "Epoch: 950, Train Loss: 1.6665, Train Accuracy: 51.7838%\n",
      "Epoch: 960, Train Loss: 1.6656, Train Accuracy: 51.8919%\n",
      "Epoch: 970, Train Loss: 1.6646, Train Accuracy: 52.0000%\n",
      "Epoch: 980, Train Loss: 1.6636, Train Accuracy: 52.0000%\n",
      "Epoch: 990, Train Loss: 1.6626, Train Accuracy: 52.0000%\n",
      "Epoch: 1000, Train Loss: 1.6617, Train Accuracy: 52.0000%\n",
      "Epoch: 1010, Train Loss: 1.6607, Train Accuracy: 52.0000%\n",
      "Epoch: 1020, Train Loss: 1.6597, Train Accuracy: 52.0000%\n",
      "Epoch: 1030, Train Loss: 1.6588, Train Accuracy: 52.1081%\n",
      "Epoch: 1040, Train Loss: 1.6578, Train Accuracy: 52.2162%\n",
      "Epoch: 1050, Train Loss: 1.6569, Train Accuracy: 52.2162%\n",
      "Epoch: 1060, Train Loss: 1.6560, Train Accuracy: 52.2162%\n",
      "Epoch: 1070, Train Loss: 1.6550, Train Accuracy: 52.2162%\n",
      "Epoch: 1080, Train Loss: 1.6541, Train Accuracy: 52.2162%\n",
      "Epoch: 1090, Train Loss: 1.6532, Train Accuracy: 52.2162%\n",
      "Epoch: 1100, Train Loss: 1.6523, Train Accuracy: 52.2162%\n",
      "Epoch: 1110, Train Loss: 1.6514, Train Accuracy: 52.3243%\n",
      "Epoch: 1120, Train Loss: 1.6505, Train Accuracy: 52.3243%\n",
      "Epoch: 1130, Train Loss: 1.6496, Train Accuracy: 52.3243%\n",
      "Epoch: 1140, Train Loss: 1.6487, Train Accuracy: 52.3243%\n",
      "Epoch: 1150, Train Loss: 1.6478, Train Accuracy: 52.3243%\n",
      "Epoch: 1160, Train Loss: 1.6469, Train Accuracy: 52.3243%\n",
      "Epoch: 1170, Train Loss: 1.6460, Train Accuracy: 52.3243%\n",
      "Epoch: 1180, Train Loss: 1.6451, Train Accuracy: 52.3243%\n",
      "Epoch: 1190, Train Loss: 1.6443, Train Accuracy: 52.4324%\n",
      "Epoch: 1200, Train Loss: 1.6434, Train Accuracy: 52.4324%\n",
      "Epoch: 1210, Train Loss: 1.6425, Train Accuracy: 52.4324%\n",
      "Epoch: 1220, Train Loss: 1.6417, Train Accuracy: 52.4324%\n",
      "Epoch: 1230, Train Loss: 1.6408, Train Accuracy: 52.4324%\n",
      "Epoch: 1240, Train Loss: 1.6400, Train Accuracy: 52.4324%\n",
      "Epoch: 1250, Train Loss: 1.6391, Train Accuracy: 52.4324%\n",
      "Epoch: 1260, Train Loss: 1.6383, Train Accuracy: 52.4324%\n",
      "Epoch: 1270, Train Loss: 1.6375, Train Accuracy: 52.4324%\n",
      "Epoch: 1280, Train Loss: 1.6366, Train Accuracy: 52.4324%\n",
      "Epoch: 1290, Train Loss: 1.6358, Train Accuracy: 52.4324%\n",
      "Epoch: 1300, Train Loss: 1.6350, Train Accuracy: 52.5405%\n",
      "Epoch: 1310, Train Loss: 1.6342, Train Accuracy: 52.5405%\n",
      "Epoch: 1320, Train Loss: 1.6334, Train Accuracy: 52.5405%\n",
      "Epoch: 1330, Train Loss: 1.6325, Train Accuracy: 52.5405%\n",
      "Epoch: 1340, Train Loss: 1.6317, Train Accuracy: 52.5405%\n",
      "Epoch: 1350, Train Loss: 1.6309, Train Accuracy: 52.5405%\n",
      "Epoch: 1360, Train Loss: 1.6301, Train Accuracy: 52.5405%\n",
      "Epoch: 1370, Train Loss: 1.6294, Train Accuracy: 52.6486%\n",
      "Epoch: 1380, Train Loss: 1.6286, Train Accuracy: 52.6486%\n",
      "Epoch: 1390, Train Loss: 1.6278, Train Accuracy: 52.6486%\n",
      "Epoch: 1400, Train Loss: 1.6270, Train Accuracy: 52.6486%\n",
      "Epoch: 1410, Train Loss: 1.6262, Train Accuracy: 52.6486%\n",
      "Epoch: 1420, Train Loss: 1.6255, Train Accuracy: 52.6486%\n",
      "Epoch: 1430, Train Loss: 1.6247, Train Accuracy: 52.6486%\n",
      "Epoch: 1440, Train Loss: 1.6239, Train Accuracy: 52.5405%\n",
      "Epoch: 1450, Train Loss: 1.6232, Train Accuracy: 52.4324%\n",
      "Epoch: 1460, Train Loss: 1.6224, Train Accuracy: 52.4324%\n",
      "Epoch: 1470, Train Loss: 1.6217, Train Accuracy: 52.4324%\n",
      "Epoch: 1480, Train Loss: 1.6209, Train Accuracy: 52.4324%\n",
      "Epoch: 1490, Train Loss: 1.6202, Train Accuracy: 52.4324%\n",
      "Epoch: 1500, Train Loss: 1.6195, Train Accuracy: 52.5405%\n",
      "Epoch: 1510, Train Loss: 1.6187, Train Accuracy: 52.5405%\n",
      "Epoch: 1520, Train Loss: 1.6180, Train Accuracy: 52.5405%\n",
      "Epoch: 1530, Train Loss: 1.6173, Train Accuracy: 52.5405%\n",
      "Epoch: 1540, Train Loss: 1.6165, Train Accuracy: 52.6486%\n",
      "Epoch: 1550, Train Loss: 1.6158, Train Accuracy: 52.7568%\n",
      "Epoch: 1560, Train Loss: 1.6151, Train Accuracy: 52.7568%\n",
      "Epoch: 1570, Train Loss: 1.6144, Train Accuracy: 52.7568%\n",
      "Epoch: 1580, Train Loss: 1.6137, Train Accuracy: 52.7568%\n",
      "Epoch: 1590, Train Loss: 1.6130, Train Accuracy: 52.6486%\n",
      "Epoch: 1600, Train Loss: 1.6123, Train Accuracy: 52.6486%\n",
      "Epoch: 1610, Train Loss: 1.6116, Train Accuracy: 52.6486%\n",
      "Epoch: 1620, Train Loss: 1.6109, Train Accuracy: 52.6486%\n",
      "Epoch: 1630, Train Loss: 1.6102, Train Accuracy: 52.6486%\n",
      "Epoch: 1640, Train Loss: 1.6095, Train Accuracy: 52.6486%\n",
      "Epoch: 1650, Train Loss: 1.6088, Train Accuracy: 52.6486%\n",
      "Epoch: 1660, Train Loss: 1.6082, Train Accuracy: 52.6486%\n",
      "Epoch: 1670, Train Loss: 1.6075, Train Accuracy: 52.6486%\n",
      "Epoch: 1680, Train Loss: 1.6068, Train Accuracy: 52.6486%\n",
      "Epoch: 1690, Train Loss: 1.6061, Train Accuracy: 52.6486%\n",
      "Epoch: 1700, Train Loss: 1.6055, Train Accuracy: 52.6486%\n",
      "Epoch: 1710, Train Loss: 1.6048, Train Accuracy: 52.6486%\n",
      "Epoch: 1720, Train Loss: 1.6042, Train Accuracy: 52.6486%\n",
      "Epoch: 1730, Train Loss: 1.6035, Train Accuracy: 52.6486%\n",
      "Epoch: 1740, Train Loss: 1.6029, Train Accuracy: 52.7568%\n",
      "Epoch: 1750, Train Loss: 1.6022, Train Accuracy: 52.7568%\n",
      "Epoch: 1760, Train Loss: 1.6016, Train Accuracy: 52.8649%\n",
      "Epoch: 1770, Train Loss: 1.6009, Train Accuracy: 52.8649%\n",
      "Epoch: 1780, Train Loss: 1.6003, Train Accuracy: 52.8649%\n",
      "Epoch: 1790, Train Loss: 1.5996, Train Accuracy: 52.8649%\n",
      "Epoch: 1800, Train Loss: 1.5990, Train Accuracy: 52.8649%\n",
      "Epoch: 1810, Train Loss: 1.5984, Train Accuracy: 52.8649%\n",
      "Epoch: 1820, Train Loss: 1.5978, Train Accuracy: 52.8649%\n",
      "Epoch: 1830, Train Loss: 1.5971, Train Accuracy: 52.8649%\n",
      "Epoch: 1840, Train Loss: 1.5965, Train Accuracy: 52.8649%\n",
      "Epoch: 1850, Train Loss: 1.5959, Train Accuracy: 52.7568%\n",
      "Epoch: 1860, Train Loss: 1.5953, Train Accuracy: 52.7568%\n",
      "Epoch: 1870, Train Loss: 1.5947, Train Accuracy: 52.7568%\n",
      "Epoch: 1880, Train Loss: 1.5941, Train Accuracy: 52.7568%\n",
      "Epoch: 1890, Train Loss: 1.5935, Train Accuracy: 52.7568%\n",
      "Epoch: 1900, Train Loss: 1.5929, Train Accuracy: 52.7568%\n",
      "Epoch: 1910, Train Loss: 1.5923, Train Accuracy: 52.7568%\n",
      "Epoch: 1920, Train Loss: 1.5917, Train Accuracy: 52.6486%\n",
      "Epoch: 1930, Train Loss: 1.5911, Train Accuracy: 52.6486%\n",
      "Epoch: 1940, Train Loss: 1.5905, Train Accuracy: 52.4324%\n",
      "Epoch: 1950, Train Loss: 1.5899, Train Accuracy: 52.4324%\n",
      "Epoch: 1960, Train Loss: 1.5893, Train Accuracy: 52.4324%\n",
      "Epoch: 1970, Train Loss: 1.5887, Train Accuracy: 52.4324%\n",
      "Epoch: 1980, Train Loss: 1.5882, Train Accuracy: 52.4324%\n",
      "Epoch: 1990, Train Loss: 1.5876, Train Accuracy: 52.5405%\n",
      "Epoch: 2000, Train Loss: 1.5870, Train Accuracy: 52.5405%\n",
      "Epoch: 2010, Train Loss: 1.5865, Train Accuracy: 52.6486%\n",
      "Epoch: 2020, Train Loss: 1.5859, Train Accuracy: 52.7568%\n",
      "Epoch: 2030, Train Loss: 1.5853, Train Accuracy: 52.7568%\n",
      "Epoch: 2040, Train Loss: 1.5848, Train Accuracy: 52.7568%\n",
      "Epoch: 2050, Train Loss: 1.5842, Train Accuracy: 52.7568%\n",
      "Epoch: 2060, Train Loss: 1.5837, Train Accuracy: 52.7568%\n",
      "Epoch: 2070, Train Loss: 1.5831, Train Accuracy: 52.7568%\n",
      "Epoch: 2080, Train Loss: 1.5826, Train Accuracy: 52.7568%\n",
      "Epoch: 2090, Train Loss: 1.5820, Train Accuracy: 52.7568%\n",
      "Epoch: 2100, Train Loss: 1.5815, Train Accuracy: 52.7568%\n",
      "Epoch: 2110, Train Loss: 1.5809, Train Accuracy: 52.7568%\n",
      "Epoch: 2120, Train Loss: 1.5804, Train Accuracy: 52.7568%\n",
      "Epoch: 2130, Train Loss: 1.5799, Train Accuracy: 52.7568%\n",
      "Epoch: 2140, Train Loss: 1.5793, Train Accuracy: 52.7568%\n",
      "Epoch: 2150, Train Loss: 1.5788, Train Accuracy: 52.7568%\n",
      "Epoch: 2160, Train Loss: 1.5783, Train Accuracy: 52.7568%\n",
      "Epoch: 2170, Train Loss: 1.5777, Train Accuracy: 52.7568%\n",
      "Epoch: 2180, Train Loss: 1.5772, Train Accuracy: 52.7568%\n",
      "Epoch: 2190, Train Loss: 1.5767, Train Accuracy: 52.7568%\n",
      "Epoch: 2200, Train Loss: 1.5762, Train Accuracy: 52.7568%\n",
      "Epoch: 2210, Train Loss: 1.5757, Train Accuracy: 52.7568%\n",
      "Epoch: 2220, Train Loss: 1.5751, Train Accuracy: 52.7568%\n",
      "Epoch: 2230, Train Loss: 1.5746, Train Accuracy: 52.7568%\n",
      "Epoch: 2240, Train Loss: 1.5741, Train Accuracy: 52.7568%\n",
      "Epoch: 2250, Train Loss: 1.5736, Train Accuracy: 52.7568%\n",
      "Epoch: 2260, Train Loss: 1.5731, Train Accuracy: 52.7568%\n",
      "Epoch: 2270, Train Loss: 1.5726, Train Accuracy: 52.7568%\n",
      "Epoch: 2280, Train Loss: 1.5721, Train Accuracy: 52.7568%\n",
      "Epoch: 2290, Train Loss: 1.5716, Train Accuracy: 52.7568%\n",
      "Epoch: 2300, Train Loss: 1.5711, Train Accuracy: 52.7568%\n",
      "Epoch: 2310, Train Loss: 1.5706, Train Accuracy: 52.7568%\n",
      "Epoch: 2320, Train Loss: 1.5702, Train Accuracy: 52.7568%\n",
      "Epoch: 2330, Train Loss: 1.5697, Train Accuracy: 52.7568%\n",
      "Epoch: 2340, Train Loss: 1.5692, Train Accuracy: 52.7568%\n",
      "Epoch: 2350, Train Loss: 1.5687, Train Accuracy: 52.7568%\n",
      "Epoch: 2360, Train Loss: 1.5682, Train Accuracy: 52.7568%\n",
      "Epoch: 2370, Train Loss: 1.5677, Train Accuracy: 52.7568%\n",
      "Epoch: 2380, Train Loss: 1.5673, Train Accuracy: 52.7568%\n",
      "Epoch: 2390, Train Loss: 1.5668, Train Accuracy: 52.7568%\n",
      "Epoch: 2400, Train Loss: 1.5663, Train Accuracy: 52.7568%\n",
      "Epoch: 2410, Train Loss: 1.5659, Train Accuracy: 52.7568%\n",
      "Epoch: 2420, Train Loss: 1.5654, Train Accuracy: 52.7568%\n",
      "Epoch: 2430, Train Loss: 1.5649, Train Accuracy: 52.7568%\n",
      "Epoch: 2440, Train Loss: 1.5645, Train Accuracy: 52.7568%\n",
      "Epoch: 2450, Train Loss: 1.5640, Train Accuracy: 52.7568%\n",
      "Epoch: 2460, Train Loss: 1.5636, Train Accuracy: 52.7568%\n",
      "Epoch: 2470, Train Loss: 1.5631, Train Accuracy: 52.7568%\n",
      "Epoch: 2480, Train Loss: 1.5626, Train Accuracy: 52.7568%\n",
      "Epoch: 2490, Train Loss: 1.5622, Train Accuracy: 52.7568%\n",
      "Epoch: 2500, Train Loss: 1.5617, Train Accuracy: 52.7568%\n",
      "Epoch: 2510, Train Loss: 1.5613, Train Accuracy: 52.7568%\n",
      "Epoch: 2520, Train Loss: 1.5609, Train Accuracy: 52.7568%\n",
      "Epoch: 2530, Train Loss: 1.5604, Train Accuracy: 52.7568%\n",
      "Epoch: 2540, Train Loss: 1.5600, Train Accuracy: 52.7568%\n",
      "Epoch: 2550, Train Loss: 1.5595, Train Accuracy: 52.7568%\n",
      "Epoch: 2560, Train Loss: 1.5591, Train Accuracy: 52.7568%\n",
      "Epoch: 2570, Train Loss: 1.5587, Train Accuracy: 52.7568%\n",
      "Epoch: 2580, Train Loss: 1.5582, Train Accuracy: 52.7568%\n",
      "Epoch: 2590, Train Loss: 1.5578, Train Accuracy: 52.7568%\n",
      "Epoch: 2600, Train Loss: 1.5574, Train Accuracy: 52.7568%\n",
      "Epoch: 2610, Train Loss: 1.5569, Train Accuracy: 52.7568%\n",
      "Epoch: 2620, Train Loss: 1.5565, Train Accuracy: 52.7568%\n",
      "Epoch: 2630, Train Loss: 1.5561, Train Accuracy: 52.7568%\n",
      "Epoch: 2640, Train Loss: 1.5557, Train Accuracy: 52.8649%\n",
      "Epoch: 2650, Train Loss: 1.5553, Train Accuracy: 52.8649%\n",
      "Epoch: 2660, Train Loss: 1.5548, Train Accuracy: 52.8649%\n",
      "Epoch: 2670, Train Loss: 1.5544, Train Accuracy: 52.8649%\n",
      "Epoch: 2680, Train Loss: 1.5540, Train Accuracy: 52.8649%\n",
      "Epoch: 2690, Train Loss: 1.5536, Train Accuracy: 52.8649%\n",
      "Epoch: 2700, Train Loss: 1.5532, Train Accuracy: 52.8649%\n",
      "Epoch: 2710, Train Loss: 1.5528, Train Accuracy: 52.9730%\n",
      "Epoch: 2720, Train Loss: 1.5524, Train Accuracy: 52.9730%\n",
      "Epoch: 2730, Train Loss: 1.5520, Train Accuracy: 52.9730%\n",
      "Epoch: 2740, Train Loss: 1.5516, Train Accuracy: 52.9730%\n",
      "Epoch: 2750, Train Loss: 1.5512, Train Accuracy: 52.9730%\n",
      "Epoch: 2760, Train Loss: 1.5508, Train Accuracy: 52.9730%\n",
      "Epoch: 2770, Train Loss: 1.5504, Train Accuracy: 52.9730%\n",
      "Epoch: 2780, Train Loss: 1.5500, Train Accuracy: 52.9730%\n",
      "Epoch: 2790, Train Loss: 1.5496, Train Accuracy: 52.9730%\n",
      "Epoch: 2800, Train Loss: 1.5492, Train Accuracy: 52.9730%\n",
      "Epoch: 2810, Train Loss: 1.5488, Train Accuracy: 52.9730%\n",
      "Epoch: 2820, Train Loss: 1.5484, Train Accuracy: 52.9730%\n",
      "Epoch: 2830, Train Loss: 1.5480, Train Accuracy: 52.9730%\n",
      "Epoch: 2840, Train Loss: 1.5476, Train Accuracy: 52.9730%\n",
      "Epoch: 2850, Train Loss: 1.5473, Train Accuracy: 52.9730%\n",
      "Epoch: 2860, Train Loss: 1.5469, Train Accuracy: 52.9730%\n",
      "Epoch: 2870, Train Loss: 1.5465, Train Accuracy: 53.0811%\n",
      "Epoch: 2880, Train Loss: 1.5461, Train Accuracy: 53.0811%\n",
      "Epoch: 2890, Train Loss: 1.5458, Train Accuracy: 53.0811%\n",
      "Epoch: 2900, Train Loss: 1.5454, Train Accuracy: 53.1892%\n",
      "Epoch: 2910, Train Loss: 1.5450, Train Accuracy: 53.1892%\n",
      "Epoch: 2920, Train Loss: 1.5446, Train Accuracy: 53.1892%\n",
      "Epoch: 2930, Train Loss: 1.5443, Train Accuracy: 53.1892%\n",
      "Epoch: 2940, Train Loss: 1.5439, Train Accuracy: 53.1892%\n",
      "Epoch: 2950, Train Loss: 1.5435, Train Accuracy: 53.1892%\n",
      "Epoch: 2960, Train Loss: 1.5432, Train Accuracy: 53.1892%\n",
      "Epoch: 2970, Train Loss: 1.5428, Train Accuracy: 53.1892%\n",
      "Epoch: 2980, Train Loss: 1.5424, Train Accuracy: 53.1892%\n",
      "Epoch: 2990, Train Loss: 1.5421, Train Accuracy: 53.2973%\n",
      "Epoch: 3000, Train Loss: 1.5417, Train Accuracy: 53.2973%\n",
      "Epoch: 3010, Train Loss: 1.5414, Train Accuracy: 53.1892%\n",
      "Epoch: 3020, Train Loss: 1.5410, Train Accuracy: 53.0811%\n",
      "Epoch: 3030, Train Loss: 1.5407, Train Accuracy: 52.9730%\n",
      "Epoch: 3040, Train Loss: 1.5403, Train Accuracy: 52.8649%\n",
      "Epoch: 3050, Train Loss: 1.5400, Train Accuracy: 52.7568%\n",
      "Epoch: 3060, Train Loss: 1.5396, Train Accuracy: 52.7568%\n",
      "Epoch: 3070, Train Loss: 1.5393, Train Accuracy: 52.7568%\n",
      "Epoch: 3080, Train Loss: 1.5389, Train Accuracy: 52.7568%\n",
      "Epoch: 3090, Train Loss: 1.5386, Train Accuracy: 52.8649%\n",
      "Epoch: 3100, Train Loss: 1.5382, Train Accuracy: 52.8649%\n",
      "Epoch: 3110, Train Loss: 1.5379, Train Accuracy: 52.8649%\n",
      "Epoch: 3120, Train Loss: 1.5376, Train Accuracy: 52.8649%\n",
      "Epoch: 3130, Train Loss: 1.5372, Train Accuracy: 52.8649%\n",
      "Epoch: 3140, Train Loss: 1.5369, Train Accuracy: 52.8649%\n",
      "Epoch: 3150, Train Loss: 1.5365, Train Accuracy: 52.8649%\n",
      "Epoch: 3160, Train Loss: 1.5362, Train Accuracy: 52.8649%\n",
      "Epoch: 3170, Train Loss: 1.5359, Train Accuracy: 52.8649%\n",
      "Epoch: 3180, Train Loss: 1.5355, Train Accuracy: 52.8649%\n",
      "Epoch: 3190, Train Loss: 1.5352, Train Accuracy: 52.8649%\n",
      "Epoch: 3200, Train Loss: 1.5349, Train Accuracy: 52.8649%\n",
      "Epoch: 3210, Train Loss: 1.5346, Train Accuracy: 52.8649%\n",
      "Epoch: 3220, Train Loss: 1.5342, Train Accuracy: 52.8649%\n",
      "Epoch: 3230, Train Loss: 1.5339, Train Accuracy: 52.8649%\n",
      "Epoch: 3240, Train Loss: 1.5336, Train Accuracy: 52.8649%\n",
      "Epoch: 3250, Train Loss: 1.5333, Train Accuracy: 52.8649%\n",
      "Epoch: 3260, Train Loss: 1.5329, Train Accuracy: 52.8649%\n",
      "Epoch: 3270, Train Loss: 1.5326, Train Accuracy: 52.8649%\n",
      "Epoch: 3280, Train Loss: 1.5323, Train Accuracy: 52.8649%\n",
      "Epoch: 3290, Train Loss: 1.5320, Train Accuracy: 52.8649%\n",
      "Epoch: 3300, Train Loss: 1.5317, Train Accuracy: 52.8649%\n",
      "Epoch: 3310, Train Loss: 1.5314, Train Accuracy: 52.9730%\n",
      "Epoch: 3320, Train Loss: 1.5311, Train Accuracy: 52.9730%\n",
      "Epoch: 3330, Train Loss: 1.5307, Train Accuracy: 52.9730%\n",
      "Epoch: 3340, Train Loss: 1.5304, Train Accuracy: 52.9730%\n",
      "Epoch: 3350, Train Loss: 1.5301, Train Accuracy: 52.9730%\n",
      "Epoch: 3360, Train Loss: 1.5298, Train Accuracy: 52.9730%\n",
      "Epoch: 3370, Train Loss: 1.5295, Train Accuracy: 52.9730%\n",
      "Epoch: 3380, Train Loss: 1.5292, Train Accuracy: 52.9730%\n",
      "Epoch: 3390, Train Loss: 1.5289, Train Accuracy: 52.9730%\n",
      "Epoch: 3400, Train Loss: 1.5286, Train Accuracy: 52.9730%\n",
      "Epoch: 3410, Train Loss: 1.5283, Train Accuracy: 52.9730%\n",
      "Epoch: 3420, Train Loss: 1.5280, Train Accuracy: 53.0811%\n",
      "Epoch: 3430, Train Loss: 1.5277, Train Accuracy: 53.0811%\n",
      "Epoch: 3440, Train Loss: 1.5274, Train Accuracy: 53.0811%\n",
      "Epoch: 3450, Train Loss: 1.5271, Train Accuracy: 53.0811%\n",
      "Epoch: 3460, Train Loss: 1.5268, Train Accuracy: 53.0811%\n",
      "Epoch: 3470, Train Loss: 1.5265, Train Accuracy: 52.9730%\n",
      "Epoch: 3480, Train Loss: 1.5262, Train Accuracy: 52.9730%\n",
      "Epoch: 3490, Train Loss: 1.5259, Train Accuracy: 52.9730%\n",
      "Epoch: 3500, Train Loss: 1.5257, Train Accuracy: 52.9730%\n",
      "Epoch: 3510, Train Loss: 1.5254, Train Accuracy: 52.9730%\n",
      "Epoch: 3520, Train Loss: 1.5251, Train Accuracy: 52.9730%\n",
      "Epoch: 3530, Train Loss: 1.5248, Train Accuracy: 52.9730%\n",
      "Epoch: 3540, Train Loss: 1.5245, Train Accuracy: 52.9730%\n",
      "Epoch: 3550, Train Loss: 1.5242, Train Accuracy: 52.9730%\n",
      "Epoch: 3560, Train Loss: 1.5239, Train Accuracy: 52.9730%\n",
      "Epoch: 3570, Train Loss: 1.5237, Train Accuracy: 52.9730%\n",
      "Epoch: 3580, Train Loss: 1.5234, Train Accuracy: 52.9730%\n",
      "Epoch: 3590, Train Loss: 1.5231, Train Accuracy: 52.9730%\n",
      "Epoch: 3600, Train Loss: 1.5228, Train Accuracy: 52.9730%\n",
      "Epoch: 3610, Train Loss: 1.5225, Train Accuracy: 52.9730%\n",
      "Epoch: 3620, Train Loss: 1.5223, Train Accuracy: 52.9730%\n",
      "Epoch: 3630, Train Loss: 1.5220, Train Accuracy: 52.9730%\n",
      "Epoch: 3640, Train Loss: 1.5217, Train Accuracy: 52.9730%\n",
      "Epoch: 3650, Train Loss: 1.5215, Train Accuracy: 52.9730%\n",
      "Epoch: 3660, Train Loss: 1.5212, Train Accuracy: 52.9730%\n",
      "Epoch: 3670, Train Loss: 1.5209, Train Accuracy: 52.9730%\n",
      "Epoch: 3680, Train Loss: 1.5206, Train Accuracy: 52.9730%\n",
      "Epoch: 3690, Train Loss: 1.5204, Train Accuracy: 52.9730%\n",
      "Epoch: 3700, Train Loss: 1.5201, Train Accuracy: 52.9730%\n",
      "Epoch: 3710, Train Loss: 1.5198, Train Accuracy: 52.9730%\n",
      "Epoch: 3720, Train Loss: 1.5196, Train Accuracy: 52.9730%\n",
      "Epoch: 3730, Train Loss: 1.5193, Train Accuracy: 52.9730%\n",
      "Epoch: 3740, Train Loss: 1.5191, Train Accuracy: 53.0811%\n",
      "Epoch: 3750, Train Loss: 1.5188, Train Accuracy: 53.0811%\n",
      "Epoch: 3760, Train Loss: 1.5185, Train Accuracy: 53.0811%\n",
      "Epoch: 3770, Train Loss: 1.5183, Train Accuracy: 53.0811%\n",
      "Epoch: 3780, Train Loss: 1.5180, Train Accuracy: 53.0811%\n",
      "Epoch: 3790, Train Loss: 1.5178, Train Accuracy: 53.0811%\n",
      "Epoch: 3800, Train Loss: 1.5175, Train Accuracy: 53.0811%\n",
      "Epoch: 3810, Train Loss: 1.5172, Train Accuracy: 53.0811%\n",
      "Epoch: 3820, Train Loss: 1.5170, Train Accuracy: 53.0811%\n",
      "Epoch: 3830, Train Loss: 1.5167, Train Accuracy: 53.0811%\n",
      "Epoch: 3840, Train Loss: 1.5165, Train Accuracy: 53.0811%\n",
      "Epoch: 3850, Train Loss: 1.5162, Train Accuracy: 53.0811%\n",
      "Epoch: 3860, Train Loss: 1.5160, Train Accuracy: 53.0811%\n",
      "Epoch: 3870, Train Loss: 1.5157, Train Accuracy: 53.0811%\n",
      "Epoch: 3880, Train Loss: 1.5155, Train Accuracy: 53.0811%\n",
      "Epoch: 3890, Train Loss: 1.5152, Train Accuracy: 53.0811%\n",
      "Epoch: 3900, Train Loss: 1.5150, Train Accuracy: 53.0811%\n",
      "Epoch: 3910, Train Loss: 1.5147, Train Accuracy: 53.0811%\n",
      "Epoch: 3920, Train Loss: 1.5145, Train Accuracy: 53.0811%\n",
      "Epoch: 3930, Train Loss: 1.5143, Train Accuracy: 53.0811%\n",
      "Epoch: 3940, Train Loss: 1.5140, Train Accuracy: 53.0811%\n",
      "Epoch: 3950, Train Loss: 1.5138, Train Accuracy: 52.9730%\n",
      "Epoch: 3960, Train Loss: 1.5135, Train Accuracy: 52.9730%\n",
      "Epoch: 3970, Train Loss: 1.5133, Train Accuracy: 52.9730%\n",
      "Epoch: 3980, Train Loss: 1.5130, Train Accuracy: 52.9730%\n",
      "Epoch: 3990, Train Loss: 1.5128, Train Accuracy: 52.9730%\n",
      "Epoch: 4000, Train Loss: 1.5126, Train Accuracy: 53.0811%\n",
      "Epoch: 4010, Train Loss: 1.5123, Train Accuracy: 53.0811%\n",
      "Epoch: 4020, Train Loss: 1.5121, Train Accuracy: 53.0811%\n",
      "Epoch: 4030, Train Loss: 1.5119, Train Accuracy: 53.0811%\n",
      "Epoch: 4040, Train Loss: 1.5116, Train Accuracy: 53.0811%\n",
      "Epoch: 4050, Train Loss: 1.5114, Train Accuracy: 53.0811%\n",
      "Epoch: 4060, Train Loss: 1.5112, Train Accuracy: 53.0811%\n",
      "Epoch: 4070, Train Loss: 1.5109, Train Accuracy: 53.0811%\n",
      "Epoch: 4080, Train Loss: 1.5107, Train Accuracy: 53.0811%\n",
      "Epoch: 4090, Train Loss: 1.5105, Train Accuracy: 53.0811%\n",
      "Epoch: 4100, Train Loss: 1.5103, Train Accuracy: 53.0811%\n",
      "Epoch: 4110, Train Loss: 1.5100, Train Accuracy: 53.0811%\n",
      "Epoch: 4120, Train Loss: 1.5098, Train Accuracy: 52.9730%\n",
      "Epoch: 4130, Train Loss: 1.5096, Train Accuracy: 52.9730%\n",
      "Epoch: 4140, Train Loss: 1.5093, Train Accuracy: 52.9730%\n",
      "Epoch: 4150, Train Loss: 1.5091, Train Accuracy: 52.9730%\n",
      "Epoch: 4160, Train Loss: 1.5089, Train Accuracy: 52.9730%\n",
      "Epoch: 4170, Train Loss: 1.5087, Train Accuracy: 52.9730%\n",
      "Epoch: 4180, Train Loss: 1.5085, Train Accuracy: 52.9730%\n",
      "Epoch: 4190, Train Loss: 1.5082, Train Accuracy: 52.9730%\n",
      "Epoch: 4200, Train Loss: 1.5080, Train Accuracy: 52.9730%\n",
      "Epoch: 4210, Train Loss: 1.5078, Train Accuracy: 52.9730%\n",
      "Epoch: 4220, Train Loss: 1.5076, Train Accuracy: 53.0811%\n",
      "Epoch: 4230, Train Loss: 1.5074, Train Accuracy: 53.0811%\n",
      "Epoch: 4240, Train Loss: 1.5071, Train Accuracy: 53.0811%\n",
      "Epoch: 4250, Train Loss: 1.5069, Train Accuracy: 53.0811%\n",
      "Epoch: 4260, Train Loss: 1.5067, Train Accuracy: 53.0811%\n",
      "Epoch: 4270, Train Loss: 1.5065, Train Accuracy: 53.0811%\n",
      "Epoch: 4280, Train Loss: 1.5063, Train Accuracy: 53.0811%\n",
      "Epoch: 4290, Train Loss: 1.5061, Train Accuracy: 53.0811%\n",
      "Epoch: 4300, Train Loss: 1.5059, Train Accuracy: 53.0811%\n",
      "Epoch: 4310, Train Loss: 1.5057, Train Accuracy: 53.0811%\n",
      "Epoch: 4320, Train Loss: 1.5054, Train Accuracy: 53.0811%\n",
      "Epoch: 4330, Train Loss: 1.5052, Train Accuracy: 53.0811%\n",
      "Epoch: 4340, Train Loss: 1.5050, Train Accuracy: 53.0811%\n",
      "Epoch: 4350, Train Loss: 1.5048, Train Accuracy: 53.0811%\n",
      "Epoch: 4360, Train Loss: 1.5046, Train Accuracy: 53.0811%\n",
      "Epoch: 4370, Train Loss: 1.5044, Train Accuracy: 53.0811%\n",
      "Epoch: 4380, Train Loss: 1.5042, Train Accuracy: 53.0811%\n",
      "Epoch: 4390, Train Loss: 1.5040, Train Accuracy: 53.0811%\n",
      "Epoch: 4400, Train Loss: 1.5038, Train Accuracy: 53.1892%\n",
      "Epoch: 4410, Train Loss: 1.5036, Train Accuracy: 53.1892%\n",
      "Epoch: 4420, Train Loss: 1.5034, Train Accuracy: 53.1892%\n",
      "Epoch: 4430, Train Loss: 1.5032, Train Accuracy: 53.1892%\n",
      "Epoch: 4440, Train Loss: 1.5030, Train Accuracy: 53.2973%\n",
      "Epoch: 4450, Train Loss: 1.5028, Train Accuracy: 53.2973%\n",
      "Epoch: 4460, Train Loss: 1.5026, Train Accuracy: 53.4054%\n",
      "Epoch: 4470, Train Loss: 1.5024, Train Accuracy: 53.4054%\n",
      "Epoch: 4480, Train Loss: 1.5022, Train Accuracy: 53.4054%\n",
      "Epoch: 4490, Train Loss: 1.5020, Train Accuracy: 53.4054%\n",
      "Epoch: 4500, Train Loss: 1.5018, Train Accuracy: 53.4054%\n",
      "Epoch: 4510, Train Loss: 1.5016, Train Accuracy: 53.4054%\n",
      "Epoch: 4520, Train Loss: 1.5014, Train Accuracy: 53.4054%\n",
      "Epoch: 4530, Train Loss: 1.5012, Train Accuracy: 53.4054%\n",
      "Epoch: 4540, Train Loss: 1.5010, Train Accuracy: 53.4054%\n",
      "Epoch: 4550, Train Loss: 1.5008, Train Accuracy: 53.4054%\n",
      "Epoch: 4560, Train Loss: 1.5006, Train Accuracy: 53.4054%\n",
      "Epoch: 4570, Train Loss: 1.5004, Train Accuracy: 53.4054%\n",
      "Epoch: 4580, Train Loss: 1.5002, Train Accuracy: 53.4054%\n",
      "Epoch: 4590, Train Loss: 1.5001, Train Accuracy: 53.4054%\n",
      "Epoch: 4600, Train Loss: 1.4999, Train Accuracy: 53.4054%\n",
      "Epoch: 4610, Train Loss: 1.4997, Train Accuracy: 53.4054%\n",
      "Epoch: 4620, Train Loss: 1.4995, Train Accuracy: 53.4054%\n",
      "Epoch: 4630, Train Loss: 1.4993, Train Accuracy: 53.4054%\n",
      "Epoch: 4640, Train Loss: 1.4991, Train Accuracy: 53.4054%\n",
      "Epoch: 4650, Train Loss: 1.4989, Train Accuracy: 53.4054%\n",
      "Epoch: 4660, Train Loss: 1.4987, Train Accuracy: 53.4054%\n",
      "Epoch: 4670, Train Loss: 1.4986, Train Accuracy: 53.4054%\n",
      "Epoch: 4680, Train Loss: 1.4984, Train Accuracy: 53.4054%\n",
      "Epoch: 4690, Train Loss: 1.4982, Train Accuracy: 53.4054%\n",
      "Epoch: 4700, Train Loss: 1.4980, Train Accuracy: 53.4054%\n",
      "Epoch: 4710, Train Loss: 1.4978, Train Accuracy: 53.4054%\n",
      "Epoch: 4720, Train Loss: 1.4976, Train Accuracy: 53.4054%\n",
      "Epoch: 4730, Train Loss: 1.4975, Train Accuracy: 53.4054%\n",
      "Epoch: 4740, Train Loss: 1.4973, Train Accuracy: 53.4054%\n",
      "Epoch: 4750, Train Loss: 1.4971, Train Accuracy: 53.4054%\n",
      "Epoch: 4760, Train Loss: 1.4969, Train Accuracy: 53.4054%\n",
      "Epoch: 4770, Train Loss: 1.4967, Train Accuracy: 53.4054%\n",
      "Epoch: 4780, Train Loss: 1.4966, Train Accuracy: 53.4054%\n",
      "Epoch: 4790, Train Loss: 1.4964, Train Accuracy: 53.4054%\n",
      "Epoch: 4800, Train Loss: 1.4962, Train Accuracy: 53.4054%\n",
      "Epoch: 4810, Train Loss: 1.4960, Train Accuracy: 53.4054%\n",
      "Epoch: 4820, Train Loss: 1.4959, Train Accuracy: 53.2973%\n",
      "Epoch: 4830, Train Loss: 1.4957, Train Accuracy: 53.2973%\n",
      "Epoch: 4840, Train Loss: 1.4955, Train Accuracy: 53.2973%\n",
      "Epoch: 4850, Train Loss: 1.4953, Train Accuracy: 53.2973%\n",
      "Epoch: 4860, Train Loss: 1.4952, Train Accuracy: 53.2973%\n",
      "Epoch: 4870, Train Loss: 1.4950, Train Accuracy: 53.2973%\n",
      "Epoch: 4880, Train Loss: 1.4948, Train Accuracy: 53.2973%\n",
      "Epoch: 4890, Train Loss: 1.4946, Train Accuracy: 53.2973%\n",
      "Epoch: 4900, Train Loss: 1.4945, Train Accuracy: 53.2973%\n",
      "Epoch: 4910, Train Loss: 1.4943, Train Accuracy: 53.2973%\n",
      "Epoch: 4920, Train Loss: 1.4941, Train Accuracy: 53.2973%\n",
      "Epoch: 4930, Train Loss: 1.4940, Train Accuracy: 53.2973%\n",
      "Epoch: 4940, Train Loss: 1.4938, Train Accuracy: 53.2973%\n",
      "Epoch: 4950, Train Loss: 1.4936, Train Accuracy: 53.2973%\n",
      "Epoch: 4960, Train Loss: 1.4935, Train Accuracy: 53.2973%\n",
      "Epoch: 4970, Train Loss: 1.4933, Train Accuracy: 53.2973%\n",
      "Epoch: 4980, Train Loss: 1.4931, Train Accuracy: 53.2973%\n",
      "Epoch: 4990, Train Loss: 1.4930, Train Accuracy: 53.2973%\n",
      "Epoch: 5000, Train Loss: 1.4928, Train Accuracy: 53.2973%\n",
      "Epoch: 5010, Train Loss: 1.4926, Train Accuracy: 53.2973%\n",
      "Epoch: 5020, Train Loss: 1.4925, Train Accuracy: 53.2973%\n",
      "Epoch: 5030, Train Loss: 1.4923, Train Accuracy: 53.2973%\n",
      "Epoch: 5040, Train Loss: 1.4921, Train Accuracy: 53.2973%\n",
      "Epoch: 5050, Train Loss: 1.4920, Train Accuracy: 53.2973%\n",
      "Epoch: 5060, Train Loss: 1.4918, Train Accuracy: 53.2973%\n",
      "Epoch: 5070, Train Loss: 1.4917, Train Accuracy: 53.2973%\n",
      "Epoch: 5080, Train Loss: 1.4915, Train Accuracy: 53.2973%\n",
      "Epoch: 5090, Train Loss: 1.4913, Train Accuracy: 53.4054%\n",
      "Epoch: 5100, Train Loss: 1.4912, Train Accuracy: 53.4054%\n",
      "Epoch: 5110, Train Loss: 1.4910, Train Accuracy: 53.4054%\n",
      "Epoch: 5120, Train Loss: 1.4909, Train Accuracy: 53.4054%\n",
      "Epoch: 5130, Train Loss: 1.4907, Train Accuracy: 53.4054%\n",
      "Epoch: 5140, Train Loss: 1.4906, Train Accuracy: 53.4054%\n",
      "Epoch: 5150, Train Loss: 1.4904, Train Accuracy: 53.5135%\n",
      "Epoch: 5160, Train Loss: 1.4902, Train Accuracy: 53.5135%\n",
      "Epoch: 5170, Train Loss: 1.4901, Train Accuracy: 53.6216%\n",
      "Epoch: 5180, Train Loss: 1.4899, Train Accuracy: 53.6216%\n",
      "Epoch: 5190, Train Loss: 1.4898, Train Accuracy: 53.5135%\n",
      "Epoch: 5200, Train Loss: 1.4896, Train Accuracy: 53.5135%\n",
      "Epoch: 5210, Train Loss: 1.4895, Train Accuracy: 53.5135%\n",
      "Epoch: 5220, Train Loss: 1.4893, Train Accuracy: 53.5135%\n",
      "Epoch: 5230, Train Loss: 1.4892, Train Accuracy: 53.5135%\n",
      "Epoch: 5240, Train Loss: 1.4890, Train Accuracy: 53.5135%\n",
      "Epoch: 5250, Train Loss: 1.4889, Train Accuracy: 53.5135%\n",
      "Epoch: 5260, Train Loss: 1.4887, Train Accuracy: 53.5135%\n",
      "Epoch: 5270, Train Loss: 1.4886, Train Accuracy: 53.5135%\n",
      "Epoch: 5280, Train Loss: 1.4884, Train Accuracy: 53.5135%\n",
      "Epoch: 5290, Train Loss: 1.4883, Train Accuracy: 53.5135%\n",
      "Epoch: 5300, Train Loss: 1.4881, Train Accuracy: 53.5135%\n",
      "Epoch: 5310, Train Loss: 1.4880, Train Accuracy: 53.5135%\n",
      "Epoch: 5320, Train Loss: 1.4878, Train Accuracy: 53.5135%\n",
      "Epoch: 5330, Train Loss: 1.4877, Train Accuracy: 53.5135%\n",
      "Epoch: 5340, Train Loss: 1.4875, Train Accuracy: 53.5135%\n",
      "Epoch: 5350, Train Loss: 1.4874, Train Accuracy: 53.5135%\n",
      "Epoch: 5360, Train Loss: 1.4872, Train Accuracy: 53.5135%\n",
      "Epoch: 5370, Train Loss: 1.4871, Train Accuracy: 53.5135%\n",
      "Epoch: 5380, Train Loss: 1.4869, Train Accuracy: 53.5135%\n",
      "Epoch: 5390, Train Loss: 1.4868, Train Accuracy: 53.5135%\n",
      "Epoch: 5400, Train Loss: 1.4866, Train Accuracy: 53.5135%\n",
      "Epoch: 5410, Train Loss: 1.4865, Train Accuracy: 53.5135%\n",
      "Epoch: 5420, Train Loss: 1.4864, Train Accuracy: 53.5135%\n",
      "Epoch: 5430, Train Loss: 1.4862, Train Accuracy: 53.5135%\n",
      "Epoch: 5440, Train Loss: 1.4861, Train Accuracy: 53.6216%\n",
      "Epoch: 5450, Train Loss: 1.4859, Train Accuracy: 53.6216%\n",
      "Epoch: 5460, Train Loss: 1.4858, Train Accuracy: 53.5135%\n",
      "Epoch: 5470, Train Loss: 1.4856, Train Accuracy: 53.5135%\n",
      "Epoch: 5480, Train Loss: 1.4855, Train Accuracy: 53.5135%\n",
      "Epoch: 5490, Train Loss: 1.4854, Train Accuracy: 53.5135%\n",
      "Epoch: 5500, Train Loss: 1.4852, Train Accuracy: 53.5135%\n",
      "Epoch: 5510, Train Loss: 1.4851, Train Accuracy: 53.5135%\n",
      "Epoch: 5520, Train Loss: 1.4849, Train Accuracy: 53.6216%\n",
      "Epoch: 5530, Train Loss: 1.4848, Train Accuracy: 53.6216%\n",
      "Epoch: 5540, Train Loss: 1.4847, Train Accuracy: 53.6216%\n",
      "Epoch: 5550, Train Loss: 1.4845, Train Accuracy: 53.5135%\n",
      "Epoch: 5560, Train Loss: 1.4844, Train Accuracy: 53.5135%\n",
      "Epoch: 5570, Train Loss: 1.4843, Train Accuracy: 53.6216%\n",
      "Epoch: 5580, Train Loss: 1.4841, Train Accuracy: 53.6216%\n",
      "Epoch: 5590, Train Loss: 1.4840, Train Accuracy: 53.6216%\n",
      "Epoch: 5600, Train Loss: 1.4839, Train Accuracy: 53.6216%\n",
      "Epoch: 5610, Train Loss: 1.4837, Train Accuracy: 53.6216%\n",
      "Epoch: 5620, Train Loss: 1.4836, Train Accuracy: 53.6216%\n",
      "Epoch: 5630, Train Loss: 1.4834, Train Accuracy: 53.6216%\n",
      "Epoch: 5640, Train Loss: 1.4833, Train Accuracy: 53.6216%\n",
      "Epoch: 5650, Train Loss: 1.4832, Train Accuracy: 53.6216%\n",
      "Epoch: 5660, Train Loss: 1.4830, Train Accuracy: 53.6216%\n",
      "Epoch: 5670, Train Loss: 1.4829, Train Accuracy: 53.6216%\n",
      "Epoch: 5680, Train Loss: 1.4828, Train Accuracy: 53.6216%\n",
      "Epoch: 5690, Train Loss: 1.4827, Train Accuracy: 53.5135%\n",
      "Epoch: 5700, Train Loss: 1.4825, Train Accuracy: 53.5135%\n",
      "Epoch: 5710, Train Loss: 1.4824, Train Accuracy: 53.5135%\n",
      "Epoch: 5720, Train Loss: 1.4823, Train Accuracy: 53.5135%\n",
      "Epoch: 5730, Train Loss: 1.4821, Train Accuracy: 53.5135%\n",
      "Epoch: 5740, Train Loss: 1.4820, Train Accuracy: 53.5135%\n",
      "Epoch: 5750, Train Loss: 1.4819, Train Accuracy: 53.5135%\n",
      "Epoch: 5760, Train Loss: 1.4817, Train Accuracy: 53.5135%\n",
      "Epoch: 5770, Train Loss: 1.4816, Train Accuracy: 53.5135%\n",
      "Epoch: 5780, Train Loss: 1.4815, Train Accuracy: 53.5135%\n",
      "Epoch: 5790, Train Loss: 1.4814, Train Accuracy: 53.5135%\n",
      "Epoch: 5800, Train Loss: 1.4812, Train Accuracy: 53.5135%\n",
      "Epoch: 5810, Train Loss: 1.4811, Train Accuracy: 53.5135%\n",
      "Epoch: 5820, Train Loss: 1.4810, Train Accuracy: 53.5135%\n",
      "Epoch: 5830, Train Loss: 1.4809, Train Accuracy: 53.5135%\n",
      "Epoch: 5840, Train Loss: 1.4807, Train Accuracy: 53.5135%\n",
      "Epoch: 5850, Train Loss: 1.4806, Train Accuracy: 53.5135%\n",
      "Epoch: 5860, Train Loss: 1.4805, Train Accuracy: 53.5135%\n",
      "Epoch: 5870, Train Loss: 1.4804, Train Accuracy: 53.5135%\n",
      "Epoch: 5880, Train Loss: 1.4802, Train Accuracy: 53.5135%\n",
      "Epoch: 5890, Train Loss: 1.4801, Train Accuracy: 53.5135%\n",
      "Epoch: 5900, Train Loss: 1.4800, Train Accuracy: 53.5135%\n",
      "Epoch: 5910, Train Loss: 1.4799, Train Accuracy: 53.5135%\n",
      "Epoch: 5920, Train Loss: 1.4797, Train Accuracy: 53.5135%\n",
      "Epoch: 5930, Train Loss: 1.4796, Train Accuracy: 53.5135%\n",
      "Epoch: 5940, Train Loss: 1.4795, Train Accuracy: 53.5135%\n",
      "Epoch: 5950, Train Loss: 1.4794, Train Accuracy: 53.5135%\n",
      "Epoch: 5960, Train Loss: 1.4793, Train Accuracy: 53.5135%\n",
      "Epoch: 5970, Train Loss: 1.4791, Train Accuracy: 53.5135%\n",
      "Epoch: 5980, Train Loss: 1.4790, Train Accuracy: 53.5135%\n",
      "Epoch: 5990, Train Loss: 1.4789, Train Accuracy: 53.5135%\n",
      "Epoch: 6000, Train Loss: 1.4788, Train Accuracy: 53.5135%\n",
      "Epoch: 6010, Train Loss: 1.4787, Train Accuracy: 53.5135%\n",
      "Epoch: 6020, Train Loss: 1.4785, Train Accuracy: 53.5135%\n",
      "Epoch: 6030, Train Loss: 1.4784, Train Accuracy: 53.5135%\n",
      "Epoch: 6040, Train Loss: 1.4783, Train Accuracy: 53.5135%\n",
      "Epoch: 6050, Train Loss: 1.4782, Train Accuracy: 53.5135%\n",
      "Epoch: 6060, Train Loss: 1.4781, Train Accuracy: 53.5135%\n",
      "Epoch: 6070, Train Loss: 1.4779, Train Accuracy: 53.6216%\n",
      "Epoch: 6080, Train Loss: 1.4778, Train Accuracy: 53.6216%\n",
      "Epoch: 6090, Train Loss: 1.4777, Train Accuracy: 53.6216%\n",
      "Epoch: 6100, Train Loss: 1.4776, Train Accuracy: 53.6216%\n",
      "Epoch: 6110, Train Loss: 1.4775, Train Accuracy: 53.6216%\n",
      "Epoch: 6120, Train Loss: 1.4774, Train Accuracy: 53.6216%\n",
      "Epoch: 6130, Train Loss: 1.4773, Train Accuracy: 53.6216%\n",
      "Epoch: 6140, Train Loss: 1.4771, Train Accuracy: 53.6216%\n",
      "Epoch: 6150, Train Loss: 1.4770, Train Accuracy: 53.6216%\n",
      "Epoch: 6160, Train Loss: 1.4769, Train Accuracy: 53.6216%\n",
      "Epoch: 6170, Train Loss: 1.4768, Train Accuracy: 53.6216%\n",
      "Epoch: 6180, Train Loss: 1.4767, Train Accuracy: 53.6216%\n",
      "Epoch: 6190, Train Loss: 1.4766, Train Accuracy: 53.6216%\n",
      "Epoch: 6200, Train Loss: 1.4765, Train Accuracy: 53.6216%\n",
      "Epoch: 6210, Train Loss: 1.4763, Train Accuracy: 53.6216%\n",
      "Epoch: 6220, Train Loss: 1.4762, Train Accuracy: 53.6216%\n",
      "Epoch: 6230, Train Loss: 1.4761, Train Accuracy: 53.6216%\n",
      "Epoch: 6240, Train Loss: 1.4760, Train Accuracy: 53.6216%\n",
      "Epoch: 6250, Train Loss: 1.4759, Train Accuracy: 53.6216%\n",
      "Epoch: 6260, Train Loss: 1.4758, Train Accuracy: 53.6216%\n",
      "Epoch: 6270, Train Loss: 1.4757, Train Accuracy: 53.6216%\n",
      "Epoch: 6280, Train Loss: 1.4756, Train Accuracy: 53.6216%\n",
      "Epoch: 6290, Train Loss: 1.4755, Train Accuracy: 53.6216%\n",
      "Epoch: 6300, Train Loss: 1.4754, Train Accuracy: 53.6216%\n",
      "Epoch: 6310, Train Loss: 1.4752, Train Accuracy: 53.6216%\n",
      "Epoch: 6320, Train Loss: 1.4751, Train Accuracy: 53.6216%\n",
      "Epoch: 6330, Train Loss: 1.4750, Train Accuracy: 53.7297%\n",
      "Epoch: 6340, Train Loss: 1.4749, Train Accuracy: 53.7297%\n",
      "Epoch: 6350, Train Loss: 1.4748, Train Accuracy: 53.6216%\n",
      "Epoch: 6360, Train Loss: 1.4747, Train Accuracy: 53.6216%\n",
      "Epoch: 6370, Train Loss: 1.4746, Train Accuracy: 53.6216%\n",
      "Epoch: 6380, Train Loss: 1.4745, Train Accuracy: 53.6216%\n",
      "Epoch: 6390, Train Loss: 1.4744, Train Accuracy: 53.6216%\n",
      "Epoch: 6400, Train Loss: 1.4743, Train Accuracy: 53.6216%\n",
      "Epoch: 6410, Train Loss: 1.4742, Train Accuracy: 53.6216%\n",
      "Epoch: 6420, Train Loss: 1.4741, Train Accuracy: 53.6216%\n",
      "Epoch: 6430, Train Loss: 1.4740, Train Accuracy: 53.6216%\n",
      "Epoch: 6440, Train Loss: 1.4739, Train Accuracy: 53.6216%\n",
      "Epoch: 6450, Train Loss: 1.4738, Train Accuracy: 53.6216%\n",
      "Epoch: 6460, Train Loss: 1.4737, Train Accuracy: 53.6216%\n",
      "Epoch: 6470, Train Loss: 1.4735, Train Accuracy: 53.6216%\n",
      "Epoch: 6480, Train Loss: 1.4734, Train Accuracy: 53.6216%\n",
      "Epoch: 6490, Train Loss: 1.4733, Train Accuracy: 53.6216%\n",
      "Epoch: 6500, Train Loss: 1.4732, Train Accuracy: 53.6216%\n",
      "Epoch: 6510, Train Loss: 1.4731, Train Accuracy: 53.5135%\n",
      "Epoch: 6520, Train Loss: 1.4730, Train Accuracy: 53.5135%\n",
      "Epoch: 6530, Train Loss: 1.4729, Train Accuracy: 53.6216%\n",
      "Epoch: 6540, Train Loss: 1.4728, Train Accuracy: 53.6216%\n",
      "Epoch: 6550, Train Loss: 1.4727, Train Accuracy: 53.6216%\n",
      "Epoch: 6560, Train Loss: 1.4726, Train Accuracy: 53.7297%\n",
      "Epoch: 6570, Train Loss: 1.4725, Train Accuracy: 53.7297%\n",
      "Epoch: 6580, Train Loss: 1.4724, Train Accuracy: 53.7297%\n",
      "Epoch: 6590, Train Loss: 1.4723, Train Accuracy: 53.7297%\n",
      "Epoch: 6600, Train Loss: 1.4722, Train Accuracy: 53.7297%\n",
      "Epoch: 6610, Train Loss: 1.4721, Train Accuracy: 53.7297%\n",
      "Epoch: 6620, Train Loss: 1.4720, Train Accuracy: 53.7297%\n",
      "Epoch: 6630, Train Loss: 1.4719, Train Accuracy: 53.7297%\n",
      "Epoch: 6640, Train Loss: 1.4718, Train Accuracy: 53.7297%\n",
      "Epoch: 6650, Train Loss: 1.4717, Train Accuracy: 53.7297%\n",
      "Epoch: 6660, Train Loss: 1.4716, Train Accuracy: 53.7297%\n",
      "Epoch: 6670, Train Loss: 1.4715, Train Accuracy: 53.7297%\n",
      "Epoch: 6680, Train Loss: 1.4714, Train Accuracy: 53.7297%\n",
      "Epoch: 6690, Train Loss: 1.4713, Train Accuracy: 53.7297%\n",
      "Epoch: 6700, Train Loss: 1.4712, Train Accuracy: 53.7297%\n",
      "Epoch: 6710, Train Loss: 1.4711, Train Accuracy: 53.7297%\n",
      "Epoch: 6720, Train Loss: 1.4710, Train Accuracy: 53.7297%\n",
      "Epoch: 6730, Train Loss: 1.4709, Train Accuracy: 53.7297%\n",
      "Epoch: 6740, Train Loss: 1.4709, Train Accuracy: 53.7297%\n",
      "Epoch: 6750, Train Loss: 1.4708, Train Accuracy: 53.7297%\n",
      "Epoch: 6760, Train Loss: 1.4707, Train Accuracy: 53.7297%\n",
      "Epoch: 6770, Train Loss: 1.4706, Train Accuracy: 53.7297%\n",
      "Epoch: 6780, Train Loss: 1.4705, Train Accuracy: 53.7297%\n",
      "Epoch: 6790, Train Loss: 1.4704, Train Accuracy: 53.7297%\n",
      "Epoch: 6800, Train Loss: 1.4703, Train Accuracy: 53.7297%\n",
      "Epoch: 6810, Train Loss: 1.4702, Train Accuracy: 53.8378%\n",
      "Epoch: 6820, Train Loss: 1.4701, Train Accuracy: 53.8378%\n",
      "Epoch: 6830, Train Loss: 1.4700, Train Accuracy: 53.8378%\n",
      "Epoch: 6840, Train Loss: 1.4699, Train Accuracy: 53.8378%\n",
      "Epoch: 6850, Train Loss: 1.4698, Train Accuracy: 53.8378%\n",
      "Epoch: 6860, Train Loss: 1.4697, Train Accuracy: 53.9459%\n",
      "Epoch: 6870, Train Loss: 1.4696, Train Accuracy: 53.9459%\n",
      "Epoch: 6880, Train Loss: 1.4695, Train Accuracy: 53.9459%\n",
      "Epoch: 6890, Train Loss: 1.4694, Train Accuracy: 53.9459%\n",
      "Epoch: 6900, Train Loss: 1.4693, Train Accuracy: 53.9459%\n",
      "Epoch: 6910, Train Loss: 1.4693, Train Accuracy: 53.9459%\n",
      "Epoch: 6920, Train Loss: 1.4692, Train Accuracy: 53.9459%\n",
      "Epoch: 6930, Train Loss: 1.4691, Train Accuracy: 53.9459%\n",
      "Epoch: 6940, Train Loss: 1.4690, Train Accuracy: 53.9459%\n",
      "Epoch: 6950, Train Loss: 1.4689, Train Accuracy: 53.9459%\n",
      "Epoch: 6960, Train Loss: 1.4688, Train Accuracy: 53.9459%\n",
      "Epoch: 6970, Train Loss: 1.4687, Train Accuracy: 53.9459%\n",
      "Epoch: 6980, Train Loss: 1.4686, Train Accuracy: 53.9459%\n",
      "Epoch: 6990, Train Loss: 1.4685, Train Accuracy: 53.9459%\n",
      "Epoch: 7000, Train Loss: 1.4684, Train Accuracy: 53.9459%\n",
      "Epoch: 7010, Train Loss: 1.4684, Train Accuracy: 53.9459%\n",
      "Epoch: 7020, Train Loss: 1.4683, Train Accuracy: 53.9459%\n",
      "Epoch: 7030, Train Loss: 1.4682, Train Accuracy: 53.9459%\n",
      "Epoch: 7040, Train Loss: 1.4681, Train Accuracy: 53.9459%\n",
      "Epoch: 7050, Train Loss: 1.4680, Train Accuracy: 53.9459%\n",
      "Epoch: 7060, Train Loss: 1.4679, Train Accuracy: 53.9459%\n",
      "Epoch: 7070, Train Loss: 1.4678, Train Accuracy: 53.9459%\n",
      "Epoch: 7080, Train Loss: 1.4677, Train Accuracy: 53.9459%\n",
      "Epoch: 7090, Train Loss: 1.4676, Train Accuracy: 53.9459%\n",
      "Epoch: 7100, Train Loss: 1.4676, Train Accuracy: 53.9459%\n",
      "Epoch: 7110, Train Loss: 1.4675, Train Accuracy: 53.9459%\n",
      "Epoch: 7120, Train Loss: 1.4674, Train Accuracy: 53.9459%\n",
      "Epoch: 7130, Train Loss: 1.4673, Train Accuracy: 53.9459%\n",
      "Epoch: 7140, Train Loss: 1.4672, Train Accuracy: 53.9459%\n",
      "Epoch: 7150, Train Loss: 1.4671, Train Accuracy: 53.9459%\n",
      "Epoch: 7160, Train Loss: 1.4670, Train Accuracy: 53.9459%\n",
      "Epoch: 7170, Train Loss: 1.4670, Train Accuracy: 53.9459%\n",
      "Epoch: 7180, Train Loss: 1.4669, Train Accuracy: 53.9459%\n",
      "Epoch: 7190, Train Loss: 1.4668, Train Accuracy: 53.9459%\n",
      "Epoch: 7200, Train Loss: 1.4667, Train Accuracy: 53.9459%\n",
      "Epoch: 7210, Train Loss: 1.4666, Train Accuracy: 53.9459%\n",
      "Epoch: 7220, Train Loss: 1.4665, Train Accuracy: 53.9459%\n",
      "Epoch: 7230, Train Loss: 1.4664, Train Accuracy: 53.9459%\n",
      "Epoch: 7240, Train Loss: 1.4664, Train Accuracy: 53.9459%\n",
      "Epoch: 7250, Train Loss: 1.4663, Train Accuracy: 53.9459%\n",
      "Epoch: 7260, Train Loss: 1.4662, Train Accuracy: 53.9459%\n",
      "Epoch: 7270, Train Loss: 1.4661, Train Accuracy: 53.8378%\n",
      "Epoch: 7280, Train Loss: 1.4660, Train Accuracy: 53.8378%\n",
      "Epoch: 7290, Train Loss: 1.4659, Train Accuracy: 53.8378%\n",
      "Epoch: 7300, Train Loss: 1.4659, Train Accuracy: 53.8378%\n",
      "Epoch: 7310, Train Loss: 1.4658, Train Accuracy: 53.9459%\n",
      "Epoch: 7320, Train Loss: 1.4657, Train Accuracy: 53.9459%\n",
      "Epoch: 7330, Train Loss: 1.4656, Train Accuracy: 53.9459%\n",
      "Epoch: 7340, Train Loss: 1.4655, Train Accuracy: 53.8378%\n",
      "Epoch: 7350, Train Loss: 1.4655, Train Accuracy: 53.8378%\n",
      "Epoch: 7360, Train Loss: 1.4654, Train Accuracy: 53.8378%\n",
      "Epoch: 7370, Train Loss: 1.4653, Train Accuracy: 53.8378%\n",
      "Epoch: 7380, Train Loss: 1.4652, Train Accuracy: 53.8378%\n",
      "Epoch: 7390, Train Loss: 1.4651, Train Accuracy: 53.8378%\n",
      "Epoch: 7400, Train Loss: 1.4651, Train Accuracy: 53.8378%\n",
      "Epoch: 7410, Train Loss: 1.4650, Train Accuracy: 53.8378%\n",
      "Epoch: 7420, Train Loss: 1.4649, Train Accuracy: 53.8378%\n",
      "Epoch: 7430, Train Loss: 1.4648, Train Accuracy: 53.8378%\n",
      "Epoch: 7440, Train Loss: 1.4647, Train Accuracy: 53.8378%\n",
      "Epoch: 7450, Train Loss: 1.4647, Train Accuracy: 53.8378%\n",
      "Epoch: 7460, Train Loss: 1.4646, Train Accuracy: 53.8378%\n",
      "Epoch: 7470, Train Loss: 1.4645, Train Accuracy: 53.8378%\n",
      "Epoch: 7480, Train Loss: 1.4644, Train Accuracy: 53.7297%\n",
      "Epoch: 7490, Train Loss: 1.4643, Train Accuracy: 53.7297%\n",
      "Epoch: 7500, Train Loss: 1.4643, Train Accuracy: 53.7297%\n",
      "Epoch: 7510, Train Loss: 1.4642, Train Accuracy: 53.7297%\n",
      "Epoch: 7520, Train Loss: 1.4641, Train Accuracy: 53.7297%\n",
      "Epoch: 7530, Train Loss: 1.4640, Train Accuracy: 53.7297%\n",
      "Epoch: 7540, Train Loss: 1.4639, Train Accuracy: 53.7297%\n",
      "Epoch: 7550, Train Loss: 1.4639, Train Accuracy: 53.7297%\n",
      "Epoch: 7560, Train Loss: 1.4638, Train Accuracy: 53.7297%\n",
      "Epoch: 7570, Train Loss: 1.4637, Train Accuracy: 53.7297%\n",
      "Epoch: 7580, Train Loss: 1.4636, Train Accuracy: 53.7297%\n",
      "Epoch: 7590, Train Loss: 1.4636, Train Accuracy: 53.7297%\n",
      "Epoch: 7600, Train Loss: 1.4635, Train Accuracy: 53.7297%\n",
      "Epoch: 7610, Train Loss: 1.4634, Train Accuracy: 53.7297%\n",
      "Epoch: 7620, Train Loss: 1.4633, Train Accuracy: 53.7297%\n",
      "Epoch: 7630, Train Loss: 1.4633, Train Accuracy: 53.7297%\n",
      "Epoch: 7640, Train Loss: 1.4632, Train Accuracy: 53.7297%\n",
      "Epoch: 7650, Train Loss: 1.4631, Train Accuracy: 53.7297%\n",
      "Epoch: 7660, Train Loss: 1.4630, Train Accuracy: 53.7297%\n",
      "Epoch: 7670, Train Loss: 1.4630, Train Accuracy: 53.7297%\n",
      "Epoch: 7680, Train Loss: 1.4629, Train Accuracy: 53.7297%\n",
      "Epoch: 7690, Train Loss: 1.4628, Train Accuracy: 53.7297%\n",
      "Epoch: 7700, Train Loss: 1.4627, Train Accuracy: 53.7297%\n",
      "Epoch: 7710, Train Loss: 1.4627, Train Accuracy: 53.7297%\n",
      "Epoch: 7720, Train Loss: 1.4626, Train Accuracy: 53.7297%\n",
      "Epoch: 7730, Train Loss: 1.4625, Train Accuracy: 53.7297%\n",
      "Epoch: 7740, Train Loss: 1.4624, Train Accuracy: 53.7297%\n",
      "Epoch: 7750, Train Loss: 1.4624, Train Accuracy: 53.7297%\n",
      "Epoch: 7760, Train Loss: 1.4623, Train Accuracy: 53.7297%\n",
      "Epoch: 7770, Train Loss: 1.4622, Train Accuracy: 53.7297%\n",
      "Epoch: 7780, Train Loss: 1.4621, Train Accuracy: 53.7297%\n",
      "Epoch: 7790, Train Loss: 1.4621, Train Accuracy: 53.7297%\n",
      "Epoch: 7800, Train Loss: 1.4620, Train Accuracy: 53.7297%\n",
      "Epoch: 7810, Train Loss: 1.4619, Train Accuracy: 53.7297%\n",
      "Epoch: 7820, Train Loss: 1.4618, Train Accuracy: 53.7297%\n",
      "Epoch: 7830, Train Loss: 1.4618, Train Accuracy: 53.7297%\n",
      "Epoch: 7840, Train Loss: 1.4617, Train Accuracy: 53.8378%\n",
      "Epoch: 7850, Train Loss: 1.4616, Train Accuracy: 53.8378%\n",
      "Epoch: 7860, Train Loss: 1.4616, Train Accuracy: 53.8378%\n",
      "Epoch: 7870, Train Loss: 1.4615, Train Accuracy: 53.8378%\n",
      "Epoch: 7880, Train Loss: 1.4614, Train Accuracy: 53.8378%\n",
      "Epoch: 7890, Train Loss: 1.4613, Train Accuracy: 53.8378%\n",
      "Epoch: 7900, Train Loss: 1.4613, Train Accuracy: 53.8378%\n",
      "Epoch: 7910, Train Loss: 1.4612, Train Accuracy: 53.8378%\n",
      "Epoch: 7920, Train Loss: 1.4611, Train Accuracy: 53.8378%\n",
      "Epoch: 7930, Train Loss: 1.4611, Train Accuracy: 53.9459%\n",
      "Epoch: 7940, Train Loss: 1.4610, Train Accuracy: 53.9459%\n",
      "Epoch: 7950, Train Loss: 1.4609, Train Accuracy: 53.9459%\n",
      "Epoch: 7960, Train Loss: 1.4609, Train Accuracy: 53.9459%\n",
      "Epoch: 7970, Train Loss: 1.4608, Train Accuracy: 53.9459%\n",
      "Epoch: 7980, Train Loss: 1.4607, Train Accuracy: 53.9459%\n",
      "Epoch: 7990, Train Loss: 1.4606, Train Accuracy: 53.9459%\n",
      "Epoch: 8000, Train Loss: 1.4606, Train Accuracy: 53.9459%\n",
      "Epoch: 8010, Train Loss: 1.4605, Train Accuracy: 53.9459%\n",
      "Epoch: 8020, Train Loss: 1.4604, Train Accuracy: 53.9459%\n",
      "Epoch: 8030, Train Loss: 1.4604, Train Accuracy: 53.9459%\n",
      "Epoch: 8040, Train Loss: 1.4603, Train Accuracy: 53.9459%\n",
      "Epoch: 8050, Train Loss: 1.4602, Train Accuracy: 53.9459%\n",
      "Epoch: 8060, Train Loss: 1.4602, Train Accuracy: 53.9459%\n",
      "Epoch: 8070, Train Loss: 1.4601, Train Accuracy: 53.9459%\n",
      "Epoch: 8080, Train Loss: 1.4600, Train Accuracy: 53.9459%\n",
      "Epoch: 8090, Train Loss: 1.4600, Train Accuracy: 53.9459%\n",
      "Epoch: 8100, Train Loss: 1.4599, Train Accuracy: 53.9459%\n",
      "Epoch: 8110, Train Loss: 1.4598, Train Accuracy: 53.9459%\n",
      "Epoch: 8120, Train Loss: 1.4598, Train Accuracy: 53.9459%\n",
      "Epoch: 8130, Train Loss: 1.4597, Train Accuracy: 53.9459%\n",
      "Epoch: 8140, Train Loss: 1.4596, Train Accuracy: 53.9459%\n",
      "Epoch: 8150, Train Loss: 1.4596, Train Accuracy: 53.9459%\n",
      "Epoch: 8160, Train Loss: 1.4595, Train Accuracy: 53.9459%\n",
      "Epoch: 8170, Train Loss: 1.4594, Train Accuracy: 53.9459%\n",
      "Epoch: 8180, Train Loss: 1.4594, Train Accuracy: 53.9459%\n",
      "Epoch: 8190, Train Loss: 1.4593, Train Accuracy: 53.9459%\n",
      "Epoch: 8200, Train Loss: 1.4592, Train Accuracy: 53.9459%\n",
      "Epoch: 8210, Train Loss: 1.4592, Train Accuracy: 53.9459%\n",
      "Epoch: 8220, Train Loss: 1.4591, Train Accuracy: 53.9459%\n",
      "Epoch: 8230, Train Loss: 1.4590, Train Accuracy: 53.9459%\n",
      "Epoch: 8240, Train Loss: 1.4590, Train Accuracy: 53.9459%\n",
      "Epoch: 8250, Train Loss: 1.4589, Train Accuracy: 53.9459%\n",
      "Epoch: 8260, Train Loss: 1.4588, Train Accuracy: 53.9459%\n",
      "Epoch: 8270, Train Loss: 1.4588, Train Accuracy: 54.0541%\n",
      "Epoch: 8280, Train Loss: 1.4587, Train Accuracy: 54.0541%\n",
      "Epoch: 8290, Train Loss: 1.4586, Train Accuracy: 54.0541%\n",
      "Epoch: 8300, Train Loss: 1.4586, Train Accuracy: 54.0541%\n",
      "Epoch: 8310, Train Loss: 1.4585, Train Accuracy: 54.0541%\n",
      "Epoch: 8320, Train Loss: 1.4585, Train Accuracy: 54.0541%\n",
      "Epoch: 8330, Train Loss: 1.4584, Train Accuracy: 54.0541%\n",
      "Epoch: 8340, Train Loss: 1.4583, Train Accuracy: 54.0541%\n",
      "Epoch: 8350, Train Loss: 1.4583, Train Accuracy: 54.0541%\n",
      "Epoch: 8360, Train Loss: 1.4582, Train Accuracy: 54.0541%\n",
      "Epoch: 8370, Train Loss: 1.4581, Train Accuracy: 54.0541%\n",
      "Epoch: 8380, Train Loss: 1.4581, Train Accuracy: 54.0541%\n",
      "Epoch: 8390, Train Loss: 1.4580, Train Accuracy: 54.0541%\n",
      "Epoch: 8400, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 8410, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 8420, Train Loss: 1.4578, Train Accuracy: 54.0541%\n",
      "Epoch: 8430, Train Loss: 1.4578, Train Accuracy: 54.0541%\n",
      "Epoch: 8440, Train Loss: 1.4577, Train Accuracy: 54.0541%\n",
      "Epoch: 8450, Train Loss: 1.4576, Train Accuracy: 54.1622%\n",
      "Epoch: 8460, Train Loss: 1.4576, Train Accuracy: 54.1622%\n",
      "Epoch: 8470, Train Loss: 1.4575, Train Accuracy: 54.1622%\n",
      "Epoch: 8480, Train Loss: 1.4574, Train Accuracy: 54.1622%\n",
      "Epoch: 8490, Train Loss: 1.4574, Train Accuracy: 54.1622%\n",
      "Epoch: 8500, Train Loss: 1.4573, Train Accuracy: 54.1622%\n",
      "Epoch: 8510, Train Loss: 1.4573, Train Accuracy: 54.1622%\n",
      "Epoch: 8520, Train Loss: 1.4572, Train Accuracy: 54.1622%\n",
      "Epoch: 8530, Train Loss: 1.4571, Train Accuracy: 54.1622%\n",
      "Epoch: 8540, Train Loss: 1.4571, Train Accuracy: 54.1622%\n",
      "Epoch: 8550, Train Loss: 1.4570, Train Accuracy: 54.1622%\n",
      "Epoch: 8560, Train Loss: 1.4570, Train Accuracy: 54.1622%\n",
      "Epoch: 8570, Train Loss: 1.4569, Train Accuracy: 54.1622%\n",
      "Epoch: 8580, Train Loss: 1.4568, Train Accuracy: 54.1622%\n",
      "Epoch: 8590, Train Loss: 1.4568, Train Accuracy: 54.1622%\n",
      "Epoch: 8600, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 8610, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 8620, Train Loss: 1.4566, Train Accuracy: 54.1622%\n",
      "Epoch: 8630, Train Loss: 1.4565, Train Accuracy: 54.1622%\n",
      "Epoch: 8640, Train Loss: 1.4565, Train Accuracy: 54.1622%\n",
      "Epoch: 8650, Train Loss: 1.4564, Train Accuracy: 54.1622%\n",
      "Epoch: 8660, Train Loss: 1.4564, Train Accuracy: 54.1622%\n",
      "Epoch: 8670, Train Loss: 1.4563, Train Accuracy: 54.1622%\n",
      "Epoch: 8680, Train Loss: 1.4562, Train Accuracy: 54.1622%\n",
      "Epoch: 8690, Train Loss: 1.4562, Train Accuracy: 54.1622%\n",
      "Epoch: 8700, Train Loss: 1.4561, Train Accuracy: 54.1622%\n",
      "Epoch: 8710, Train Loss: 1.4561, Train Accuracy: 54.1622%\n",
      "Epoch: 8720, Train Loss: 1.4560, Train Accuracy: 54.1622%\n",
      "Epoch: 8730, Train Loss: 1.4560, Train Accuracy: 54.1622%\n",
      "Epoch: 8740, Train Loss: 1.4559, Train Accuracy: 54.1622%\n",
      "Epoch: 8750, Train Loss: 1.4558, Train Accuracy: 54.1622%\n",
      "Epoch: 8760, Train Loss: 1.4558, Train Accuracy: 54.1622%\n",
      "Epoch: 8770, Train Loss: 1.4557, Train Accuracy: 54.1622%\n",
      "Epoch: 8780, Train Loss: 1.4557, Train Accuracy: 54.1622%\n",
      "Epoch: 8790, Train Loss: 1.4556, Train Accuracy: 54.1622%\n",
      "Epoch: 8800, Train Loss: 1.4555, Train Accuracy: 54.1622%\n",
      "Epoch: 8810, Train Loss: 1.4555, Train Accuracy: 54.1622%\n",
      "Epoch: 8820, Train Loss: 1.4554, Train Accuracy: 54.1622%\n",
      "Epoch: 8830, Train Loss: 1.4554, Train Accuracy: 54.1622%\n",
      "Epoch: 8840, Train Loss: 1.4553, Train Accuracy: 54.1622%\n",
      "Epoch: 8850, Train Loss: 1.4553, Train Accuracy: 54.1622%\n",
      "Epoch: 8860, Train Loss: 1.4552, Train Accuracy: 54.1622%\n",
      "Epoch: 8870, Train Loss: 1.4552, Train Accuracy: 54.1622%\n",
      "Epoch: 8880, Train Loss: 1.4551, Train Accuracy: 54.1622%\n",
      "Epoch: 8890, Train Loss: 1.4550, Train Accuracy: 54.1622%\n",
      "Epoch: 8900, Train Loss: 1.4550, Train Accuracy: 54.1622%\n",
      "Epoch: 8910, Train Loss: 1.4549, Train Accuracy: 54.1622%\n",
      "Epoch: 8920, Train Loss: 1.4549, Train Accuracy: 54.1622%\n",
      "Epoch: 8930, Train Loss: 1.4548, Train Accuracy: 54.2703%\n",
      "Epoch: 8940, Train Loss: 1.4548, Train Accuracy: 54.2703%\n",
      "Epoch: 8950, Train Loss: 1.4547, Train Accuracy: 54.2703%\n",
      "Epoch: 8960, Train Loss: 1.4546, Train Accuracy: 54.2703%\n",
      "Epoch: 8970, Train Loss: 1.4546, Train Accuracy: 54.3784%\n",
      "Epoch: 8980, Train Loss: 1.4545, Train Accuracy: 54.3784%\n",
      "Epoch: 8990, Train Loss: 1.4545, Train Accuracy: 54.3784%\n",
      "Epoch: 9000, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 9010, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 9020, Train Loss: 1.4543, Train Accuracy: 54.3784%\n",
      "Epoch: 9030, Train Loss: 1.4543, Train Accuracy: 54.3784%\n",
      "Epoch: 9040, Train Loss: 1.4542, Train Accuracy: 54.3784%\n",
      "Epoch: 9050, Train Loss: 1.4542, Train Accuracy: 54.3784%\n",
      "Epoch: 9060, Train Loss: 1.4541, Train Accuracy: 54.3784%\n",
      "Epoch: 9070, Train Loss: 1.4540, Train Accuracy: 54.4865%\n",
      "Epoch: 9080, Train Loss: 1.4540, Train Accuracy: 54.4865%\n",
      "Epoch: 9090, Train Loss: 1.4539, Train Accuracy: 54.5946%\n",
      "Epoch: 9100, Train Loss: 1.4539, Train Accuracy: 54.5946%\n",
      "Epoch: 9110, Train Loss: 1.4538, Train Accuracy: 54.5946%\n",
      "Epoch: 9120, Train Loss: 1.4538, Train Accuracy: 54.5946%\n",
      "Epoch: 9130, Train Loss: 1.4537, Train Accuracy: 54.5946%\n",
      "Epoch: 9140, Train Loss: 1.4537, Train Accuracy: 54.5946%\n",
      "Epoch: 9150, Train Loss: 1.4536, Train Accuracy: 54.5946%\n",
      "Epoch: 9160, Train Loss: 1.4536, Train Accuracy: 54.7027%\n",
      "Epoch: 9170, Train Loss: 1.4535, Train Accuracy: 54.7027%\n",
      "Epoch: 9180, Train Loss: 1.4535, Train Accuracy: 54.7027%\n",
      "Epoch: 9190, Train Loss: 1.4534, Train Accuracy: 54.7027%\n",
      "Epoch: 9200, Train Loss: 1.4534, Train Accuracy: 54.7027%\n",
      "Epoch: 9210, Train Loss: 1.4533, Train Accuracy: 54.7027%\n",
      "Epoch: 9220, Train Loss: 1.4533, Train Accuracy: 54.7027%\n",
      "Epoch: 9230, Train Loss: 1.4532, Train Accuracy: 54.7027%\n",
      "Epoch: 9240, Train Loss: 1.4531, Train Accuracy: 54.7027%\n",
      "Epoch: 9250, Train Loss: 1.4531, Train Accuracy: 54.7027%\n",
      "Epoch: 9260, Train Loss: 1.4530, Train Accuracy: 54.7027%\n",
      "Epoch: 9270, Train Loss: 1.4530, Train Accuracy: 54.7027%\n",
      "Epoch: 9280, Train Loss: 1.4529, Train Accuracy: 54.7027%\n",
      "Epoch: 9290, Train Loss: 1.4529, Train Accuracy: 54.7027%\n",
      "Epoch: 9300, Train Loss: 1.4528, Train Accuracy: 54.7027%\n",
      "Epoch: 9310, Train Loss: 1.4528, Train Accuracy: 54.7027%\n",
      "Epoch: 9320, Train Loss: 1.4527, Train Accuracy: 54.7027%\n",
      "Epoch: 9330, Train Loss: 1.4527, Train Accuracy: 54.7027%\n",
      "Epoch: 9340, Train Loss: 1.4526, Train Accuracy: 54.7027%\n",
      "Epoch: 9350, Train Loss: 1.4526, Train Accuracy: 54.7027%\n",
      "Epoch: 9360, Train Loss: 1.4525, Train Accuracy: 54.7027%\n",
      "Epoch: 9370, Train Loss: 1.4525, Train Accuracy: 54.7027%\n",
      "Epoch: 9380, Train Loss: 1.4524, Train Accuracy: 54.7027%\n",
      "Epoch: 9390, Train Loss: 1.4524, Train Accuracy: 54.7027%\n",
      "Epoch: 9400, Train Loss: 1.4523, Train Accuracy: 54.7027%\n",
      "Epoch: 9410, Train Loss: 1.4523, Train Accuracy: 54.7027%\n",
      "Epoch: 9420, Train Loss: 1.4522, Train Accuracy: 54.7027%\n",
      "Epoch: 9430, Train Loss: 1.4522, Train Accuracy: 54.7027%\n",
      "Epoch: 9440, Train Loss: 1.4521, Train Accuracy: 54.7027%\n",
      "Epoch: 9450, Train Loss: 1.4521, Train Accuracy: 54.7027%\n",
      "Epoch: 9460, Train Loss: 1.4520, Train Accuracy: 54.7027%\n",
      "Epoch: 9470, Train Loss: 1.4520, Train Accuracy: 54.7027%\n",
      "Epoch: 9480, Train Loss: 1.4519, Train Accuracy: 54.7027%\n",
      "Epoch: 9490, Train Loss: 1.4519, Train Accuracy: 54.7027%\n",
      "Epoch: 9500, Train Loss: 1.4518, Train Accuracy: 54.5946%\n",
      "Epoch: 9510, Train Loss: 1.4518, Train Accuracy: 54.5946%\n",
      "Epoch: 9520, Train Loss: 1.4517, Train Accuracy: 54.5946%\n",
      "Epoch: 9530, Train Loss: 1.4517, Train Accuracy: 54.5946%\n",
      "Epoch: 9540, Train Loss: 1.4516, Train Accuracy: 54.5946%\n",
      "Epoch: 9550, Train Loss: 1.4516, Train Accuracy: 54.5946%\n",
      "Epoch: 9560, Train Loss: 1.4515, Train Accuracy: 54.5946%\n",
      "Epoch: 9570, Train Loss: 1.4515, Train Accuracy: 54.5946%\n",
      "Epoch: 9580, Train Loss: 1.4514, Train Accuracy: 54.5946%\n",
      "Epoch: 9590, Train Loss: 1.4514, Train Accuracy: 54.5946%\n",
      "Epoch: 9600, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 9610, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 9620, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 9630, Train Loss: 1.4512, Train Accuracy: 54.5946%\n",
      "Epoch: 9640, Train Loss: 1.4512, Train Accuracy: 54.5946%\n",
      "Epoch: 9650, Train Loss: 1.4511, Train Accuracy: 54.5946%\n",
      "Epoch: 9660, Train Loss: 1.4511, Train Accuracy: 54.5946%\n",
      "Epoch: 9670, Train Loss: 1.4510, Train Accuracy: 54.5946%\n",
      "Epoch: 9680, Train Loss: 1.4510, Train Accuracy: 54.5946%\n",
      "Epoch: 9690, Train Loss: 1.4509, Train Accuracy: 54.5946%\n",
      "Epoch: 9700, Train Loss: 1.4509, Train Accuracy: 54.5946%\n",
      "Epoch: 9710, Train Loss: 1.4508, Train Accuracy: 54.5946%\n",
      "Epoch: 9720, Train Loss: 1.4508, Train Accuracy: 54.5946%\n",
      "Epoch: 9730, Train Loss: 1.4507, Train Accuracy: 54.5946%\n",
      "Epoch: 9740, Train Loss: 1.4507, Train Accuracy: 54.5946%\n",
      "Epoch: 9750, Train Loss: 1.4506, Train Accuracy: 54.5946%\n",
      "Epoch: 9760, Train Loss: 1.4506, Train Accuracy: 54.5946%\n",
      "Epoch: 9770, Train Loss: 1.4505, Train Accuracy: 54.5946%\n",
      "Epoch: 9780, Train Loss: 1.4505, Train Accuracy: 54.5946%\n",
      "Epoch: 9790, Train Loss: 1.4505, Train Accuracy: 54.5946%\n",
      "Epoch: 9800, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 9810, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 9820, Train Loss: 1.4503, Train Accuracy: 54.5946%\n",
      "Epoch: 9830, Train Loss: 1.4503, Train Accuracy: 54.5946%\n",
      "Epoch: 9840, Train Loss: 1.4502, Train Accuracy: 54.5946%\n",
      "Epoch: 9850, Train Loss: 1.4502, Train Accuracy: 54.5946%\n",
      "Epoch: 9860, Train Loss: 1.4501, Train Accuracy: 54.4865%\n",
      "Epoch: 9870, Train Loss: 1.4501, Train Accuracy: 54.3784%\n",
      "Epoch: 9880, Train Loss: 1.4500, Train Accuracy: 54.3784%\n",
      "Epoch: 9890, Train Loss: 1.4500, Train Accuracy: 54.3784%\n",
      "Epoch: 9900, Train Loss: 1.4500, Train Accuracy: 54.3784%\n",
      "Epoch: 9910, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 9920, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 9930, Train Loss: 1.4498, Train Accuracy: 54.3784%\n",
      "Epoch: 9940, Train Loss: 1.4498, Train Accuracy: 54.3784%\n",
      "Epoch: 9950, Train Loss: 1.4497, Train Accuracy: 54.3784%\n",
      "Epoch: 9960, Train Loss: 1.4497, Train Accuracy: 54.3784%\n",
      "Epoch: 9970, Train Loss: 1.4496, Train Accuracy: 54.3784%\n",
      "Epoch: 9980, Train Loss: 1.4496, Train Accuracy: 54.3784%\n",
      "Epoch: 9990, Train Loss: 1.4495, Train Accuracy: 54.3784%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:opycsgqr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▂▃▃▄▄▄▄▄▄▄▄▄▄▄▅▅▅▅▆▅▆▆▆▆▆▆▆▆▆▇▇▇███▇</td></tr><tr><td>train_loss</td><td>██▇▆▆▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▆▄▃▃▃▃▄▃▃▃▃▃▃▃▁▃▃▃▄▄▄▄▄▄▄▄▄▄▄▆▆▆▆█▆▆▆▄▄</td></tr><tr><td>val_loss</td><td>██▇▆▆▅▅▅▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.54378</td></tr><tr><td>train_loss</td><td>1.44951</td></tr><tr><td>val_accuracy</td><td>0.54369</td></tr><tr><td>val_loss</td><td>1.42473</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.001</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/opycsgqr' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/opycsgqr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190138-opycsgqr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:opycsgqr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190158-jiewbnzn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/jiewbnzn' target=\"_blank\">Logistic Regression lr=0.0001</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/jiewbnzn' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/jiewbnzn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7916, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7914, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7912, Train Accuracy: 51.5676%\n",
      "Epoch: 40, Train Loss: 1.7911, Train Accuracy: 51.5676%\n",
      "Epoch: 50, Train Loss: 1.7909, Train Accuracy: 51.5676%\n",
      "Epoch: 60, Train Loss: 1.7907, Train Accuracy: 51.5676%\n",
      "Epoch: 70, Train Loss: 1.7906, Train Accuracy: 51.5676%\n",
      "Epoch: 80, Train Loss: 1.7904, Train Accuracy: 51.5676%\n",
      "Epoch: 90, Train Loss: 1.7902, Train Accuracy: 51.5676%\n",
      "Epoch: 100, Train Loss: 1.7900, Train Accuracy: 51.5676%\n",
      "Epoch: 110, Train Loss: 1.7899, Train Accuracy: 51.5676%\n",
      "Epoch: 120, Train Loss: 1.7897, Train Accuracy: 51.5676%\n",
      "Epoch: 130, Train Loss: 1.7895, Train Accuracy: 51.5676%\n",
      "Epoch: 140, Train Loss: 1.7894, Train Accuracy: 51.5676%\n",
      "Epoch: 150, Train Loss: 1.7892, Train Accuracy: 51.5676%\n",
      "Epoch: 160, Train Loss: 1.7890, Train Accuracy: 51.5676%\n",
      "Epoch: 170, Train Loss: 1.7888, Train Accuracy: 51.5676%\n",
      "Epoch: 180, Train Loss: 1.7887, Train Accuracy: 51.5676%\n",
      "Epoch: 190, Train Loss: 1.7885, Train Accuracy: 51.5676%\n",
      "Epoch: 200, Train Loss: 1.7883, Train Accuracy: 51.5676%\n",
      "Epoch: 210, Train Loss: 1.7882, Train Accuracy: 51.5676%\n",
      "Epoch: 220, Train Loss: 1.7880, Train Accuracy: 51.5676%\n",
      "Epoch: 230, Train Loss: 1.7878, Train Accuracy: 51.5676%\n",
      "Epoch: 240, Train Loss: 1.7877, Train Accuracy: 51.5676%\n",
      "Epoch: 250, Train Loss: 1.7875, Train Accuracy: 51.5676%\n",
      "Epoch: 260, Train Loss: 1.7873, Train Accuracy: 51.5676%\n",
      "Epoch: 270, Train Loss: 1.7872, Train Accuracy: 51.5676%\n",
      "Epoch: 280, Train Loss: 1.7870, Train Accuracy: 51.5676%\n",
      "Epoch: 290, Train Loss: 1.7868, Train Accuracy: 51.5676%\n",
      "Epoch: 300, Train Loss: 1.7866, Train Accuracy: 51.5676%\n",
      "Epoch: 310, Train Loss: 1.7865, Train Accuracy: 51.5676%\n",
      "Epoch: 320, Train Loss: 1.7863, Train Accuracy: 51.5676%\n",
      "Epoch: 330, Train Loss: 1.7861, Train Accuracy: 51.5676%\n",
      "Epoch: 340, Train Loss: 1.7860, Train Accuracy: 51.5676%\n",
      "Epoch: 350, Train Loss: 1.7858, Train Accuracy: 51.5676%\n",
      "Epoch: 360, Train Loss: 1.7856, Train Accuracy: 51.5676%\n",
      "Epoch: 370, Train Loss: 1.7855, Train Accuracy: 51.5676%\n",
      "Epoch: 380, Train Loss: 1.7853, Train Accuracy: 51.5676%\n",
      "Epoch: 390, Train Loss: 1.7851, Train Accuracy: 51.5676%\n",
      "Epoch: 400, Train Loss: 1.7850, Train Accuracy: 51.5676%\n",
      "Epoch: 410, Train Loss: 1.7848, Train Accuracy: 51.5676%\n",
      "Epoch: 420, Train Loss: 1.7846, Train Accuracy: 51.5676%\n",
      "Epoch: 430, Train Loss: 1.7845, Train Accuracy: 51.5676%\n",
      "Epoch: 440, Train Loss: 1.7843, Train Accuracy: 51.5676%\n",
      "Epoch: 450, Train Loss: 1.7841, Train Accuracy: 51.5676%\n",
      "Epoch: 460, Train Loss: 1.7840, Train Accuracy: 51.5676%\n",
      "Epoch: 470, Train Loss: 1.7838, Train Accuracy: 51.5676%\n",
      "Epoch: 480, Train Loss: 1.7836, Train Accuracy: 51.5676%\n",
      "Epoch: 490, Train Loss: 1.7835, Train Accuracy: 51.5676%\n",
      "Epoch: 500, Train Loss: 1.7833, Train Accuracy: 51.5676%\n",
      "Epoch: 510, Train Loss: 1.7831, Train Accuracy: 51.5676%\n",
      "Epoch: 520, Train Loss: 1.7830, Train Accuracy: 51.5676%\n",
      "Epoch: 530, Train Loss: 1.7828, Train Accuracy: 51.5676%\n",
      "Epoch: 540, Train Loss: 1.7826, Train Accuracy: 51.5676%\n",
      "Epoch: 550, Train Loss: 1.7825, Train Accuracy: 51.5676%\n",
      "Epoch: 560, Train Loss: 1.7823, Train Accuracy: 51.5676%\n",
      "Epoch: 570, Train Loss: 1.7821, Train Accuracy: 51.5676%\n",
      "Epoch: 580, Train Loss: 1.7820, Train Accuracy: 51.5676%\n",
      "Epoch: 590, Train Loss: 1.7818, Train Accuracy: 51.5676%\n",
      "Epoch: 600, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 610, Train Loss: 1.7815, Train Accuracy: 51.5676%\n",
      "Epoch: 620, Train Loss: 1.7813, Train Accuracy: 51.5676%\n",
      "Epoch: 630, Train Loss: 1.7811, Train Accuracy: 51.5676%\n",
      "Epoch: 640, Train Loss: 1.7810, Train Accuracy: 51.5676%\n",
      "Epoch: 650, Train Loss: 1.7808, Train Accuracy: 51.5676%\n",
      "Epoch: 660, Train Loss: 1.7806, Train Accuracy: 51.5676%\n",
      "Epoch: 670, Train Loss: 1.7805, Train Accuracy: 51.5676%\n",
      "Epoch: 680, Train Loss: 1.7803, Train Accuracy: 51.5676%\n",
      "Epoch: 690, Train Loss: 1.7801, Train Accuracy: 51.5676%\n",
      "Epoch: 700, Train Loss: 1.7800, Train Accuracy: 51.5676%\n",
      "Epoch: 710, Train Loss: 1.7798, Train Accuracy: 51.5676%\n",
      "Epoch: 720, Train Loss: 1.7796, Train Accuracy: 51.5676%\n",
      "Epoch: 730, Train Loss: 1.7795, Train Accuracy: 51.5676%\n",
      "Epoch: 740, Train Loss: 1.7793, Train Accuracy: 51.5676%\n",
      "Epoch: 750, Train Loss: 1.7791, Train Accuracy: 51.5676%\n",
      "Epoch: 760, Train Loss: 1.7790, Train Accuracy: 51.5676%\n",
      "Epoch: 770, Train Loss: 1.7788, Train Accuracy: 51.5676%\n",
      "Epoch: 780, Train Loss: 1.7787, Train Accuracy: 51.5676%\n",
      "Epoch: 790, Train Loss: 1.7785, Train Accuracy: 51.5676%\n",
      "Epoch: 800, Train Loss: 1.7783, Train Accuracy: 51.5676%\n",
      "Epoch: 810, Train Loss: 1.7782, Train Accuracy: 51.5676%\n",
      "Epoch: 820, Train Loss: 1.7780, Train Accuracy: 51.5676%\n",
      "Epoch: 830, Train Loss: 1.7778, Train Accuracy: 51.5676%\n",
      "Epoch: 840, Train Loss: 1.7777, Train Accuracy: 51.5676%\n",
      "Epoch: 850, Train Loss: 1.7775, Train Accuracy: 51.6757%\n",
      "Epoch: 860, Train Loss: 1.7773, Train Accuracy: 51.6757%\n",
      "Epoch: 870, Train Loss: 1.7772, Train Accuracy: 51.6757%\n",
      "Epoch: 880, Train Loss: 1.7770, Train Accuracy: 51.6757%\n",
      "Epoch: 890, Train Loss: 1.7769, Train Accuracy: 51.6757%\n",
      "Epoch: 900, Train Loss: 1.7767, Train Accuracy: 51.6757%\n",
      "Epoch: 910, Train Loss: 1.7765, Train Accuracy: 51.6757%\n",
      "Epoch: 920, Train Loss: 1.7764, Train Accuracy: 51.6757%\n",
      "Epoch: 930, Train Loss: 1.7762, Train Accuracy: 51.6757%\n",
      "Epoch: 940, Train Loss: 1.7760, Train Accuracy: 51.6757%\n",
      "Epoch: 950, Train Loss: 1.7759, Train Accuracy: 51.6757%\n",
      "Epoch: 960, Train Loss: 1.7757, Train Accuracy: 51.6757%\n",
      "Epoch: 970, Train Loss: 1.7755, Train Accuracy: 51.6757%\n",
      "Epoch: 980, Train Loss: 1.7754, Train Accuracy: 51.6757%\n",
      "Epoch: 990, Train Loss: 1.7752, Train Accuracy: 51.6757%\n",
      "Epoch: 1000, Train Loss: 1.7751, Train Accuracy: 51.6757%\n",
      "Epoch: 1010, Train Loss: 1.7749, Train Accuracy: 51.6757%\n",
      "Epoch: 1020, Train Loss: 1.7747, Train Accuracy: 51.6757%\n",
      "Epoch: 1030, Train Loss: 1.7746, Train Accuracy: 51.6757%\n",
      "Epoch: 1040, Train Loss: 1.7744, Train Accuracy: 51.6757%\n",
      "Epoch: 1050, Train Loss: 1.7743, Train Accuracy: 51.6757%\n",
      "Epoch: 1060, Train Loss: 1.7741, Train Accuracy: 51.6757%\n",
      "Epoch: 1070, Train Loss: 1.7739, Train Accuracy: 51.6757%\n",
      "Epoch: 1080, Train Loss: 1.7738, Train Accuracy: 51.6757%\n",
      "Epoch: 1090, Train Loss: 1.7736, Train Accuracy: 51.6757%\n",
      "Epoch: 1100, Train Loss: 1.7734, Train Accuracy: 51.6757%\n",
      "Epoch: 1110, Train Loss: 1.7733, Train Accuracy: 51.6757%\n",
      "Epoch: 1120, Train Loss: 1.7731, Train Accuracy: 51.6757%\n",
      "Epoch: 1130, Train Loss: 1.7730, Train Accuracy: 51.6757%\n",
      "Epoch: 1140, Train Loss: 1.7728, Train Accuracy: 51.6757%\n",
      "Epoch: 1150, Train Loss: 1.7726, Train Accuracy: 51.6757%\n",
      "Epoch: 1160, Train Loss: 1.7725, Train Accuracy: 51.6757%\n",
      "Epoch: 1170, Train Loss: 1.7723, Train Accuracy: 51.6757%\n",
      "Epoch: 1180, Train Loss: 1.7722, Train Accuracy: 51.6757%\n",
      "Epoch: 1190, Train Loss: 1.7720, Train Accuracy: 51.6757%\n",
      "Epoch: 1200, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 1210, Train Loss: 1.7717, Train Accuracy: 51.6757%\n",
      "Epoch: 1220, Train Loss: 1.7715, Train Accuracy: 51.6757%\n",
      "Epoch: 1230, Train Loss: 1.7714, Train Accuracy: 51.6757%\n",
      "Epoch: 1240, Train Loss: 1.7712, Train Accuracy: 51.6757%\n",
      "Epoch: 1250, Train Loss: 1.7710, Train Accuracy: 51.6757%\n",
      "Epoch: 1260, Train Loss: 1.7709, Train Accuracy: 51.6757%\n",
      "Epoch: 1270, Train Loss: 1.7707, Train Accuracy: 51.6757%\n",
      "Epoch: 1280, Train Loss: 1.7706, Train Accuracy: 51.6757%\n",
      "Epoch: 1290, Train Loss: 1.7704, Train Accuracy: 51.6757%\n",
      "Epoch: 1300, Train Loss: 1.7702, Train Accuracy: 51.6757%\n",
      "Epoch: 1310, Train Loss: 1.7701, Train Accuracy: 51.6757%\n",
      "Epoch: 1320, Train Loss: 1.7699, Train Accuracy: 51.6757%\n",
      "Epoch: 1330, Train Loss: 1.7698, Train Accuracy: 51.6757%\n",
      "Epoch: 1340, Train Loss: 1.7696, Train Accuracy: 51.6757%\n",
      "Epoch: 1350, Train Loss: 1.7695, Train Accuracy: 51.6757%\n",
      "Epoch: 1360, Train Loss: 1.7693, Train Accuracy: 51.6757%\n",
      "Epoch: 1370, Train Loss: 1.7691, Train Accuracy: 51.6757%\n",
      "Epoch: 1380, Train Loss: 1.7690, Train Accuracy: 51.6757%\n",
      "Epoch: 1390, Train Loss: 1.7688, Train Accuracy: 51.6757%\n",
      "Epoch: 1400, Train Loss: 1.7687, Train Accuracy: 51.6757%\n",
      "Epoch: 1410, Train Loss: 1.7685, Train Accuracy: 51.6757%\n",
      "Epoch: 1420, Train Loss: 1.7683, Train Accuracy: 51.6757%\n",
      "Epoch: 1430, Train Loss: 1.7682, Train Accuracy: 51.6757%\n",
      "Epoch: 1440, Train Loss: 1.7680, Train Accuracy: 51.6757%\n",
      "Epoch: 1450, Train Loss: 1.7679, Train Accuracy: 51.6757%\n",
      "Epoch: 1460, Train Loss: 1.7677, Train Accuracy: 51.6757%\n",
      "Epoch: 1470, Train Loss: 1.7676, Train Accuracy: 51.6757%\n",
      "Epoch: 1480, Train Loss: 1.7674, Train Accuracy: 51.6757%\n",
      "Epoch: 1490, Train Loss: 1.7672, Train Accuracy: 51.6757%\n",
      "Epoch: 1500, Train Loss: 1.7671, Train Accuracy: 51.6757%\n",
      "Epoch: 1510, Train Loss: 1.7669, Train Accuracy: 51.6757%\n",
      "Epoch: 1520, Train Loss: 1.7668, Train Accuracy: 51.6757%\n",
      "Epoch: 1530, Train Loss: 1.7666, Train Accuracy: 51.6757%\n",
      "Epoch: 1540, Train Loss: 1.7665, Train Accuracy: 51.6757%\n",
      "Epoch: 1550, Train Loss: 1.7663, Train Accuracy: 51.6757%\n",
      "Epoch: 1560, Train Loss: 1.7661, Train Accuracy: 51.6757%\n",
      "Epoch: 1570, Train Loss: 1.7660, Train Accuracy: 51.6757%\n",
      "Epoch: 1580, Train Loss: 1.7658, Train Accuracy: 51.6757%\n",
      "Epoch: 1590, Train Loss: 1.7657, Train Accuracy: 51.6757%\n",
      "Epoch: 1600, Train Loss: 1.7655, Train Accuracy: 51.6757%\n",
      "Epoch: 1610, Train Loss: 1.7654, Train Accuracy: 51.6757%\n",
      "Epoch: 1620, Train Loss: 1.7652, Train Accuracy: 51.6757%\n",
      "Epoch: 1630, Train Loss: 1.7650, Train Accuracy: 51.6757%\n",
      "Epoch: 1640, Train Loss: 1.7649, Train Accuracy: 51.6757%\n",
      "Epoch: 1650, Train Loss: 1.7647, Train Accuracy: 51.6757%\n",
      "Epoch: 1660, Train Loss: 1.7646, Train Accuracy: 51.6757%\n",
      "Epoch: 1670, Train Loss: 1.7644, Train Accuracy: 51.6757%\n",
      "Epoch: 1680, Train Loss: 1.7643, Train Accuracy: 51.6757%\n",
      "Epoch: 1690, Train Loss: 1.7641, Train Accuracy: 51.6757%\n",
      "Epoch: 1700, Train Loss: 1.7640, Train Accuracy: 51.6757%\n",
      "Epoch: 1710, Train Loss: 1.7638, Train Accuracy: 51.6757%\n",
      "Epoch: 1720, Train Loss: 1.7636, Train Accuracy: 51.6757%\n",
      "Epoch: 1730, Train Loss: 1.7635, Train Accuracy: 51.6757%\n",
      "Epoch: 1740, Train Loss: 1.7633, Train Accuracy: 51.6757%\n",
      "Epoch: 1750, Train Loss: 1.7632, Train Accuracy: 51.6757%\n",
      "Epoch: 1760, Train Loss: 1.7630, Train Accuracy: 51.6757%\n",
      "Epoch: 1770, Train Loss: 1.7629, Train Accuracy: 51.6757%\n",
      "Epoch: 1780, Train Loss: 1.7627, Train Accuracy: 51.6757%\n",
      "Epoch: 1790, Train Loss: 1.7626, Train Accuracy: 51.6757%\n",
      "Epoch: 1800, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 1810, Train Loss: 1.7623, Train Accuracy: 51.6757%\n",
      "Epoch: 1820, Train Loss: 1.7621, Train Accuracy: 51.6757%\n",
      "Epoch: 1830, Train Loss: 1.7619, Train Accuracy: 51.6757%\n",
      "Epoch: 1840, Train Loss: 1.7618, Train Accuracy: 51.6757%\n",
      "Epoch: 1850, Train Loss: 1.7616, Train Accuracy: 51.6757%\n",
      "Epoch: 1860, Train Loss: 1.7615, Train Accuracy: 51.6757%\n",
      "Epoch: 1870, Train Loss: 1.7613, Train Accuracy: 51.6757%\n",
      "Epoch: 1880, Train Loss: 1.7612, Train Accuracy: 51.6757%\n",
      "Epoch: 1890, Train Loss: 1.7610, Train Accuracy: 51.6757%\n",
      "Epoch: 1900, Train Loss: 1.7609, Train Accuracy: 51.6757%\n",
      "Epoch: 1910, Train Loss: 1.7607, Train Accuracy: 51.6757%\n",
      "Epoch: 1920, Train Loss: 1.7606, Train Accuracy: 51.6757%\n",
      "Epoch: 1930, Train Loss: 1.7604, Train Accuracy: 51.6757%\n",
      "Epoch: 1940, Train Loss: 1.7603, Train Accuracy: 51.6757%\n",
      "Epoch: 1950, Train Loss: 1.7601, Train Accuracy: 51.6757%\n",
      "Epoch: 1960, Train Loss: 1.7599, Train Accuracy: 51.6757%\n",
      "Epoch: 1970, Train Loss: 1.7598, Train Accuracy: 51.6757%\n",
      "Epoch: 1980, Train Loss: 1.7596, Train Accuracy: 51.6757%\n",
      "Epoch: 1990, Train Loss: 1.7595, Train Accuracy: 51.6757%\n",
      "Epoch: 2000, Train Loss: 1.7593, Train Accuracy: 51.6757%\n",
      "Epoch: 2010, Train Loss: 1.7592, Train Accuracy: 51.6757%\n",
      "Epoch: 2020, Train Loss: 1.7590, Train Accuracy: 51.6757%\n",
      "Epoch: 2030, Train Loss: 1.7589, Train Accuracy: 51.6757%\n",
      "Epoch: 2040, Train Loss: 1.7587, Train Accuracy: 51.6757%\n",
      "Epoch: 2050, Train Loss: 1.7586, Train Accuracy: 51.6757%\n",
      "Epoch: 2060, Train Loss: 1.7584, Train Accuracy: 51.6757%\n",
      "Epoch: 2070, Train Loss: 1.7583, Train Accuracy: 51.6757%\n",
      "Epoch: 2080, Train Loss: 1.7581, Train Accuracy: 51.6757%\n",
      "Epoch: 2090, Train Loss: 1.7580, Train Accuracy: 51.6757%\n",
      "Epoch: 2100, Train Loss: 1.7578, Train Accuracy: 51.6757%\n",
      "Epoch: 2110, Train Loss: 1.7577, Train Accuracy: 51.6757%\n",
      "Epoch: 2120, Train Loss: 1.7575, Train Accuracy: 51.6757%\n",
      "Epoch: 2130, Train Loss: 1.7574, Train Accuracy: 51.6757%\n",
      "Epoch: 2140, Train Loss: 1.7572, Train Accuracy: 51.6757%\n",
      "Epoch: 2150, Train Loss: 1.7571, Train Accuracy: 51.6757%\n",
      "Epoch: 2160, Train Loss: 1.7569, Train Accuracy: 51.6757%\n",
      "Epoch: 2170, Train Loss: 1.7568, Train Accuracy: 51.6757%\n",
      "Epoch: 2180, Train Loss: 1.7566, Train Accuracy: 51.6757%\n",
      "Epoch: 2190, Train Loss: 1.7564, Train Accuracy: 51.6757%\n",
      "Epoch: 2200, Train Loss: 1.7563, Train Accuracy: 51.6757%\n",
      "Epoch: 2210, Train Loss: 1.7561, Train Accuracy: 51.6757%\n",
      "Epoch: 2220, Train Loss: 1.7560, Train Accuracy: 51.6757%\n",
      "Epoch: 2230, Train Loss: 1.7558, Train Accuracy: 51.6757%\n",
      "Epoch: 2240, Train Loss: 1.7557, Train Accuracy: 51.6757%\n",
      "Epoch: 2250, Train Loss: 1.7555, Train Accuracy: 51.6757%\n",
      "Epoch: 2260, Train Loss: 1.7554, Train Accuracy: 51.6757%\n",
      "Epoch: 2270, Train Loss: 1.7552, Train Accuracy: 51.6757%\n",
      "Epoch: 2280, Train Loss: 1.7551, Train Accuracy: 51.6757%\n",
      "Epoch: 2290, Train Loss: 1.7549, Train Accuracy: 51.6757%\n",
      "Epoch: 2300, Train Loss: 1.7548, Train Accuracy: 51.6757%\n",
      "Epoch: 2310, Train Loss: 1.7546, Train Accuracy: 51.6757%\n",
      "Epoch: 2320, Train Loss: 1.7545, Train Accuracy: 51.6757%\n",
      "Epoch: 2330, Train Loss: 1.7543, Train Accuracy: 51.6757%\n",
      "Epoch: 2340, Train Loss: 1.7542, Train Accuracy: 51.6757%\n",
      "Epoch: 2350, Train Loss: 1.7540, Train Accuracy: 51.6757%\n",
      "Epoch: 2360, Train Loss: 1.7539, Train Accuracy: 51.6757%\n",
      "Epoch: 2370, Train Loss: 1.7537, Train Accuracy: 51.6757%\n",
      "Epoch: 2380, Train Loss: 1.7536, Train Accuracy: 51.6757%\n",
      "Epoch: 2390, Train Loss: 1.7534, Train Accuracy: 51.6757%\n",
      "Epoch: 2400, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 2410, Train Loss: 1.7531, Train Accuracy: 51.6757%\n",
      "Epoch: 2420, Train Loss: 1.7530, Train Accuracy: 51.6757%\n",
      "Epoch: 2430, Train Loss: 1.7529, Train Accuracy: 51.6757%\n",
      "Epoch: 2440, Train Loss: 1.7527, Train Accuracy: 51.6757%\n",
      "Epoch: 2450, Train Loss: 1.7526, Train Accuracy: 51.6757%\n",
      "Epoch: 2460, Train Loss: 1.7524, Train Accuracy: 51.6757%\n",
      "Epoch: 2470, Train Loss: 1.7523, Train Accuracy: 51.6757%\n",
      "Epoch: 2480, Train Loss: 1.7521, Train Accuracy: 51.6757%\n",
      "Epoch: 2490, Train Loss: 1.7520, Train Accuracy: 51.6757%\n",
      "Epoch: 2500, Train Loss: 1.7518, Train Accuracy: 51.6757%\n",
      "Epoch: 2510, Train Loss: 1.7517, Train Accuracy: 51.6757%\n",
      "Epoch: 2520, Train Loss: 1.7515, Train Accuracy: 51.6757%\n",
      "Epoch: 2530, Train Loss: 1.7514, Train Accuracy: 51.6757%\n",
      "Epoch: 2540, Train Loss: 1.7512, Train Accuracy: 51.6757%\n",
      "Epoch: 2550, Train Loss: 1.7511, Train Accuracy: 51.6757%\n",
      "Epoch: 2560, Train Loss: 1.7509, Train Accuracy: 51.6757%\n",
      "Epoch: 2570, Train Loss: 1.7508, Train Accuracy: 51.6757%\n",
      "Epoch: 2580, Train Loss: 1.7506, Train Accuracy: 51.6757%\n",
      "Epoch: 2590, Train Loss: 1.7505, Train Accuracy: 51.6757%\n",
      "Epoch: 2600, Train Loss: 1.7503, Train Accuracy: 51.6757%\n",
      "Epoch: 2610, Train Loss: 1.7502, Train Accuracy: 51.6757%\n",
      "Epoch: 2620, Train Loss: 1.7500, Train Accuracy: 51.6757%\n",
      "Epoch: 2630, Train Loss: 1.7499, Train Accuracy: 51.6757%\n",
      "Epoch: 2640, Train Loss: 1.7497, Train Accuracy: 51.6757%\n",
      "Epoch: 2650, Train Loss: 1.7496, Train Accuracy: 51.6757%\n",
      "Epoch: 2660, Train Loss: 1.7495, Train Accuracy: 51.6757%\n",
      "Epoch: 2670, Train Loss: 1.7493, Train Accuracy: 51.6757%\n",
      "Epoch: 2680, Train Loss: 1.7492, Train Accuracy: 51.6757%\n",
      "Epoch: 2690, Train Loss: 1.7490, Train Accuracy: 51.6757%\n",
      "Epoch: 2700, Train Loss: 1.7489, Train Accuracy: 51.6757%\n",
      "Epoch: 2710, Train Loss: 1.7487, Train Accuracy: 51.6757%\n",
      "Epoch: 2720, Train Loss: 1.7486, Train Accuracy: 51.6757%\n",
      "Epoch: 2730, Train Loss: 1.7484, Train Accuracy: 51.6757%\n",
      "Epoch: 2740, Train Loss: 1.7483, Train Accuracy: 51.6757%\n",
      "Epoch: 2750, Train Loss: 1.7481, Train Accuracy: 51.6757%\n",
      "Epoch: 2760, Train Loss: 1.7480, Train Accuracy: 51.6757%\n",
      "Epoch: 2770, Train Loss: 1.7478, Train Accuracy: 51.6757%\n",
      "Epoch: 2780, Train Loss: 1.7477, Train Accuracy: 51.6757%\n",
      "Epoch: 2790, Train Loss: 1.7476, Train Accuracy: 51.6757%\n",
      "Epoch: 2800, Train Loss: 1.7474, Train Accuracy: 51.6757%\n",
      "Epoch: 2810, Train Loss: 1.7473, Train Accuracy: 51.6757%\n",
      "Epoch: 2820, Train Loss: 1.7471, Train Accuracy: 51.6757%\n",
      "Epoch: 2830, Train Loss: 1.7470, Train Accuracy: 51.6757%\n",
      "Epoch: 2840, Train Loss: 1.7468, Train Accuracy: 51.6757%\n",
      "Epoch: 2850, Train Loss: 1.7467, Train Accuracy: 51.6757%\n",
      "Epoch: 2860, Train Loss: 1.7465, Train Accuracy: 51.6757%\n",
      "Epoch: 2870, Train Loss: 1.7464, Train Accuracy: 51.6757%\n",
      "Epoch: 2880, Train Loss: 1.7462, Train Accuracy: 51.6757%\n",
      "Epoch: 2890, Train Loss: 1.7461, Train Accuracy: 51.6757%\n",
      "Epoch: 2900, Train Loss: 1.7460, Train Accuracy: 51.6757%\n",
      "Epoch: 2910, Train Loss: 1.7458, Train Accuracy: 51.6757%\n",
      "Epoch: 2920, Train Loss: 1.7457, Train Accuracy: 51.6757%\n",
      "Epoch: 2930, Train Loss: 1.7455, Train Accuracy: 51.6757%\n",
      "Epoch: 2940, Train Loss: 1.7454, Train Accuracy: 51.6757%\n",
      "Epoch: 2950, Train Loss: 1.7452, Train Accuracy: 51.6757%\n",
      "Epoch: 2960, Train Loss: 1.7451, Train Accuracy: 51.6757%\n",
      "Epoch: 2970, Train Loss: 1.7449, Train Accuracy: 51.6757%\n",
      "Epoch: 2980, Train Loss: 1.7448, Train Accuracy: 51.6757%\n",
      "Epoch: 2990, Train Loss: 1.7447, Train Accuracy: 51.6757%\n",
      "Epoch: 3000, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 3010, Train Loss: 1.7444, Train Accuracy: 51.6757%\n",
      "Epoch: 3020, Train Loss: 1.7442, Train Accuracy: 51.6757%\n",
      "Epoch: 3030, Train Loss: 1.7441, Train Accuracy: 51.6757%\n",
      "Epoch: 3040, Train Loss: 1.7439, Train Accuracy: 51.6757%\n",
      "Epoch: 3050, Train Loss: 1.7438, Train Accuracy: 51.6757%\n",
      "Epoch: 3060, Train Loss: 1.7436, Train Accuracy: 51.6757%\n",
      "Epoch: 3070, Train Loss: 1.7435, Train Accuracy: 51.6757%\n",
      "Epoch: 3080, Train Loss: 1.7434, Train Accuracy: 51.6757%\n",
      "Epoch: 3090, Train Loss: 1.7432, Train Accuracy: 51.6757%\n",
      "Epoch: 3100, Train Loss: 1.7431, Train Accuracy: 51.6757%\n",
      "Epoch: 3110, Train Loss: 1.7429, Train Accuracy: 51.6757%\n",
      "Epoch: 3120, Train Loss: 1.7428, Train Accuracy: 51.6757%\n",
      "Epoch: 3130, Train Loss: 1.7426, Train Accuracy: 51.6757%\n",
      "Epoch: 3140, Train Loss: 1.7425, Train Accuracy: 51.6757%\n",
      "Epoch: 3150, Train Loss: 1.7424, Train Accuracy: 51.6757%\n",
      "Epoch: 3160, Train Loss: 1.7422, Train Accuracy: 51.6757%\n",
      "Epoch: 3170, Train Loss: 1.7421, Train Accuracy: 51.6757%\n",
      "Epoch: 3180, Train Loss: 1.7419, Train Accuracy: 51.6757%\n",
      "Epoch: 3190, Train Loss: 1.7418, Train Accuracy: 51.6757%\n",
      "Epoch: 3200, Train Loss: 1.7416, Train Accuracy: 51.6757%\n",
      "Epoch: 3210, Train Loss: 1.7415, Train Accuracy: 51.6757%\n",
      "Epoch: 3220, Train Loss: 1.7414, Train Accuracy: 51.6757%\n",
      "Epoch: 3230, Train Loss: 1.7412, Train Accuracy: 51.6757%\n",
      "Epoch: 3240, Train Loss: 1.7411, Train Accuracy: 51.6757%\n",
      "Epoch: 3250, Train Loss: 1.7409, Train Accuracy: 51.6757%\n",
      "Epoch: 3260, Train Loss: 1.7408, Train Accuracy: 51.6757%\n",
      "Epoch: 3270, Train Loss: 1.7407, Train Accuracy: 51.6757%\n",
      "Epoch: 3280, Train Loss: 1.7405, Train Accuracy: 51.6757%\n",
      "Epoch: 3290, Train Loss: 1.7404, Train Accuracy: 51.6757%\n",
      "Epoch: 3300, Train Loss: 1.7402, Train Accuracy: 51.6757%\n",
      "Epoch: 3310, Train Loss: 1.7401, Train Accuracy: 51.6757%\n",
      "Epoch: 3320, Train Loss: 1.7399, Train Accuracy: 51.6757%\n",
      "Epoch: 3330, Train Loss: 1.7398, Train Accuracy: 51.6757%\n",
      "Epoch: 3340, Train Loss: 1.7397, Train Accuracy: 51.6757%\n",
      "Epoch: 3350, Train Loss: 1.7395, Train Accuracy: 51.6757%\n",
      "Epoch: 3360, Train Loss: 1.7394, Train Accuracy: 51.6757%\n",
      "Epoch: 3370, Train Loss: 1.7392, Train Accuracy: 51.6757%\n",
      "Epoch: 3380, Train Loss: 1.7391, Train Accuracy: 51.6757%\n",
      "Epoch: 3390, Train Loss: 1.7390, Train Accuracy: 51.6757%\n",
      "Epoch: 3400, Train Loss: 1.7388, Train Accuracy: 51.6757%\n",
      "Epoch: 3410, Train Loss: 1.7387, Train Accuracy: 51.6757%\n",
      "Epoch: 3420, Train Loss: 1.7385, Train Accuracy: 51.6757%\n",
      "Epoch: 3430, Train Loss: 1.7384, Train Accuracy: 51.6757%\n",
      "Epoch: 3440, Train Loss: 1.7383, Train Accuracy: 51.6757%\n",
      "Epoch: 3450, Train Loss: 1.7381, Train Accuracy: 51.6757%\n",
      "Epoch: 3460, Train Loss: 1.7380, Train Accuracy: 51.6757%\n",
      "Epoch: 3470, Train Loss: 1.7378, Train Accuracy: 51.6757%\n",
      "Epoch: 3480, Train Loss: 1.7377, Train Accuracy: 51.6757%\n",
      "Epoch: 3490, Train Loss: 1.7376, Train Accuracy: 51.6757%\n",
      "Epoch: 3500, Train Loss: 1.7374, Train Accuracy: 51.6757%\n",
      "Epoch: 3510, Train Loss: 1.7373, Train Accuracy: 51.6757%\n",
      "Epoch: 3520, Train Loss: 1.7371, Train Accuracy: 51.6757%\n",
      "Epoch: 3530, Train Loss: 1.7370, Train Accuracy: 51.6757%\n",
      "Epoch: 3540, Train Loss: 1.7369, Train Accuracy: 51.6757%\n",
      "Epoch: 3550, Train Loss: 1.7367, Train Accuracy: 51.6757%\n",
      "Epoch: 3560, Train Loss: 1.7366, Train Accuracy: 51.6757%\n",
      "Epoch: 3570, Train Loss: 1.7364, Train Accuracy: 51.6757%\n",
      "Epoch: 3580, Train Loss: 1.7363, Train Accuracy: 51.6757%\n",
      "Epoch: 3590, Train Loss: 1.7362, Train Accuracy: 51.6757%\n",
      "Epoch: 3600, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 3610, Train Loss: 1.7359, Train Accuracy: 51.6757%\n",
      "Epoch: 3620, Train Loss: 1.7357, Train Accuracy: 51.6757%\n",
      "Epoch: 3630, Train Loss: 1.7356, Train Accuracy: 51.6757%\n",
      "Epoch: 3640, Train Loss: 1.7355, Train Accuracy: 51.6757%\n",
      "Epoch: 3650, Train Loss: 1.7353, Train Accuracy: 51.6757%\n",
      "Epoch: 3660, Train Loss: 1.7352, Train Accuracy: 51.6757%\n",
      "Epoch: 3670, Train Loss: 1.7351, Train Accuracy: 51.6757%\n",
      "Epoch: 3680, Train Loss: 1.7349, Train Accuracy: 51.6757%\n",
      "Epoch: 3690, Train Loss: 1.7348, Train Accuracy: 51.6757%\n",
      "Epoch: 3700, Train Loss: 1.7346, Train Accuracy: 51.6757%\n",
      "Epoch: 3710, Train Loss: 1.7345, Train Accuracy: 51.6757%\n",
      "Epoch: 3720, Train Loss: 1.7344, Train Accuracy: 51.6757%\n",
      "Epoch: 3730, Train Loss: 1.7342, Train Accuracy: 51.6757%\n",
      "Epoch: 3740, Train Loss: 1.7341, Train Accuracy: 51.6757%\n",
      "Epoch: 3750, Train Loss: 1.7340, Train Accuracy: 51.6757%\n",
      "Epoch: 3760, Train Loss: 1.7338, Train Accuracy: 51.6757%\n",
      "Epoch: 3770, Train Loss: 1.7337, Train Accuracy: 51.6757%\n",
      "Epoch: 3780, Train Loss: 1.7335, Train Accuracy: 51.6757%\n",
      "Epoch: 3790, Train Loss: 1.7334, Train Accuracy: 51.6757%\n",
      "Epoch: 3800, Train Loss: 1.7333, Train Accuracy: 51.6757%\n",
      "Epoch: 3810, Train Loss: 1.7331, Train Accuracy: 51.6757%\n",
      "Epoch: 3820, Train Loss: 1.7330, Train Accuracy: 51.6757%\n",
      "Epoch: 3830, Train Loss: 1.7329, Train Accuracy: 51.6757%\n",
      "Epoch: 3840, Train Loss: 1.7327, Train Accuracy: 51.6757%\n",
      "Epoch: 3850, Train Loss: 1.7326, Train Accuracy: 51.6757%\n",
      "Epoch: 3860, Train Loss: 1.7324, Train Accuracy: 51.6757%\n",
      "Epoch: 3870, Train Loss: 1.7323, Train Accuracy: 51.6757%\n",
      "Epoch: 3880, Train Loss: 1.7322, Train Accuracy: 51.6757%\n",
      "Epoch: 3890, Train Loss: 1.7320, Train Accuracy: 51.6757%\n",
      "Epoch: 3900, Train Loss: 1.7319, Train Accuracy: 51.6757%\n",
      "Epoch: 3910, Train Loss: 1.7318, Train Accuracy: 51.6757%\n",
      "Epoch: 3920, Train Loss: 1.7316, Train Accuracy: 51.6757%\n",
      "Epoch: 3930, Train Loss: 1.7315, Train Accuracy: 51.6757%\n",
      "Epoch: 3940, Train Loss: 1.7313, Train Accuracy: 51.6757%\n",
      "Epoch: 3950, Train Loss: 1.7312, Train Accuracy: 51.6757%\n",
      "Epoch: 3960, Train Loss: 1.7311, Train Accuracy: 51.6757%\n",
      "Epoch: 3970, Train Loss: 1.7309, Train Accuracy: 51.6757%\n",
      "Epoch: 3980, Train Loss: 1.7308, Train Accuracy: 51.6757%\n",
      "Epoch: 3990, Train Loss: 1.7307, Train Accuracy: 51.6757%\n",
      "Epoch: 4000, Train Loss: 1.7305, Train Accuracy: 51.6757%\n",
      "Epoch: 4010, Train Loss: 1.7304, Train Accuracy: 51.6757%\n",
      "Epoch: 4020, Train Loss: 1.7303, Train Accuracy: 51.6757%\n",
      "Epoch: 4030, Train Loss: 1.7301, Train Accuracy: 51.6757%\n",
      "Epoch: 4040, Train Loss: 1.7300, Train Accuracy: 51.6757%\n",
      "Epoch: 4050, Train Loss: 1.7299, Train Accuracy: 51.6757%\n",
      "Epoch: 4060, Train Loss: 1.7297, Train Accuracy: 51.6757%\n",
      "Epoch: 4070, Train Loss: 1.7296, Train Accuracy: 51.6757%\n",
      "Epoch: 4080, Train Loss: 1.7295, Train Accuracy: 51.6757%\n",
      "Epoch: 4090, Train Loss: 1.7293, Train Accuracy: 51.6757%\n",
      "Epoch: 4100, Train Loss: 1.7292, Train Accuracy: 51.6757%\n",
      "Epoch: 4110, Train Loss: 1.7290, Train Accuracy: 51.6757%\n",
      "Epoch: 4120, Train Loss: 1.7289, Train Accuracy: 51.6757%\n",
      "Epoch: 4130, Train Loss: 1.7288, Train Accuracy: 51.6757%\n",
      "Epoch: 4140, Train Loss: 1.7286, Train Accuracy: 51.6757%\n",
      "Epoch: 4150, Train Loss: 1.7285, Train Accuracy: 51.6757%\n",
      "Epoch: 4160, Train Loss: 1.7284, Train Accuracy: 51.6757%\n",
      "Epoch: 4170, Train Loss: 1.7282, Train Accuracy: 51.6757%\n",
      "Epoch: 4180, Train Loss: 1.7281, Train Accuracy: 51.6757%\n",
      "Epoch: 4190, Train Loss: 1.7280, Train Accuracy: 51.6757%\n",
      "Epoch: 4200, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 4210, Train Loss: 1.7277, Train Accuracy: 51.6757%\n",
      "Epoch: 4220, Train Loss: 1.7276, Train Accuracy: 51.6757%\n",
      "Epoch: 4230, Train Loss: 1.7274, Train Accuracy: 51.6757%\n",
      "Epoch: 4240, Train Loss: 1.7273, Train Accuracy: 51.6757%\n",
      "Epoch: 4250, Train Loss: 1.7272, Train Accuracy: 51.6757%\n",
      "Epoch: 4260, Train Loss: 1.7270, Train Accuracy: 51.6757%\n",
      "Epoch: 4270, Train Loss: 1.7269, Train Accuracy: 51.6757%\n",
      "Epoch: 4280, Train Loss: 1.7268, Train Accuracy: 51.6757%\n",
      "Epoch: 4290, Train Loss: 1.7266, Train Accuracy: 51.6757%\n",
      "Epoch: 4300, Train Loss: 1.7265, Train Accuracy: 51.6757%\n",
      "Epoch: 4310, Train Loss: 1.7264, Train Accuracy: 51.6757%\n",
      "Epoch: 4320, Train Loss: 1.7262, Train Accuracy: 51.6757%\n",
      "Epoch: 4330, Train Loss: 1.7261, Train Accuracy: 51.6757%\n",
      "Epoch: 4340, Train Loss: 1.7260, Train Accuracy: 51.6757%\n",
      "Epoch: 4350, Train Loss: 1.7258, Train Accuracy: 51.6757%\n",
      "Epoch: 4360, Train Loss: 1.7257, Train Accuracy: 51.6757%\n",
      "Epoch: 4370, Train Loss: 1.7256, Train Accuracy: 51.6757%\n",
      "Epoch: 4380, Train Loss: 1.7254, Train Accuracy: 51.6757%\n",
      "Epoch: 4390, Train Loss: 1.7253, Train Accuracy: 51.6757%\n",
      "Epoch: 4400, Train Loss: 1.7252, Train Accuracy: 51.6757%\n",
      "Epoch: 4410, Train Loss: 1.7250, Train Accuracy: 51.6757%\n",
      "Epoch: 4420, Train Loss: 1.7249, Train Accuracy: 51.6757%\n",
      "Epoch: 4430, Train Loss: 1.7248, Train Accuracy: 51.6757%\n",
      "Epoch: 4440, Train Loss: 1.7246, Train Accuracy: 51.6757%\n",
      "Epoch: 4450, Train Loss: 1.7245, Train Accuracy: 51.6757%\n",
      "Epoch: 4460, Train Loss: 1.7244, Train Accuracy: 51.6757%\n",
      "Epoch: 4470, Train Loss: 1.7242, Train Accuracy: 51.6757%\n",
      "Epoch: 4480, Train Loss: 1.7241, Train Accuracy: 51.6757%\n",
      "Epoch: 4490, Train Loss: 1.7240, Train Accuracy: 51.6757%\n",
      "Epoch: 4500, Train Loss: 1.7238, Train Accuracy: 51.6757%\n",
      "Epoch: 4510, Train Loss: 1.7237, Train Accuracy: 51.6757%\n",
      "Epoch: 4520, Train Loss: 1.7236, Train Accuracy: 51.6757%\n",
      "Epoch: 4530, Train Loss: 1.7235, Train Accuracy: 51.6757%\n",
      "Epoch: 4540, Train Loss: 1.7233, Train Accuracy: 51.6757%\n",
      "Epoch: 4550, Train Loss: 1.7232, Train Accuracy: 51.6757%\n",
      "Epoch: 4560, Train Loss: 1.7231, Train Accuracy: 51.6757%\n",
      "Epoch: 4570, Train Loss: 1.7229, Train Accuracy: 51.6757%\n",
      "Epoch: 4580, Train Loss: 1.7228, Train Accuracy: 51.6757%\n",
      "Epoch: 4590, Train Loss: 1.7227, Train Accuracy: 51.6757%\n",
      "Epoch: 4600, Train Loss: 1.7225, Train Accuracy: 51.6757%\n",
      "Epoch: 4610, Train Loss: 1.7224, Train Accuracy: 51.6757%\n",
      "Epoch: 4620, Train Loss: 1.7223, Train Accuracy: 51.6757%\n",
      "Epoch: 4630, Train Loss: 1.7221, Train Accuracy: 51.6757%\n",
      "Epoch: 4640, Train Loss: 1.7220, Train Accuracy: 51.6757%\n",
      "Epoch: 4650, Train Loss: 1.7219, Train Accuracy: 51.6757%\n",
      "Epoch: 4660, Train Loss: 1.7217, Train Accuracy: 51.6757%\n",
      "Epoch: 4670, Train Loss: 1.7216, Train Accuracy: 51.6757%\n",
      "Epoch: 4680, Train Loss: 1.7215, Train Accuracy: 51.6757%\n",
      "Epoch: 4690, Train Loss: 1.7214, Train Accuracy: 51.6757%\n",
      "Epoch: 4700, Train Loss: 1.7212, Train Accuracy: 51.6757%\n",
      "Epoch: 4710, Train Loss: 1.7211, Train Accuracy: 51.6757%\n",
      "Epoch: 4720, Train Loss: 1.7210, Train Accuracy: 51.6757%\n",
      "Epoch: 4730, Train Loss: 1.7208, Train Accuracy: 51.6757%\n",
      "Epoch: 4740, Train Loss: 1.7207, Train Accuracy: 51.6757%\n",
      "Epoch: 4750, Train Loss: 1.7206, Train Accuracy: 51.6757%\n",
      "Epoch: 4760, Train Loss: 1.7204, Train Accuracy: 51.6757%\n",
      "Epoch: 4770, Train Loss: 1.7203, Train Accuracy: 51.6757%\n",
      "Epoch: 4780, Train Loss: 1.7202, Train Accuracy: 51.6757%\n",
      "Epoch: 4790, Train Loss: 1.7201, Train Accuracy: 51.6757%\n",
      "Epoch: 4800, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 4810, Train Loss: 1.7198, Train Accuracy: 51.6757%\n",
      "Epoch: 4820, Train Loss: 1.7197, Train Accuracy: 51.6757%\n",
      "Epoch: 4830, Train Loss: 1.7195, Train Accuracy: 51.6757%\n",
      "Epoch: 4840, Train Loss: 1.7194, Train Accuracy: 51.6757%\n",
      "Epoch: 4850, Train Loss: 1.7193, Train Accuracy: 51.6757%\n",
      "Epoch: 4860, Train Loss: 1.7192, Train Accuracy: 51.6757%\n",
      "Epoch: 4870, Train Loss: 1.7190, Train Accuracy: 51.6757%\n",
      "Epoch: 4880, Train Loss: 1.7189, Train Accuracy: 51.6757%\n",
      "Epoch: 4890, Train Loss: 1.7188, Train Accuracy: 51.6757%\n",
      "Epoch: 4900, Train Loss: 1.7186, Train Accuracy: 51.6757%\n",
      "Epoch: 4910, Train Loss: 1.7185, Train Accuracy: 51.6757%\n",
      "Epoch: 4920, Train Loss: 1.7184, Train Accuracy: 51.6757%\n",
      "Epoch: 4930, Train Loss: 1.7182, Train Accuracy: 51.6757%\n",
      "Epoch: 4940, Train Loss: 1.7181, Train Accuracy: 51.6757%\n",
      "Epoch: 4950, Train Loss: 1.7180, Train Accuracy: 51.6757%\n",
      "Epoch: 4960, Train Loss: 1.7179, Train Accuracy: 51.6757%\n",
      "Epoch: 4970, Train Loss: 1.7177, Train Accuracy: 51.6757%\n",
      "Epoch: 4980, Train Loss: 1.7176, Train Accuracy: 51.6757%\n",
      "Epoch: 4990, Train Loss: 1.7175, Train Accuracy: 51.6757%\n",
      "Epoch: 5000, Train Loss: 1.7174, Train Accuracy: 51.6757%\n",
      "Epoch: 5010, Train Loss: 1.7172, Train Accuracy: 51.6757%\n",
      "Epoch: 5020, Train Loss: 1.7171, Train Accuracy: 51.6757%\n",
      "Epoch: 5030, Train Loss: 1.7170, Train Accuracy: 51.6757%\n",
      "Epoch: 5040, Train Loss: 1.7168, Train Accuracy: 51.6757%\n",
      "Epoch: 5050, Train Loss: 1.7167, Train Accuracy: 51.6757%\n",
      "Epoch: 5060, Train Loss: 1.7166, Train Accuracy: 51.6757%\n",
      "Epoch: 5070, Train Loss: 1.7165, Train Accuracy: 51.6757%\n",
      "Epoch: 5080, Train Loss: 1.7163, Train Accuracy: 51.6757%\n",
      "Epoch: 5090, Train Loss: 1.7162, Train Accuracy: 51.6757%\n",
      "Epoch: 5100, Train Loss: 1.7161, Train Accuracy: 51.6757%\n",
      "Epoch: 5110, Train Loss: 1.7159, Train Accuracy: 51.6757%\n",
      "Epoch: 5120, Train Loss: 1.7158, Train Accuracy: 51.6757%\n",
      "Epoch: 5130, Train Loss: 1.7157, Train Accuracy: 51.6757%\n",
      "Epoch: 5140, Train Loss: 1.7156, Train Accuracy: 51.6757%\n",
      "Epoch: 5150, Train Loss: 1.7154, Train Accuracy: 51.6757%\n",
      "Epoch: 5160, Train Loss: 1.7153, Train Accuracy: 51.6757%\n",
      "Epoch: 5170, Train Loss: 1.7152, Train Accuracy: 51.6757%\n",
      "Epoch: 5180, Train Loss: 1.7151, Train Accuracy: 51.6757%\n",
      "Epoch: 5190, Train Loss: 1.7149, Train Accuracy: 51.6757%\n",
      "Epoch: 5200, Train Loss: 1.7148, Train Accuracy: 51.6757%\n",
      "Epoch: 5210, Train Loss: 1.7147, Train Accuracy: 51.6757%\n",
      "Epoch: 5220, Train Loss: 1.7146, Train Accuracy: 51.6757%\n",
      "Epoch: 5230, Train Loss: 1.7144, Train Accuracy: 51.6757%\n",
      "Epoch: 5240, Train Loss: 1.7143, Train Accuracy: 51.6757%\n",
      "Epoch: 5250, Train Loss: 1.7142, Train Accuracy: 51.6757%\n",
      "Epoch: 5260, Train Loss: 1.7140, Train Accuracy: 51.6757%\n",
      "Epoch: 5270, Train Loss: 1.7139, Train Accuracy: 51.6757%\n",
      "Epoch: 5280, Train Loss: 1.7138, Train Accuracy: 51.6757%\n",
      "Epoch: 5290, Train Loss: 1.7137, Train Accuracy: 51.6757%\n",
      "Epoch: 5300, Train Loss: 1.7135, Train Accuracy: 51.6757%\n",
      "Epoch: 5310, Train Loss: 1.7134, Train Accuracy: 51.6757%\n",
      "Epoch: 5320, Train Loss: 1.7133, Train Accuracy: 51.6757%\n",
      "Epoch: 5330, Train Loss: 1.7132, Train Accuracy: 51.6757%\n",
      "Epoch: 5340, Train Loss: 1.7130, Train Accuracy: 51.6757%\n",
      "Epoch: 5350, Train Loss: 1.7129, Train Accuracy: 51.6757%\n",
      "Epoch: 5360, Train Loss: 1.7128, Train Accuracy: 51.6757%\n",
      "Epoch: 5370, Train Loss: 1.7127, Train Accuracy: 51.6757%\n",
      "Epoch: 5380, Train Loss: 1.7125, Train Accuracy: 51.6757%\n",
      "Epoch: 5390, Train Loss: 1.7124, Train Accuracy: 51.6757%\n",
      "Epoch: 5400, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 5410, Train Loss: 1.7122, Train Accuracy: 51.6757%\n",
      "Epoch: 5420, Train Loss: 1.7120, Train Accuracy: 51.6757%\n",
      "Epoch: 5430, Train Loss: 1.7119, Train Accuracy: 51.6757%\n",
      "Epoch: 5440, Train Loss: 1.7118, Train Accuracy: 51.6757%\n",
      "Epoch: 5450, Train Loss: 1.7117, Train Accuracy: 51.6757%\n",
      "Epoch: 5460, Train Loss: 1.7115, Train Accuracy: 51.6757%\n",
      "Epoch: 5470, Train Loss: 1.7114, Train Accuracy: 51.6757%\n",
      "Epoch: 5480, Train Loss: 1.7113, Train Accuracy: 51.6757%\n",
      "Epoch: 5490, Train Loss: 1.7112, Train Accuracy: 51.6757%\n",
      "Epoch: 5500, Train Loss: 1.7110, Train Accuracy: 51.6757%\n",
      "Epoch: 5510, Train Loss: 1.7109, Train Accuracy: 51.6757%\n",
      "Epoch: 5520, Train Loss: 1.7108, Train Accuracy: 51.6757%\n",
      "Epoch: 5530, Train Loss: 1.7107, Train Accuracy: 51.6757%\n",
      "Epoch: 5540, Train Loss: 1.7105, Train Accuracy: 51.6757%\n",
      "Epoch: 5550, Train Loss: 1.7104, Train Accuracy: 51.6757%\n",
      "Epoch: 5560, Train Loss: 1.7103, Train Accuracy: 51.6757%\n",
      "Epoch: 5570, Train Loss: 1.7102, Train Accuracy: 51.6757%\n",
      "Epoch: 5580, Train Loss: 1.7100, Train Accuracy: 51.7838%\n",
      "Epoch: 5590, Train Loss: 1.7099, Train Accuracy: 51.7838%\n",
      "Epoch: 5600, Train Loss: 1.7098, Train Accuracy: 51.7838%\n",
      "Epoch: 5610, Train Loss: 1.7097, Train Accuracy: 51.7838%\n",
      "Epoch: 5620, Train Loss: 1.7096, Train Accuracy: 51.7838%\n",
      "Epoch: 5630, Train Loss: 1.7094, Train Accuracy: 51.7838%\n",
      "Epoch: 5640, Train Loss: 1.7093, Train Accuracy: 51.7838%\n",
      "Epoch: 5650, Train Loss: 1.7092, Train Accuracy: 51.7838%\n",
      "Epoch: 5660, Train Loss: 1.7091, Train Accuracy: 51.7838%\n",
      "Epoch: 5670, Train Loss: 1.7089, Train Accuracy: 51.7838%\n",
      "Epoch: 5680, Train Loss: 1.7088, Train Accuracy: 51.7838%\n",
      "Epoch: 5690, Train Loss: 1.7087, Train Accuracy: 51.7838%\n",
      "Epoch: 5700, Train Loss: 1.7086, Train Accuracy: 51.7838%\n",
      "Epoch: 5710, Train Loss: 1.7084, Train Accuracy: 51.7838%\n",
      "Epoch: 5720, Train Loss: 1.7083, Train Accuracy: 51.7838%\n",
      "Epoch: 5730, Train Loss: 1.7082, Train Accuracy: 51.7838%\n",
      "Epoch: 5740, Train Loss: 1.7081, Train Accuracy: 51.7838%\n",
      "Epoch: 5750, Train Loss: 1.7080, Train Accuracy: 51.7838%\n",
      "Epoch: 5760, Train Loss: 1.7078, Train Accuracy: 51.7838%\n",
      "Epoch: 5770, Train Loss: 1.7077, Train Accuracy: 51.7838%\n",
      "Epoch: 5780, Train Loss: 1.7076, Train Accuracy: 51.7838%\n",
      "Epoch: 5790, Train Loss: 1.7075, Train Accuracy: 51.7838%\n",
      "Epoch: 5800, Train Loss: 1.7073, Train Accuracy: 51.7838%\n",
      "Epoch: 5810, Train Loss: 1.7072, Train Accuracy: 51.8919%\n",
      "Epoch: 5820, Train Loss: 1.7071, Train Accuracy: 51.8919%\n",
      "Epoch: 5830, Train Loss: 1.7070, Train Accuracy: 51.8919%\n",
      "Epoch: 5840, Train Loss: 1.7069, Train Accuracy: 51.8919%\n",
      "Epoch: 5850, Train Loss: 1.7067, Train Accuracy: 51.8919%\n",
      "Epoch: 5860, Train Loss: 1.7066, Train Accuracy: 51.8919%\n",
      "Epoch: 5870, Train Loss: 1.7065, Train Accuracy: 51.8919%\n",
      "Epoch: 5880, Train Loss: 1.7064, Train Accuracy: 51.8919%\n",
      "Epoch: 5890, Train Loss: 1.7062, Train Accuracy: 51.8919%\n",
      "Epoch: 5900, Train Loss: 1.7061, Train Accuracy: 51.8919%\n",
      "Epoch: 5910, Train Loss: 1.7060, Train Accuracy: 51.8919%\n",
      "Epoch: 5920, Train Loss: 1.7059, Train Accuracy: 51.8919%\n",
      "Epoch: 5930, Train Loss: 1.7058, Train Accuracy: 51.8919%\n",
      "Epoch: 5940, Train Loss: 1.7056, Train Accuracy: 51.8919%\n",
      "Epoch: 5950, Train Loss: 1.7055, Train Accuracy: 51.8919%\n",
      "Epoch: 5960, Train Loss: 1.7054, Train Accuracy: 51.8919%\n",
      "Epoch: 5970, Train Loss: 1.7053, Train Accuracy: 51.8919%\n",
      "Epoch: 5980, Train Loss: 1.7052, Train Accuracy: 51.8919%\n",
      "Epoch: 5990, Train Loss: 1.7050, Train Accuracy: 51.8919%\n",
      "Epoch: 6000, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 6010, Train Loss: 1.7048, Train Accuracy: 51.8919%\n",
      "Epoch: 6020, Train Loss: 1.7047, Train Accuracy: 51.8919%\n",
      "Epoch: 6030, Train Loss: 1.7045, Train Accuracy: 51.8919%\n",
      "Epoch: 6040, Train Loss: 1.7044, Train Accuracy: 51.8919%\n",
      "Epoch: 6050, Train Loss: 1.7043, Train Accuracy: 51.8919%\n",
      "Epoch: 6060, Train Loss: 1.7042, Train Accuracy: 51.8919%\n",
      "Epoch: 6070, Train Loss: 1.7041, Train Accuracy: 51.8919%\n",
      "Epoch: 6080, Train Loss: 1.7039, Train Accuracy: 51.8919%\n",
      "Epoch: 6090, Train Loss: 1.7038, Train Accuracy: 51.8919%\n",
      "Epoch: 6100, Train Loss: 1.7037, Train Accuracy: 51.8919%\n",
      "Epoch: 6110, Train Loss: 1.7036, Train Accuracy: 51.8919%\n",
      "Epoch: 6120, Train Loss: 1.7035, Train Accuracy: 51.8919%\n",
      "Epoch: 6130, Train Loss: 1.7033, Train Accuracy: 51.8919%\n",
      "Epoch: 6140, Train Loss: 1.7032, Train Accuracy: 51.8919%\n",
      "Epoch: 6150, Train Loss: 1.7031, Train Accuracy: 51.8919%\n",
      "Epoch: 6160, Train Loss: 1.7030, Train Accuracy: 51.8919%\n",
      "Epoch: 6170, Train Loss: 1.7029, Train Accuracy: 51.8919%\n",
      "Epoch: 6180, Train Loss: 1.7027, Train Accuracy: 51.8919%\n",
      "Epoch: 6190, Train Loss: 1.7026, Train Accuracy: 51.8919%\n",
      "Epoch: 6200, Train Loss: 1.7025, Train Accuracy: 51.8919%\n",
      "Epoch: 6210, Train Loss: 1.7024, Train Accuracy: 51.8919%\n",
      "Epoch: 6220, Train Loss: 1.7023, Train Accuracy: 51.8919%\n",
      "Epoch: 6230, Train Loss: 1.7021, Train Accuracy: 51.8919%\n",
      "Epoch: 6240, Train Loss: 1.7020, Train Accuracy: 51.8919%\n",
      "Epoch: 6250, Train Loss: 1.7019, Train Accuracy: 51.8919%\n",
      "Epoch: 6260, Train Loss: 1.7018, Train Accuracy: 51.8919%\n",
      "Epoch: 6270, Train Loss: 1.7017, Train Accuracy: 51.8919%\n",
      "Epoch: 6280, Train Loss: 1.7016, Train Accuracy: 51.8919%\n",
      "Epoch: 6290, Train Loss: 1.7014, Train Accuracy: 51.8919%\n",
      "Epoch: 6300, Train Loss: 1.7013, Train Accuracy: 51.8919%\n",
      "Epoch: 6310, Train Loss: 1.7012, Train Accuracy: 51.8919%\n",
      "Epoch: 6320, Train Loss: 1.7011, Train Accuracy: 51.8919%\n",
      "Epoch: 6330, Train Loss: 1.7010, Train Accuracy: 51.8919%\n",
      "Epoch: 6340, Train Loss: 1.7008, Train Accuracy: 51.8919%\n",
      "Epoch: 6350, Train Loss: 1.7007, Train Accuracy: 51.8919%\n",
      "Epoch: 6360, Train Loss: 1.7006, Train Accuracy: 51.8919%\n",
      "Epoch: 6370, Train Loss: 1.7005, Train Accuracy: 51.8919%\n",
      "Epoch: 6380, Train Loss: 1.7004, Train Accuracy: 51.8919%\n",
      "Epoch: 6390, Train Loss: 1.7002, Train Accuracy: 51.8919%\n",
      "Epoch: 6400, Train Loss: 1.7001, Train Accuracy: 51.8919%\n",
      "Epoch: 6410, Train Loss: 1.7000, Train Accuracy: 51.8919%\n",
      "Epoch: 6420, Train Loss: 1.6999, Train Accuracy: 51.8919%\n",
      "Epoch: 6430, Train Loss: 1.6998, Train Accuracy: 51.8919%\n",
      "Epoch: 6440, Train Loss: 1.6997, Train Accuracy: 51.8919%\n",
      "Epoch: 6450, Train Loss: 1.6995, Train Accuracy: 51.8919%\n",
      "Epoch: 6460, Train Loss: 1.6994, Train Accuracy: 51.8919%\n",
      "Epoch: 6470, Train Loss: 1.6993, Train Accuracy: 51.8919%\n",
      "Epoch: 6480, Train Loss: 1.6992, Train Accuracy: 51.8919%\n",
      "Epoch: 6490, Train Loss: 1.6991, Train Accuracy: 51.8919%\n",
      "Epoch: 6500, Train Loss: 1.6990, Train Accuracy: 51.8919%\n",
      "Epoch: 6510, Train Loss: 1.6988, Train Accuracy: 51.8919%\n",
      "Epoch: 6520, Train Loss: 1.6987, Train Accuracy: 51.8919%\n",
      "Epoch: 6530, Train Loss: 1.6986, Train Accuracy: 51.8919%\n",
      "Epoch: 6540, Train Loss: 1.6985, Train Accuracy: 51.7838%\n",
      "Epoch: 6550, Train Loss: 1.6984, Train Accuracy: 51.7838%\n",
      "Epoch: 6560, Train Loss: 1.6982, Train Accuracy: 51.7838%\n",
      "Epoch: 6570, Train Loss: 1.6981, Train Accuracy: 51.7838%\n",
      "Epoch: 6580, Train Loss: 1.6980, Train Accuracy: 51.7838%\n",
      "Epoch: 6590, Train Loss: 1.6979, Train Accuracy: 51.7838%\n",
      "Epoch: 6600, Train Loss: 1.6978, Train Accuracy: 51.7838%\n",
      "Epoch: 6610, Train Loss: 1.6977, Train Accuracy: 51.7838%\n",
      "Epoch: 6620, Train Loss: 1.6975, Train Accuracy: 51.7838%\n",
      "Epoch: 6630, Train Loss: 1.6974, Train Accuracy: 51.7838%\n",
      "Epoch: 6640, Train Loss: 1.6973, Train Accuracy: 51.7838%\n",
      "Epoch: 6650, Train Loss: 1.6972, Train Accuracy: 51.7838%\n",
      "Epoch: 6660, Train Loss: 1.6971, Train Accuracy: 51.7838%\n",
      "Epoch: 6670, Train Loss: 1.6970, Train Accuracy: 51.7838%\n",
      "Epoch: 6680, Train Loss: 1.6968, Train Accuracy: 51.7838%\n",
      "Epoch: 6690, Train Loss: 1.6967, Train Accuracy: 51.7838%\n",
      "Epoch: 6700, Train Loss: 1.6966, Train Accuracy: 51.7838%\n",
      "Epoch: 6710, Train Loss: 1.6965, Train Accuracy: 51.7838%\n",
      "Epoch: 6720, Train Loss: 1.6964, Train Accuracy: 51.7838%\n",
      "Epoch: 6730, Train Loss: 1.6963, Train Accuracy: 51.7838%\n",
      "Epoch: 6740, Train Loss: 1.6962, Train Accuracy: 51.7838%\n",
      "Epoch: 6750, Train Loss: 1.6960, Train Accuracy: 51.7838%\n",
      "Epoch: 6760, Train Loss: 1.6959, Train Accuracy: 51.7838%\n",
      "Epoch: 6770, Train Loss: 1.6958, Train Accuracy: 51.7838%\n",
      "Epoch: 6780, Train Loss: 1.6957, Train Accuracy: 51.7838%\n",
      "Epoch: 6790, Train Loss: 1.6956, Train Accuracy: 51.7838%\n",
      "Epoch: 6800, Train Loss: 1.6955, Train Accuracy: 51.7838%\n",
      "Epoch: 6810, Train Loss: 1.6953, Train Accuracy: 51.7838%\n",
      "Epoch: 6820, Train Loss: 1.6952, Train Accuracy: 51.7838%\n",
      "Epoch: 6830, Train Loss: 1.6951, Train Accuracy: 51.7838%\n",
      "Epoch: 6840, Train Loss: 1.6950, Train Accuracy: 51.7838%\n",
      "Epoch: 6850, Train Loss: 1.6949, Train Accuracy: 51.7838%\n",
      "Epoch: 6860, Train Loss: 1.6948, Train Accuracy: 51.7838%\n",
      "Epoch: 6870, Train Loss: 1.6947, Train Accuracy: 51.7838%\n",
      "Epoch: 6880, Train Loss: 1.6945, Train Accuracy: 51.6757%\n",
      "Epoch: 6890, Train Loss: 1.6944, Train Accuracy: 51.6757%\n",
      "Epoch: 6900, Train Loss: 1.6943, Train Accuracy: 51.6757%\n",
      "Epoch: 6910, Train Loss: 1.6942, Train Accuracy: 51.6757%\n",
      "Epoch: 6920, Train Loss: 1.6941, Train Accuracy: 51.6757%\n",
      "Epoch: 6930, Train Loss: 1.6940, Train Accuracy: 51.6757%\n",
      "Epoch: 6940, Train Loss: 1.6938, Train Accuracy: 51.6757%\n",
      "Epoch: 6950, Train Loss: 1.6937, Train Accuracy: 51.6757%\n",
      "Epoch: 6960, Train Loss: 1.6936, Train Accuracy: 51.6757%\n",
      "Epoch: 6970, Train Loss: 1.6935, Train Accuracy: 51.6757%\n",
      "Epoch: 6980, Train Loss: 1.6934, Train Accuracy: 51.6757%\n",
      "Epoch: 6990, Train Loss: 1.6933, Train Accuracy: 51.6757%\n",
      "Epoch: 7000, Train Loss: 1.6932, Train Accuracy: 51.6757%\n",
      "Epoch: 7010, Train Loss: 1.6930, Train Accuracy: 51.6757%\n",
      "Epoch: 7020, Train Loss: 1.6929, Train Accuracy: 51.6757%\n",
      "Epoch: 7030, Train Loss: 1.6928, Train Accuracy: 51.6757%\n",
      "Epoch: 7040, Train Loss: 1.6927, Train Accuracy: 51.6757%\n",
      "Epoch: 7050, Train Loss: 1.6926, Train Accuracy: 51.6757%\n",
      "Epoch: 7060, Train Loss: 1.6925, Train Accuracy: 51.6757%\n",
      "Epoch: 7070, Train Loss: 1.6924, Train Accuracy: 51.6757%\n",
      "Epoch: 7080, Train Loss: 1.6923, Train Accuracy: 51.6757%\n",
      "Epoch: 7090, Train Loss: 1.6921, Train Accuracy: 51.6757%\n",
      "Epoch: 7100, Train Loss: 1.6920, Train Accuracy: 51.6757%\n",
      "Epoch: 7110, Train Loss: 1.6919, Train Accuracy: 51.6757%\n",
      "Epoch: 7120, Train Loss: 1.6918, Train Accuracy: 51.6757%\n",
      "Epoch: 7130, Train Loss: 1.6917, Train Accuracy: 51.6757%\n",
      "Epoch: 7140, Train Loss: 1.6916, Train Accuracy: 51.6757%\n",
      "Epoch: 7150, Train Loss: 1.6915, Train Accuracy: 51.6757%\n",
      "Epoch: 7160, Train Loss: 1.6913, Train Accuracy: 51.6757%\n",
      "Epoch: 7170, Train Loss: 1.6912, Train Accuracy: 51.6757%\n",
      "Epoch: 7180, Train Loss: 1.6911, Train Accuracy: 51.6757%\n",
      "Epoch: 7190, Train Loss: 1.6910, Train Accuracy: 51.6757%\n",
      "Epoch: 7200, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 7210, Train Loss: 1.6908, Train Accuracy: 51.6757%\n",
      "Epoch: 7220, Train Loss: 1.6907, Train Accuracy: 51.6757%\n",
      "Epoch: 7230, Train Loss: 1.6906, Train Accuracy: 51.6757%\n",
      "Epoch: 7240, Train Loss: 1.6904, Train Accuracy: 51.6757%\n",
      "Epoch: 7250, Train Loss: 1.6903, Train Accuracy: 51.6757%\n",
      "Epoch: 7260, Train Loss: 1.6902, Train Accuracy: 51.6757%\n",
      "Epoch: 7270, Train Loss: 1.6901, Train Accuracy: 51.6757%\n",
      "Epoch: 7280, Train Loss: 1.6900, Train Accuracy: 51.6757%\n",
      "Epoch: 7290, Train Loss: 1.6899, Train Accuracy: 51.6757%\n",
      "Epoch: 7300, Train Loss: 1.6898, Train Accuracy: 51.6757%\n",
      "Epoch: 7310, Train Loss: 1.6897, Train Accuracy: 51.6757%\n",
      "Epoch: 7320, Train Loss: 1.6895, Train Accuracy: 51.6757%\n",
      "Epoch: 7330, Train Loss: 1.6894, Train Accuracy: 51.6757%\n",
      "Epoch: 7340, Train Loss: 1.6893, Train Accuracy: 51.6757%\n",
      "Epoch: 7350, Train Loss: 1.6892, Train Accuracy: 51.6757%\n",
      "Epoch: 7360, Train Loss: 1.6891, Train Accuracy: 51.6757%\n",
      "Epoch: 7370, Train Loss: 1.6890, Train Accuracy: 51.6757%\n",
      "Epoch: 7380, Train Loss: 1.6889, Train Accuracy: 51.6757%\n",
      "Epoch: 7390, Train Loss: 1.6888, Train Accuracy: 51.6757%\n",
      "Epoch: 7400, Train Loss: 1.6886, Train Accuracy: 51.6757%\n",
      "Epoch: 7410, Train Loss: 1.6885, Train Accuracy: 51.6757%\n",
      "Epoch: 7420, Train Loss: 1.6884, Train Accuracy: 51.6757%\n",
      "Epoch: 7430, Train Loss: 1.6883, Train Accuracy: 51.6757%\n",
      "Epoch: 7440, Train Loss: 1.6882, Train Accuracy: 51.6757%\n",
      "Epoch: 7450, Train Loss: 1.6881, Train Accuracy: 51.6757%\n",
      "Epoch: 7460, Train Loss: 1.6880, Train Accuracy: 51.6757%\n",
      "Epoch: 7470, Train Loss: 1.6879, Train Accuracy: 51.6757%\n",
      "Epoch: 7480, Train Loss: 1.6878, Train Accuracy: 51.6757%\n",
      "Epoch: 7490, Train Loss: 1.6876, Train Accuracy: 51.6757%\n",
      "Epoch: 7500, Train Loss: 1.6875, Train Accuracy: 51.6757%\n",
      "Epoch: 7510, Train Loss: 1.6874, Train Accuracy: 51.6757%\n",
      "Epoch: 7520, Train Loss: 1.6873, Train Accuracy: 51.6757%\n",
      "Epoch: 7530, Train Loss: 1.6872, Train Accuracy: 51.6757%\n",
      "Epoch: 7540, Train Loss: 1.6871, Train Accuracy: 51.6757%\n",
      "Epoch: 7550, Train Loss: 1.6870, Train Accuracy: 51.6757%\n",
      "Epoch: 7560, Train Loss: 1.6869, Train Accuracy: 51.6757%\n",
      "Epoch: 7570, Train Loss: 1.6868, Train Accuracy: 51.6757%\n",
      "Epoch: 7580, Train Loss: 1.6867, Train Accuracy: 51.6757%\n",
      "Epoch: 7590, Train Loss: 1.6865, Train Accuracy: 51.6757%\n",
      "Epoch: 7600, Train Loss: 1.6864, Train Accuracy: 51.5676%\n",
      "Epoch: 7610, Train Loss: 1.6863, Train Accuracy: 51.5676%\n",
      "Epoch: 7620, Train Loss: 1.6862, Train Accuracy: 51.5676%\n",
      "Epoch: 7630, Train Loss: 1.6861, Train Accuracy: 51.5676%\n",
      "Epoch: 7640, Train Loss: 1.6860, Train Accuracy: 51.5676%\n",
      "Epoch: 7650, Train Loss: 1.6859, Train Accuracy: 51.5676%\n",
      "Epoch: 7660, Train Loss: 1.6858, Train Accuracy: 51.5676%\n",
      "Epoch: 7670, Train Loss: 1.6857, Train Accuracy: 51.5676%\n",
      "Epoch: 7680, Train Loss: 1.6855, Train Accuracy: 51.6757%\n",
      "Epoch: 7690, Train Loss: 1.6854, Train Accuracy: 51.6757%\n",
      "Epoch: 7700, Train Loss: 1.6853, Train Accuracy: 51.6757%\n",
      "Epoch: 7710, Train Loss: 1.6852, Train Accuracy: 51.6757%\n",
      "Epoch: 7720, Train Loss: 1.6851, Train Accuracy: 51.6757%\n",
      "Epoch: 7730, Train Loss: 1.6850, Train Accuracy: 51.6757%\n",
      "Epoch: 7740, Train Loss: 1.6849, Train Accuracy: 51.6757%\n",
      "Epoch: 7750, Train Loss: 1.6848, Train Accuracy: 51.6757%\n",
      "Epoch: 7760, Train Loss: 1.6847, Train Accuracy: 51.6757%\n",
      "Epoch: 7770, Train Loss: 1.6846, Train Accuracy: 51.6757%\n",
      "Epoch: 7780, Train Loss: 1.6845, Train Accuracy: 51.6757%\n",
      "Epoch: 7790, Train Loss: 1.6843, Train Accuracy: 51.6757%\n",
      "Epoch: 7800, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 7810, Train Loss: 1.6841, Train Accuracy: 51.6757%\n",
      "Epoch: 7820, Train Loss: 1.6840, Train Accuracy: 51.6757%\n",
      "Epoch: 7830, Train Loss: 1.6839, Train Accuracy: 51.6757%\n",
      "Epoch: 7840, Train Loss: 1.6838, Train Accuracy: 51.6757%\n",
      "Epoch: 7850, Train Loss: 1.6837, Train Accuracy: 51.6757%\n",
      "Epoch: 7860, Train Loss: 1.6836, Train Accuracy: 51.6757%\n",
      "Epoch: 7870, Train Loss: 1.6835, Train Accuracy: 51.6757%\n",
      "Epoch: 7880, Train Loss: 1.6834, Train Accuracy: 51.6757%\n",
      "Epoch: 7890, Train Loss: 1.6833, Train Accuracy: 51.6757%\n",
      "Epoch: 7900, Train Loss: 1.6831, Train Accuracy: 51.6757%\n",
      "Epoch: 7910, Train Loss: 1.6830, Train Accuracy: 51.6757%\n",
      "Epoch: 7920, Train Loss: 1.6829, Train Accuracy: 51.6757%\n",
      "Epoch: 7930, Train Loss: 1.6828, Train Accuracy: 51.6757%\n",
      "Epoch: 7940, Train Loss: 1.6827, Train Accuracy: 51.6757%\n",
      "Epoch: 7950, Train Loss: 1.6826, Train Accuracy: 51.6757%\n",
      "Epoch: 7960, Train Loss: 1.6825, Train Accuracy: 51.6757%\n",
      "Epoch: 7970, Train Loss: 1.6824, Train Accuracy: 51.6757%\n",
      "Epoch: 7980, Train Loss: 1.6823, Train Accuracy: 51.6757%\n",
      "Epoch: 7990, Train Loss: 1.6822, Train Accuracy: 51.6757%\n",
      "Epoch: 8000, Train Loss: 1.6821, Train Accuracy: 51.6757%\n",
      "Epoch: 8010, Train Loss: 1.6820, Train Accuracy: 51.6757%\n",
      "Epoch: 8020, Train Loss: 1.6819, Train Accuracy: 51.6757%\n",
      "Epoch: 8030, Train Loss: 1.6817, Train Accuracy: 51.6757%\n",
      "Epoch: 8040, Train Loss: 1.6816, Train Accuracy: 51.6757%\n",
      "Epoch: 8050, Train Loss: 1.6815, Train Accuracy: 51.6757%\n",
      "Epoch: 8060, Train Loss: 1.6814, Train Accuracy: 51.6757%\n",
      "Epoch: 8070, Train Loss: 1.6813, Train Accuracy: 51.6757%\n",
      "Epoch: 8080, Train Loss: 1.6812, Train Accuracy: 51.6757%\n",
      "Epoch: 8090, Train Loss: 1.6811, Train Accuracy: 51.6757%\n",
      "Epoch: 8100, Train Loss: 1.6810, Train Accuracy: 51.6757%\n",
      "Epoch: 8110, Train Loss: 1.6809, Train Accuracy: 51.6757%\n",
      "Epoch: 8120, Train Loss: 1.6808, Train Accuracy: 51.6757%\n",
      "Epoch: 8130, Train Loss: 1.6807, Train Accuracy: 51.6757%\n",
      "Epoch: 8140, Train Loss: 1.6806, Train Accuracy: 51.6757%\n",
      "Epoch: 8150, Train Loss: 1.6805, Train Accuracy: 51.6757%\n",
      "Epoch: 8160, Train Loss: 1.6803, Train Accuracy: 51.6757%\n",
      "Epoch: 8170, Train Loss: 1.6802, Train Accuracy: 51.6757%\n",
      "Epoch: 8180, Train Loss: 1.6801, Train Accuracy: 51.6757%\n",
      "Epoch: 8190, Train Loss: 1.6800, Train Accuracy: 51.6757%\n",
      "Epoch: 8200, Train Loss: 1.6799, Train Accuracy: 51.6757%\n",
      "Epoch: 8210, Train Loss: 1.6798, Train Accuracy: 51.6757%\n",
      "Epoch: 8220, Train Loss: 1.6797, Train Accuracy: 51.6757%\n",
      "Epoch: 8230, Train Loss: 1.6796, Train Accuracy: 51.6757%\n",
      "Epoch: 8240, Train Loss: 1.6795, Train Accuracy: 51.6757%\n",
      "Epoch: 8250, Train Loss: 1.6794, Train Accuracy: 51.6757%\n",
      "Epoch: 8260, Train Loss: 1.6793, Train Accuracy: 51.6757%\n",
      "Epoch: 8270, Train Loss: 1.6792, Train Accuracy: 51.6757%\n",
      "Epoch: 8280, Train Loss: 1.6791, Train Accuracy: 51.6757%\n",
      "Epoch: 8290, Train Loss: 1.6790, Train Accuracy: 51.6757%\n",
      "Epoch: 8300, Train Loss: 1.6789, Train Accuracy: 51.6757%\n",
      "Epoch: 8310, Train Loss: 1.6788, Train Accuracy: 51.6757%\n",
      "Epoch: 8320, Train Loss: 1.6786, Train Accuracy: 51.6757%\n",
      "Epoch: 8330, Train Loss: 1.6785, Train Accuracy: 51.6757%\n",
      "Epoch: 8340, Train Loss: 1.6784, Train Accuracy: 51.6757%\n",
      "Epoch: 8350, Train Loss: 1.6783, Train Accuracy: 51.6757%\n",
      "Epoch: 8360, Train Loss: 1.6782, Train Accuracy: 51.6757%\n",
      "Epoch: 8370, Train Loss: 1.6781, Train Accuracy: 51.6757%\n",
      "Epoch: 8380, Train Loss: 1.6780, Train Accuracy: 51.6757%\n",
      "Epoch: 8390, Train Loss: 1.6779, Train Accuracy: 51.6757%\n",
      "Epoch: 8400, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 8410, Train Loss: 1.6777, Train Accuracy: 51.6757%\n",
      "Epoch: 8420, Train Loss: 1.6776, Train Accuracy: 51.6757%\n",
      "Epoch: 8430, Train Loss: 1.6775, Train Accuracy: 51.6757%\n",
      "Epoch: 8440, Train Loss: 1.6774, Train Accuracy: 51.6757%\n",
      "Epoch: 8450, Train Loss: 1.6773, Train Accuracy: 51.6757%\n",
      "Epoch: 8460, Train Loss: 1.6772, Train Accuracy: 51.6757%\n",
      "Epoch: 8470, Train Loss: 1.6771, Train Accuracy: 51.6757%\n",
      "Epoch: 8480, Train Loss: 1.6770, Train Accuracy: 51.6757%\n",
      "Epoch: 8490, Train Loss: 1.6769, Train Accuracy: 51.6757%\n",
      "Epoch: 8500, Train Loss: 1.6767, Train Accuracy: 51.6757%\n",
      "Epoch: 8510, Train Loss: 1.6766, Train Accuracy: 51.6757%\n",
      "Epoch: 8520, Train Loss: 1.6765, Train Accuracy: 51.6757%\n",
      "Epoch: 8530, Train Loss: 1.6764, Train Accuracy: 51.6757%\n",
      "Epoch: 8540, Train Loss: 1.6763, Train Accuracy: 51.6757%\n",
      "Epoch: 8550, Train Loss: 1.6762, Train Accuracy: 51.6757%\n",
      "Epoch: 8560, Train Loss: 1.6761, Train Accuracy: 51.6757%\n",
      "Epoch: 8570, Train Loss: 1.6760, Train Accuracy: 51.6757%\n",
      "Epoch: 8580, Train Loss: 1.6759, Train Accuracy: 51.6757%\n",
      "Epoch: 8590, Train Loss: 1.6758, Train Accuracy: 51.6757%\n",
      "Epoch: 8600, Train Loss: 1.6757, Train Accuracy: 51.6757%\n",
      "Epoch: 8610, Train Loss: 1.6756, Train Accuracy: 51.6757%\n",
      "Epoch: 8620, Train Loss: 1.6755, Train Accuracy: 51.6757%\n",
      "Epoch: 8630, Train Loss: 1.6754, Train Accuracy: 51.6757%\n",
      "Epoch: 8640, Train Loss: 1.6753, Train Accuracy: 51.6757%\n",
      "Epoch: 8650, Train Loss: 1.6752, Train Accuracy: 51.6757%\n",
      "Epoch: 8660, Train Loss: 1.6751, Train Accuracy: 51.6757%\n",
      "Epoch: 8670, Train Loss: 1.6750, Train Accuracy: 51.6757%\n",
      "Epoch: 8680, Train Loss: 1.6749, Train Accuracy: 51.6757%\n",
      "Epoch: 8690, Train Loss: 1.6748, Train Accuracy: 51.6757%\n",
      "Epoch: 8700, Train Loss: 1.6747, Train Accuracy: 51.6757%\n",
      "Epoch: 8710, Train Loss: 1.6746, Train Accuracy: 51.6757%\n",
      "Epoch: 8720, Train Loss: 1.6745, Train Accuracy: 51.6757%\n",
      "Epoch: 8730, Train Loss: 1.6744, Train Accuracy: 51.6757%\n",
      "Epoch: 8740, Train Loss: 1.6742, Train Accuracy: 51.6757%\n",
      "Epoch: 8750, Train Loss: 1.6741, Train Accuracy: 51.6757%\n",
      "Epoch: 8760, Train Loss: 1.6740, Train Accuracy: 51.6757%\n",
      "Epoch: 8770, Train Loss: 1.6739, Train Accuracy: 51.6757%\n",
      "Epoch: 8780, Train Loss: 1.6738, Train Accuracy: 51.6757%\n",
      "Epoch: 8790, Train Loss: 1.6737, Train Accuracy: 51.6757%\n",
      "Epoch: 8800, Train Loss: 1.6736, Train Accuracy: 51.6757%\n",
      "Epoch: 8810, Train Loss: 1.6735, Train Accuracy: 51.6757%\n",
      "Epoch: 8820, Train Loss: 1.6734, Train Accuracy: 51.6757%\n",
      "Epoch: 8830, Train Loss: 1.6733, Train Accuracy: 51.6757%\n",
      "Epoch: 8840, Train Loss: 1.6732, Train Accuracy: 51.6757%\n",
      "Epoch: 8850, Train Loss: 1.6731, Train Accuracy: 51.6757%\n",
      "Epoch: 8860, Train Loss: 1.6730, Train Accuracy: 51.6757%\n",
      "Epoch: 8870, Train Loss: 1.6729, Train Accuracy: 51.6757%\n",
      "Epoch: 8880, Train Loss: 1.6728, Train Accuracy: 51.6757%\n",
      "Epoch: 8890, Train Loss: 1.6727, Train Accuracy: 51.6757%\n",
      "Epoch: 8900, Train Loss: 1.6726, Train Accuracy: 51.6757%\n",
      "Epoch: 8910, Train Loss: 1.6725, Train Accuracy: 51.6757%\n",
      "Epoch: 8920, Train Loss: 1.6724, Train Accuracy: 51.6757%\n",
      "Epoch: 8930, Train Loss: 1.6723, Train Accuracy: 51.6757%\n",
      "Epoch: 8940, Train Loss: 1.6722, Train Accuracy: 51.6757%\n",
      "Epoch: 8950, Train Loss: 1.6721, Train Accuracy: 51.7838%\n",
      "Epoch: 8960, Train Loss: 1.6720, Train Accuracy: 51.7838%\n",
      "Epoch: 8970, Train Loss: 1.6719, Train Accuracy: 51.7838%\n",
      "Epoch: 8980, Train Loss: 1.6718, Train Accuracy: 51.7838%\n",
      "Epoch: 8990, Train Loss: 1.6717, Train Accuracy: 51.7838%\n",
      "Epoch: 9000, Train Loss: 1.6716, Train Accuracy: 51.7838%\n",
      "Epoch: 9010, Train Loss: 1.6715, Train Accuracy: 51.7838%\n",
      "Epoch: 9020, Train Loss: 1.6714, Train Accuracy: 51.7838%\n",
      "Epoch: 9030, Train Loss: 1.6713, Train Accuracy: 51.7838%\n",
      "Epoch: 9040, Train Loss: 1.6712, Train Accuracy: 51.7838%\n",
      "Epoch: 9050, Train Loss: 1.6711, Train Accuracy: 51.7838%\n",
      "Epoch: 9060, Train Loss: 1.6710, Train Accuracy: 51.7838%\n",
      "Epoch: 9070, Train Loss: 1.6709, Train Accuracy: 51.7838%\n",
      "Epoch: 9080, Train Loss: 1.6708, Train Accuracy: 51.7838%\n",
      "Epoch: 9090, Train Loss: 1.6707, Train Accuracy: 51.7838%\n",
      "Epoch: 9100, Train Loss: 1.6706, Train Accuracy: 51.7838%\n",
      "Epoch: 9110, Train Loss: 1.6705, Train Accuracy: 51.7838%\n",
      "Epoch: 9120, Train Loss: 1.6704, Train Accuracy: 51.7838%\n",
      "Epoch: 9130, Train Loss: 1.6703, Train Accuracy: 51.7838%\n",
      "Epoch: 9140, Train Loss: 1.6702, Train Accuracy: 51.7838%\n",
      "Epoch: 9150, Train Loss: 1.6701, Train Accuracy: 51.7838%\n",
      "Epoch: 9160, Train Loss: 1.6700, Train Accuracy: 51.7838%\n",
      "Epoch: 9170, Train Loss: 1.6699, Train Accuracy: 51.7838%\n",
      "Epoch: 9180, Train Loss: 1.6698, Train Accuracy: 51.7838%\n",
      "Epoch: 9190, Train Loss: 1.6697, Train Accuracy: 51.7838%\n",
      "Epoch: 9200, Train Loss: 1.6696, Train Accuracy: 51.7838%\n",
      "Epoch: 9210, Train Loss: 1.6695, Train Accuracy: 51.7838%\n",
      "Epoch: 9220, Train Loss: 1.6694, Train Accuracy: 51.7838%\n",
      "Epoch: 9230, Train Loss: 1.6692, Train Accuracy: 51.7838%\n",
      "Epoch: 9240, Train Loss: 1.6691, Train Accuracy: 51.7838%\n",
      "Epoch: 9250, Train Loss: 1.6690, Train Accuracy: 51.7838%\n",
      "Epoch: 9260, Train Loss: 1.6689, Train Accuracy: 51.7838%\n",
      "Epoch: 9270, Train Loss: 1.6688, Train Accuracy: 51.7838%\n",
      "Epoch: 9280, Train Loss: 1.6687, Train Accuracy: 51.7838%\n",
      "Epoch: 9290, Train Loss: 1.6686, Train Accuracy: 51.7838%\n",
      "Epoch: 9300, Train Loss: 1.6685, Train Accuracy: 51.7838%\n",
      "Epoch: 9310, Train Loss: 1.6684, Train Accuracy: 51.7838%\n",
      "Epoch: 9320, Train Loss: 1.6683, Train Accuracy: 51.7838%\n",
      "Epoch: 9330, Train Loss: 1.6682, Train Accuracy: 51.7838%\n",
      "Epoch: 9340, Train Loss: 1.6681, Train Accuracy: 51.7838%\n",
      "Epoch: 9350, Train Loss: 1.6680, Train Accuracy: 51.7838%\n",
      "Epoch: 9360, Train Loss: 1.6679, Train Accuracy: 51.7838%\n",
      "Epoch: 9370, Train Loss: 1.6678, Train Accuracy: 51.7838%\n",
      "Epoch: 9380, Train Loss: 1.6677, Train Accuracy: 51.7838%\n",
      "Epoch: 9390, Train Loss: 1.6676, Train Accuracy: 51.7838%\n",
      "Epoch: 9400, Train Loss: 1.6675, Train Accuracy: 51.7838%\n",
      "Epoch: 9410, Train Loss: 1.6674, Train Accuracy: 51.7838%\n",
      "Epoch: 9420, Train Loss: 1.6673, Train Accuracy: 51.7838%\n",
      "Epoch: 9430, Train Loss: 1.6672, Train Accuracy: 51.7838%\n",
      "Epoch: 9440, Train Loss: 1.6671, Train Accuracy: 51.7838%\n",
      "Epoch: 9450, Train Loss: 1.6670, Train Accuracy: 51.7838%\n",
      "Epoch: 9460, Train Loss: 1.6669, Train Accuracy: 51.7838%\n",
      "Epoch: 9470, Train Loss: 1.6669, Train Accuracy: 51.7838%\n",
      "Epoch: 9480, Train Loss: 1.6668, Train Accuracy: 51.7838%\n",
      "Epoch: 9490, Train Loss: 1.6667, Train Accuracy: 51.7838%\n",
      "Epoch: 9500, Train Loss: 1.6666, Train Accuracy: 51.7838%\n",
      "Epoch: 9510, Train Loss: 1.6665, Train Accuracy: 51.7838%\n",
      "Epoch: 9520, Train Loss: 1.6664, Train Accuracy: 51.7838%\n",
      "Epoch: 9530, Train Loss: 1.6663, Train Accuracy: 51.7838%\n",
      "Epoch: 9540, Train Loss: 1.6662, Train Accuracy: 51.7838%\n",
      "Epoch: 9550, Train Loss: 1.6661, Train Accuracy: 51.7838%\n",
      "Epoch: 9560, Train Loss: 1.6660, Train Accuracy: 51.7838%\n",
      "Epoch: 9570, Train Loss: 1.6659, Train Accuracy: 51.7838%\n",
      "Epoch: 9580, Train Loss: 1.6658, Train Accuracy: 51.8919%\n",
      "Epoch: 9590, Train Loss: 1.6657, Train Accuracy: 51.8919%\n",
      "Epoch: 9600, Train Loss: 1.6656, Train Accuracy: 51.8919%\n",
      "Epoch: 9610, Train Loss: 1.6655, Train Accuracy: 51.8919%\n",
      "Epoch: 9620, Train Loss: 1.6654, Train Accuracy: 51.8919%\n",
      "Epoch: 9630, Train Loss: 1.6653, Train Accuracy: 51.8919%\n",
      "Epoch: 9640, Train Loss: 1.6652, Train Accuracy: 51.8919%\n",
      "Epoch: 9650, Train Loss: 1.6651, Train Accuracy: 51.8919%\n",
      "Epoch: 9660, Train Loss: 1.6650, Train Accuracy: 51.8919%\n",
      "Epoch: 9670, Train Loss: 1.6649, Train Accuracy: 51.8919%\n",
      "Epoch: 9680, Train Loss: 1.6648, Train Accuracy: 51.8919%\n",
      "Epoch: 9690, Train Loss: 1.6647, Train Accuracy: 52.0000%\n",
      "Epoch: 9700, Train Loss: 1.6646, Train Accuracy: 52.0000%\n",
      "Epoch: 9710, Train Loss: 1.6645, Train Accuracy: 52.0000%\n",
      "Epoch: 9720, Train Loss: 1.6644, Train Accuracy: 52.0000%\n",
      "Epoch: 9730, Train Loss: 1.6643, Train Accuracy: 52.0000%\n",
      "Epoch: 9740, Train Loss: 1.6642, Train Accuracy: 52.0000%\n",
      "Epoch: 9750, Train Loss: 1.6641, Train Accuracy: 52.0000%\n",
      "Epoch: 9760, Train Loss: 1.6640, Train Accuracy: 52.0000%\n",
      "Epoch: 9770, Train Loss: 1.6639, Train Accuracy: 52.0000%\n",
      "Epoch: 9780, Train Loss: 1.6638, Train Accuracy: 52.0000%\n",
      "Epoch: 9790, Train Loss: 1.6637, Train Accuracy: 52.0000%\n",
      "Epoch: 9800, Train Loss: 1.6636, Train Accuracy: 52.0000%\n",
      "Epoch: 9810, Train Loss: 1.6635, Train Accuracy: 52.0000%\n",
      "Epoch: 9820, Train Loss: 1.6634, Train Accuracy: 52.0000%\n",
      "Epoch: 9830, Train Loss: 1.6633, Train Accuracy: 52.0000%\n",
      "Epoch: 9840, Train Loss: 1.6632, Train Accuracy: 52.0000%\n",
      "Epoch: 9850, Train Loss: 1.6631, Train Accuracy: 52.0000%\n",
      "Epoch: 9860, Train Loss: 1.6630, Train Accuracy: 52.0000%\n",
      "Epoch: 9870, Train Loss: 1.6629, Train Accuracy: 52.0000%\n",
      "Epoch: 9880, Train Loss: 1.6628, Train Accuracy: 52.0000%\n",
      "Epoch: 9890, Train Loss: 1.6627, Train Accuracy: 52.0000%\n",
      "Epoch: 9900, Train Loss: 1.6626, Train Accuracy: 52.0000%\n",
      "Epoch: 9910, Train Loss: 1.6625, Train Accuracy: 52.0000%\n",
      "Epoch: 9920, Train Loss: 1.6624, Train Accuracy: 52.0000%\n",
      "Epoch: 9930, Train Loss: 1.6623, Train Accuracy: 52.0000%\n",
      "Epoch: 9940, Train Loss: 1.6622, Train Accuracy: 52.0000%\n",
      "Epoch: 9950, Train Loss: 1.6621, Train Accuracy: 52.0000%\n",
      "Epoch: 9960, Train Loss: 1.6620, Train Accuracy: 52.0000%\n",
      "Epoch: 9970, Train Loss: 1.6620, Train Accuracy: 52.0000%\n",
      "Epoch: 9980, Train Loss: 1.6619, Train Accuracy: 52.0000%\n",
      "Epoch: 9990, Train Loss: 1.6618, Train Accuracy: 52.0000%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:jiewbnzn) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▁▁▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▅▆▆▆▅▃▃▃▃▃▃▃▃▅▅▅██</td></tr><tr><td>train_loss</td><td>███▇▇▇▇▇▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>█████████████▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.52</td></tr><tr><td>train_loss</td><td>1.66167</td></tr><tr><td>val_accuracy</td><td>0.53398</td></tr><tr><td>val_loss</td><td>1.66425</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.0001</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/jiewbnzn' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/jiewbnzn</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190158-jiewbnzn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:jiewbnzn). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190219-bilp0sps</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/bilp0sps' target=\"_blank\">Logistic Regression lr=0.2</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/bilp0sps' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/bilp0sps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.5840, Train Accuracy: 52.7568%\n",
      "Epoch: 20, Train Loss: 1.5105, Train Accuracy: 52.9730%\n",
      "Epoch: 30, Train Loss: 1.4775, Train Accuracy: 53.5135%\n",
      "Epoch: 40, Train Loss: 1.4598, Train Accuracy: 53.9459%\n",
      "Epoch: 50, Train Loss: 1.4490, Train Accuracy: 54.3784%\n",
      "Epoch: 60, Train Loss: 1.4418, Train Accuracy: 55.1351%\n",
      "Epoch: 70, Train Loss: 1.4366, Train Accuracy: 55.2432%\n",
      "Epoch: 80, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 90, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 100, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 110, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 120, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 130, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 140, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 150, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 160, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 170, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 180, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 190, Train Loss: 1.4169, Train Accuracy: 55.8919%\n",
      "Epoch: 200, Train Loss: 1.4164, Train Accuracy: 56.2162%\n",
      "Epoch: 210, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 220, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 230, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 240, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 250, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 260, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 270, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 280, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 290, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 300, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 310, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 320, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 330, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 340, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 350, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 360, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 370, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 380, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 390, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 400, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 410, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 420, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 430, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 440, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 450, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 460, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 470, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 480, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 490, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 500, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 510, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 520, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 530, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 540, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 550, Train Loss: 1.4108, Train Accuracy: 57.0811%\n",
      "Epoch: 560, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 570, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 580, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 590, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 600, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 610, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 620, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 630, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 640, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 650, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 660, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 670, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 680, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 690, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 700, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 710, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 720, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 730, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 740, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 750, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 760, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 770, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 780, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 790, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 800, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 810, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 820, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 830, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 840, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 850, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 860, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 870, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 880, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 890, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 900, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 910, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 920, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 930, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 940, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 950, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 960, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 970, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 980, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 990, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1000, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1010, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 1020, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 1030, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 1040, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 1050, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1060, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1070, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1080, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1090, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1100, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1110, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1120, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1130, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1140, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1150, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1160, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1170, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1180, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1190, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1200, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1210, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1220, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1230, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1240, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1250, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 1260, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 1270, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 1280, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1290, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1300, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1310, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1320, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1330, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1340, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1350, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1360, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1370, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1380, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1390, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1400, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1410, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1420, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1430, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1440, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1450, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1460, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1470, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1480, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1490, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1500, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1510, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1520, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1530, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1540, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1550, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1560, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1570, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1580, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1590, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1600, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1610, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1620, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1630, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1640, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1650, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1660, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1670, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1680, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1690, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1700, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1710, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1720, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1730, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1740, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1750, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1760, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1770, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1780, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1790, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1800, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1810, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1820, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1830, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1840, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1850, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1860, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1870, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1880, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1890, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1900, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1910, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1920, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1930, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1940, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1950, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1960, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1970, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1980, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1990, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 2000, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 2010, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2020, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2030, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2040, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2050, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2060, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2070, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2080, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2090, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2100, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 2110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bilp0sps) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▅▅▇███████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▅▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56757</td></tr><tr><td>train_loss</td><td>1.40974</td></tr><tr><td>val_accuracy</td><td>0.61165</td></tr><tr><td>val_loss</td><td>1.34033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.2</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/bilp0sps' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/bilp0sps</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190219-bilp0sps/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bilp0sps). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190243-c0ur5fut</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/c0ur5fut' target=\"_blank\">Logistic Regression lr=0.02</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/c0ur5fut' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/c0ur5fut</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7592, Train Accuracy: 51.6757%\n",
      "Epoch: 20, Train Loss: 1.7304, Train Accuracy: 51.6757%\n",
      "Epoch: 30, Train Loss: 1.7047, Train Accuracy: 51.8919%\n",
      "Epoch: 40, Train Loss: 1.6818, Train Accuracy: 51.6757%\n",
      "Epoch: 50, Train Loss: 1.6614, Train Accuracy: 52.0000%\n",
      "Epoch: 60, Train Loss: 1.6431, Train Accuracy: 52.3243%\n",
      "Epoch: 70, Train Loss: 1.6267, Train Accuracy: 52.6486%\n",
      "Epoch: 80, Train Loss: 1.6120, Train Accuracy: 52.6486%\n",
      "Epoch: 90, Train Loss: 1.5987, Train Accuracy: 52.8649%\n",
      "Epoch: 100, Train Loss: 1.5867, Train Accuracy: 52.5405%\n",
      "Epoch: 110, Train Loss: 1.5759, Train Accuracy: 52.7568%\n",
      "Epoch: 120, Train Loss: 1.5661, Train Accuracy: 52.7568%\n",
      "Epoch: 130, Train Loss: 1.5571, Train Accuracy: 52.7568%\n",
      "Epoch: 140, Train Loss: 1.5489, Train Accuracy: 52.9730%\n",
      "Epoch: 150, Train Loss: 1.5415, Train Accuracy: 53.1892%\n",
      "Epoch: 160, Train Loss: 1.5347, Train Accuracy: 52.8649%\n",
      "Epoch: 170, Train Loss: 1.5284, Train Accuracy: 52.9730%\n",
      "Epoch: 180, Train Loss: 1.5226, Train Accuracy: 52.9730%\n",
      "Epoch: 190, Train Loss: 1.5173, Train Accuracy: 53.0811%\n",
      "Epoch: 200, Train Loss: 1.5124, Train Accuracy: 53.0811%\n",
      "Epoch: 210, Train Loss: 1.5078, Train Accuracy: 52.9730%\n",
      "Epoch: 220, Train Loss: 1.5036, Train Accuracy: 53.1892%\n",
      "Epoch: 230, Train Loss: 1.4997, Train Accuracy: 53.4054%\n",
      "Epoch: 240, Train Loss: 1.4960, Train Accuracy: 53.4054%\n",
      "Epoch: 250, Train Loss: 1.4926, Train Accuracy: 53.2973%\n",
      "Epoch: 260, Train Loss: 1.4895, Train Accuracy: 53.5135%\n",
      "Epoch: 270, Train Loss: 1.4865, Train Accuracy: 53.5135%\n",
      "Epoch: 280, Train Loss: 1.4837, Train Accuracy: 53.6216%\n",
      "Epoch: 290, Train Loss: 1.4811, Train Accuracy: 53.5135%\n",
      "Epoch: 300, Train Loss: 1.4787, Train Accuracy: 53.5135%\n",
      "Epoch: 310, Train Loss: 1.4763, Train Accuracy: 53.6216%\n",
      "Epoch: 320, Train Loss: 1.4742, Train Accuracy: 53.6216%\n",
      "Epoch: 330, Train Loss: 1.4721, Train Accuracy: 53.7297%\n",
      "Epoch: 340, Train Loss: 1.4702, Train Accuracy: 53.7297%\n",
      "Epoch: 350, Train Loss: 1.4683, Train Accuracy: 53.9459%\n",
      "Epoch: 360, Train Loss: 1.4666, Train Accuracy: 53.9459%\n",
      "Epoch: 370, Train Loss: 1.4650, Train Accuracy: 53.8378%\n",
      "Epoch: 380, Train Loss: 1.4634, Train Accuracy: 53.7297%\n",
      "Epoch: 390, Train Loss: 1.4619, Train Accuracy: 53.7297%\n",
      "Epoch: 400, Train Loss: 1.4605, Train Accuracy: 53.9459%\n",
      "Epoch: 410, Train Loss: 1.4592, Train Accuracy: 53.9459%\n",
      "Epoch: 420, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 430, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 440, Train Loss: 1.4555, Train Accuracy: 54.1622%\n",
      "Epoch: 450, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 460, Train Loss: 1.4533, Train Accuracy: 54.7027%\n",
      "Epoch: 470, Train Loss: 1.4523, Train Accuracy: 54.7027%\n",
      "Epoch: 480, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 490, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 500, Train Loss: 1.4495, Train Accuracy: 54.3784%\n",
      "Epoch: 510, Train Loss: 1.4486, Train Accuracy: 54.3784%\n",
      "Epoch: 520, Train Loss: 1.4478, Train Accuracy: 54.3784%\n",
      "Epoch: 530, Train Loss: 1.4469, Train Accuracy: 54.3784%\n",
      "Epoch: 540, Train Loss: 1.4462, Train Accuracy: 54.4865%\n",
      "Epoch: 550, Train Loss: 1.4454, Train Accuracy: 54.4865%\n",
      "Epoch: 560, Train Loss: 1.4447, Train Accuracy: 54.4865%\n",
      "Epoch: 570, Train Loss: 1.4440, Train Accuracy: 54.5946%\n",
      "Epoch: 580, Train Loss: 1.4434, Train Accuracy: 54.7027%\n",
      "Epoch: 590, Train Loss: 1.4427, Train Accuracy: 54.9189%\n",
      "Epoch: 600, Train Loss: 1.4421, Train Accuracy: 55.0270%\n",
      "Epoch: 610, Train Loss: 1.4415, Train Accuracy: 55.1351%\n",
      "Epoch: 620, Train Loss: 1.4409, Train Accuracy: 54.9189%\n",
      "Epoch: 630, Train Loss: 1.4403, Train Accuracy: 54.9189%\n",
      "Epoch: 640, Train Loss: 1.4398, Train Accuracy: 54.9189%\n",
      "Epoch: 650, Train Loss: 1.4393, Train Accuracy: 55.0270%\n",
      "Epoch: 660, Train Loss: 1.4388, Train Accuracy: 55.0270%\n",
      "Epoch: 670, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 680, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 690, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 700, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 710, Train Loss: 1.4364, Train Accuracy: 55.1351%\n",
      "Epoch: 720, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 730, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 740, Train Loss: 1.4352, Train Accuracy: 55.1351%\n",
      "Epoch: 750, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 760, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 770, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 780, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 790, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 800, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 810, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 820, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 830, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 840, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 850, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 860, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 870, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 880, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 890, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 900, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 910, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 920, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 930, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 940, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 950, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 960, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 970, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 980, Train Loss: 1.4279, Train Accuracy: 55.2432%\n",
      "Epoch: 990, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 1000, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 1010, Train Loss: 1.4272, Train Accuracy: 55.4595%\n",
      "Epoch: 1020, Train Loss: 1.4270, Train Accuracy: 55.3514%\n",
      "Epoch: 1030, Train Loss: 1.4268, Train Accuracy: 55.3514%\n",
      "Epoch: 1040, Train Loss: 1.4266, Train Accuracy: 55.3514%\n",
      "Epoch: 1050, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 1060, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 1070, Train Loss: 1.4260, Train Accuracy: 55.3514%\n",
      "Epoch: 1080, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 1090, Train Loss: 1.4256, Train Accuracy: 55.3514%\n",
      "Epoch: 1100, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 1110, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 1120, Train Loss: 1.4251, Train Accuracy: 55.2432%\n",
      "Epoch: 1130, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 1140, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 1150, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 1160, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 1170, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 1180, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 1190, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 1200, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 1210, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 1220, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 1230, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 1240, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 1250, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 1260, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 1270, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 1280, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 1290, Train Loss: 1.4224, Train Accuracy: 55.0270%\n",
      "Epoch: 1300, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 1310, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 1320, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 1330, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 1340, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 1350, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 1360, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 1370, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 1380, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 1390, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 1400, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 1410, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 1420, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 1430, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 1440, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 1450, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 1460, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 1470, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 1480, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 1490, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 1500, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 1510, Train Loss: 1.4199, Train Accuracy: 55.2432%\n",
      "Epoch: 1520, Train Loss: 1.4198, Train Accuracy: 55.2432%\n",
      "Epoch: 1530, Train Loss: 1.4197, Train Accuracy: 55.2432%\n",
      "Epoch: 1540, Train Loss: 1.4196, Train Accuracy: 55.2432%\n",
      "Epoch: 1550, Train Loss: 1.4196, Train Accuracy: 55.2432%\n",
      "Epoch: 1560, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 1570, Train Loss: 1.4194, Train Accuracy: 55.2432%\n",
      "Epoch: 1580, Train Loss: 1.4193, Train Accuracy: 55.2432%\n",
      "Epoch: 1590, Train Loss: 1.4192, Train Accuracy: 55.3514%\n",
      "Epoch: 1600, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 1610, Train Loss: 1.4190, Train Accuracy: 55.3514%\n",
      "Epoch: 1620, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 1630, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 1640, Train Loss: 1.4188, Train Accuracy: 55.3514%\n",
      "Epoch: 1650, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 1660, Train Loss: 1.4186, Train Accuracy: 55.3514%\n",
      "Epoch: 1670, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 1680, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 1690, Train Loss: 1.4184, Train Accuracy: 55.4595%\n",
      "Epoch: 1700, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 1710, Train Loss: 1.4182, Train Accuracy: 55.4595%\n",
      "Epoch: 1720, Train Loss: 1.4182, Train Accuracy: 55.3514%\n",
      "Epoch: 1730, Train Loss: 1.4181, Train Accuracy: 55.4595%\n",
      "Epoch: 1740, Train Loss: 1.4180, Train Accuracy: 55.4595%\n",
      "Epoch: 1750, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 1760, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 1770, Train Loss: 1.4178, Train Accuracy: 55.4595%\n",
      "Epoch: 1780, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 1790, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 1800, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 1810, Train Loss: 1.4175, Train Accuracy: 55.6757%\n",
      "Epoch: 1820, Train Loss: 1.4175, Train Accuracy: 55.7838%\n",
      "Epoch: 1830, Train Loss: 1.4174, Train Accuracy: 55.7838%\n",
      "Epoch: 1840, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 1850, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 1860, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 1870, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 1880, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 1890, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 1900, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 1910, Train Loss: 1.4169, Train Accuracy: 55.8919%\n",
      "Epoch: 1920, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 1930, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 1940, Train Loss: 1.4167, Train Accuracy: 55.8919%\n",
      "Epoch: 1950, Train Loss: 1.4167, Train Accuracy: 56.0000%\n",
      "Epoch: 1960, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 1970, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 1980, Train Loss: 1.4165, Train Accuracy: 56.1081%\n",
      "Epoch: 1990, Train Loss: 1.4164, Train Accuracy: 56.1081%\n",
      "Epoch: 2000, Train Loss: 1.4164, Train Accuracy: 56.2162%\n",
      "Epoch: 2010, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 2020, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 2030, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 2040, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 2050, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 2060, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 2070, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 2080, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 2090, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 2100, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 2110, Train Loss: 1.4158, Train Accuracy: 56.3243%\n",
      "Epoch: 2120, Train Loss: 1.4158, Train Accuracy: 56.4324%\n",
      "Epoch: 2130, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 2140, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 2150, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 2160, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 2170, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 2180, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 2190, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 2200, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 2210, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 2220, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 2230, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 2240, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 2250, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 2260, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 2270, Train Loss: 1.4151, Train Accuracy: 56.4324%\n",
      "Epoch: 2280, Train Loss: 1.4151, Train Accuracy: 56.5405%\n",
      "Epoch: 2290, Train Loss: 1.4151, Train Accuracy: 56.6486%\n",
      "Epoch: 2300, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 2310, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 2320, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 2330, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 2340, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 2350, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 2360, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 2370, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 2380, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 2390, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 2400, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 2410, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 2420, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 2430, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 2440, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 2450, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 2460, Train Loss: 1.4145, Train Accuracy: 56.7568%\n",
      "Epoch: 2470, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 2480, Train Loss: 1.4144, Train Accuracy: 56.6486%\n",
      "Epoch: 2490, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 2500, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 2510, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 2520, Train Loss: 1.4143, Train Accuracy: 56.9730%\n",
      "Epoch: 2530, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 2540, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 2550, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 2560, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 2570, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 2580, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 2590, Train Loss: 1.4141, Train Accuracy: 57.0811%\n",
      "Epoch: 2600, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 2610, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 2620, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 2630, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 2640, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 2650, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 2660, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 2670, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 2680, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 2690, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 2700, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 2710, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 2720, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 2730, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 2740, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 2750, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 2760, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 2770, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 2780, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 2790, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 2800, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 2810, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 2820, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 2830, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 2840, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 2850, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 2860, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 2870, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 2880, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 2890, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 2900, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 2910, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 2920, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 2930, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 2940, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 2950, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 2960, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 2970, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 2980, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 2990, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 3000, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 3010, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3020, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3030, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3040, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3050, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3060, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 3070, Train Loss: 1.4129, Train Accuracy: 56.7568%\n",
      "Epoch: 3080, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 3090, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 3100, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 3110, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 3120, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 3130, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 3140, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 3150, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 3160, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 3170, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 3180, Train Loss: 1.4127, Train Accuracy: 56.7568%\n",
      "Epoch: 3190, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 3200, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 3210, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 3220, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 3230, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 3240, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3250, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3260, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3270, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3280, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3290, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 3300, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3310, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3320, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3330, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3340, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3350, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 3360, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3370, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3380, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3390, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3400, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3410, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3420, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 3430, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3440, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3450, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3460, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3470, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3480, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3490, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 3500, Train Loss: 1.4123, Train Accuracy: 56.9730%\n",
      "Epoch: 3510, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3520, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3530, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3540, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3550, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3560, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3570, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 3580, Train Loss: 1.4121, Train Accuracy: 56.9730%\n",
      "Epoch: 3590, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3600, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3610, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3620, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3630, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3640, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3650, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3660, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 3670, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 3680, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 3690, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 3700, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 3710, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 3720, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 3730, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 3740, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 3750, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3760, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3770, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3780, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3790, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3800, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3810, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3820, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3830, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3840, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 3850, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3860, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3870, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3880, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3890, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3900, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3910, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3920, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3930, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3940, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 3950, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 3960, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 3970, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 3980, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 3990, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4000, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4010, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4020, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4030, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4040, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4050, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 4060, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 4070, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 4080, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 4090, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 4100, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4110, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4120, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4130, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4140, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4150, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4160, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 4170, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 4180, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 4190, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 4200, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 4210, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 4220, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4230, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4240, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4250, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4260, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4270, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4280, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4290, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 4300, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4310, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4320, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4330, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4340, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4350, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4360, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4370, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4380, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 4390, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 4400, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 4410, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 4420, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 4430, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 4440, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4450, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4460, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4470, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4480, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4490, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4500, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4510, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4520, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4530, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4540, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4550, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4560, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4570, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4580, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 4590, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4600, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4610, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4620, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4630, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4640, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4650, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4660, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4670, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4680, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4690, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 4700, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 4710, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 4720, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 4730, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 4740, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 4750, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4760, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4770, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4780, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4790, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4800, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4810, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4820, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4830, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4840, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4850, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4860, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4870, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4880, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4890, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4900, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4910, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4920, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 4930, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4940, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4950, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4960, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4970, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4980, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 4990, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 5000, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 5010, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5020, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5030, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5040, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5050, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5060, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5070, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 5080, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 5090, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 5100, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 5110, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 5120, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 5130, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 5140, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 5150, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 5160, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 5170, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 5180, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5190, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5200, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5210, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5220, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5230, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5240, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5250, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5260, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5270, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5280, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5290, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5300, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5310, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5320, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5330, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5340, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5350, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 5360, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5370, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5380, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5390, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5400, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5410, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5420, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5430, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5440, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5450, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5460, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5470, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5480, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5490, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 5500, Train Loss: 1.4108, Train Accuracy: 57.0811%\n",
      "Epoch: 5510, Train Loss: 1.4108, Train Accuracy: 57.0811%\n",
      "Epoch: 5520, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5530, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5540, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5550, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5560, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5570, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5580, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5590, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5600, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 5610, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5620, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5630, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5640, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5650, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5660, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5670, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5680, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5690, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5700, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5710, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5720, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5730, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5740, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5750, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5760, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5770, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5780, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5790, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5800, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 5810, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5820, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5830, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5840, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5850, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5860, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 5870, Train Loss: 1.4107, Train Accuracy: 57.1892%\n",
      "Epoch: 5880, Train Loss: 1.4107, Train Accuracy: 57.1892%\n",
      "Epoch: 5890, Train Loss: 1.4107, Train Accuracy: 57.1892%\n",
      "Epoch: 5900, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5910, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5920, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5930, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5940, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5950, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5960, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5970, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5980, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 5990, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6000, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6010, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6020, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6030, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6040, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6050, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6060, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6070, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6080, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6090, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6100, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6110, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6120, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6130, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6140, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6150, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6160, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6170, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6180, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6190, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6200, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6210, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6220, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 6230, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6240, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6250, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6260, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6270, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6280, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6290, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6300, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6310, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6320, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6330, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6340, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6350, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 6360, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6370, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6380, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6390, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6400, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6410, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6420, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6430, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6440, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6450, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6460, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6470, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6480, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6490, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6500, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6510, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6520, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6530, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6540, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6550, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6560, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6570, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6580, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6590, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6600, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 6610, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6620, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6630, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6640, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6650, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6660, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6670, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6680, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6690, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6700, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6710, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6720, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6730, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6740, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6750, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6760, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6770, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6780, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6790, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6800, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6810, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 6820, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6830, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6840, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6850, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6860, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6870, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6880, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6890, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6900, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6910, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6920, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6930, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6940, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6950, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6960, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6970, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6980, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 6990, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 7000, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 7010, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 7020, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 7030, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 7040, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 7050, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 7060, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7070, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7080, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7090, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7100, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7110, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7120, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7130, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7140, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7150, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7160, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7170, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7180, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7190, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7200, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7210, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7220, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 7230, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7240, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7250, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7260, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7270, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7280, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7290, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7300, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7310, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7320, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7330, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7340, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7350, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7360, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7370, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7380, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7390, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7400, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7410, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7420, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7430, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7440, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7450, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7460, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7470, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7480, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7490, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7500, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7510, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7520, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7530, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7540, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7550, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7560, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7570, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7580, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7590, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7600, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 7610, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7620, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7630, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7640, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7650, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7660, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7670, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7680, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7690, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7700, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7710, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7720, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7730, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7740, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7750, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7760, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7770, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7780, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7790, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7800, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7810, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7820, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7830, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 7840, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7850, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7860, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7870, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7880, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7890, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7900, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7910, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7920, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7930, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7940, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7950, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7960, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7970, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7980, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 7990, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8000, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8010, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8020, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8030, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8040, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8050, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8060, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8070, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8080, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8090, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8100, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8110, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8120, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8130, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8140, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8150, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8160, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8170, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8180, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8190, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8200, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8210, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8220, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8230, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8240, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8250, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8260, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8270, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8280, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 8290, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8300, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8310, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8320, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8330, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8340, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8350, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8360, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8370, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8380, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8390, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8400, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8410, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8420, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8430, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8440, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8450, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8460, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8470, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8480, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8490, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8500, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8510, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8520, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8530, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8540, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8550, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8560, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8570, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8580, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8590, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8600, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8610, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8620, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8630, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8640, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8650, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8660, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8670, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8680, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8690, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8700, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8710, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8720, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8730, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8740, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8750, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8760, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8770, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8780, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8790, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8800, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8810, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8820, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8830, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8840, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8850, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8860, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8870, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8880, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8890, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8900, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8910, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8920, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8930, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8940, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8950, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8960, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8970, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8980, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 8990, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9000, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9010, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9020, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9030, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9040, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9050, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9060, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9070, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9080, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9090, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9100, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9110, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9120, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9130, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9140, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9150, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9160, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9170, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 9180, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9190, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9200, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9210, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9220, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9230, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9240, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9250, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9260, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9270, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9280, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9290, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9300, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9310, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9320, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9330, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9340, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9350, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9360, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9370, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9380, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9390, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9400, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9410, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9420, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9430, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9440, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9450, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9460, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9470, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9480, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9490, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9500, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9510, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9520, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9530, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9540, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9550, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9560, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9570, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9580, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9590, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9600, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9610, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 9620, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9630, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9640, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9650, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9660, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9670, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9680, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9690, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9700, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9710, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9720, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9730, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9740, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9750, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9760, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9770, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9780, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9790, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9800, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9810, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9820, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9830, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9840, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9850, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9860, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9870, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9880, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9890, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9900, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9910, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9920, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9930, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9940, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9950, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9960, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9970, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9980, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 9990, Train Loss: 1.4100, Train Accuracy: 56.7568%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:c0ur5fut) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▂▄▅▅▅▅▅▆▇█▇▇▇█████▇███████████▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▅▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▂▂▂▃▄▄▄▄▄▅▆▇▇▇▇▇▇▇▇▇████▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56757</td></tr><tr><td>train_loss</td><td>1.40998</td></tr><tr><td>val_accuracy</td><td>0.59223</td></tr><tr><td>val_loss</td><td>1.3419</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.02</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/c0ur5fut' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/c0ur5fut</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190243-c0ur5fut/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:c0ur5fut). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190303-1f0nibaq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/1f0nibaq' target=\"_blank\">Logistic Regression lr=0.002</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/1f0nibaq' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/1f0nibaq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7883, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7850, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 40, Train Loss: 1.7783, Train Accuracy: 51.5676%\n",
      "Epoch: 50, Train Loss: 1.7751, Train Accuracy: 51.6757%\n",
      "Epoch: 60, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 70, Train Loss: 1.7687, Train Accuracy: 51.6757%\n",
      "Epoch: 80, Train Loss: 1.7655, Train Accuracy: 51.6757%\n",
      "Epoch: 90, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 100, Train Loss: 1.7593, Train Accuracy: 51.6757%\n",
      "Epoch: 110, Train Loss: 1.7563, Train Accuracy: 51.6757%\n",
      "Epoch: 120, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 130, Train Loss: 1.7503, Train Accuracy: 51.6757%\n",
      "Epoch: 140, Train Loss: 1.7474, Train Accuracy: 51.6757%\n",
      "Epoch: 150, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 160, Train Loss: 1.7416, Train Accuracy: 51.6757%\n",
      "Epoch: 170, Train Loss: 1.7388, Train Accuracy: 51.6757%\n",
      "Epoch: 180, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 190, Train Loss: 1.7332, Train Accuracy: 51.6757%\n",
      "Epoch: 200, Train Loss: 1.7305, Train Accuracy: 51.6757%\n",
      "Epoch: 210, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 220, Train Loss: 1.7252, Train Accuracy: 51.6757%\n",
      "Epoch: 230, Train Loss: 1.7225, Train Accuracy: 51.6757%\n",
      "Epoch: 240, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 250, Train Loss: 1.7173, Train Accuracy: 51.6757%\n",
      "Epoch: 260, Train Loss: 1.7148, Train Accuracy: 51.6757%\n",
      "Epoch: 270, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 280, Train Loss: 1.7098, Train Accuracy: 51.7838%\n",
      "Epoch: 290, Train Loss: 1.7073, Train Accuracy: 51.7838%\n",
      "Epoch: 300, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 310, Train Loss: 1.7025, Train Accuracy: 51.8919%\n",
      "Epoch: 320, Train Loss: 1.7001, Train Accuracy: 51.8919%\n",
      "Epoch: 330, Train Loss: 1.6978, Train Accuracy: 51.7838%\n",
      "Epoch: 340, Train Loss: 1.6954, Train Accuracy: 51.7838%\n",
      "Epoch: 350, Train Loss: 1.6931, Train Accuracy: 51.6757%\n",
      "Epoch: 360, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 370, Train Loss: 1.6886, Train Accuracy: 51.6757%\n",
      "Epoch: 380, Train Loss: 1.6864, Train Accuracy: 51.6757%\n",
      "Epoch: 390, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 400, Train Loss: 1.6820, Train Accuracy: 51.6757%\n",
      "Epoch: 410, Train Loss: 1.6799, Train Accuracy: 51.6757%\n",
      "Epoch: 420, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 430, Train Loss: 1.6757, Train Accuracy: 51.6757%\n",
      "Epoch: 440, Train Loss: 1.6736, Train Accuracy: 51.6757%\n",
      "Epoch: 450, Train Loss: 1.6716, Train Accuracy: 51.7838%\n",
      "Epoch: 460, Train Loss: 1.6695, Train Accuracy: 51.7838%\n",
      "Epoch: 470, Train Loss: 1.6675, Train Accuracy: 51.7838%\n",
      "Epoch: 480, Train Loss: 1.6655, Train Accuracy: 51.8919%\n",
      "Epoch: 490, Train Loss: 1.6636, Train Accuracy: 52.0000%\n",
      "Epoch: 500, Train Loss: 1.6616, Train Accuracy: 52.0000%\n",
      "Epoch: 510, Train Loss: 1.6597, Train Accuracy: 52.0000%\n",
      "Epoch: 520, Train Loss: 1.6578, Train Accuracy: 52.2162%\n",
      "Epoch: 530, Train Loss: 1.6559, Train Accuracy: 52.2162%\n",
      "Epoch: 540, Train Loss: 1.6541, Train Accuracy: 52.2162%\n",
      "Epoch: 550, Train Loss: 1.6523, Train Accuracy: 52.1081%\n",
      "Epoch: 560, Train Loss: 1.6504, Train Accuracy: 52.3243%\n",
      "Epoch: 570, Train Loss: 1.6486, Train Accuracy: 52.3243%\n",
      "Epoch: 580, Train Loss: 1.6469, Train Accuracy: 52.3243%\n",
      "Epoch: 590, Train Loss: 1.6451, Train Accuracy: 52.3243%\n",
      "Epoch: 600, Train Loss: 1.6434, Train Accuracy: 52.4324%\n",
      "Epoch: 610, Train Loss: 1.6417, Train Accuracy: 52.4324%\n",
      "Epoch: 620, Train Loss: 1.6400, Train Accuracy: 52.4324%\n",
      "Epoch: 630, Train Loss: 1.6383, Train Accuracy: 52.4324%\n",
      "Epoch: 640, Train Loss: 1.6366, Train Accuracy: 52.4324%\n",
      "Epoch: 650, Train Loss: 1.6350, Train Accuracy: 52.5405%\n",
      "Epoch: 660, Train Loss: 1.6333, Train Accuracy: 52.5405%\n",
      "Epoch: 670, Train Loss: 1.6317, Train Accuracy: 52.5405%\n",
      "Epoch: 680, Train Loss: 1.6301, Train Accuracy: 52.5405%\n",
      "Epoch: 690, Train Loss: 1.6286, Train Accuracy: 52.6486%\n",
      "Epoch: 700, Train Loss: 1.6270, Train Accuracy: 52.6486%\n",
      "Epoch: 710, Train Loss: 1.6255, Train Accuracy: 52.6486%\n",
      "Epoch: 720, Train Loss: 1.6239, Train Accuracy: 52.5405%\n",
      "Epoch: 730, Train Loss: 1.6224, Train Accuracy: 52.4324%\n",
      "Epoch: 740, Train Loss: 1.6209, Train Accuracy: 52.4324%\n",
      "Epoch: 750, Train Loss: 1.6194, Train Accuracy: 52.5405%\n",
      "Epoch: 760, Train Loss: 1.6180, Train Accuracy: 52.5405%\n",
      "Epoch: 770, Train Loss: 1.6165, Train Accuracy: 52.6486%\n",
      "Epoch: 780, Train Loss: 1.6151, Train Accuracy: 52.7568%\n",
      "Epoch: 790, Train Loss: 1.6137, Train Accuracy: 52.7568%\n",
      "Epoch: 800, Train Loss: 1.6123, Train Accuracy: 52.6486%\n",
      "Epoch: 810, Train Loss: 1.6109, Train Accuracy: 52.6486%\n",
      "Epoch: 820, Train Loss: 1.6095, Train Accuracy: 52.6486%\n",
      "Epoch: 830, Train Loss: 1.6081, Train Accuracy: 52.6486%\n",
      "Epoch: 840, Train Loss: 1.6068, Train Accuracy: 52.6486%\n",
      "Epoch: 850, Train Loss: 1.6055, Train Accuracy: 52.6486%\n",
      "Epoch: 860, Train Loss: 1.6041, Train Accuracy: 52.6486%\n",
      "Epoch: 870, Train Loss: 1.6028, Train Accuracy: 52.7568%\n",
      "Epoch: 880, Train Loss: 1.6015, Train Accuracy: 52.8649%\n",
      "Epoch: 890, Train Loss: 1.6003, Train Accuracy: 52.8649%\n",
      "Epoch: 900, Train Loss: 1.5990, Train Accuracy: 52.8649%\n",
      "Epoch: 910, Train Loss: 1.5977, Train Accuracy: 52.8649%\n",
      "Epoch: 920, Train Loss: 1.5965, Train Accuracy: 52.8649%\n",
      "Epoch: 930, Train Loss: 1.5953, Train Accuracy: 52.7568%\n",
      "Epoch: 940, Train Loss: 1.5941, Train Accuracy: 52.7568%\n",
      "Epoch: 950, Train Loss: 1.5929, Train Accuracy: 52.7568%\n",
      "Epoch: 960, Train Loss: 1.5917, Train Accuracy: 52.6486%\n",
      "Epoch: 970, Train Loss: 1.5905, Train Accuracy: 52.4324%\n",
      "Epoch: 980, Train Loss: 1.5893, Train Accuracy: 52.4324%\n",
      "Epoch: 990, Train Loss: 1.5882, Train Accuracy: 52.4324%\n",
      "Epoch: 1000, Train Loss: 1.5870, Train Accuracy: 52.5405%\n",
      "Epoch: 1010, Train Loss: 1.5859, Train Accuracy: 52.7568%\n",
      "Epoch: 1020, Train Loss: 1.5848, Train Accuracy: 52.7568%\n",
      "Epoch: 1030, Train Loss: 1.5836, Train Accuracy: 52.7568%\n",
      "Epoch: 1040, Train Loss: 1.5825, Train Accuracy: 52.7568%\n",
      "Epoch: 1050, Train Loss: 1.5815, Train Accuracy: 52.7568%\n",
      "Epoch: 1060, Train Loss: 1.5804, Train Accuracy: 52.7568%\n",
      "Epoch: 1070, Train Loss: 1.5793, Train Accuracy: 52.7568%\n",
      "Epoch: 1080, Train Loss: 1.5782, Train Accuracy: 52.7568%\n",
      "Epoch: 1090, Train Loss: 1.5772, Train Accuracy: 52.7568%\n",
      "Epoch: 1100, Train Loss: 1.5762, Train Accuracy: 52.7568%\n",
      "Epoch: 1110, Train Loss: 1.5751, Train Accuracy: 52.7568%\n",
      "Epoch: 1120, Train Loss: 1.5741, Train Accuracy: 52.7568%\n",
      "Epoch: 1130, Train Loss: 1.5731, Train Accuracy: 52.7568%\n",
      "Epoch: 1140, Train Loss: 1.5721, Train Accuracy: 52.7568%\n",
      "Epoch: 1150, Train Loss: 1.5711, Train Accuracy: 52.7568%\n",
      "Epoch: 1160, Train Loss: 1.5701, Train Accuracy: 52.7568%\n",
      "Epoch: 1170, Train Loss: 1.5692, Train Accuracy: 52.7568%\n",
      "Epoch: 1180, Train Loss: 1.5682, Train Accuracy: 52.7568%\n",
      "Epoch: 1190, Train Loss: 1.5673, Train Accuracy: 52.7568%\n",
      "Epoch: 1200, Train Loss: 1.5663, Train Accuracy: 52.7568%\n",
      "Epoch: 1210, Train Loss: 1.5654, Train Accuracy: 52.7568%\n",
      "Epoch: 1220, Train Loss: 1.5645, Train Accuracy: 52.7568%\n",
      "Epoch: 1230, Train Loss: 1.5635, Train Accuracy: 52.7568%\n",
      "Epoch: 1240, Train Loss: 1.5626, Train Accuracy: 52.7568%\n",
      "Epoch: 1250, Train Loss: 1.5617, Train Accuracy: 52.7568%\n",
      "Epoch: 1260, Train Loss: 1.5608, Train Accuracy: 52.7568%\n",
      "Epoch: 1270, Train Loss: 1.5600, Train Accuracy: 52.7568%\n",
      "Epoch: 1280, Train Loss: 1.5591, Train Accuracy: 52.7568%\n",
      "Epoch: 1290, Train Loss: 1.5582, Train Accuracy: 52.7568%\n",
      "Epoch: 1300, Train Loss: 1.5574, Train Accuracy: 52.7568%\n",
      "Epoch: 1310, Train Loss: 1.5565, Train Accuracy: 52.7568%\n",
      "Epoch: 1320, Train Loss: 1.5557, Train Accuracy: 52.8649%\n",
      "Epoch: 1330, Train Loss: 1.5548, Train Accuracy: 52.8649%\n",
      "Epoch: 1340, Train Loss: 1.5540, Train Accuracy: 52.8649%\n",
      "Epoch: 1350, Train Loss: 1.5532, Train Accuracy: 52.8649%\n",
      "Epoch: 1360, Train Loss: 1.5524, Train Accuracy: 52.9730%\n",
      "Epoch: 1370, Train Loss: 1.5516, Train Accuracy: 52.9730%\n",
      "Epoch: 1380, Train Loss: 1.5508, Train Accuracy: 52.9730%\n",
      "Epoch: 1390, Train Loss: 1.5500, Train Accuracy: 52.9730%\n",
      "Epoch: 1400, Train Loss: 1.5492, Train Accuracy: 52.9730%\n",
      "Epoch: 1410, Train Loss: 1.5484, Train Accuracy: 52.9730%\n",
      "Epoch: 1420, Train Loss: 1.5476, Train Accuracy: 52.9730%\n",
      "Epoch: 1430, Train Loss: 1.5469, Train Accuracy: 52.9730%\n",
      "Epoch: 1440, Train Loss: 1.5461, Train Accuracy: 53.0811%\n",
      "Epoch: 1450, Train Loss: 1.5454, Train Accuracy: 53.1892%\n",
      "Epoch: 1460, Train Loss: 1.5446, Train Accuracy: 53.1892%\n",
      "Epoch: 1470, Train Loss: 1.5439, Train Accuracy: 53.1892%\n",
      "Epoch: 1480, Train Loss: 1.5432, Train Accuracy: 53.1892%\n",
      "Epoch: 1490, Train Loss: 1.5424, Train Accuracy: 53.1892%\n",
      "Epoch: 1500, Train Loss: 1.5417, Train Accuracy: 53.2973%\n",
      "Epoch: 1510, Train Loss: 1.5410, Train Accuracy: 53.0811%\n",
      "Epoch: 1520, Train Loss: 1.5403, Train Accuracy: 52.8649%\n",
      "Epoch: 1530, Train Loss: 1.5396, Train Accuracy: 52.7568%\n",
      "Epoch: 1540, Train Loss: 1.5389, Train Accuracy: 52.7568%\n",
      "Epoch: 1550, Train Loss: 1.5382, Train Accuracy: 52.8649%\n",
      "Epoch: 1560, Train Loss: 1.5375, Train Accuracy: 52.8649%\n",
      "Epoch: 1570, Train Loss: 1.5369, Train Accuracy: 52.8649%\n",
      "Epoch: 1580, Train Loss: 1.5362, Train Accuracy: 52.8649%\n",
      "Epoch: 1590, Train Loss: 1.5355, Train Accuracy: 52.8649%\n",
      "Epoch: 1600, Train Loss: 1.5349, Train Accuracy: 52.8649%\n",
      "Epoch: 1610, Train Loss: 1.5342, Train Accuracy: 52.8649%\n",
      "Epoch: 1620, Train Loss: 1.5336, Train Accuracy: 52.8649%\n",
      "Epoch: 1630, Train Loss: 1.5329, Train Accuracy: 52.8649%\n",
      "Epoch: 1640, Train Loss: 1.5323, Train Accuracy: 52.8649%\n",
      "Epoch: 1650, Train Loss: 1.5317, Train Accuracy: 52.8649%\n",
      "Epoch: 1660, Train Loss: 1.5310, Train Accuracy: 52.9730%\n",
      "Epoch: 1670, Train Loss: 1.5304, Train Accuracy: 52.9730%\n",
      "Epoch: 1680, Train Loss: 1.5298, Train Accuracy: 52.9730%\n",
      "Epoch: 1690, Train Loss: 1.5292, Train Accuracy: 52.9730%\n",
      "Epoch: 1700, Train Loss: 1.5286, Train Accuracy: 52.9730%\n",
      "Epoch: 1710, Train Loss: 1.5280, Train Accuracy: 53.0811%\n",
      "Epoch: 1720, Train Loss: 1.5274, Train Accuracy: 53.0811%\n",
      "Epoch: 1730, Train Loss: 1.5268, Train Accuracy: 53.0811%\n",
      "Epoch: 1740, Train Loss: 1.5262, Train Accuracy: 52.9730%\n",
      "Epoch: 1750, Train Loss: 1.5256, Train Accuracy: 52.9730%\n",
      "Epoch: 1760, Train Loss: 1.5251, Train Accuracy: 52.9730%\n",
      "Epoch: 1770, Train Loss: 1.5245, Train Accuracy: 52.9730%\n",
      "Epoch: 1780, Train Loss: 1.5239, Train Accuracy: 52.9730%\n",
      "Epoch: 1790, Train Loss: 1.5234, Train Accuracy: 52.9730%\n",
      "Epoch: 1800, Train Loss: 1.5228, Train Accuracy: 52.9730%\n",
      "Epoch: 1810, Train Loss: 1.5223, Train Accuracy: 52.9730%\n",
      "Epoch: 1820, Train Loss: 1.5217, Train Accuracy: 52.9730%\n",
      "Epoch: 1830, Train Loss: 1.5212, Train Accuracy: 52.9730%\n",
      "Epoch: 1840, Train Loss: 1.5206, Train Accuracy: 52.9730%\n",
      "Epoch: 1850, Train Loss: 1.5201, Train Accuracy: 52.9730%\n",
      "Epoch: 1860, Train Loss: 1.5196, Train Accuracy: 52.9730%\n",
      "Epoch: 1870, Train Loss: 1.5190, Train Accuracy: 53.0811%\n",
      "Epoch: 1880, Train Loss: 1.5185, Train Accuracy: 53.0811%\n",
      "Epoch: 1890, Train Loss: 1.5180, Train Accuracy: 53.0811%\n",
      "Epoch: 1900, Train Loss: 1.5175, Train Accuracy: 53.0811%\n",
      "Epoch: 1910, Train Loss: 1.5170, Train Accuracy: 53.0811%\n",
      "Epoch: 1920, Train Loss: 1.5165, Train Accuracy: 53.0811%\n",
      "Epoch: 1930, Train Loss: 1.5160, Train Accuracy: 53.0811%\n",
      "Epoch: 1940, Train Loss: 1.5155, Train Accuracy: 53.0811%\n",
      "Epoch: 1950, Train Loss: 1.5150, Train Accuracy: 53.0811%\n",
      "Epoch: 1960, Train Loss: 1.5145, Train Accuracy: 53.0811%\n",
      "Epoch: 1970, Train Loss: 1.5140, Train Accuracy: 53.0811%\n",
      "Epoch: 1980, Train Loss: 1.5135, Train Accuracy: 52.9730%\n",
      "Epoch: 1990, Train Loss: 1.5130, Train Accuracy: 52.9730%\n",
      "Epoch: 2000, Train Loss: 1.5126, Train Accuracy: 53.0811%\n",
      "Epoch: 2010, Train Loss: 1.5121, Train Accuracy: 53.0811%\n",
      "Epoch: 2020, Train Loss: 1.5116, Train Accuracy: 53.0811%\n",
      "Epoch: 2030, Train Loss: 1.5112, Train Accuracy: 53.0811%\n",
      "Epoch: 2040, Train Loss: 1.5107, Train Accuracy: 53.0811%\n",
      "Epoch: 2050, Train Loss: 1.5102, Train Accuracy: 53.0811%\n",
      "Epoch: 2060, Train Loss: 1.5098, Train Accuracy: 52.9730%\n",
      "Epoch: 2070, Train Loss: 1.5093, Train Accuracy: 52.9730%\n",
      "Epoch: 2080, Train Loss: 1.5089, Train Accuracy: 52.9730%\n",
      "Epoch: 2090, Train Loss: 1.5084, Train Accuracy: 52.9730%\n",
      "Epoch: 2100, Train Loss: 1.5080, Train Accuracy: 52.9730%\n",
      "Epoch: 2110, Train Loss: 1.5076, Train Accuracy: 53.0811%\n",
      "Epoch: 2120, Train Loss: 1.5071, Train Accuracy: 53.0811%\n",
      "Epoch: 2130, Train Loss: 1.5067, Train Accuracy: 53.0811%\n",
      "Epoch: 2140, Train Loss: 1.5063, Train Accuracy: 53.0811%\n",
      "Epoch: 2150, Train Loss: 1.5059, Train Accuracy: 53.0811%\n",
      "Epoch: 2160, Train Loss: 1.5054, Train Accuracy: 53.0811%\n",
      "Epoch: 2170, Train Loss: 1.5050, Train Accuracy: 53.0811%\n",
      "Epoch: 2180, Train Loss: 1.5046, Train Accuracy: 53.0811%\n",
      "Epoch: 2190, Train Loss: 1.5042, Train Accuracy: 53.0811%\n",
      "Epoch: 2200, Train Loss: 1.5038, Train Accuracy: 53.1892%\n",
      "Epoch: 2210, Train Loss: 1.5034, Train Accuracy: 53.1892%\n",
      "Epoch: 2220, Train Loss: 1.5030, Train Accuracy: 53.2973%\n",
      "Epoch: 2230, Train Loss: 1.5026, Train Accuracy: 53.4054%\n",
      "Epoch: 2240, Train Loss: 1.5022, Train Accuracy: 53.4054%\n",
      "Epoch: 2250, Train Loss: 1.5018, Train Accuracy: 53.4054%\n",
      "Epoch: 2260, Train Loss: 1.5014, Train Accuracy: 53.4054%\n",
      "Epoch: 2270, Train Loss: 1.5010, Train Accuracy: 53.4054%\n",
      "Epoch: 2280, Train Loss: 1.5006, Train Accuracy: 53.4054%\n",
      "Epoch: 2290, Train Loss: 1.5002, Train Accuracy: 53.4054%\n",
      "Epoch: 2300, Train Loss: 1.4999, Train Accuracy: 53.4054%\n",
      "Epoch: 2310, Train Loss: 1.4995, Train Accuracy: 53.4054%\n",
      "Epoch: 2320, Train Loss: 1.4991, Train Accuracy: 53.4054%\n",
      "Epoch: 2330, Train Loss: 1.4987, Train Accuracy: 53.4054%\n",
      "Epoch: 2340, Train Loss: 1.4984, Train Accuracy: 53.4054%\n",
      "Epoch: 2350, Train Loss: 1.4980, Train Accuracy: 53.4054%\n",
      "Epoch: 2360, Train Loss: 1.4976, Train Accuracy: 53.4054%\n",
      "Epoch: 2370, Train Loss: 1.4973, Train Accuracy: 53.4054%\n",
      "Epoch: 2380, Train Loss: 1.4969, Train Accuracy: 53.4054%\n",
      "Epoch: 2390, Train Loss: 1.4966, Train Accuracy: 53.4054%\n",
      "Epoch: 2400, Train Loss: 1.4962, Train Accuracy: 53.4054%\n",
      "Epoch: 2410, Train Loss: 1.4958, Train Accuracy: 53.2973%\n",
      "Epoch: 2420, Train Loss: 1.4955, Train Accuracy: 53.2973%\n",
      "Epoch: 2430, Train Loss: 1.4952, Train Accuracy: 53.2973%\n",
      "Epoch: 2440, Train Loss: 1.4948, Train Accuracy: 53.2973%\n",
      "Epoch: 2450, Train Loss: 1.4945, Train Accuracy: 53.2973%\n",
      "Epoch: 2460, Train Loss: 1.4941, Train Accuracy: 53.2973%\n",
      "Epoch: 2470, Train Loss: 1.4938, Train Accuracy: 53.2973%\n",
      "Epoch: 2480, Train Loss: 1.4935, Train Accuracy: 53.2973%\n",
      "Epoch: 2490, Train Loss: 1.4931, Train Accuracy: 53.2973%\n",
      "Epoch: 2500, Train Loss: 1.4928, Train Accuracy: 53.2973%\n",
      "Epoch: 2510, Train Loss: 1.4925, Train Accuracy: 53.2973%\n",
      "Epoch: 2520, Train Loss: 1.4921, Train Accuracy: 53.2973%\n",
      "Epoch: 2530, Train Loss: 1.4918, Train Accuracy: 53.2973%\n",
      "Epoch: 2540, Train Loss: 1.4915, Train Accuracy: 53.2973%\n",
      "Epoch: 2550, Train Loss: 1.4912, Train Accuracy: 53.4054%\n",
      "Epoch: 2560, Train Loss: 1.4909, Train Accuracy: 53.4054%\n",
      "Epoch: 2570, Train Loss: 1.4905, Train Accuracy: 53.4054%\n",
      "Epoch: 2580, Train Loss: 1.4902, Train Accuracy: 53.5135%\n",
      "Epoch: 2590, Train Loss: 1.4899, Train Accuracy: 53.6216%\n",
      "Epoch: 2600, Train Loss: 1.4896, Train Accuracy: 53.5135%\n",
      "Epoch: 2610, Train Loss: 1.4893, Train Accuracy: 53.5135%\n",
      "Epoch: 2620, Train Loss: 1.4890, Train Accuracy: 53.5135%\n",
      "Epoch: 2630, Train Loss: 1.4887, Train Accuracy: 53.5135%\n",
      "Epoch: 2640, Train Loss: 1.4884, Train Accuracy: 53.5135%\n",
      "Epoch: 2650, Train Loss: 1.4881, Train Accuracy: 53.5135%\n",
      "Epoch: 2660, Train Loss: 1.4878, Train Accuracy: 53.5135%\n",
      "Epoch: 2670, Train Loss: 1.4875, Train Accuracy: 53.5135%\n",
      "Epoch: 2680, Train Loss: 1.4872, Train Accuracy: 53.5135%\n",
      "Epoch: 2690, Train Loss: 1.4869, Train Accuracy: 53.5135%\n",
      "Epoch: 2700, Train Loss: 1.4866, Train Accuracy: 53.5135%\n",
      "Epoch: 2710, Train Loss: 1.4863, Train Accuracy: 53.5135%\n",
      "Epoch: 2720, Train Loss: 1.4861, Train Accuracy: 53.6216%\n",
      "Epoch: 2730, Train Loss: 1.4858, Train Accuracy: 53.5135%\n",
      "Epoch: 2740, Train Loss: 1.4855, Train Accuracy: 53.5135%\n",
      "Epoch: 2750, Train Loss: 1.4852, Train Accuracy: 53.5135%\n",
      "Epoch: 2760, Train Loss: 1.4849, Train Accuracy: 53.6216%\n",
      "Epoch: 2770, Train Loss: 1.4847, Train Accuracy: 53.6216%\n",
      "Epoch: 2780, Train Loss: 1.4844, Train Accuracy: 53.5135%\n",
      "Epoch: 2790, Train Loss: 1.4841, Train Accuracy: 53.6216%\n",
      "Epoch: 2800, Train Loss: 1.4838, Train Accuracy: 53.6216%\n",
      "Epoch: 2810, Train Loss: 1.4836, Train Accuracy: 53.6216%\n",
      "Epoch: 2820, Train Loss: 1.4833, Train Accuracy: 53.6216%\n",
      "Epoch: 2830, Train Loss: 1.4830, Train Accuracy: 53.6216%\n",
      "Epoch: 2840, Train Loss: 1.4828, Train Accuracy: 53.6216%\n",
      "Epoch: 2850, Train Loss: 1.4825, Train Accuracy: 53.5135%\n",
      "Epoch: 2860, Train Loss: 1.4823, Train Accuracy: 53.5135%\n",
      "Epoch: 2870, Train Loss: 1.4820, Train Accuracy: 53.5135%\n",
      "Epoch: 2880, Train Loss: 1.4817, Train Accuracy: 53.5135%\n",
      "Epoch: 2890, Train Loss: 1.4815, Train Accuracy: 53.5135%\n",
      "Epoch: 2900, Train Loss: 1.4812, Train Accuracy: 53.5135%\n",
      "Epoch: 2910, Train Loss: 1.4810, Train Accuracy: 53.5135%\n",
      "Epoch: 2920, Train Loss: 1.4807, Train Accuracy: 53.5135%\n",
      "Epoch: 2930, Train Loss: 1.4805, Train Accuracy: 53.5135%\n",
      "Epoch: 2940, Train Loss: 1.4802, Train Accuracy: 53.5135%\n",
      "Epoch: 2950, Train Loss: 1.4800, Train Accuracy: 53.5135%\n",
      "Epoch: 2960, Train Loss: 1.4797, Train Accuracy: 53.5135%\n",
      "Epoch: 2970, Train Loss: 1.4795, Train Accuracy: 53.5135%\n",
      "Epoch: 2980, Train Loss: 1.4792, Train Accuracy: 53.5135%\n",
      "Epoch: 2990, Train Loss: 1.4790, Train Accuracy: 53.5135%\n",
      "Epoch: 3000, Train Loss: 1.4788, Train Accuracy: 53.5135%\n",
      "Epoch: 3010, Train Loss: 1.4785, Train Accuracy: 53.5135%\n",
      "Epoch: 3020, Train Loss: 1.4783, Train Accuracy: 53.5135%\n",
      "Epoch: 3030, Train Loss: 1.4781, Train Accuracy: 53.5135%\n",
      "Epoch: 3040, Train Loss: 1.4778, Train Accuracy: 53.6216%\n",
      "Epoch: 3050, Train Loss: 1.4776, Train Accuracy: 53.6216%\n",
      "Epoch: 3060, Train Loss: 1.4774, Train Accuracy: 53.6216%\n",
      "Epoch: 3070, Train Loss: 1.4771, Train Accuracy: 53.6216%\n",
      "Epoch: 3080, Train Loss: 1.4769, Train Accuracy: 53.6216%\n",
      "Epoch: 3090, Train Loss: 1.4767, Train Accuracy: 53.6216%\n",
      "Epoch: 3100, Train Loss: 1.4765, Train Accuracy: 53.6216%\n",
      "Epoch: 3110, Train Loss: 1.4762, Train Accuracy: 53.6216%\n",
      "Epoch: 3120, Train Loss: 1.4760, Train Accuracy: 53.6216%\n",
      "Epoch: 3130, Train Loss: 1.4758, Train Accuracy: 53.6216%\n",
      "Epoch: 3140, Train Loss: 1.4756, Train Accuracy: 53.6216%\n",
      "Epoch: 3150, Train Loss: 1.4753, Train Accuracy: 53.6216%\n",
      "Epoch: 3160, Train Loss: 1.4751, Train Accuracy: 53.6216%\n",
      "Epoch: 3170, Train Loss: 1.4749, Train Accuracy: 53.7297%\n",
      "Epoch: 3180, Train Loss: 1.4747, Train Accuracy: 53.6216%\n",
      "Epoch: 3190, Train Loss: 1.4745, Train Accuracy: 53.6216%\n",
      "Epoch: 3200, Train Loss: 1.4743, Train Accuracy: 53.6216%\n",
      "Epoch: 3210, Train Loss: 1.4741, Train Accuracy: 53.6216%\n",
      "Epoch: 3220, Train Loss: 1.4739, Train Accuracy: 53.6216%\n",
      "Epoch: 3230, Train Loss: 1.4736, Train Accuracy: 53.6216%\n",
      "Epoch: 3240, Train Loss: 1.4734, Train Accuracy: 53.6216%\n",
      "Epoch: 3250, Train Loss: 1.4732, Train Accuracy: 53.6216%\n",
      "Epoch: 3260, Train Loss: 1.4730, Train Accuracy: 53.5135%\n",
      "Epoch: 3270, Train Loss: 1.4728, Train Accuracy: 53.6216%\n",
      "Epoch: 3280, Train Loss: 1.4726, Train Accuracy: 53.7297%\n",
      "Epoch: 3290, Train Loss: 1.4724, Train Accuracy: 53.7297%\n",
      "Epoch: 3300, Train Loss: 1.4722, Train Accuracy: 53.7297%\n",
      "Epoch: 3310, Train Loss: 1.4720, Train Accuracy: 53.7297%\n",
      "Epoch: 3320, Train Loss: 1.4718, Train Accuracy: 53.7297%\n",
      "Epoch: 3330, Train Loss: 1.4716, Train Accuracy: 53.7297%\n",
      "Epoch: 3340, Train Loss: 1.4714, Train Accuracy: 53.7297%\n",
      "Epoch: 3350, Train Loss: 1.4712, Train Accuracy: 53.7297%\n",
      "Epoch: 3360, Train Loss: 1.4710, Train Accuracy: 53.7297%\n",
      "Epoch: 3370, Train Loss: 1.4708, Train Accuracy: 53.7297%\n",
      "Epoch: 3380, Train Loss: 1.4707, Train Accuracy: 53.7297%\n",
      "Epoch: 3390, Train Loss: 1.4705, Train Accuracy: 53.7297%\n",
      "Epoch: 3400, Train Loss: 1.4703, Train Accuracy: 53.7297%\n",
      "Epoch: 3410, Train Loss: 1.4701, Train Accuracy: 53.8378%\n",
      "Epoch: 3420, Train Loss: 1.4699, Train Accuracy: 53.8378%\n",
      "Epoch: 3430, Train Loss: 1.4697, Train Accuracy: 53.9459%\n",
      "Epoch: 3440, Train Loss: 1.4695, Train Accuracy: 53.9459%\n",
      "Epoch: 3450, Train Loss: 1.4693, Train Accuracy: 53.9459%\n",
      "Epoch: 3460, Train Loss: 1.4692, Train Accuracy: 53.9459%\n",
      "Epoch: 3470, Train Loss: 1.4690, Train Accuracy: 53.9459%\n",
      "Epoch: 3480, Train Loss: 1.4688, Train Accuracy: 53.9459%\n",
      "Epoch: 3490, Train Loss: 1.4686, Train Accuracy: 53.9459%\n",
      "Epoch: 3500, Train Loss: 1.4684, Train Accuracy: 53.9459%\n",
      "Epoch: 3510, Train Loss: 1.4683, Train Accuracy: 53.9459%\n",
      "Epoch: 3520, Train Loss: 1.4681, Train Accuracy: 53.9459%\n",
      "Epoch: 3530, Train Loss: 1.4679, Train Accuracy: 53.9459%\n",
      "Epoch: 3540, Train Loss: 1.4677, Train Accuracy: 53.9459%\n",
      "Epoch: 3550, Train Loss: 1.4676, Train Accuracy: 53.9459%\n",
      "Epoch: 3560, Train Loss: 1.4674, Train Accuracy: 53.9459%\n",
      "Epoch: 3570, Train Loss: 1.4672, Train Accuracy: 53.9459%\n",
      "Epoch: 3580, Train Loss: 1.4670, Train Accuracy: 53.9459%\n",
      "Epoch: 3590, Train Loss: 1.4669, Train Accuracy: 53.9459%\n",
      "Epoch: 3600, Train Loss: 1.4667, Train Accuracy: 53.9459%\n",
      "Epoch: 3610, Train Loss: 1.4665, Train Accuracy: 53.9459%\n",
      "Epoch: 3620, Train Loss: 1.4664, Train Accuracy: 53.9459%\n",
      "Epoch: 3630, Train Loss: 1.4662, Train Accuracy: 53.9459%\n",
      "Epoch: 3640, Train Loss: 1.4660, Train Accuracy: 53.8378%\n",
      "Epoch: 3650, Train Loss: 1.4659, Train Accuracy: 53.8378%\n",
      "Epoch: 3660, Train Loss: 1.4657, Train Accuracy: 53.9459%\n",
      "Epoch: 3670, Train Loss: 1.4655, Train Accuracy: 53.8378%\n",
      "Epoch: 3680, Train Loss: 1.4654, Train Accuracy: 53.8378%\n",
      "Epoch: 3690, Train Loss: 1.4652, Train Accuracy: 53.8378%\n",
      "Epoch: 3700, Train Loss: 1.4650, Train Accuracy: 53.8378%\n",
      "Epoch: 3710, Train Loss: 1.4649, Train Accuracy: 53.8378%\n",
      "Epoch: 3720, Train Loss: 1.4647, Train Accuracy: 53.8378%\n",
      "Epoch: 3730, Train Loss: 1.4646, Train Accuracy: 53.8378%\n",
      "Epoch: 3740, Train Loss: 1.4644, Train Accuracy: 53.7297%\n",
      "Epoch: 3750, Train Loss: 1.4643, Train Accuracy: 53.7297%\n",
      "Epoch: 3760, Train Loss: 1.4641, Train Accuracy: 53.7297%\n",
      "Epoch: 3770, Train Loss: 1.4639, Train Accuracy: 53.7297%\n",
      "Epoch: 3780, Train Loss: 1.4638, Train Accuracy: 53.7297%\n",
      "Epoch: 3790, Train Loss: 1.4636, Train Accuracy: 53.7297%\n",
      "Epoch: 3800, Train Loss: 1.4635, Train Accuracy: 53.7297%\n",
      "Epoch: 3810, Train Loss: 1.4633, Train Accuracy: 53.7297%\n",
      "Epoch: 3820, Train Loss: 1.4632, Train Accuracy: 53.7297%\n",
      "Epoch: 3830, Train Loss: 1.4630, Train Accuracy: 53.7297%\n",
      "Epoch: 3840, Train Loss: 1.4629, Train Accuracy: 53.7297%\n",
      "Epoch: 3850, Train Loss: 1.4627, Train Accuracy: 53.7297%\n",
      "Epoch: 3860, Train Loss: 1.4626, Train Accuracy: 53.7297%\n",
      "Epoch: 3870, Train Loss: 1.4624, Train Accuracy: 53.7297%\n",
      "Epoch: 3880, Train Loss: 1.4623, Train Accuracy: 53.7297%\n",
      "Epoch: 3890, Train Loss: 1.4621, Train Accuracy: 53.7297%\n",
      "Epoch: 3900, Train Loss: 1.4620, Train Accuracy: 53.7297%\n",
      "Epoch: 3910, Train Loss: 1.4618, Train Accuracy: 53.7297%\n",
      "Epoch: 3920, Train Loss: 1.4617, Train Accuracy: 53.8378%\n",
      "Epoch: 3930, Train Loss: 1.4616, Train Accuracy: 53.8378%\n",
      "Epoch: 3940, Train Loss: 1.4614, Train Accuracy: 53.8378%\n",
      "Epoch: 3950, Train Loss: 1.4613, Train Accuracy: 53.8378%\n",
      "Epoch: 3960, Train Loss: 1.4611, Train Accuracy: 53.8378%\n",
      "Epoch: 3970, Train Loss: 1.4610, Train Accuracy: 53.9459%\n",
      "Epoch: 3980, Train Loss: 1.4609, Train Accuracy: 53.9459%\n",
      "Epoch: 3990, Train Loss: 1.4607, Train Accuracy: 53.9459%\n",
      "Epoch: 4000, Train Loss: 1.4606, Train Accuracy: 53.9459%\n",
      "Epoch: 4010, Train Loss: 1.4604, Train Accuracy: 53.9459%\n",
      "Epoch: 4020, Train Loss: 1.4603, Train Accuracy: 53.9459%\n",
      "Epoch: 4030, Train Loss: 1.4602, Train Accuracy: 53.9459%\n",
      "Epoch: 4040, Train Loss: 1.4600, Train Accuracy: 53.9459%\n",
      "Epoch: 4050, Train Loss: 1.4599, Train Accuracy: 53.9459%\n",
      "Epoch: 4060, Train Loss: 1.4598, Train Accuracy: 53.9459%\n",
      "Epoch: 4070, Train Loss: 1.4596, Train Accuracy: 53.9459%\n",
      "Epoch: 4080, Train Loss: 1.4595, Train Accuracy: 53.9459%\n",
      "Epoch: 4090, Train Loss: 1.4594, Train Accuracy: 53.9459%\n",
      "Epoch: 4100, Train Loss: 1.4592, Train Accuracy: 53.9459%\n",
      "Epoch: 4110, Train Loss: 1.4591, Train Accuracy: 53.9459%\n",
      "Epoch: 4120, Train Loss: 1.4590, Train Accuracy: 53.9459%\n",
      "Epoch: 4130, Train Loss: 1.4588, Train Accuracy: 53.9459%\n",
      "Epoch: 4140, Train Loss: 1.4587, Train Accuracy: 54.0541%\n",
      "Epoch: 4150, Train Loss: 1.4586, Train Accuracy: 54.0541%\n",
      "Epoch: 4160, Train Loss: 1.4584, Train Accuracy: 54.0541%\n",
      "Epoch: 4170, Train Loss: 1.4583, Train Accuracy: 54.0541%\n",
      "Epoch: 4180, Train Loss: 1.4582, Train Accuracy: 54.0541%\n",
      "Epoch: 4190, Train Loss: 1.4581, Train Accuracy: 54.0541%\n",
      "Epoch: 4200, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 4210, Train Loss: 1.4578, Train Accuracy: 54.0541%\n",
      "Epoch: 4220, Train Loss: 1.4577, Train Accuracy: 54.0541%\n",
      "Epoch: 4230, Train Loss: 1.4576, Train Accuracy: 54.1622%\n",
      "Epoch: 4240, Train Loss: 1.4574, Train Accuracy: 54.1622%\n",
      "Epoch: 4250, Train Loss: 1.4573, Train Accuracy: 54.1622%\n",
      "Epoch: 4260, Train Loss: 1.4572, Train Accuracy: 54.1622%\n",
      "Epoch: 4270, Train Loss: 1.4571, Train Accuracy: 54.1622%\n",
      "Epoch: 4280, Train Loss: 1.4570, Train Accuracy: 54.1622%\n",
      "Epoch: 4290, Train Loss: 1.4568, Train Accuracy: 54.1622%\n",
      "Epoch: 4300, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 4310, Train Loss: 1.4566, Train Accuracy: 54.1622%\n",
      "Epoch: 4320, Train Loss: 1.4565, Train Accuracy: 54.1622%\n",
      "Epoch: 4330, Train Loss: 1.4564, Train Accuracy: 54.1622%\n",
      "Epoch: 4340, Train Loss: 1.4562, Train Accuracy: 54.1622%\n",
      "Epoch: 4350, Train Loss: 1.4561, Train Accuracy: 54.1622%\n",
      "Epoch: 4360, Train Loss: 1.4560, Train Accuracy: 54.1622%\n",
      "Epoch: 4370, Train Loss: 1.4559, Train Accuracy: 54.1622%\n",
      "Epoch: 4380, Train Loss: 1.4558, Train Accuracy: 54.1622%\n",
      "Epoch: 4390, Train Loss: 1.4557, Train Accuracy: 54.1622%\n",
      "Epoch: 4400, Train Loss: 1.4555, Train Accuracy: 54.1622%\n",
      "Epoch: 4410, Train Loss: 1.4554, Train Accuracy: 54.1622%\n",
      "Epoch: 4420, Train Loss: 1.4553, Train Accuracy: 54.1622%\n",
      "Epoch: 4430, Train Loss: 1.4552, Train Accuracy: 54.1622%\n",
      "Epoch: 4440, Train Loss: 1.4551, Train Accuracy: 54.1622%\n",
      "Epoch: 4450, Train Loss: 1.4550, Train Accuracy: 54.1622%\n",
      "Epoch: 4460, Train Loss: 1.4549, Train Accuracy: 54.1622%\n",
      "Epoch: 4470, Train Loss: 1.4548, Train Accuracy: 54.2703%\n",
      "Epoch: 4480, Train Loss: 1.4546, Train Accuracy: 54.2703%\n",
      "Epoch: 4490, Train Loss: 1.4545, Train Accuracy: 54.3784%\n",
      "Epoch: 4500, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 4510, Train Loss: 1.4543, Train Accuracy: 54.3784%\n",
      "Epoch: 4520, Train Loss: 1.4542, Train Accuracy: 54.3784%\n",
      "Epoch: 4530, Train Loss: 1.4541, Train Accuracy: 54.3784%\n",
      "Epoch: 4540, Train Loss: 1.4540, Train Accuracy: 54.4865%\n",
      "Epoch: 4550, Train Loss: 1.4539, Train Accuracy: 54.5946%\n",
      "Epoch: 4560, Train Loss: 1.4538, Train Accuracy: 54.5946%\n",
      "Epoch: 4570, Train Loss: 1.4537, Train Accuracy: 54.5946%\n",
      "Epoch: 4580, Train Loss: 1.4536, Train Accuracy: 54.7027%\n",
      "Epoch: 4590, Train Loss: 1.4535, Train Accuracy: 54.7027%\n",
      "Epoch: 4600, Train Loss: 1.4534, Train Accuracy: 54.7027%\n",
      "Epoch: 4610, Train Loss: 1.4532, Train Accuracy: 54.7027%\n",
      "Epoch: 4620, Train Loss: 1.4531, Train Accuracy: 54.7027%\n",
      "Epoch: 4630, Train Loss: 1.4530, Train Accuracy: 54.7027%\n",
      "Epoch: 4640, Train Loss: 1.4529, Train Accuracy: 54.7027%\n",
      "Epoch: 4650, Train Loss: 1.4528, Train Accuracy: 54.7027%\n",
      "Epoch: 4660, Train Loss: 1.4527, Train Accuracy: 54.7027%\n",
      "Epoch: 4670, Train Loss: 1.4526, Train Accuracy: 54.7027%\n",
      "Epoch: 4680, Train Loss: 1.4525, Train Accuracy: 54.7027%\n",
      "Epoch: 4690, Train Loss: 1.4524, Train Accuracy: 54.7027%\n",
      "Epoch: 4700, Train Loss: 1.4523, Train Accuracy: 54.7027%\n",
      "Epoch: 4710, Train Loss: 1.4522, Train Accuracy: 54.7027%\n",
      "Epoch: 4720, Train Loss: 1.4521, Train Accuracy: 54.7027%\n",
      "Epoch: 4730, Train Loss: 1.4520, Train Accuracy: 54.7027%\n",
      "Epoch: 4740, Train Loss: 1.4519, Train Accuracy: 54.7027%\n",
      "Epoch: 4750, Train Loss: 1.4518, Train Accuracy: 54.5946%\n",
      "Epoch: 4760, Train Loss: 1.4517, Train Accuracy: 54.5946%\n",
      "Epoch: 4770, Train Loss: 1.4516, Train Accuracy: 54.5946%\n",
      "Epoch: 4780, Train Loss: 1.4515, Train Accuracy: 54.5946%\n",
      "Epoch: 4790, Train Loss: 1.4514, Train Accuracy: 54.5946%\n",
      "Epoch: 4800, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 4810, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 4820, Train Loss: 1.4512, Train Accuracy: 54.5946%\n",
      "Epoch: 4830, Train Loss: 1.4511, Train Accuracy: 54.5946%\n",
      "Epoch: 4840, Train Loss: 1.4510, Train Accuracy: 54.5946%\n",
      "Epoch: 4850, Train Loss: 1.4509, Train Accuracy: 54.5946%\n",
      "Epoch: 4860, Train Loss: 1.4508, Train Accuracy: 54.5946%\n",
      "Epoch: 4870, Train Loss: 1.4507, Train Accuracy: 54.5946%\n",
      "Epoch: 4880, Train Loss: 1.4506, Train Accuracy: 54.5946%\n",
      "Epoch: 4890, Train Loss: 1.4505, Train Accuracy: 54.5946%\n",
      "Epoch: 4900, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 4910, Train Loss: 1.4503, Train Accuracy: 54.5946%\n",
      "Epoch: 4920, Train Loss: 1.4502, Train Accuracy: 54.5946%\n",
      "Epoch: 4930, Train Loss: 1.4501, Train Accuracy: 54.4865%\n",
      "Epoch: 4940, Train Loss: 1.4500, Train Accuracy: 54.3784%\n",
      "Epoch: 4950, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 4960, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 4970, Train Loss: 1.4498, Train Accuracy: 54.3784%\n",
      "Epoch: 4980, Train Loss: 1.4497, Train Accuracy: 54.3784%\n",
      "Epoch: 4990, Train Loss: 1.4496, Train Accuracy: 54.3784%\n",
      "Epoch: 5000, Train Loss: 1.4495, Train Accuracy: 54.3784%\n",
      "Epoch: 5010, Train Loss: 1.4494, Train Accuracy: 54.3784%\n",
      "Epoch: 5020, Train Loss: 1.4493, Train Accuracy: 54.2703%\n",
      "Epoch: 5030, Train Loss: 1.4492, Train Accuracy: 54.2703%\n",
      "Epoch: 5040, Train Loss: 1.4491, Train Accuracy: 54.2703%\n",
      "Epoch: 5050, Train Loss: 1.4491, Train Accuracy: 54.2703%\n",
      "Epoch: 5060, Train Loss: 1.4490, Train Accuracy: 54.2703%\n",
      "Epoch: 5070, Train Loss: 1.4489, Train Accuracy: 54.2703%\n",
      "Epoch: 5080, Train Loss: 1.4488, Train Accuracy: 54.2703%\n",
      "Epoch: 5090, Train Loss: 1.4487, Train Accuracy: 54.3784%\n",
      "Epoch: 5100, Train Loss: 1.4486, Train Accuracy: 54.3784%\n",
      "Epoch: 5110, Train Loss: 1.4485, Train Accuracy: 54.3784%\n",
      "Epoch: 5120, Train Loss: 1.4485, Train Accuracy: 54.3784%\n",
      "Epoch: 5130, Train Loss: 1.4484, Train Accuracy: 54.3784%\n",
      "Epoch: 5140, Train Loss: 1.4483, Train Accuracy: 54.3784%\n",
      "Epoch: 5150, Train Loss: 1.4482, Train Accuracy: 54.3784%\n",
      "Epoch: 5160, Train Loss: 1.4481, Train Accuracy: 54.3784%\n",
      "Epoch: 5170, Train Loss: 1.4480, Train Accuracy: 54.3784%\n",
      "Epoch: 5180, Train Loss: 1.4480, Train Accuracy: 54.3784%\n",
      "Epoch: 5190, Train Loss: 1.4479, Train Accuracy: 54.3784%\n",
      "Epoch: 5200, Train Loss: 1.4478, Train Accuracy: 54.3784%\n",
      "Epoch: 5210, Train Loss: 1.4477, Train Accuracy: 54.3784%\n",
      "Epoch: 5220, Train Loss: 1.4476, Train Accuracy: 54.3784%\n",
      "Epoch: 5230, Train Loss: 1.4476, Train Accuracy: 54.3784%\n",
      "Epoch: 5240, Train Loss: 1.4475, Train Accuracy: 54.3784%\n",
      "Epoch: 5250, Train Loss: 1.4474, Train Accuracy: 54.3784%\n",
      "Epoch: 5260, Train Loss: 1.4473, Train Accuracy: 54.3784%\n",
      "Epoch: 5270, Train Loss: 1.4472, Train Accuracy: 54.3784%\n",
      "Epoch: 5280, Train Loss: 1.4472, Train Accuracy: 54.3784%\n",
      "Epoch: 5290, Train Loss: 1.4471, Train Accuracy: 54.3784%\n",
      "Epoch: 5300, Train Loss: 1.4470, Train Accuracy: 54.3784%\n",
      "Epoch: 5310, Train Loss: 1.4469, Train Accuracy: 54.3784%\n",
      "Epoch: 5320, Train Loss: 1.4468, Train Accuracy: 54.3784%\n",
      "Epoch: 5330, Train Loss: 1.4468, Train Accuracy: 54.3784%\n",
      "Epoch: 5340, Train Loss: 1.4467, Train Accuracy: 54.3784%\n",
      "Epoch: 5350, Train Loss: 1.4466, Train Accuracy: 54.3784%\n",
      "Epoch: 5360, Train Loss: 1.4465, Train Accuracy: 54.3784%\n",
      "Epoch: 5370, Train Loss: 1.4464, Train Accuracy: 54.3784%\n",
      "Epoch: 5380, Train Loss: 1.4464, Train Accuracy: 54.3784%\n",
      "Epoch: 5390, Train Loss: 1.4463, Train Accuracy: 54.4865%\n",
      "Epoch: 5400, Train Loss: 1.4462, Train Accuracy: 54.4865%\n",
      "Epoch: 5410, Train Loss: 1.4461, Train Accuracy: 54.4865%\n",
      "Epoch: 5420, Train Loss: 1.4461, Train Accuracy: 54.4865%\n",
      "Epoch: 5430, Train Loss: 1.4460, Train Accuracy: 54.4865%\n",
      "Epoch: 5440, Train Loss: 1.4459, Train Accuracy: 54.4865%\n",
      "Epoch: 5450, Train Loss: 1.4458, Train Accuracy: 54.4865%\n",
      "Epoch: 5460, Train Loss: 1.4458, Train Accuracy: 54.4865%\n",
      "Epoch: 5470, Train Loss: 1.4457, Train Accuracy: 54.4865%\n",
      "Epoch: 5480, Train Loss: 1.4456, Train Accuracy: 54.4865%\n",
      "Epoch: 5490, Train Loss: 1.4455, Train Accuracy: 54.4865%\n",
      "Epoch: 5500, Train Loss: 1.4455, Train Accuracy: 54.4865%\n",
      "Epoch: 5510, Train Loss: 1.4454, Train Accuracy: 54.4865%\n",
      "Epoch: 5520, Train Loss: 1.4453, Train Accuracy: 54.4865%\n",
      "Epoch: 5530, Train Loss: 1.4453, Train Accuracy: 54.4865%\n",
      "Epoch: 5540, Train Loss: 1.4452, Train Accuracy: 54.4865%\n",
      "Epoch: 5550, Train Loss: 1.4451, Train Accuracy: 54.4865%\n",
      "Epoch: 5560, Train Loss: 1.4450, Train Accuracy: 54.4865%\n",
      "Epoch: 5570, Train Loss: 1.4450, Train Accuracy: 54.4865%\n",
      "Epoch: 5580, Train Loss: 1.4449, Train Accuracy: 54.4865%\n",
      "Epoch: 5590, Train Loss: 1.4448, Train Accuracy: 54.4865%\n",
      "Epoch: 5600, Train Loss: 1.4448, Train Accuracy: 54.4865%\n",
      "Epoch: 5610, Train Loss: 1.4447, Train Accuracy: 54.4865%\n",
      "Epoch: 5620, Train Loss: 1.4446, Train Accuracy: 54.4865%\n",
      "Epoch: 5630, Train Loss: 1.4445, Train Accuracy: 54.4865%\n",
      "Epoch: 5640, Train Loss: 1.4445, Train Accuracy: 54.4865%\n",
      "Epoch: 5650, Train Loss: 1.4444, Train Accuracy: 54.4865%\n",
      "Epoch: 5660, Train Loss: 1.4443, Train Accuracy: 54.4865%\n",
      "Epoch: 5670, Train Loss: 1.4443, Train Accuracy: 54.4865%\n",
      "Epoch: 5680, Train Loss: 1.4442, Train Accuracy: 54.5946%\n",
      "Epoch: 5690, Train Loss: 1.4441, Train Accuracy: 54.5946%\n",
      "Epoch: 5700, Train Loss: 1.4441, Train Accuracy: 54.5946%\n",
      "Epoch: 5710, Train Loss: 1.4440, Train Accuracy: 54.5946%\n",
      "Epoch: 5720, Train Loss: 1.4439, Train Accuracy: 54.5946%\n",
      "Epoch: 5730, Train Loss: 1.4439, Train Accuracy: 54.5946%\n",
      "Epoch: 5740, Train Loss: 1.4438, Train Accuracy: 54.5946%\n",
      "Epoch: 5750, Train Loss: 1.4437, Train Accuracy: 54.5946%\n",
      "Epoch: 5760, Train Loss: 1.4437, Train Accuracy: 54.5946%\n",
      "Epoch: 5770, Train Loss: 1.4436, Train Accuracy: 54.7027%\n",
      "Epoch: 5780, Train Loss: 1.4435, Train Accuracy: 54.7027%\n",
      "Epoch: 5790, Train Loss: 1.4435, Train Accuracy: 54.7027%\n",
      "Epoch: 5800, Train Loss: 1.4434, Train Accuracy: 54.7027%\n",
      "Epoch: 5810, Train Loss: 1.4433, Train Accuracy: 54.7027%\n",
      "Epoch: 5820, Train Loss: 1.4433, Train Accuracy: 54.7027%\n",
      "Epoch: 5830, Train Loss: 1.4432, Train Accuracy: 54.8108%\n",
      "Epoch: 5840, Train Loss: 1.4431, Train Accuracy: 54.9189%\n",
      "Epoch: 5850, Train Loss: 1.4431, Train Accuracy: 54.9189%\n",
      "Epoch: 5860, Train Loss: 1.4430, Train Accuracy: 54.9189%\n",
      "Epoch: 5870, Train Loss: 1.4429, Train Accuracy: 54.9189%\n",
      "Epoch: 5880, Train Loss: 1.4429, Train Accuracy: 54.9189%\n",
      "Epoch: 5890, Train Loss: 1.4428, Train Accuracy: 54.9189%\n",
      "Epoch: 5900, Train Loss: 1.4428, Train Accuracy: 54.9189%\n",
      "Epoch: 5910, Train Loss: 1.4427, Train Accuracy: 54.9189%\n",
      "Epoch: 5920, Train Loss: 1.4426, Train Accuracy: 54.9189%\n",
      "Epoch: 5930, Train Loss: 1.4426, Train Accuracy: 54.8108%\n",
      "Epoch: 5940, Train Loss: 1.4425, Train Accuracy: 54.8108%\n",
      "Epoch: 5950, Train Loss: 1.4424, Train Accuracy: 54.8108%\n",
      "Epoch: 5960, Train Loss: 1.4424, Train Accuracy: 54.8108%\n",
      "Epoch: 5970, Train Loss: 1.4423, Train Accuracy: 54.8108%\n",
      "Epoch: 5980, Train Loss: 1.4423, Train Accuracy: 54.8108%\n",
      "Epoch: 5990, Train Loss: 1.4422, Train Accuracy: 54.8108%\n",
      "Epoch: 6000, Train Loss: 1.4421, Train Accuracy: 54.9189%\n",
      "Epoch: 6010, Train Loss: 1.4421, Train Accuracy: 55.0270%\n",
      "Epoch: 6020, Train Loss: 1.4420, Train Accuracy: 55.1351%\n",
      "Epoch: 6030, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 6040, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 6050, Train Loss: 1.4418, Train Accuracy: 55.1351%\n",
      "Epoch: 6060, Train Loss: 1.4418, Train Accuracy: 55.1351%\n",
      "Epoch: 6070, Train Loss: 1.4417, Train Accuracy: 55.1351%\n",
      "Epoch: 6080, Train Loss: 1.4416, Train Accuracy: 55.1351%\n",
      "Epoch: 6090, Train Loss: 1.4416, Train Accuracy: 55.1351%\n",
      "Epoch: 6100, Train Loss: 1.4415, Train Accuracy: 55.1351%\n",
      "Epoch: 6110, Train Loss: 1.4415, Train Accuracy: 55.1351%\n",
      "Epoch: 6120, Train Loss: 1.4414, Train Accuracy: 55.0270%\n",
      "Epoch: 6130, Train Loss: 1.4413, Train Accuracy: 54.9189%\n",
      "Epoch: 6140, Train Loss: 1.4413, Train Accuracy: 54.9189%\n",
      "Epoch: 6150, Train Loss: 1.4412, Train Accuracy: 54.9189%\n",
      "Epoch: 6160, Train Loss: 1.4412, Train Accuracy: 54.9189%\n",
      "Epoch: 6170, Train Loss: 1.4411, Train Accuracy: 54.9189%\n",
      "Epoch: 6180, Train Loss: 1.4411, Train Accuracy: 54.9189%\n",
      "Epoch: 6190, Train Loss: 1.4410, Train Accuracy: 54.9189%\n",
      "Epoch: 6200, Train Loss: 1.4409, Train Accuracy: 54.9189%\n",
      "Epoch: 6210, Train Loss: 1.4409, Train Accuracy: 54.9189%\n",
      "Epoch: 6220, Train Loss: 1.4408, Train Accuracy: 54.9189%\n",
      "Epoch: 6230, Train Loss: 1.4408, Train Accuracy: 54.9189%\n",
      "Epoch: 6240, Train Loss: 1.4407, Train Accuracy: 54.9189%\n",
      "Epoch: 6250, Train Loss: 1.4407, Train Accuracy: 54.9189%\n",
      "Epoch: 6260, Train Loss: 1.4406, Train Accuracy: 54.9189%\n",
      "Epoch: 6270, Train Loss: 1.4405, Train Accuracy: 54.9189%\n",
      "Epoch: 6280, Train Loss: 1.4405, Train Accuracy: 54.9189%\n",
      "Epoch: 6290, Train Loss: 1.4404, Train Accuracy: 54.9189%\n",
      "Epoch: 6300, Train Loss: 1.4404, Train Accuracy: 54.9189%\n",
      "Epoch: 6310, Train Loss: 1.4403, Train Accuracy: 54.9189%\n",
      "Epoch: 6320, Train Loss: 1.4403, Train Accuracy: 54.9189%\n",
      "Epoch: 6330, Train Loss: 1.4402, Train Accuracy: 54.9189%\n",
      "Epoch: 6340, Train Loss: 1.4402, Train Accuracy: 54.9189%\n",
      "Epoch: 6350, Train Loss: 1.4401, Train Accuracy: 54.9189%\n",
      "Epoch: 6360, Train Loss: 1.4400, Train Accuracy: 54.9189%\n",
      "Epoch: 6370, Train Loss: 1.4400, Train Accuracy: 54.9189%\n",
      "Epoch: 6380, Train Loss: 1.4399, Train Accuracy: 54.9189%\n",
      "Epoch: 6390, Train Loss: 1.4399, Train Accuracy: 54.9189%\n",
      "Epoch: 6400, Train Loss: 1.4398, Train Accuracy: 54.9189%\n",
      "Epoch: 6410, Train Loss: 1.4398, Train Accuracy: 54.9189%\n",
      "Epoch: 6420, Train Loss: 1.4397, Train Accuracy: 54.9189%\n",
      "Epoch: 6430, Train Loss: 1.4397, Train Accuracy: 54.9189%\n",
      "Epoch: 6440, Train Loss: 1.4396, Train Accuracy: 54.9189%\n",
      "Epoch: 6450, Train Loss: 1.4396, Train Accuracy: 54.9189%\n",
      "Epoch: 6460, Train Loss: 1.4395, Train Accuracy: 54.9189%\n",
      "Epoch: 6470, Train Loss: 1.4395, Train Accuracy: 55.0270%\n",
      "Epoch: 6480, Train Loss: 1.4394, Train Accuracy: 55.0270%\n",
      "Epoch: 6490, Train Loss: 1.4394, Train Accuracy: 55.0270%\n",
      "Epoch: 6500, Train Loss: 1.4393, Train Accuracy: 55.0270%\n",
      "Epoch: 6510, Train Loss: 1.4392, Train Accuracy: 55.0270%\n",
      "Epoch: 6520, Train Loss: 1.4392, Train Accuracy: 55.0270%\n",
      "Epoch: 6530, Train Loss: 1.4391, Train Accuracy: 55.0270%\n",
      "Epoch: 6540, Train Loss: 1.4391, Train Accuracy: 55.0270%\n",
      "Epoch: 6550, Train Loss: 1.4390, Train Accuracy: 55.0270%\n",
      "Epoch: 6560, Train Loss: 1.4390, Train Accuracy: 55.0270%\n",
      "Epoch: 6570, Train Loss: 1.4389, Train Accuracy: 55.0270%\n",
      "Epoch: 6580, Train Loss: 1.4389, Train Accuracy: 55.0270%\n",
      "Epoch: 6590, Train Loss: 1.4388, Train Accuracy: 55.0270%\n",
      "Epoch: 6600, Train Loss: 1.4388, Train Accuracy: 55.0270%\n",
      "Epoch: 6610, Train Loss: 1.4387, Train Accuracy: 55.0270%\n",
      "Epoch: 6620, Train Loss: 1.4387, Train Accuracy: 54.9189%\n",
      "Epoch: 6630, Train Loss: 1.4386, Train Accuracy: 54.9189%\n",
      "Epoch: 6640, Train Loss: 1.4386, Train Accuracy: 54.9189%\n",
      "Epoch: 6650, Train Loss: 1.4385, Train Accuracy: 54.9189%\n",
      "Epoch: 6660, Train Loss: 1.4385, Train Accuracy: 54.9189%\n",
      "Epoch: 6670, Train Loss: 1.4384, Train Accuracy: 54.9189%\n",
      "Epoch: 6680, Train Loss: 1.4384, Train Accuracy: 55.0270%\n",
      "Epoch: 6690, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 6700, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 6710, Train Loss: 1.4382, Train Accuracy: 55.1351%\n",
      "Epoch: 6720, Train Loss: 1.4382, Train Accuracy: 55.1351%\n",
      "Epoch: 6730, Train Loss: 1.4381, Train Accuracy: 55.1351%\n",
      "Epoch: 6740, Train Loss: 1.4381, Train Accuracy: 55.1351%\n",
      "Epoch: 6750, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 6760, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 6770, Train Loss: 1.4379, Train Accuracy: 55.1351%\n",
      "Epoch: 6780, Train Loss: 1.4379, Train Accuracy: 55.1351%\n",
      "Epoch: 6790, Train Loss: 1.4379, Train Accuracy: 55.1351%\n",
      "Epoch: 6800, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 6810, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 6820, Train Loss: 1.4377, Train Accuracy: 55.1351%\n",
      "Epoch: 6830, Train Loss: 1.4377, Train Accuracy: 55.1351%\n",
      "Epoch: 6840, Train Loss: 1.4376, Train Accuracy: 55.1351%\n",
      "Epoch: 6850, Train Loss: 1.4376, Train Accuracy: 55.1351%\n",
      "Epoch: 6860, Train Loss: 1.4375, Train Accuracy: 55.1351%\n",
      "Epoch: 6870, Train Loss: 1.4375, Train Accuracy: 55.1351%\n",
      "Epoch: 6880, Train Loss: 1.4374, Train Accuracy: 55.1351%\n",
      "Epoch: 6890, Train Loss: 1.4374, Train Accuracy: 55.1351%\n",
      "Epoch: 6900, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 6910, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 6920, Train Loss: 1.4372, Train Accuracy: 55.1351%\n",
      "Epoch: 6930, Train Loss: 1.4372, Train Accuracy: 55.1351%\n",
      "Epoch: 6940, Train Loss: 1.4371, Train Accuracy: 55.1351%\n",
      "Epoch: 6950, Train Loss: 1.4371, Train Accuracy: 55.2432%\n",
      "Epoch: 6960, Train Loss: 1.4371, Train Accuracy: 55.2432%\n",
      "Epoch: 6970, Train Loss: 1.4370, Train Accuracy: 55.2432%\n",
      "Epoch: 6980, Train Loss: 1.4370, Train Accuracy: 55.2432%\n",
      "Epoch: 6990, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 7000, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 7010, Train Loss: 1.4368, Train Accuracy: 55.2432%\n",
      "Epoch: 7020, Train Loss: 1.4368, Train Accuracy: 55.2432%\n",
      "Epoch: 7030, Train Loss: 1.4367, Train Accuracy: 55.1351%\n",
      "Epoch: 7040, Train Loss: 1.4367, Train Accuracy: 55.1351%\n",
      "Epoch: 7050, Train Loss: 1.4367, Train Accuracy: 55.1351%\n",
      "Epoch: 7060, Train Loss: 1.4366, Train Accuracy: 55.1351%\n",
      "Epoch: 7070, Train Loss: 1.4366, Train Accuracy: 55.1351%\n",
      "Epoch: 7080, Train Loss: 1.4365, Train Accuracy: 55.1351%\n",
      "Epoch: 7090, Train Loss: 1.4365, Train Accuracy: 55.1351%\n",
      "Epoch: 7100, Train Loss: 1.4364, Train Accuracy: 55.1351%\n",
      "Epoch: 7110, Train Loss: 1.4364, Train Accuracy: 55.1351%\n",
      "Epoch: 7120, Train Loss: 1.4363, Train Accuracy: 55.1351%\n",
      "Epoch: 7130, Train Loss: 1.4363, Train Accuracy: 55.1351%\n",
      "Epoch: 7140, Train Loss: 1.4363, Train Accuracy: 55.1351%\n",
      "Epoch: 7150, Train Loss: 1.4362, Train Accuracy: 55.1351%\n",
      "Epoch: 7160, Train Loss: 1.4362, Train Accuracy: 55.1351%\n",
      "Epoch: 7170, Train Loss: 1.4361, Train Accuracy: 55.1351%\n",
      "Epoch: 7180, Train Loss: 1.4361, Train Accuracy: 55.1351%\n",
      "Epoch: 7190, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 7200, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 7210, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 7220, Train Loss: 1.4359, Train Accuracy: 55.1351%\n",
      "Epoch: 7230, Train Loss: 1.4359, Train Accuracy: 55.1351%\n",
      "Epoch: 7240, Train Loss: 1.4358, Train Accuracy: 55.1351%\n",
      "Epoch: 7250, Train Loss: 1.4358, Train Accuracy: 55.1351%\n",
      "Epoch: 7260, Train Loss: 1.4358, Train Accuracy: 55.1351%\n",
      "Epoch: 7270, Train Loss: 1.4357, Train Accuracy: 55.1351%\n",
      "Epoch: 7280, Train Loss: 1.4357, Train Accuracy: 55.1351%\n",
      "Epoch: 7290, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 7300, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 7310, Train Loss: 1.4355, Train Accuracy: 55.1351%\n",
      "Epoch: 7320, Train Loss: 1.4355, Train Accuracy: 55.0270%\n",
      "Epoch: 7330, Train Loss: 1.4355, Train Accuracy: 55.0270%\n",
      "Epoch: 7340, Train Loss: 1.4354, Train Accuracy: 55.0270%\n",
      "Epoch: 7350, Train Loss: 1.4354, Train Accuracy: 55.0270%\n",
      "Epoch: 7360, Train Loss: 1.4353, Train Accuracy: 55.0270%\n",
      "Epoch: 7370, Train Loss: 1.4353, Train Accuracy: 55.1351%\n",
      "Epoch: 7380, Train Loss: 1.4353, Train Accuracy: 55.1351%\n",
      "Epoch: 7390, Train Loss: 1.4352, Train Accuracy: 55.1351%\n",
      "Epoch: 7400, Train Loss: 1.4352, Train Accuracy: 55.1351%\n",
      "Epoch: 7410, Train Loss: 1.4351, Train Accuracy: 55.2432%\n",
      "Epoch: 7420, Train Loss: 1.4351, Train Accuracy: 55.2432%\n",
      "Epoch: 7430, Train Loss: 1.4351, Train Accuracy: 55.2432%\n",
      "Epoch: 7440, Train Loss: 1.4350, Train Accuracy: 55.3514%\n",
      "Epoch: 7450, Train Loss: 1.4350, Train Accuracy: 55.3514%\n",
      "Epoch: 7460, Train Loss: 1.4349, Train Accuracy: 55.3514%\n",
      "Epoch: 7470, Train Loss: 1.4349, Train Accuracy: 55.3514%\n",
      "Epoch: 7480, Train Loss: 1.4349, Train Accuracy: 55.3514%\n",
      "Epoch: 7490, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 7500, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 7510, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 7520, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 7530, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 7540, Train Loss: 1.4346, Train Accuracy: 55.3514%\n",
      "Epoch: 7550, Train Loss: 1.4346, Train Accuracy: 55.3514%\n",
      "Epoch: 7560, Train Loss: 1.4345, Train Accuracy: 55.3514%\n",
      "Epoch: 7570, Train Loss: 1.4345, Train Accuracy: 55.3514%\n",
      "Epoch: 7580, Train Loss: 1.4345, Train Accuracy: 55.3514%\n",
      "Epoch: 7590, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 7600, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 7610, Train Loss: 1.4344, Train Accuracy: 55.4595%\n",
      "Epoch: 7620, Train Loss: 1.4343, Train Accuracy: 55.4595%\n",
      "Epoch: 7630, Train Loss: 1.4343, Train Accuracy: 55.4595%\n",
      "Epoch: 7640, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 7650, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 7660, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 7670, Train Loss: 1.4341, Train Accuracy: 55.3514%\n",
      "Epoch: 7680, Train Loss: 1.4341, Train Accuracy: 55.3514%\n",
      "Epoch: 7690, Train Loss: 1.4341, Train Accuracy: 55.3514%\n",
      "Epoch: 7700, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 7710, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 7720, Train Loss: 1.4339, Train Accuracy: 55.3514%\n",
      "Epoch: 7730, Train Loss: 1.4339, Train Accuracy: 55.3514%\n",
      "Epoch: 7740, Train Loss: 1.4339, Train Accuracy: 55.3514%\n",
      "Epoch: 7750, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 7760, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 7770, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 7780, Train Loss: 1.4337, Train Accuracy: 55.3514%\n",
      "Epoch: 7790, Train Loss: 1.4337, Train Accuracy: 55.3514%\n",
      "Epoch: 7800, Train Loss: 1.4337, Train Accuracy: 55.3514%\n",
      "Epoch: 7810, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 7820, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 7830, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 7840, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 7850, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 7860, Train Loss: 1.4334, Train Accuracy: 55.4595%\n",
      "Epoch: 7870, Train Loss: 1.4334, Train Accuracy: 55.4595%\n",
      "Epoch: 7880, Train Loss: 1.4334, Train Accuracy: 55.4595%\n",
      "Epoch: 7890, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 7900, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 7910, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 7920, Train Loss: 1.4332, Train Accuracy: 55.4595%\n",
      "Epoch: 7930, Train Loss: 1.4332, Train Accuracy: 55.4595%\n",
      "Epoch: 7940, Train Loss: 1.4332, Train Accuracy: 55.4595%\n",
      "Epoch: 7950, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 7960, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 7970, Train Loss: 1.4330, Train Accuracy: 55.4595%\n",
      "Epoch: 7980, Train Loss: 1.4330, Train Accuracy: 55.4595%\n",
      "Epoch: 7990, Train Loss: 1.4330, Train Accuracy: 55.4595%\n",
      "Epoch: 8000, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 8010, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 8020, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 8030, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 8040, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 8050, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 8060, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 8070, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 8080, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 8090, Train Loss: 1.4326, Train Accuracy: 55.4595%\n",
      "Epoch: 8100, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 8110, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 8120, Train Loss: 1.4325, Train Accuracy: 55.3514%\n",
      "Epoch: 8130, Train Loss: 1.4325, Train Accuracy: 55.3514%\n",
      "Epoch: 8140, Train Loss: 1.4325, Train Accuracy: 55.3514%\n",
      "Epoch: 8150, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 8160, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 8170, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 8180, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 8190, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 8200, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 8210, Train Loss: 1.4322, Train Accuracy: 55.3514%\n",
      "Epoch: 8220, Train Loss: 1.4322, Train Accuracy: 55.3514%\n",
      "Epoch: 8230, Train Loss: 1.4322, Train Accuracy: 55.3514%\n",
      "Epoch: 8240, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 8250, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 8260, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 8270, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 8280, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 8290, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 8300, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 8310, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 8320, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 8330, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 8340, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 8350, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 8360, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 8370, Train Loss: 1.4317, Train Accuracy: 55.3514%\n",
      "Epoch: 8380, Train Loss: 1.4317, Train Accuracy: 55.3514%\n",
      "Epoch: 8390, Train Loss: 1.4317, Train Accuracy: 55.3514%\n",
      "Epoch: 8400, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 8410, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 8420, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 8430, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 8440, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 8450, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 8460, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 8470, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 8480, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 8490, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 8500, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 8510, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 8520, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 8530, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 8540, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 8550, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 8560, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 8570, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 8580, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 8590, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 8600, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 8610, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 8620, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 8630, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 8640, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 8650, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 8660, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 8670, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 8680, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 8690, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 8700, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 8710, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 8720, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 8730, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 8740, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 8750, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 8760, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 8770, Train Loss: 1.4305, Train Accuracy: 55.3514%\n",
      "Epoch: 8780, Train Loss: 1.4305, Train Accuracy: 55.3514%\n",
      "Epoch: 8790, Train Loss: 1.4305, Train Accuracy: 55.4595%\n",
      "Epoch: 8800, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 8810, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 8820, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 8830, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 8840, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 8850, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 8860, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 8870, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 8880, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 8890, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 8900, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 8910, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 8920, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 8930, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 8940, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 8950, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 8960, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 8970, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 8980, Train Loss: 1.4299, Train Accuracy: 55.4595%\n",
      "Epoch: 8990, Train Loss: 1.4299, Train Accuracy: 55.4595%\n",
      "Epoch: 9000, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 9010, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 9020, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 9030, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 9040, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 9050, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 9060, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 9070, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 9080, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 9090, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 9100, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 9110, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 9120, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 9130, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 9140, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 9150, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 9160, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 9170, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 9180, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 9190, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 9200, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 9210, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 9220, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 9230, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 9240, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 9250, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 9260, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 9270, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 9280, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 9290, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 9300, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 9310, Train Loss: 1.4291, Train Accuracy: 55.4595%\n",
      "Epoch: 9320, Train Loss: 1.4290, Train Accuracy: 55.4595%\n",
      "Epoch: 9330, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 9340, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 9350, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 9360, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 9370, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 9380, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 9390, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 9400, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 9410, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 9420, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 9430, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 9440, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 9450, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 9460, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 9470, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 9480, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 9490, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 9500, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 9510, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 9520, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 9530, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 9540, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 9550, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 9560, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 9570, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 9580, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 9590, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 9600, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 9610, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 9620, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 9630, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 9640, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 9650, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 9660, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 9670, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 9680, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 9690, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 9700, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 9710, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 9720, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 9730, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 9740, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 9750, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 9760, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 9770, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 9780, Train Loss: 1.4279, Train Accuracy: 55.3514%\n",
      "Epoch: 9790, Train Loss: 1.4279, Train Accuracy: 55.3514%\n",
      "Epoch: 9800, Train Loss: 1.4279, Train Accuracy: 55.2432%\n",
      "Epoch: 9810, Train Loss: 1.4279, Train Accuracy: 55.2432%\n",
      "Epoch: 9820, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 9830, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 9840, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 9850, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 9860, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 9870, Train Loss: 1.4277, Train Accuracy: 55.1351%\n",
      "Epoch: 9880, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 9890, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 9900, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 9910, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 9920, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 9930, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 9940, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 9950, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 9960, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 9970, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 9980, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 9990, Train Loss: 1.4275, Train Accuracy: 55.2432%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1f0nibaq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇█████████▇</td></tr><tr><td>train_loss</td><td>█▇▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▆▃▁▁▁▁▁▁▁▁▃▃▃▃▃▆▆█▆▃▃▃▃▃▃▃▃▃▃▃▃▆▆▆█▆▆▆▆▆</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.55243</td></tr><tr><td>train_loss</td><td>1.42743</td></tr><tr><td>val_accuracy</td><td>0.5534</td></tr><tr><td>val_loss</td><td>1.39059</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.002</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/1f0nibaq' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/1f0nibaq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190303-1f0nibaq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1f0nibaq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190322-btdc8o80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/btdc8o80' target=\"_blank\">Logistic Regression lr=0.0002</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/btdc8o80' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/btdc8o80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7914, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7911, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7907, Train Accuracy: 51.5676%\n",
      "Epoch: 40, Train Loss: 1.7904, Train Accuracy: 51.5676%\n",
      "Epoch: 50, Train Loss: 1.7900, Train Accuracy: 51.5676%\n",
      "Epoch: 60, Train Loss: 1.7897, Train Accuracy: 51.5676%\n",
      "Epoch: 70, Train Loss: 1.7894, Train Accuracy: 51.5676%\n",
      "Epoch: 80, Train Loss: 1.7890, Train Accuracy: 51.5676%\n",
      "Epoch: 90, Train Loss: 1.7887, Train Accuracy: 51.5676%\n",
      "Epoch: 100, Train Loss: 1.7883, Train Accuracy: 51.5676%\n",
      "Epoch: 110, Train Loss: 1.7880, Train Accuracy: 51.5676%\n",
      "Epoch: 120, Train Loss: 1.7877, Train Accuracy: 51.5676%\n",
      "Epoch: 130, Train Loss: 1.7873, Train Accuracy: 51.5676%\n",
      "Epoch: 140, Train Loss: 1.7870, Train Accuracy: 51.5676%\n",
      "Epoch: 150, Train Loss: 1.7866, Train Accuracy: 51.5676%\n",
      "Epoch: 160, Train Loss: 1.7863, Train Accuracy: 51.5676%\n",
      "Epoch: 170, Train Loss: 1.7860, Train Accuracy: 51.5676%\n",
      "Epoch: 180, Train Loss: 1.7856, Train Accuracy: 51.5676%\n",
      "Epoch: 190, Train Loss: 1.7853, Train Accuracy: 51.5676%\n",
      "Epoch: 200, Train Loss: 1.7850, Train Accuracy: 51.5676%\n",
      "Epoch: 210, Train Loss: 1.7846, Train Accuracy: 51.5676%\n",
      "Epoch: 220, Train Loss: 1.7843, Train Accuracy: 51.5676%\n",
      "Epoch: 230, Train Loss: 1.7840, Train Accuracy: 51.5676%\n",
      "Epoch: 240, Train Loss: 1.7836, Train Accuracy: 51.5676%\n",
      "Epoch: 250, Train Loss: 1.7833, Train Accuracy: 51.5676%\n",
      "Epoch: 260, Train Loss: 1.7830, Train Accuracy: 51.5676%\n",
      "Epoch: 270, Train Loss: 1.7826, Train Accuracy: 51.5676%\n",
      "Epoch: 280, Train Loss: 1.7823, Train Accuracy: 51.5676%\n",
      "Epoch: 290, Train Loss: 1.7820, Train Accuracy: 51.5676%\n",
      "Epoch: 300, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 310, Train Loss: 1.7813, Train Accuracy: 51.5676%\n",
      "Epoch: 320, Train Loss: 1.7810, Train Accuracy: 51.5676%\n",
      "Epoch: 330, Train Loss: 1.7806, Train Accuracy: 51.5676%\n",
      "Epoch: 340, Train Loss: 1.7803, Train Accuracy: 51.5676%\n",
      "Epoch: 350, Train Loss: 1.7800, Train Accuracy: 51.5676%\n",
      "Epoch: 360, Train Loss: 1.7796, Train Accuracy: 51.5676%\n",
      "Epoch: 370, Train Loss: 1.7793, Train Accuracy: 51.5676%\n",
      "Epoch: 380, Train Loss: 1.7790, Train Accuracy: 51.5676%\n",
      "Epoch: 390, Train Loss: 1.7787, Train Accuracy: 51.5676%\n",
      "Epoch: 400, Train Loss: 1.7783, Train Accuracy: 51.5676%\n",
      "Epoch: 410, Train Loss: 1.7780, Train Accuracy: 51.5676%\n",
      "Epoch: 420, Train Loss: 1.7777, Train Accuracy: 51.5676%\n",
      "Epoch: 430, Train Loss: 1.7773, Train Accuracy: 51.6757%\n",
      "Epoch: 440, Train Loss: 1.7770, Train Accuracy: 51.6757%\n",
      "Epoch: 450, Train Loss: 1.7767, Train Accuracy: 51.6757%\n",
      "Epoch: 460, Train Loss: 1.7764, Train Accuracy: 51.6757%\n",
      "Epoch: 470, Train Loss: 1.7760, Train Accuracy: 51.6757%\n",
      "Epoch: 480, Train Loss: 1.7757, Train Accuracy: 51.6757%\n",
      "Epoch: 490, Train Loss: 1.7754, Train Accuracy: 51.6757%\n",
      "Epoch: 500, Train Loss: 1.7751, Train Accuracy: 51.6757%\n",
      "Epoch: 510, Train Loss: 1.7747, Train Accuracy: 51.6757%\n",
      "Epoch: 520, Train Loss: 1.7744, Train Accuracy: 51.6757%\n",
      "Epoch: 530, Train Loss: 1.7741, Train Accuracy: 51.6757%\n",
      "Epoch: 540, Train Loss: 1.7738, Train Accuracy: 51.6757%\n",
      "Epoch: 550, Train Loss: 1.7734, Train Accuracy: 51.6757%\n",
      "Epoch: 560, Train Loss: 1.7731, Train Accuracy: 51.6757%\n",
      "Epoch: 570, Train Loss: 1.7728, Train Accuracy: 51.6757%\n",
      "Epoch: 580, Train Loss: 1.7725, Train Accuracy: 51.6757%\n",
      "Epoch: 590, Train Loss: 1.7722, Train Accuracy: 51.6757%\n",
      "Epoch: 600, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 610, Train Loss: 1.7715, Train Accuracy: 51.6757%\n",
      "Epoch: 620, Train Loss: 1.7712, Train Accuracy: 51.6757%\n",
      "Epoch: 630, Train Loss: 1.7709, Train Accuracy: 51.6757%\n",
      "Epoch: 640, Train Loss: 1.7706, Train Accuracy: 51.6757%\n",
      "Epoch: 650, Train Loss: 1.7702, Train Accuracy: 51.6757%\n",
      "Epoch: 660, Train Loss: 1.7699, Train Accuracy: 51.6757%\n",
      "Epoch: 670, Train Loss: 1.7696, Train Accuracy: 51.6757%\n",
      "Epoch: 680, Train Loss: 1.7693, Train Accuracy: 51.6757%\n",
      "Epoch: 690, Train Loss: 1.7690, Train Accuracy: 51.6757%\n",
      "Epoch: 700, Train Loss: 1.7687, Train Accuracy: 51.6757%\n",
      "Epoch: 710, Train Loss: 1.7683, Train Accuracy: 51.6757%\n",
      "Epoch: 720, Train Loss: 1.7680, Train Accuracy: 51.6757%\n",
      "Epoch: 730, Train Loss: 1.7677, Train Accuracy: 51.6757%\n",
      "Epoch: 740, Train Loss: 1.7674, Train Accuracy: 51.6757%\n",
      "Epoch: 750, Train Loss: 1.7671, Train Accuracy: 51.6757%\n",
      "Epoch: 760, Train Loss: 1.7668, Train Accuracy: 51.6757%\n",
      "Epoch: 770, Train Loss: 1.7665, Train Accuracy: 51.6757%\n",
      "Epoch: 780, Train Loss: 1.7661, Train Accuracy: 51.6757%\n",
      "Epoch: 790, Train Loss: 1.7658, Train Accuracy: 51.6757%\n",
      "Epoch: 800, Train Loss: 1.7655, Train Accuracy: 51.6757%\n",
      "Epoch: 810, Train Loss: 1.7652, Train Accuracy: 51.6757%\n",
      "Epoch: 820, Train Loss: 1.7649, Train Accuracy: 51.6757%\n",
      "Epoch: 830, Train Loss: 1.7646, Train Accuracy: 51.6757%\n",
      "Epoch: 840, Train Loss: 1.7643, Train Accuracy: 51.6757%\n",
      "Epoch: 850, Train Loss: 1.7640, Train Accuracy: 51.6757%\n",
      "Epoch: 860, Train Loss: 1.7636, Train Accuracy: 51.6757%\n",
      "Epoch: 870, Train Loss: 1.7633, Train Accuracy: 51.6757%\n",
      "Epoch: 880, Train Loss: 1.7630, Train Accuracy: 51.6757%\n",
      "Epoch: 890, Train Loss: 1.7627, Train Accuracy: 51.6757%\n",
      "Epoch: 900, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 910, Train Loss: 1.7621, Train Accuracy: 51.6757%\n",
      "Epoch: 920, Train Loss: 1.7618, Train Accuracy: 51.6757%\n",
      "Epoch: 930, Train Loss: 1.7615, Train Accuracy: 51.6757%\n",
      "Epoch: 940, Train Loss: 1.7612, Train Accuracy: 51.6757%\n",
      "Epoch: 950, Train Loss: 1.7609, Train Accuracy: 51.6757%\n",
      "Epoch: 960, Train Loss: 1.7606, Train Accuracy: 51.6757%\n",
      "Epoch: 970, Train Loss: 1.7603, Train Accuracy: 51.6757%\n",
      "Epoch: 980, Train Loss: 1.7599, Train Accuracy: 51.6757%\n",
      "Epoch: 990, Train Loss: 1.7596, Train Accuracy: 51.6757%\n",
      "Epoch: 1000, Train Loss: 1.7593, Train Accuracy: 51.6757%\n",
      "Epoch: 1010, Train Loss: 1.7590, Train Accuracy: 51.6757%\n",
      "Epoch: 1020, Train Loss: 1.7587, Train Accuracy: 51.6757%\n",
      "Epoch: 1030, Train Loss: 1.7584, Train Accuracy: 51.6757%\n",
      "Epoch: 1040, Train Loss: 1.7581, Train Accuracy: 51.6757%\n",
      "Epoch: 1050, Train Loss: 1.7578, Train Accuracy: 51.6757%\n",
      "Epoch: 1060, Train Loss: 1.7575, Train Accuracy: 51.6757%\n",
      "Epoch: 1070, Train Loss: 1.7572, Train Accuracy: 51.6757%\n",
      "Epoch: 1080, Train Loss: 1.7569, Train Accuracy: 51.6757%\n",
      "Epoch: 1090, Train Loss: 1.7566, Train Accuracy: 51.6757%\n",
      "Epoch: 1100, Train Loss: 1.7563, Train Accuracy: 51.6757%\n",
      "Epoch: 1110, Train Loss: 1.7560, Train Accuracy: 51.6757%\n",
      "Epoch: 1120, Train Loss: 1.7557, Train Accuracy: 51.6757%\n",
      "Epoch: 1130, Train Loss: 1.7554, Train Accuracy: 51.6757%\n",
      "Epoch: 1140, Train Loss: 1.7551, Train Accuracy: 51.6757%\n",
      "Epoch: 1150, Train Loss: 1.7548, Train Accuracy: 51.6757%\n",
      "Epoch: 1160, Train Loss: 1.7545, Train Accuracy: 51.6757%\n",
      "Epoch: 1170, Train Loss: 1.7542, Train Accuracy: 51.6757%\n",
      "Epoch: 1180, Train Loss: 1.7539, Train Accuracy: 51.6757%\n",
      "Epoch: 1190, Train Loss: 1.7536, Train Accuracy: 51.6757%\n",
      "Epoch: 1200, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 1210, Train Loss: 1.7530, Train Accuracy: 51.6757%\n",
      "Epoch: 1220, Train Loss: 1.7527, Train Accuracy: 51.6757%\n",
      "Epoch: 1230, Train Loss: 1.7524, Train Accuracy: 51.6757%\n",
      "Epoch: 1240, Train Loss: 1.7521, Train Accuracy: 51.6757%\n",
      "Epoch: 1250, Train Loss: 1.7518, Train Accuracy: 51.6757%\n",
      "Epoch: 1260, Train Loss: 1.7515, Train Accuracy: 51.6757%\n",
      "Epoch: 1270, Train Loss: 1.7512, Train Accuracy: 51.6757%\n",
      "Epoch: 1280, Train Loss: 1.7509, Train Accuracy: 51.6757%\n",
      "Epoch: 1290, Train Loss: 1.7506, Train Accuracy: 51.6757%\n",
      "Epoch: 1300, Train Loss: 1.7503, Train Accuracy: 51.6757%\n",
      "Epoch: 1310, Train Loss: 1.7500, Train Accuracy: 51.6757%\n",
      "Epoch: 1320, Train Loss: 1.7497, Train Accuracy: 51.6757%\n",
      "Epoch: 1330, Train Loss: 1.7495, Train Accuracy: 51.6757%\n",
      "Epoch: 1340, Train Loss: 1.7492, Train Accuracy: 51.6757%\n",
      "Epoch: 1350, Train Loss: 1.7489, Train Accuracy: 51.6757%\n",
      "Epoch: 1360, Train Loss: 1.7486, Train Accuracy: 51.6757%\n",
      "Epoch: 1370, Train Loss: 1.7483, Train Accuracy: 51.6757%\n",
      "Epoch: 1380, Train Loss: 1.7480, Train Accuracy: 51.6757%\n",
      "Epoch: 1390, Train Loss: 1.7477, Train Accuracy: 51.6757%\n",
      "Epoch: 1400, Train Loss: 1.7474, Train Accuracy: 51.6757%\n",
      "Epoch: 1410, Train Loss: 1.7471, Train Accuracy: 51.6757%\n",
      "Epoch: 1420, Train Loss: 1.7468, Train Accuracy: 51.6757%\n",
      "Epoch: 1430, Train Loss: 1.7465, Train Accuracy: 51.6757%\n",
      "Epoch: 1440, Train Loss: 1.7462, Train Accuracy: 51.6757%\n",
      "Epoch: 1450, Train Loss: 1.7460, Train Accuracy: 51.6757%\n",
      "Epoch: 1460, Train Loss: 1.7457, Train Accuracy: 51.6757%\n",
      "Epoch: 1470, Train Loss: 1.7454, Train Accuracy: 51.6757%\n",
      "Epoch: 1480, Train Loss: 1.7451, Train Accuracy: 51.6757%\n",
      "Epoch: 1490, Train Loss: 1.7448, Train Accuracy: 51.6757%\n",
      "Epoch: 1500, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 1510, Train Loss: 1.7442, Train Accuracy: 51.6757%\n",
      "Epoch: 1520, Train Loss: 1.7439, Train Accuracy: 51.6757%\n",
      "Epoch: 1530, Train Loss: 1.7436, Train Accuracy: 51.6757%\n",
      "Epoch: 1540, Train Loss: 1.7434, Train Accuracy: 51.6757%\n",
      "Epoch: 1550, Train Loss: 1.7431, Train Accuracy: 51.6757%\n",
      "Epoch: 1560, Train Loss: 1.7428, Train Accuracy: 51.6757%\n",
      "Epoch: 1570, Train Loss: 1.7425, Train Accuracy: 51.6757%\n",
      "Epoch: 1580, Train Loss: 1.7422, Train Accuracy: 51.6757%\n",
      "Epoch: 1590, Train Loss: 1.7419, Train Accuracy: 51.6757%\n",
      "Epoch: 1600, Train Loss: 1.7416, Train Accuracy: 51.6757%\n",
      "Epoch: 1610, Train Loss: 1.7414, Train Accuracy: 51.6757%\n",
      "Epoch: 1620, Train Loss: 1.7411, Train Accuracy: 51.6757%\n",
      "Epoch: 1630, Train Loss: 1.7408, Train Accuracy: 51.6757%\n",
      "Epoch: 1640, Train Loss: 1.7405, Train Accuracy: 51.6757%\n",
      "Epoch: 1650, Train Loss: 1.7402, Train Accuracy: 51.6757%\n",
      "Epoch: 1660, Train Loss: 1.7399, Train Accuracy: 51.6757%\n",
      "Epoch: 1670, Train Loss: 1.7397, Train Accuracy: 51.6757%\n",
      "Epoch: 1680, Train Loss: 1.7394, Train Accuracy: 51.6757%\n",
      "Epoch: 1690, Train Loss: 1.7391, Train Accuracy: 51.6757%\n",
      "Epoch: 1700, Train Loss: 1.7388, Train Accuracy: 51.6757%\n",
      "Epoch: 1710, Train Loss: 1.7385, Train Accuracy: 51.6757%\n",
      "Epoch: 1720, Train Loss: 1.7383, Train Accuracy: 51.6757%\n",
      "Epoch: 1730, Train Loss: 1.7380, Train Accuracy: 51.6757%\n",
      "Epoch: 1740, Train Loss: 1.7377, Train Accuracy: 51.6757%\n",
      "Epoch: 1750, Train Loss: 1.7374, Train Accuracy: 51.6757%\n",
      "Epoch: 1760, Train Loss: 1.7371, Train Accuracy: 51.6757%\n",
      "Epoch: 1770, Train Loss: 1.7369, Train Accuracy: 51.6757%\n",
      "Epoch: 1780, Train Loss: 1.7366, Train Accuracy: 51.6757%\n",
      "Epoch: 1790, Train Loss: 1.7363, Train Accuracy: 51.6757%\n",
      "Epoch: 1800, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 1810, Train Loss: 1.7357, Train Accuracy: 51.6757%\n",
      "Epoch: 1820, Train Loss: 1.7355, Train Accuracy: 51.6757%\n",
      "Epoch: 1830, Train Loss: 1.7352, Train Accuracy: 51.6757%\n",
      "Epoch: 1840, Train Loss: 1.7349, Train Accuracy: 51.6757%\n",
      "Epoch: 1850, Train Loss: 1.7346, Train Accuracy: 51.6757%\n",
      "Epoch: 1860, Train Loss: 1.7344, Train Accuracy: 51.6757%\n",
      "Epoch: 1870, Train Loss: 1.7341, Train Accuracy: 51.6757%\n",
      "Epoch: 1880, Train Loss: 1.7338, Train Accuracy: 51.6757%\n",
      "Epoch: 1890, Train Loss: 1.7335, Train Accuracy: 51.6757%\n",
      "Epoch: 1900, Train Loss: 1.7333, Train Accuracy: 51.6757%\n",
      "Epoch: 1910, Train Loss: 1.7330, Train Accuracy: 51.6757%\n",
      "Epoch: 1920, Train Loss: 1.7327, Train Accuracy: 51.6757%\n",
      "Epoch: 1930, Train Loss: 1.7324, Train Accuracy: 51.6757%\n",
      "Epoch: 1940, Train Loss: 1.7322, Train Accuracy: 51.6757%\n",
      "Epoch: 1950, Train Loss: 1.7319, Train Accuracy: 51.6757%\n",
      "Epoch: 1960, Train Loss: 1.7316, Train Accuracy: 51.6757%\n",
      "Epoch: 1970, Train Loss: 1.7313, Train Accuracy: 51.6757%\n",
      "Epoch: 1980, Train Loss: 1.7311, Train Accuracy: 51.6757%\n",
      "Epoch: 1990, Train Loss: 1.7308, Train Accuracy: 51.6757%\n",
      "Epoch: 2000, Train Loss: 1.7305, Train Accuracy: 51.6757%\n",
      "Epoch: 2010, Train Loss: 1.7303, Train Accuracy: 51.6757%\n",
      "Epoch: 2020, Train Loss: 1.7300, Train Accuracy: 51.6757%\n",
      "Epoch: 2030, Train Loss: 1.7297, Train Accuracy: 51.6757%\n",
      "Epoch: 2040, Train Loss: 1.7294, Train Accuracy: 51.6757%\n",
      "Epoch: 2050, Train Loss: 1.7292, Train Accuracy: 51.6757%\n",
      "Epoch: 2060, Train Loss: 1.7289, Train Accuracy: 51.6757%\n",
      "Epoch: 2070, Train Loss: 1.7286, Train Accuracy: 51.6757%\n",
      "Epoch: 2080, Train Loss: 1.7284, Train Accuracy: 51.6757%\n",
      "Epoch: 2090, Train Loss: 1.7281, Train Accuracy: 51.6757%\n",
      "Epoch: 2100, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 2110, Train Loss: 1.7276, Train Accuracy: 51.6757%\n",
      "Epoch: 2120, Train Loss: 1.7273, Train Accuracy: 51.6757%\n",
      "Epoch: 2130, Train Loss: 1.7270, Train Accuracy: 51.6757%\n",
      "Epoch: 2140, Train Loss: 1.7268, Train Accuracy: 51.6757%\n",
      "Epoch: 2150, Train Loss: 1.7265, Train Accuracy: 51.6757%\n",
      "Epoch: 2160, Train Loss: 1.7262, Train Accuracy: 51.6757%\n",
      "Epoch: 2170, Train Loss: 1.7260, Train Accuracy: 51.6757%\n",
      "Epoch: 2180, Train Loss: 1.7257, Train Accuracy: 51.6757%\n",
      "Epoch: 2190, Train Loss: 1.7254, Train Accuracy: 51.6757%\n",
      "Epoch: 2200, Train Loss: 1.7252, Train Accuracy: 51.6757%\n",
      "Epoch: 2210, Train Loss: 1.7249, Train Accuracy: 51.6757%\n",
      "Epoch: 2220, Train Loss: 1.7246, Train Accuracy: 51.6757%\n",
      "Epoch: 2230, Train Loss: 1.7244, Train Accuracy: 51.6757%\n",
      "Epoch: 2240, Train Loss: 1.7241, Train Accuracy: 51.6757%\n",
      "Epoch: 2250, Train Loss: 1.7238, Train Accuracy: 51.6757%\n",
      "Epoch: 2260, Train Loss: 1.7236, Train Accuracy: 51.6757%\n",
      "Epoch: 2270, Train Loss: 1.7233, Train Accuracy: 51.6757%\n",
      "Epoch: 2280, Train Loss: 1.7231, Train Accuracy: 51.6757%\n",
      "Epoch: 2290, Train Loss: 1.7228, Train Accuracy: 51.6757%\n",
      "Epoch: 2300, Train Loss: 1.7225, Train Accuracy: 51.6757%\n",
      "Epoch: 2310, Train Loss: 1.7223, Train Accuracy: 51.6757%\n",
      "Epoch: 2320, Train Loss: 1.7220, Train Accuracy: 51.6757%\n",
      "Epoch: 2330, Train Loss: 1.7217, Train Accuracy: 51.6757%\n",
      "Epoch: 2340, Train Loss: 1.7215, Train Accuracy: 51.6757%\n",
      "Epoch: 2350, Train Loss: 1.7212, Train Accuracy: 51.6757%\n",
      "Epoch: 2360, Train Loss: 1.7210, Train Accuracy: 51.6757%\n",
      "Epoch: 2370, Train Loss: 1.7207, Train Accuracy: 51.6757%\n",
      "Epoch: 2380, Train Loss: 1.7204, Train Accuracy: 51.6757%\n",
      "Epoch: 2390, Train Loss: 1.7202, Train Accuracy: 51.6757%\n",
      "Epoch: 2400, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 2410, Train Loss: 1.7197, Train Accuracy: 51.6757%\n",
      "Epoch: 2420, Train Loss: 1.7194, Train Accuracy: 51.6757%\n",
      "Epoch: 2430, Train Loss: 1.7191, Train Accuracy: 51.6757%\n",
      "Epoch: 2440, Train Loss: 1.7189, Train Accuracy: 51.6757%\n",
      "Epoch: 2450, Train Loss: 1.7186, Train Accuracy: 51.6757%\n",
      "Epoch: 2460, Train Loss: 1.7184, Train Accuracy: 51.6757%\n",
      "Epoch: 2470, Train Loss: 1.7181, Train Accuracy: 51.6757%\n",
      "Epoch: 2480, Train Loss: 1.7179, Train Accuracy: 51.6757%\n",
      "Epoch: 2490, Train Loss: 1.7176, Train Accuracy: 51.6757%\n",
      "Epoch: 2500, Train Loss: 1.7173, Train Accuracy: 51.6757%\n",
      "Epoch: 2510, Train Loss: 1.7171, Train Accuracy: 51.6757%\n",
      "Epoch: 2520, Train Loss: 1.7168, Train Accuracy: 51.6757%\n",
      "Epoch: 2530, Train Loss: 1.7166, Train Accuracy: 51.6757%\n",
      "Epoch: 2540, Train Loss: 1.7163, Train Accuracy: 51.6757%\n",
      "Epoch: 2550, Train Loss: 1.7161, Train Accuracy: 51.6757%\n",
      "Epoch: 2560, Train Loss: 1.7158, Train Accuracy: 51.6757%\n",
      "Epoch: 2570, Train Loss: 1.7156, Train Accuracy: 51.6757%\n",
      "Epoch: 2580, Train Loss: 1.7153, Train Accuracy: 51.6757%\n",
      "Epoch: 2590, Train Loss: 1.7151, Train Accuracy: 51.6757%\n",
      "Epoch: 2600, Train Loss: 1.7148, Train Accuracy: 51.6757%\n",
      "Epoch: 2610, Train Loss: 1.7146, Train Accuracy: 51.6757%\n",
      "Epoch: 2620, Train Loss: 1.7143, Train Accuracy: 51.6757%\n",
      "Epoch: 2630, Train Loss: 1.7140, Train Accuracy: 51.6757%\n",
      "Epoch: 2640, Train Loss: 1.7138, Train Accuracy: 51.6757%\n",
      "Epoch: 2650, Train Loss: 1.7135, Train Accuracy: 51.6757%\n",
      "Epoch: 2660, Train Loss: 1.7133, Train Accuracy: 51.6757%\n",
      "Epoch: 2670, Train Loss: 1.7130, Train Accuracy: 51.6757%\n",
      "Epoch: 2680, Train Loss: 1.7128, Train Accuracy: 51.6757%\n",
      "Epoch: 2690, Train Loss: 1.7125, Train Accuracy: 51.6757%\n",
      "Epoch: 2700, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 2710, Train Loss: 1.7120, Train Accuracy: 51.6757%\n",
      "Epoch: 2720, Train Loss: 1.7118, Train Accuracy: 51.6757%\n",
      "Epoch: 2730, Train Loss: 1.7115, Train Accuracy: 51.6757%\n",
      "Epoch: 2740, Train Loss: 1.7113, Train Accuracy: 51.6757%\n",
      "Epoch: 2750, Train Loss: 1.7110, Train Accuracy: 51.6757%\n",
      "Epoch: 2760, Train Loss: 1.7108, Train Accuracy: 51.6757%\n",
      "Epoch: 2770, Train Loss: 1.7105, Train Accuracy: 51.6757%\n",
      "Epoch: 2780, Train Loss: 1.7103, Train Accuracy: 51.6757%\n",
      "Epoch: 2790, Train Loss: 1.7100, Train Accuracy: 51.7838%\n",
      "Epoch: 2800, Train Loss: 1.7098, Train Accuracy: 51.7838%\n",
      "Epoch: 2810, Train Loss: 1.7096, Train Accuracy: 51.7838%\n",
      "Epoch: 2820, Train Loss: 1.7093, Train Accuracy: 51.7838%\n",
      "Epoch: 2830, Train Loss: 1.7091, Train Accuracy: 51.7838%\n",
      "Epoch: 2840, Train Loss: 1.7088, Train Accuracy: 51.7838%\n",
      "Epoch: 2850, Train Loss: 1.7086, Train Accuracy: 51.7838%\n",
      "Epoch: 2860, Train Loss: 1.7083, Train Accuracy: 51.7838%\n",
      "Epoch: 2870, Train Loss: 1.7081, Train Accuracy: 51.7838%\n",
      "Epoch: 2880, Train Loss: 1.7078, Train Accuracy: 51.7838%\n",
      "Epoch: 2890, Train Loss: 1.7076, Train Accuracy: 51.7838%\n",
      "Epoch: 2900, Train Loss: 1.7073, Train Accuracy: 51.7838%\n",
      "Epoch: 2910, Train Loss: 1.7071, Train Accuracy: 51.8919%\n",
      "Epoch: 2920, Train Loss: 1.7069, Train Accuracy: 51.8919%\n",
      "Epoch: 2930, Train Loss: 1.7066, Train Accuracy: 51.8919%\n",
      "Epoch: 2940, Train Loss: 1.7064, Train Accuracy: 51.8919%\n",
      "Epoch: 2950, Train Loss: 1.7061, Train Accuracy: 51.8919%\n",
      "Epoch: 2960, Train Loss: 1.7059, Train Accuracy: 51.8919%\n",
      "Epoch: 2970, Train Loss: 1.7056, Train Accuracy: 51.8919%\n",
      "Epoch: 2980, Train Loss: 1.7054, Train Accuracy: 51.8919%\n",
      "Epoch: 2990, Train Loss: 1.7051, Train Accuracy: 51.8919%\n",
      "Epoch: 3000, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 3010, Train Loss: 1.7047, Train Accuracy: 51.8919%\n",
      "Epoch: 3020, Train Loss: 1.7044, Train Accuracy: 51.8919%\n",
      "Epoch: 3030, Train Loss: 1.7042, Train Accuracy: 51.8919%\n",
      "Epoch: 3040, Train Loss: 1.7039, Train Accuracy: 51.8919%\n",
      "Epoch: 3050, Train Loss: 1.7037, Train Accuracy: 51.8919%\n",
      "Epoch: 3060, Train Loss: 1.7035, Train Accuracy: 51.8919%\n",
      "Epoch: 3070, Train Loss: 1.7032, Train Accuracy: 51.8919%\n",
      "Epoch: 3080, Train Loss: 1.7030, Train Accuracy: 51.8919%\n",
      "Epoch: 3090, Train Loss: 1.7027, Train Accuracy: 51.8919%\n",
      "Epoch: 3100, Train Loss: 1.7025, Train Accuracy: 51.8919%\n",
      "Epoch: 3110, Train Loss: 1.7023, Train Accuracy: 51.8919%\n",
      "Epoch: 3120, Train Loss: 1.7020, Train Accuracy: 51.8919%\n",
      "Epoch: 3130, Train Loss: 1.7018, Train Accuracy: 51.8919%\n",
      "Epoch: 3140, Train Loss: 1.7016, Train Accuracy: 51.8919%\n",
      "Epoch: 3150, Train Loss: 1.7013, Train Accuracy: 51.8919%\n",
      "Epoch: 3160, Train Loss: 1.7011, Train Accuracy: 51.8919%\n",
      "Epoch: 3170, Train Loss: 1.7008, Train Accuracy: 51.8919%\n",
      "Epoch: 3180, Train Loss: 1.7006, Train Accuracy: 51.8919%\n",
      "Epoch: 3190, Train Loss: 1.7004, Train Accuracy: 51.8919%\n",
      "Epoch: 3200, Train Loss: 1.7001, Train Accuracy: 51.8919%\n",
      "Epoch: 3210, Train Loss: 1.6999, Train Accuracy: 51.8919%\n",
      "Epoch: 3220, Train Loss: 1.6997, Train Accuracy: 51.8919%\n",
      "Epoch: 3230, Train Loss: 1.6994, Train Accuracy: 51.8919%\n",
      "Epoch: 3240, Train Loss: 1.6992, Train Accuracy: 51.8919%\n",
      "Epoch: 3250, Train Loss: 1.6990, Train Accuracy: 51.8919%\n",
      "Epoch: 3260, Train Loss: 1.6987, Train Accuracy: 51.8919%\n",
      "Epoch: 3270, Train Loss: 1.6985, Train Accuracy: 51.7838%\n",
      "Epoch: 3280, Train Loss: 1.6982, Train Accuracy: 51.7838%\n",
      "Epoch: 3290, Train Loss: 1.6980, Train Accuracy: 51.7838%\n",
      "Epoch: 3300, Train Loss: 1.6978, Train Accuracy: 51.7838%\n",
      "Epoch: 3310, Train Loss: 1.6975, Train Accuracy: 51.7838%\n",
      "Epoch: 3320, Train Loss: 1.6973, Train Accuracy: 51.7838%\n",
      "Epoch: 3330, Train Loss: 1.6971, Train Accuracy: 51.7838%\n",
      "Epoch: 3340, Train Loss: 1.6968, Train Accuracy: 51.7838%\n",
      "Epoch: 3350, Train Loss: 1.6966, Train Accuracy: 51.7838%\n",
      "Epoch: 3360, Train Loss: 1.6964, Train Accuracy: 51.7838%\n",
      "Epoch: 3370, Train Loss: 1.6962, Train Accuracy: 51.7838%\n",
      "Epoch: 3380, Train Loss: 1.6959, Train Accuracy: 51.7838%\n",
      "Epoch: 3390, Train Loss: 1.6957, Train Accuracy: 51.7838%\n",
      "Epoch: 3400, Train Loss: 1.6955, Train Accuracy: 51.7838%\n",
      "Epoch: 3410, Train Loss: 1.6952, Train Accuracy: 51.7838%\n",
      "Epoch: 3420, Train Loss: 1.6950, Train Accuracy: 51.7838%\n",
      "Epoch: 3430, Train Loss: 1.6948, Train Accuracy: 51.7838%\n",
      "Epoch: 3440, Train Loss: 1.6945, Train Accuracy: 51.6757%\n",
      "Epoch: 3450, Train Loss: 1.6943, Train Accuracy: 51.6757%\n",
      "Epoch: 3460, Train Loss: 1.6941, Train Accuracy: 51.6757%\n",
      "Epoch: 3470, Train Loss: 1.6938, Train Accuracy: 51.6757%\n",
      "Epoch: 3480, Train Loss: 1.6936, Train Accuracy: 51.6757%\n",
      "Epoch: 3490, Train Loss: 1.6934, Train Accuracy: 51.6757%\n",
      "Epoch: 3500, Train Loss: 1.6932, Train Accuracy: 51.6757%\n",
      "Epoch: 3510, Train Loss: 1.6929, Train Accuracy: 51.6757%\n",
      "Epoch: 3520, Train Loss: 1.6927, Train Accuracy: 51.6757%\n",
      "Epoch: 3530, Train Loss: 1.6925, Train Accuracy: 51.6757%\n",
      "Epoch: 3540, Train Loss: 1.6923, Train Accuracy: 51.6757%\n",
      "Epoch: 3550, Train Loss: 1.6920, Train Accuracy: 51.6757%\n",
      "Epoch: 3560, Train Loss: 1.6918, Train Accuracy: 51.6757%\n",
      "Epoch: 3570, Train Loss: 1.6916, Train Accuracy: 51.6757%\n",
      "Epoch: 3580, Train Loss: 1.6913, Train Accuracy: 51.6757%\n",
      "Epoch: 3590, Train Loss: 1.6911, Train Accuracy: 51.6757%\n",
      "Epoch: 3600, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 3610, Train Loss: 1.6907, Train Accuracy: 51.6757%\n",
      "Epoch: 3620, Train Loss: 1.6904, Train Accuracy: 51.6757%\n",
      "Epoch: 3630, Train Loss: 1.6902, Train Accuracy: 51.6757%\n",
      "Epoch: 3640, Train Loss: 1.6900, Train Accuracy: 51.6757%\n",
      "Epoch: 3650, Train Loss: 1.6898, Train Accuracy: 51.6757%\n",
      "Epoch: 3660, Train Loss: 1.6895, Train Accuracy: 51.6757%\n",
      "Epoch: 3670, Train Loss: 1.6893, Train Accuracy: 51.6757%\n",
      "Epoch: 3680, Train Loss: 1.6891, Train Accuracy: 51.6757%\n",
      "Epoch: 3690, Train Loss: 1.6889, Train Accuracy: 51.6757%\n",
      "Epoch: 3700, Train Loss: 1.6886, Train Accuracy: 51.6757%\n",
      "Epoch: 3710, Train Loss: 1.6884, Train Accuracy: 51.6757%\n",
      "Epoch: 3720, Train Loss: 1.6882, Train Accuracy: 51.6757%\n",
      "Epoch: 3730, Train Loss: 1.6880, Train Accuracy: 51.6757%\n",
      "Epoch: 3740, Train Loss: 1.6878, Train Accuracy: 51.6757%\n",
      "Epoch: 3750, Train Loss: 1.6875, Train Accuracy: 51.6757%\n",
      "Epoch: 3760, Train Loss: 1.6873, Train Accuracy: 51.6757%\n",
      "Epoch: 3770, Train Loss: 1.6871, Train Accuracy: 51.6757%\n",
      "Epoch: 3780, Train Loss: 1.6869, Train Accuracy: 51.6757%\n",
      "Epoch: 3790, Train Loss: 1.6866, Train Accuracy: 51.6757%\n",
      "Epoch: 3800, Train Loss: 1.6864, Train Accuracy: 51.5676%\n",
      "Epoch: 3810, Train Loss: 1.6862, Train Accuracy: 51.5676%\n",
      "Epoch: 3820, Train Loss: 1.6860, Train Accuracy: 51.5676%\n",
      "Epoch: 3830, Train Loss: 1.6858, Train Accuracy: 51.5676%\n",
      "Epoch: 3840, Train Loss: 1.6855, Train Accuracy: 51.6757%\n",
      "Epoch: 3850, Train Loss: 1.6853, Train Accuracy: 51.6757%\n",
      "Epoch: 3860, Train Loss: 1.6851, Train Accuracy: 51.6757%\n",
      "Epoch: 3870, Train Loss: 1.6849, Train Accuracy: 51.6757%\n",
      "Epoch: 3880, Train Loss: 1.6847, Train Accuracy: 51.6757%\n",
      "Epoch: 3890, Train Loss: 1.6845, Train Accuracy: 51.6757%\n",
      "Epoch: 3900, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 3910, Train Loss: 1.6840, Train Accuracy: 51.6757%\n",
      "Epoch: 3920, Train Loss: 1.6838, Train Accuracy: 51.6757%\n",
      "Epoch: 3930, Train Loss: 1.6836, Train Accuracy: 51.6757%\n",
      "Epoch: 3940, Train Loss: 1.6834, Train Accuracy: 51.6757%\n",
      "Epoch: 3950, Train Loss: 1.6831, Train Accuracy: 51.6757%\n",
      "Epoch: 3960, Train Loss: 1.6829, Train Accuracy: 51.6757%\n",
      "Epoch: 3970, Train Loss: 1.6827, Train Accuracy: 51.6757%\n",
      "Epoch: 3980, Train Loss: 1.6825, Train Accuracy: 51.6757%\n",
      "Epoch: 3990, Train Loss: 1.6823, Train Accuracy: 51.6757%\n",
      "Epoch: 4000, Train Loss: 1.6821, Train Accuracy: 51.6757%\n",
      "Epoch: 4010, Train Loss: 1.6818, Train Accuracy: 51.6757%\n",
      "Epoch: 4020, Train Loss: 1.6816, Train Accuracy: 51.6757%\n",
      "Epoch: 4030, Train Loss: 1.6814, Train Accuracy: 51.6757%\n",
      "Epoch: 4040, Train Loss: 1.6812, Train Accuracy: 51.6757%\n",
      "Epoch: 4050, Train Loss: 1.6810, Train Accuracy: 51.6757%\n",
      "Epoch: 4060, Train Loss: 1.6808, Train Accuracy: 51.6757%\n",
      "Epoch: 4070, Train Loss: 1.6806, Train Accuracy: 51.6757%\n",
      "Epoch: 4080, Train Loss: 1.6803, Train Accuracy: 51.6757%\n",
      "Epoch: 4090, Train Loss: 1.6801, Train Accuracy: 51.6757%\n",
      "Epoch: 4100, Train Loss: 1.6799, Train Accuracy: 51.6757%\n",
      "Epoch: 4110, Train Loss: 1.6797, Train Accuracy: 51.6757%\n",
      "Epoch: 4120, Train Loss: 1.6795, Train Accuracy: 51.6757%\n",
      "Epoch: 4130, Train Loss: 1.6793, Train Accuracy: 51.6757%\n",
      "Epoch: 4140, Train Loss: 1.6791, Train Accuracy: 51.6757%\n",
      "Epoch: 4150, Train Loss: 1.6789, Train Accuracy: 51.6757%\n",
      "Epoch: 4160, Train Loss: 1.6786, Train Accuracy: 51.6757%\n",
      "Epoch: 4170, Train Loss: 1.6784, Train Accuracy: 51.6757%\n",
      "Epoch: 4180, Train Loss: 1.6782, Train Accuracy: 51.6757%\n",
      "Epoch: 4190, Train Loss: 1.6780, Train Accuracy: 51.6757%\n",
      "Epoch: 4200, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 4210, Train Loss: 1.6776, Train Accuracy: 51.6757%\n",
      "Epoch: 4220, Train Loss: 1.6774, Train Accuracy: 51.6757%\n",
      "Epoch: 4230, Train Loss: 1.6772, Train Accuracy: 51.6757%\n",
      "Epoch: 4240, Train Loss: 1.6770, Train Accuracy: 51.6757%\n",
      "Epoch: 4250, Train Loss: 1.6767, Train Accuracy: 51.6757%\n",
      "Epoch: 4260, Train Loss: 1.6765, Train Accuracy: 51.6757%\n",
      "Epoch: 4270, Train Loss: 1.6763, Train Accuracy: 51.6757%\n",
      "Epoch: 4280, Train Loss: 1.6761, Train Accuracy: 51.6757%\n",
      "Epoch: 4290, Train Loss: 1.6759, Train Accuracy: 51.6757%\n",
      "Epoch: 4300, Train Loss: 1.6757, Train Accuracy: 51.6757%\n",
      "Epoch: 4310, Train Loss: 1.6755, Train Accuracy: 51.6757%\n",
      "Epoch: 4320, Train Loss: 1.6753, Train Accuracy: 51.6757%\n",
      "Epoch: 4330, Train Loss: 1.6751, Train Accuracy: 51.6757%\n",
      "Epoch: 4340, Train Loss: 1.6749, Train Accuracy: 51.6757%\n",
      "Epoch: 4350, Train Loss: 1.6747, Train Accuracy: 51.6757%\n",
      "Epoch: 4360, Train Loss: 1.6745, Train Accuracy: 51.6757%\n",
      "Epoch: 4370, Train Loss: 1.6742, Train Accuracy: 51.6757%\n",
      "Epoch: 4380, Train Loss: 1.6740, Train Accuracy: 51.6757%\n",
      "Epoch: 4390, Train Loss: 1.6738, Train Accuracy: 51.6757%\n",
      "Epoch: 4400, Train Loss: 1.6736, Train Accuracy: 51.6757%\n",
      "Epoch: 4410, Train Loss: 1.6734, Train Accuracy: 51.6757%\n",
      "Epoch: 4420, Train Loss: 1.6732, Train Accuracy: 51.6757%\n",
      "Epoch: 4430, Train Loss: 1.6730, Train Accuracy: 51.6757%\n",
      "Epoch: 4440, Train Loss: 1.6728, Train Accuracy: 51.6757%\n",
      "Epoch: 4450, Train Loss: 1.6726, Train Accuracy: 51.6757%\n",
      "Epoch: 4460, Train Loss: 1.6724, Train Accuracy: 51.6757%\n",
      "Epoch: 4470, Train Loss: 1.6722, Train Accuracy: 51.6757%\n",
      "Epoch: 4480, Train Loss: 1.6720, Train Accuracy: 51.7838%\n",
      "Epoch: 4490, Train Loss: 1.6718, Train Accuracy: 51.7838%\n",
      "Epoch: 4500, Train Loss: 1.6716, Train Accuracy: 51.7838%\n",
      "Epoch: 4510, Train Loss: 1.6714, Train Accuracy: 51.7838%\n",
      "Epoch: 4520, Train Loss: 1.6712, Train Accuracy: 51.7838%\n",
      "Epoch: 4530, Train Loss: 1.6710, Train Accuracy: 51.7838%\n",
      "Epoch: 4540, Train Loss: 1.6708, Train Accuracy: 51.7838%\n",
      "Epoch: 4550, Train Loss: 1.6706, Train Accuracy: 51.7838%\n",
      "Epoch: 4560, Train Loss: 1.6704, Train Accuracy: 51.7838%\n",
      "Epoch: 4570, Train Loss: 1.6702, Train Accuracy: 51.7838%\n",
      "Epoch: 4580, Train Loss: 1.6700, Train Accuracy: 51.7838%\n",
      "Epoch: 4590, Train Loss: 1.6698, Train Accuracy: 51.7838%\n",
      "Epoch: 4600, Train Loss: 1.6696, Train Accuracy: 51.7838%\n",
      "Epoch: 4610, Train Loss: 1.6693, Train Accuracy: 51.7838%\n",
      "Epoch: 4620, Train Loss: 1.6691, Train Accuracy: 51.7838%\n",
      "Epoch: 4630, Train Loss: 1.6689, Train Accuracy: 51.7838%\n",
      "Epoch: 4640, Train Loss: 1.6687, Train Accuracy: 51.7838%\n",
      "Epoch: 4650, Train Loss: 1.6685, Train Accuracy: 51.7838%\n",
      "Epoch: 4660, Train Loss: 1.6683, Train Accuracy: 51.7838%\n",
      "Epoch: 4670, Train Loss: 1.6681, Train Accuracy: 51.7838%\n",
      "Epoch: 4680, Train Loss: 1.6679, Train Accuracy: 51.7838%\n",
      "Epoch: 4690, Train Loss: 1.6677, Train Accuracy: 51.7838%\n",
      "Epoch: 4700, Train Loss: 1.6675, Train Accuracy: 51.7838%\n",
      "Epoch: 4710, Train Loss: 1.6673, Train Accuracy: 51.7838%\n",
      "Epoch: 4720, Train Loss: 1.6671, Train Accuracy: 51.7838%\n",
      "Epoch: 4730, Train Loss: 1.6669, Train Accuracy: 51.7838%\n",
      "Epoch: 4740, Train Loss: 1.6667, Train Accuracy: 51.7838%\n",
      "Epoch: 4750, Train Loss: 1.6666, Train Accuracy: 51.7838%\n",
      "Epoch: 4760, Train Loss: 1.6664, Train Accuracy: 51.7838%\n",
      "Epoch: 4770, Train Loss: 1.6662, Train Accuracy: 51.7838%\n",
      "Epoch: 4780, Train Loss: 1.6660, Train Accuracy: 51.7838%\n",
      "Epoch: 4790, Train Loss: 1.6658, Train Accuracy: 51.8919%\n",
      "Epoch: 4800, Train Loss: 1.6656, Train Accuracy: 51.8919%\n",
      "Epoch: 4810, Train Loss: 1.6654, Train Accuracy: 51.8919%\n",
      "Epoch: 4820, Train Loss: 1.6652, Train Accuracy: 51.8919%\n",
      "Epoch: 4830, Train Loss: 1.6650, Train Accuracy: 51.8919%\n",
      "Epoch: 4840, Train Loss: 1.6648, Train Accuracy: 51.8919%\n",
      "Epoch: 4850, Train Loss: 1.6646, Train Accuracy: 52.0000%\n",
      "Epoch: 4860, Train Loss: 1.6644, Train Accuracy: 52.0000%\n",
      "Epoch: 4870, Train Loss: 1.6642, Train Accuracy: 52.0000%\n",
      "Epoch: 4880, Train Loss: 1.6640, Train Accuracy: 52.0000%\n",
      "Epoch: 4890, Train Loss: 1.6638, Train Accuracy: 52.0000%\n",
      "Epoch: 4900, Train Loss: 1.6636, Train Accuracy: 52.0000%\n",
      "Epoch: 4910, Train Loss: 1.6634, Train Accuracy: 52.0000%\n",
      "Epoch: 4920, Train Loss: 1.6632, Train Accuracy: 52.0000%\n",
      "Epoch: 4930, Train Loss: 1.6630, Train Accuracy: 52.0000%\n",
      "Epoch: 4940, Train Loss: 1.6628, Train Accuracy: 52.0000%\n",
      "Epoch: 4950, Train Loss: 1.6626, Train Accuracy: 52.0000%\n",
      "Epoch: 4960, Train Loss: 1.6624, Train Accuracy: 52.0000%\n",
      "Epoch: 4970, Train Loss: 1.6622, Train Accuracy: 52.0000%\n",
      "Epoch: 4980, Train Loss: 1.6620, Train Accuracy: 52.0000%\n",
      "Epoch: 4990, Train Loss: 1.6619, Train Accuracy: 52.0000%\n",
      "Epoch: 5000, Train Loss: 1.6617, Train Accuracy: 52.0000%\n",
      "Epoch: 5010, Train Loss: 1.6615, Train Accuracy: 52.0000%\n",
      "Epoch: 5020, Train Loss: 1.6613, Train Accuracy: 52.0000%\n",
      "Epoch: 5030, Train Loss: 1.6611, Train Accuracy: 52.0000%\n",
      "Epoch: 5040, Train Loss: 1.6609, Train Accuracy: 52.0000%\n",
      "Epoch: 5050, Train Loss: 1.6607, Train Accuracy: 52.0000%\n",
      "Epoch: 5060, Train Loss: 1.6605, Train Accuracy: 52.0000%\n",
      "Epoch: 5070, Train Loss: 1.6603, Train Accuracy: 52.0000%\n",
      "Epoch: 5080, Train Loss: 1.6601, Train Accuracy: 52.0000%\n",
      "Epoch: 5090, Train Loss: 1.6599, Train Accuracy: 52.0000%\n",
      "Epoch: 5100, Train Loss: 1.6597, Train Accuracy: 52.0000%\n",
      "Epoch: 5110, Train Loss: 1.6596, Train Accuracy: 52.0000%\n",
      "Epoch: 5120, Train Loss: 1.6594, Train Accuracy: 52.1081%\n",
      "Epoch: 5130, Train Loss: 1.6592, Train Accuracy: 52.1081%\n",
      "Epoch: 5140, Train Loss: 1.6590, Train Accuracy: 52.1081%\n",
      "Epoch: 5150, Train Loss: 1.6588, Train Accuracy: 52.1081%\n",
      "Epoch: 5160, Train Loss: 1.6586, Train Accuracy: 52.1081%\n",
      "Epoch: 5170, Train Loss: 1.6584, Train Accuracy: 52.1081%\n",
      "Epoch: 5180, Train Loss: 1.6582, Train Accuracy: 52.1081%\n",
      "Epoch: 5190, Train Loss: 1.6580, Train Accuracy: 52.2162%\n",
      "Epoch: 5200, Train Loss: 1.6578, Train Accuracy: 52.2162%\n",
      "Epoch: 5210, Train Loss: 1.6577, Train Accuracy: 52.2162%\n",
      "Epoch: 5220, Train Loss: 1.6575, Train Accuracy: 52.2162%\n",
      "Epoch: 5230, Train Loss: 1.6573, Train Accuracy: 52.2162%\n",
      "Epoch: 5240, Train Loss: 1.6571, Train Accuracy: 52.2162%\n",
      "Epoch: 5250, Train Loss: 1.6569, Train Accuracy: 52.2162%\n",
      "Epoch: 5260, Train Loss: 1.6567, Train Accuracy: 52.2162%\n",
      "Epoch: 5270, Train Loss: 1.6565, Train Accuracy: 52.2162%\n",
      "Epoch: 5280, Train Loss: 1.6563, Train Accuracy: 52.2162%\n",
      "Epoch: 5290, Train Loss: 1.6562, Train Accuracy: 52.2162%\n",
      "Epoch: 5300, Train Loss: 1.6560, Train Accuracy: 52.2162%\n",
      "Epoch: 5310, Train Loss: 1.6558, Train Accuracy: 52.2162%\n",
      "Epoch: 5320, Train Loss: 1.6556, Train Accuracy: 52.2162%\n",
      "Epoch: 5330, Train Loss: 1.6554, Train Accuracy: 52.2162%\n",
      "Epoch: 5340, Train Loss: 1.6552, Train Accuracy: 52.2162%\n",
      "Epoch: 5350, Train Loss: 1.6550, Train Accuracy: 52.2162%\n",
      "Epoch: 5360, Train Loss: 1.6549, Train Accuracy: 52.2162%\n",
      "Epoch: 5370, Train Loss: 1.6547, Train Accuracy: 52.2162%\n",
      "Epoch: 5380, Train Loss: 1.6545, Train Accuracy: 52.2162%\n",
      "Epoch: 5390, Train Loss: 1.6543, Train Accuracy: 52.2162%\n",
      "Epoch: 5400, Train Loss: 1.6541, Train Accuracy: 52.2162%\n",
      "Epoch: 5410, Train Loss: 1.6539, Train Accuracy: 52.2162%\n",
      "Epoch: 5420, Train Loss: 1.6537, Train Accuracy: 52.2162%\n",
      "Epoch: 5430, Train Loss: 1.6536, Train Accuracy: 52.2162%\n",
      "Epoch: 5440, Train Loss: 1.6534, Train Accuracy: 52.2162%\n",
      "Epoch: 5450, Train Loss: 1.6532, Train Accuracy: 52.2162%\n",
      "Epoch: 5460, Train Loss: 1.6530, Train Accuracy: 52.2162%\n",
      "Epoch: 5470, Train Loss: 1.6528, Train Accuracy: 52.2162%\n",
      "Epoch: 5480, Train Loss: 1.6526, Train Accuracy: 52.2162%\n",
      "Epoch: 5490, Train Loss: 1.6525, Train Accuracy: 52.1081%\n",
      "Epoch: 5500, Train Loss: 1.6523, Train Accuracy: 52.2162%\n",
      "Epoch: 5510, Train Loss: 1.6521, Train Accuracy: 52.2162%\n",
      "Epoch: 5520, Train Loss: 1.6519, Train Accuracy: 52.3243%\n",
      "Epoch: 5530, Train Loss: 1.6517, Train Accuracy: 52.3243%\n",
      "Epoch: 5540, Train Loss: 1.6516, Train Accuracy: 52.3243%\n",
      "Epoch: 5550, Train Loss: 1.6514, Train Accuracy: 52.3243%\n",
      "Epoch: 5560, Train Loss: 1.6512, Train Accuracy: 52.3243%\n",
      "Epoch: 5570, Train Loss: 1.6510, Train Accuracy: 52.3243%\n",
      "Epoch: 5580, Train Loss: 1.6508, Train Accuracy: 52.3243%\n",
      "Epoch: 5590, Train Loss: 1.6506, Train Accuracy: 52.3243%\n",
      "Epoch: 5600, Train Loss: 1.6505, Train Accuracy: 52.3243%\n",
      "Epoch: 5610, Train Loss: 1.6503, Train Accuracy: 52.3243%\n",
      "Epoch: 5620, Train Loss: 1.6501, Train Accuracy: 52.3243%\n",
      "Epoch: 5630, Train Loss: 1.6499, Train Accuracy: 52.3243%\n",
      "Epoch: 5640, Train Loss: 1.6497, Train Accuracy: 52.3243%\n",
      "Epoch: 5650, Train Loss: 1.6496, Train Accuracy: 52.3243%\n",
      "Epoch: 5660, Train Loss: 1.6494, Train Accuracy: 52.3243%\n",
      "Epoch: 5670, Train Loss: 1.6492, Train Accuracy: 52.3243%\n",
      "Epoch: 5680, Train Loss: 1.6490, Train Accuracy: 52.3243%\n",
      "Epoch: 5690, Train Loss: 1.6488, Train Accuracy: 52.3243%\n",
      "Epoch: 5700, Train Loss: 1.6487, Train Accuracy: 52.3243%\n",
      "Epoch: 5710, Train Loss: 1.6485, Train Accuracy: 52.3243%\n",
      "Epoch: 5720, Train Loss: 1.6483, Train Accuracy: 52.3243%\n",
      "Epoch: 5730, Train Loss: 1.6481, Train Accuracy: 52.3243%\n",
      "Epoch: 5740, Train Loss: 1.6480, Train Accuracy: 52.3243%\n",
      "Epoch: 5750, Train Loss: 1.6478, Train Accuracy: 52.3243%\n",
      "Epoch: 5760, Train Loss: 1.6476, Train Accuracy: 52.3243%\n",
      "Epoch: 5770, Train Loss: 1.6474, Train Accuracy: 52.3243%\n",
      "Epoch: 5780, Train Loss: 1.6472, Train Accuracy: 52.3243%\n",
      "Epoch: 5790, Train Loss: 1.6471, Train Accuracy: 52.3243%\n",
      "Epoch: 5800, Train Loss: 1.6469, Train Accuracy: 52.3243%\n",
      "Epoch: 5810, Train Loss: 1.6467, Train Accuracy: 52.3243%\n",
      "Epoch: 5820, Train Loss: 1.6465, Train Accuracy: 52.3243%\n",
      "Epoch: 5830, Train Loss: 1.6464, Train Accuracy: 52.3243%\n",
      "Epoch: 5840, Train Loss: 1.6462, Train Accuracy: 52.3243%\n",
      "Epoch: 5850, Train Loss: 1.6460, Train Accuracy: 52.3243%\n",
      "Epoch: 5860, Train Loss: 1.6458, Train Accuracy: 52.3243%\n",
      "Epoch: 5870, Train Loss: 1.6457, Train Accuracy: 52.3243%\n",
      "Epoch: 5880, Train Loss: 1.6455, Train Accuracy: 52.3243%\n",
      "Epoch: 5890, Train Loss: 1.6453, Train Accuracy: 52.3243%\n",
      "Epoch: 5900, Train Loss: 1.6451, Train Accuracy: 52.3243%\n",
      "Epoch: 5910, Train Loss: 1.6450, Train Accuracy: 52.3243%\n",
      "Epoch: 5920, Train Loss: 1.6448, Train Accuracy: 52.3243%\n",
      "Epoch: 5930, Train Loss: 1.6446, Train Accuracy: 52.3243%\n",
      "Epoch: 5940, Train Loss: 1.6444, Train Accuracy: 52.4324%\n",
      "Epoch: 5950, Train Loss: 1.6443, Train Accuracy: 52.4324%\n",
      "Epoch: 5960, Train Loss: 1.6441, Train Accuracy: 52.4324%\n",
      "Epoch: 5970, Train Loss: 1.6439, Train Accuracy: 52.4324%\n",
      "Epoch: 5980, Train Loss: 1.6437, Train Accuracy: 52.4324%\n",
      "Epoch: 5990, Train Loss: 1.6436, Train Accuracy: 52.4324%\n",
      "Epoch: 6000, Train Loss: 1.6434, Train Accuracy: 52.4324%\n",
      "Epoch: 6010, Train Loss: 1.6432, Train Accuracy: 52.4324%\n",
      "Epoch: 6020, Train Loss: 1.6431, Train Accuracy: 52.5405%\n",
      "Epoch: 6030, Train Loss: 1.6429, Train Accuracy: 52.5405%\n",
      "Epoch: 6040, Train Loss: 1.6427, Train Accuracy: 52.4324%\n",
      "Epoch: 6050, Train Loss: 1.6425, Train Accuracy: 52.4324%\n",
      "Epoch: 6060, Train Loss: 1.6424, Train Accuracy: 52.4324%\n",
      "Epoch: 6070, Train Loss: 1.6422, Train Accuracy: 52.4324%\n",
      "Epoch: 6080, Train Loss: 1.6420, Train Accuracy: 52.4324%\n",
      "Epoch: 6090, Train Loss: 1.6419, Train Accuracy: 52.4324%\n",
      "Epoch: 6100, Train Loss: 1.6417, Train Accuracy: 52.4324%\n",
      "Epoch: 6110, Train Loss: 1.6415, Train Accuracy: 52.4324%\n",
      "Epoch: 6120, Train Loss: 1.6413, Train Accuracy: 52.4324%\n",
      "Epoch: 6130, Train Loss: 1.6412, Train Accuracy: 52.4324%\n",
      "Epoch: 6140, Train Loss: 1.6410, Train Accuracy: 52.4324%\n",
      "Epoch: 6150, Train Loss: 1.6408, Train Accuracy: 52.4324%\n",
      "Epoch: 6160, Train Loss: 1.6407, Train Accuracy: 52.4324%\n",
      "Epoch: 6170, Train Loss: 1.6405, Train Accuracy: 52.4324%\n",
      "Epoch: 6180, Train Loss: 1.6403, Train Accuracy: 52.4324%\n",
      "Epoch: 6190, Train Loss: 1.6402, Train Accuracy: 52.4324%\n",
      "Epoch: 6200, Train Loss: 1.6400, Train Accuracy: 52.4324%\n",
      "Epoch: 6210, Train Loss: 1.6398, Train Accuracy: 52.4324%\n",
      "Epoch: 6220, Train Loss: 1.6396, Train Accuracy: 52.4324%\n",
      "Epoch: 6230, Train Loss: 1.6395, Train Accuracy: 52.4324%\n",
      "Epoch: 6240, Train Loss: 1.6393, Train Accuracy: 52.4324%\n",
      "Epoch: 6250, Train Loss: 1.6391, Train Accuracy: 52.4324%\n",
      "Epoch: 6260, Train Loss: 1.6390, Train Accuracy: 52.4324%\n",
      "Epoch: 6270, Train Loss: 1.6388, Train Accuracy: 52.4324%\n",
      "Epoch: 6280, Train Loss: 1.6386, Train Accuracy: 52.4324%\n",
      "Epoch: 6290, Train Loss: 1.6385, Train Accuracy: 52.4324%\n",
      "Epoch: 6300, Train Loss: 1.6383, Train Accuracy: 52.4324%\n",
      "Epoch: 6310, Train Loss: 1.6381, Train Accuracy: 52.4324%\n",
      "Epoch: 6320, Train Loss: 1.6380, Train Accuracy: 52.4324%\n",
      "Epoch: 6330, Train Loss: 1.6378, Train Accuracy: 52.4324%\n",
      "Epoch: 6340, Train Loss: 1.6376, Train Accuracy: 52.4324%\n",
      "Epoch: 6350, Train Loss: 1.6375, Train Accuracy: 52.4324%\n",
      "Epoch: 6360, Train Loss: 1.6373, Train Accuracy: 52.4324%\n",
      "Epoch: 6370, Train Loss: 1.6371, Train Accuracy: 52.4324%\n",
      "Epoch: 6380, Train Loss: 1.6370, Train Accuracy: 52.4324%\n",
      "Epoch: 6390, Train Loss: 1.6368, Train Accuracy: 52.4324%\n",
      "Epoch: 6400, Train Loss: 1.6366, Train Accuracy: 52.4324%\n",
      "Epoch: 6410, Train Loss: 1.6365, Train Accuracy: 52.4324%\n",
      "Epoch: 6420, Train Loss: 1.6363, Train Accuracy: 52.4324%\n",
      "Epoch: 6430, Train Loss: 1.6361, Train Accuracy: 52.4324%\n",
      "Epoch: 6440, Train Loss: 1.6360, Train Accuracy: 52.4324%\n",
      "Epoch: 6450, Train Loss: 1.6358, Train Accuracy: 52.4324%\n",
      "Epoch: 6460, Train Loss: 1.6356, Train Accuracy: 52.4324%\n",
      "Epoch: 6470, Train Loss: 1.6355, Train Accuracy: 52.4324%\n",
      "Epoch: 6480, Train Loss: 1.6353, Train Accuracy: 52.5405%\n",
      "Epoch: 6490, Train Loss: 1.6352, Train Accuracy: 52.5405%\n",
      "Epoch: 6500, Train Loss: 1.6350, Train Accuracy: 52.5405%\n",
      "Epoch: 6510, Train Loss: 1.6348, Train Accuracy: 52.5405%\n",
      "Epoch: 6520, Train Loss: 1.6347, Train Accuracy: 52.5405%\n",
      "Epoch: 6530, Train Loss: 1.6345, Train Accuracy: 52.5405%\n",
      "Epoch: 6540, Train Loss: 1.6343, Train Accuracy: 52.5405%\n",
      "Epoch: 6550, Train Loss: 1.6342, Train Accuracy: 52.5405%\n",
      "Epoch: 6560, Train Loss: 1.6340, Train Accuracy: 52.5405%\n",
      "Epoch: 6570, Train Loss: 1.6338, Train Accuracy: 52.5405%\n",
      "Epoch: 6580, Train Loss: 1.6337, Train Accuracy: 52.5405%\n",
      "Epoch: 6590, Train Loss: 1.6335, Train Accuracy: 52.5405%\n",
      "Epoch: 6600, Train Loss: 1.6334, Train Accuracy: 52.5405%\n",
      "Epoch: 6610, Train Loss: 1.6332, Train Accuracy: 52.5405%\n",
      "Epoch: 6620, Train Loss: 1.6330, Train Accuracy: 52.5405%\n",
      "Epoch: 6630, Train Loss: 1.6329, Train Accuracy: 52.5405%\n",
      "Epoch: 6640, Train Loss: 1.6327, Train Accuracy: 52.5405%\n",
      "Epoch: 6650, Train Loss: 1.6326, Train Accuracy: 52.5405%\n",
      "Epoch: 6660, Train Loss: 1.6324, Train Accuracy: 52.5405%\n",
      "Epoch: 6670, Train Loss: 1.6322, Train Accuracy: 52.5405%\n",
      "Epoch: 6680, Train Loss: 1.6321, Train Accuracy: 52.5405%\n",
      "Epoch: 6690, Train Loss: 1.6319, Train Accuracy: 52.5405%\n",
      "Epoch: 6700, Train Loss: 1.6318, Train Accuracy: 52.5405%\n",
      "Epoch: 6710, Train Loss: 1.6316, Train Accuracy: 52.5405%\n",
      "Epoch: 6720, Train Loss: 1.6314, Train Accuracy: 52.5405%\n",
      "Epoch: 6730, Train Loss: 1.6313, Train Accuracy: 52.5405%\n",
      "Epoch: 6740, Train Loss: 1.6311, Train Accuracy: 52.5405%\n",
      "Epoch: 6750, Train Loss: 1.6310, Train Accuracy: 52.5405%\n",
      "Epoch: 6760, Train Loss: 1.6308, Train Accuracy: 52.5405%\n",
      "Epoch: 6770, Train Loss: 1.6306, Train Accuracy: 52.5405%\n",
      "Epoch: 6780, Train Loss: 1.6305, Train Accuracy: 52.5405%\n",
      "Epoch: 6790, Train Loss: 1.6303, Train Accuracy: 52.5405%\n",
      "Epoch: 6800, Train Loss: 1.6302, Train Accuracy: 52.5405%\n",
      "Epoch: 6810, Train Loss: 1.6300, Train Accuracy: 52.6486%\n",
      "Epoch: 6820, Train Loss: 1.6298, Train Accuracy: 52.6486%\n",
      "Epoch: 6830, Train Loss: 1.6297, Train Accuracy: 52.6486%\n",
      "Epoch: 6840, Train Loss: 1.6295, Train Accuracy: 52.6486%\n",
      "Epoch: 6850, Train Loss: 1.6294, Train Accuracy: 52.6486%\n",
      "Epoch: 6860, Train Loss: 1.6292, Train Accuracy: 52.6486%\n",
      "Epoch: 6870, Train Loss: 1.6291, Train Accuracy: 52.6486%\n",
      "Epoch: 6880, Train Loss: 1.6289, Train Accuracy: 52.6486%\n",
      "Epoch: 6890, Train Loss: 1.6287, Train Accuracy: 52.6486%\n",
      "Epoch: 6900, Train Loss: 1.6286, Train Accuracy: 52.6486%\n",
      "Epoch: 6910, Train Loss: 1.6284, Train Accuracy: 52.6486%\n",
      "Epoch: 6920, Train Loss: 1.6283, Train Accuracy: 52.6486%\n",
      "Epoch: 6930, Train Loss: 1.6281, Train Accuracy: 52.6486%\n",
      "Epoch: 6940, Train Loss: 1.6280, Train Accuracy: 52.6486%\n",
      "Epoch: 6950, Train Loss: 1.6278, Train Accuracy: 52.6486%\n",
      "Epoch: 6960, Train Loss: 1.6276, Train Accuracy: 52.6486%\n",
      "Epoch: 6970, Train Loss: 1.6275, Train Accuracy: 52.6486%\n",
      "Epoch: 6980, Train Loss: 1.6273, Train Accuracy: 52.6486%\n",
      "Epoch: 6990, Train Loss: 1.6272, Train Accuracy: 52.6486%\n",
      "Epoch: 7000, Train Loss: 1.6270, Train Accuracy: 52.6486%\n",
      "Epoch: 7010, Train Loss: 1.6269, Train Accuracy: 52.6486%\n",
      "Epoch: 7020, Train Loss: 1.6267, Train Accuracy: 52.6486%\n",
      "Epoch: 7030, Train Loss: 1.6266, Train Accuracy: 52.6486%\n",
      "Epoch: 7040, Train Loss: 1.6264, Train Accuracy: 52.6486%\n",
      "Epoch: 7050, Train Loss: 1.6262, Train Accuracy: 52.6486%\n",
      "Epoch: 7060, Train Loss: 1.6261, Train Accuracy: 52.6486%\n",
      "Epoch: 7070, Train Loss: 1.6259, Train Accuracy: 52.6486%\n",
      "Epoch: 7080, Train Loss: 1.6258, Train Accuracy: 52.6486%\n",
      "Epoch: 7090, Train Loss: 1.6256, Train Accuracy: 52.6486%\n",
      "Epoch: 7100, Train Loss: 1.6255, Train Accuracy: 52.6486%\n",
      "Epoch: 7110, Train Loss: 1.6253, Train Accuracy: 52.6486%\n",
      "Epoch: 7120, Train Loss: 1.6252, Train Accuracy: 52.6486%\n",
      "Epoch: 7130, Train Loss: 1.6250, Train Accuracy: 52.6486%\n",
      "Epoch: 7140, Train Loss: 1.6249, Train Accuracy: 52.6486%\n",
      "Epoch: 7150, Train Loss: 1.6247, Train Accuracy: 52.6486%\n",
      "Epoch: 7160, Train Loss: 1.6246, Train Accuracy: 52.5405%\n",
      "Epoch: 7170, Train Loss: 1.6244, Train Accuracy: 52.5405%\n",
      "Epoch: 7180, Train Loss: 1.6243, Train Accuracy: 52.5405%\n",
      "Epoch: 7190, Train Loss: 1.6241, Train Accuracy: 52.5405%\n",
      "Epoch: 7200, Train Loss: 1.6239, Train Accuracy: 52.5405%\n",
      "Epoch: 7210, Train Loss: 1.6238, Train Accuracy: 52.5405%\n",
      "Epoch: 7220, Train Loss: 1.6236, Train Accuracy: 52.5405%\n",
      "Epoch: 7230, Train Loss: 1.6235, Train Accuracy: 52.5405%\n",
      "Epoch: 7240, Train Loss: 1.6233, Train Accuracy: 52.4324%\n",
      "Epoch: 7250, Train Loss: 1.6232, Train Accuracy: 52.4324%\n",
      "Epoch: 7260, Train Loss: 1.6230, Train Accuracy: 52.4324%\n",
      "Epoch: 7270, Train Loss: 1.6229, Train Accuracy: 52.4324%\n",
      "Epoch: 7280, Train Loss: 1.6227, Train Accuracy: 52.4324%\n",
      "Epoch: 7290, Train Loss: 1.6226, Train Accuracy: 52.4324%\n",
      "Epoch: 7300, Train Loss: 1.6224, Train Accuracy: 52.4324%\n",
      "Epoch: 7310, Train Loss: 1.6223, Train Accuracy: 52.4324%\n",
      "Epoch: 7320, Train Loss: 1.6221, Train Accuracy: 52.4324%\n",
      "Epoch: 7330, Train Loss: 1.6220, Train Accuracy: 52.4324%\n",
      "Epoch: 7340, Train Loss: 1.6218, Train Accuracy: 52.4324%\n",
      "Epoch: 7350, Train Loss: 1.6217, Train Accuracy: 52.4324%\n",
      "Epoch: 7360, Train Loss: 1.6215, Train Accuracy: 52.4324%\n",
      "Epoch: 7370, Train Loss: 1.6214, Train Accuracy: 52.4324%\n",
      "Epoch: 7380, Train Loss: 1.6212, Train Accuracy: 52.4324%\n",
      "Epoch: 7390, Train Loss: 1.6211, Train Accuracy: 52.4324%\n",
      "Epoch: 7400, Train Loss: 1.6209, Train Accuracy: 52.4324%\n",
      "Epoch: 7410, Train Loss: 1.6208, Train Accuracy: 52.4324%\n",
      "Epoch: 7420, Train Loss: 1.6206, Train Accuracy: 52.4324%\n",
      "Epoch: 7430, Train Loss: 1.6205, Train Accuracy: 52.4324%\n",
      "Epoch: 7440, Train Loss: 1.6203, Train Accuracy: 52.4324%\n",
      "Epoch: 7450, Train Loss: 1.6202, Train Accuracy: 52.4324%\n",
      "Epoch: 7460, Train Loss: 1.6201, Train Accuracy: 52.5405%\n",
      "Epoch: 7470, Train Loss: 1.6199, Train Accuracy: 52.5405%\n",
      "Epoch: 7480, Train Loss: 1.6198, Train Accuracy: 52.5405%\n",
      "Epoch: 7490, Train Loss: 1.6196, Train Accuracy: 52.5405%\n",
      "Epoch: 7500, Train Loss: 1.6195, Train Accuracy: 52.5405%\n",
      "Epoch: 7510, Train Loss: 1.6193, Train Accuracy: 52.5405%\n",
      "Epoch: 7520, Train Loss: 1.6192, Train Accuracy: 52.5405%\n",
      "Epoch: 7530, Train Loss: 1.6190, Train Accuracy: 52.5405%\n",
      "Epoch: 7540, Train Loss: 1.6189, Train Accuracy: 52.5405%\n",
      "Epoch: 7550, Train Loss: 1.6187, Train Accuracy: 52.5405%\n",
      "Epoch: 7560, Train Loss: 1.6186, Train Accuracy: 52.5405%\n",
      "Epoch: 7570, Train Loss: 1.6184, Train Accuracy: 52.5405%\n",
      "Epoch: 7580, Train Loss: 1.6183, Train Accuracy: 52.5405%\n",
      "Epoch: 7590, Train Loss: 1.6181, Train Accuracy: 52.5405%\n",
      "Epoch: 7600, Train Loss: 1.6180, Train Accuracy: 52.5405%\n",
      "Epoch: 7610, Train Loss: 1.6179, Train Accuracy: 52.5405%\n",
      "Epoch: 7620, Train Loss: 1.6177, Train Accuracy: 52.5405%\n",
      "Epoch: 7630, Train Loss: 1.6176, Train Accuracy: 52.5405%\n",
      "Epoch: 7640, Train Loss: 1.6174, Train Accuracy: 52.5405%\n",
      "Epoch: 7650, Train Loss: 1.6173, Train Accuracy: 52.6486%\n",
      "Epoch: 7660, Train Loss: 1.6171, Train Accuracy: 52.6486%\n",
      "Epoch: 7670, Train Loss: 1.6170, Train Accuracy: 52.6486%\n",
      "Epoch: 7680, Train Loss: 1.6168, Train Accuracy: 52.6486%\n",
      "Epoch: 7690, Train Loss: 1.6167, Train Accuracy: 52.6486%\n",
      "Epoch: 7700, Train Loss: 1.6166, Train Accuracy: 52.6486%\n",
      "Epoch: 7710, Train Loss: 1.6164, Train Accuracy: 52.7568%\n",
      "Epoch: 7720, Train Loss: 1.6163, Train Accuracy: 52.7568%\n",
      "Epoch: 7730, Train Loss: 1.6161, Train Accuracy: 52.7568%\n",
      "Epoch: 7740, Train Loss: 1.6160, Train Accuracy: 52.7568%\n",
      "Epoch: 7750, Train Loss: 1.6158, Train Accuracy: 52.7568%\n",
      "Epoch: 7760, Train Loss: 1.6157, Train Accuracy: 52.7568%\n",
      "Epoch: 7770, Train Loss: 1.6155, Train Accuracy: 52.7568%\n",
      "Epoch: 7780, Train Loss: 1.6154, Train Accuracy: 52.7568%\n",
      "Epoch: 7790, Train Loss: 1.6153, Train Accuracy: 52.7568%\n",
      "Epoch: 7800, Train Loss: 1.6151, Train Accuracy: 52.7568%\n",
      "Epoch: 7810, Train Loss: 1.6150, Train Accuracy: 52.7568%\n",
      "Epoch: 7820, Train Loss: 1.6148, Train Accuracy: 52.7568%\n",
      "Epoch: 7830, Train Loss: 1.6147, Train Accuracy: 52.7568%\n",
      "Epoch: 7840, Train Loss: 1.6145, Train Accuracy: 52.7568%\n",
      "Epoch: 7850, Train Loss: 1.6144, Train Accuracy: 52.7568%\n",
      "Epoch: 7860, Train Loss: 1.6143, Train Accuracy: 52.7568%\n",
      "Epoch: 7870, Train Loss: 1.6141, Train Accuracy: 52.7568%\n",
      "Epoch: 7880, Train Loss: 1.6140, Train Accuracy: 52.7568%\n",
      "Epoch: 7890, Train Loss: 1.6138, Train Accuracy: 52.7568%\n",
      "Epoch: 7900, Train Loss: 1.6137, Train Accuracy: 52.7568%\n",
      "Epoch: 7910, Train Loss: 1.6136, Train Accuracy: 52.7568%\n",
      "Epoch: 7920, Train Loss: 1.6134, Train Accuracy: 52.6486%\n",
      "Epoch: 7930, Train Loss: 1.6133, Train Accuracy: 52.6486%\n",
      "Epoch: 7940, Train Loss: 1.6131, Train Accuracy: 52.6486%\n",
      "Epoch: 7950, Train Loss: 1.6130, Train Accuracy: 52.6486%\n",
      "Epoch: 7960, Train Loss: 1.6129, Train Accuracy: 52.6486%\n",
      "Epoch: 7970, Train Loss: 1.6127, Train Accuracy: 52.6486%\n",
      "Epoch: 7980, Train Loss: 1.6126, Train Accuracy: 52.6486%\n",
      "Epoch: 7990, Train Loss: 1.6124, Train Accuracy: 52.6486%\n",
      "Epoch: 8000, Train Loss: 1.6123, Train Accuracy: 52.6486%\n",
      "Epoch: 8010, Train Loss: 1.6122, Train Accuracy: 52.6486%\n",
      "Epoch: 8020, Train Loss: 1.6120, Train Accuracy: 52.6486%\n",
      "Epoch: 8030, Train Loss: 1.6119, Train Accuracy: 52.6486%\n",
      "Epoch: 8040, Train Loss: 1.6117, Train Accuracy: 52.6486%\n",
      "Epoch: 8050, Train Loss: 1.6116, Train Accuracy: 52.6486%\n",
      "Epoch: 8060, Train Loss: 1.6115, Train Accuracy: 52.6486%\n",
      "Epoch: 8070, Train Loss: 1.6113, Train Accuracy: 52.6486%\n",
      "Epoch: 8080, Train Loss: 1.6112, Train Accuracy: 52.6486%\n",
      "Epoch: 8090, Train Loss: 1.6110, Train Accuracy: 52.6486%\n",
      "Epoch: 8100, Train Loss: 1.6109, Train Accuracy: 52.6486%\n",
      "Epoch: 8110, Train Loss: 1.6108, Train Accuracy: 52.6486%\n",
      "Epoch: 8120, Train Loss: 1.6106, Train Accuracy: 52.6486%\n",
      "Epoch: 8130, Train Loss: 1.6105, Train Accuracy: 52.6486%\n",
      "Epoch: 8140, Train Loss: 1.6104, Train Accuracy: 52.6486%\n",
      "Epoch: 8150, Train Loss: 1.6102, Train Accuracy: 52.6486%\n",
      "Epoch: 8160, Train Loss: 1.6101, Train Accuracy: 52.6486%\n",
      "Epoch: 8170, Train Loss: 1.6099, Train Accuracy: 52.6486%\n",
      "Epoch: 8180, Train Loss: 1.6098, Train Accuracy: 52.6486%\n",
      "Epoch: 8190, Train Loss: 1.6097, Train Accuracy: 52.6486%\n",
      "Epoch: 8200, Train Loss: 1.6095, Train Accuracy: 52.6486%\n",
      "Epoch: 8210, Train Loss: 1.6094, Train Accuracy: 52.6486%\n",
      "Epoch: 8220, Train Loss: 1.6093, Train Accuracy: 52.6486%\n",
      "Epoch: 8230, Train Loss: 1.6091, Train Accuracy: 52.6486%\n",
      "Epoch: 8240, Train Loss: 1.6090, Train Accuracy: 52.6486%\n",
      "Epoch: 8250, Train Loss: 1.6088, Train Accuracy: 52.6486%\n",
      "Epoch: 8260, Train Loss: 1.6087, Train Accuracy: 52.6486%\n",
      "Epoch: 8270, Train Loss: 1.6086, Train Accuracy: 52.6486%\n",
      "Epoch: 8280, Train Loss: 1.6084, Train Accuracy: 52.6486%\n",
      "Epoch: 8290, Train Loss: 1.6083, Train Accuracy: 52.6486%\n",
      "Epoch: 8300, Train Loss: 1.6082, Train Accuracy: 52.6486%\n",
      "Epoch: 8310, Train Loss: 1.6080, Train Accuracy: 52.6486%\n",
      "Epoch: 8320, Train Loss: 1.6079, Train Accuracy: 52.6486%\n",
      "Epoch: 8330, Train Loss: 1.6078, Train Accuracy: 52.6486%\n",
      "Epoch: 8340, Train Loss: 1.6076, Train Accuracy: 52.6486%\n",
      "Epoch: 8350, Train Loss: 1.6075, Train Accuracy: 52.6486%\n",
      "Epoch: 8360, Train Loss: 1.6074, Train Accuracy: 52.6486%\n",
      "Epoch: 8370, Train Loss: 1.6072, Train Accuracy: 52.6486%\n",
      "Epoch: 8380, Train Loss: 1.6071, Train Accuracy: 52.6486%\n",
      "Epoch: 8390, Train Loss: 1.6070, Train Accuracy: 52.6486%\n",
      "Epoch: 8400, Train Loss: 1.6068, Train Accuracy: 52.6486%\n",
      "Epoch: 8410, Train Loss: 1.6067, Train Accuracy: 52.6486%\n",
      "Epoch: 8420, Train Loss: 1.6066, Train Accuracy: 52.6486%\n",
      "Epoch: 8430, Train Loss: 1.6064, Train Accuracy: 52.6486%\n",
      "Epoch: 8440, Train Loss: 1.6063, Train Accuracy: 52.6486%\n",
      "Epoch: 8450, Train Loss: 1.6062, Train Accuracy: 52.6486%\n",
      "Epoch: 8460, Train Loss: 1.6060, Train Accuracy: 52.6486%\n",
      "Epoch: 8470, Train Loss: 1.6059, Train Accuracy: 52.6486%\n",
      "Epoch: 8480, Train Loss: 1.6058, Train Accuracy: 52.6486%\n",
      "Epoch: 8490, Train Loss: 1.6056, Train Accuracy: 52.6486%\n",
      "Epoch: 8500, Train Loss: 1.6055, Train Accuracy: 52.6486%\n",
      "Epoch: 8510, Train Loss: 1.6054, Train Accuracy: 52.6486%\n",
      "Epoch: 8520, Train Loss: 1.6052, Train Accuracy: 52.6486%\n",
      "Epoch: 8530, Train Loss: 1.6051, Train Accuracy: 52.6486%\n",
      "Epoch: 8540, Train Loss: 1.6050, Train Accuracy: 52.6486%\n",
      "Epoch: 8550, Train Loss: 1.6048, Train Accuracy: 52.6486%\n",
      "Epoch: 8560, Train Loss: 1.6047, Train Accuracy: 52.6486%\n",
      "Epoch: 8570, Train Loss: 1.6046, Train Accuracy: 52.6486%\n",
      "Epoch: 8580, Train Loss: 1.6044, Train Accuracy: 52.6486%\n",
      "Epoch: 8590, Train Loss: 1.6043, Train Accuracy: 52.6486%\n",
      "Epoch: 8600, Train Loss: 1.6042, Train Accuracy: 52.6486%\n",
      "Epoch: 8610, Train Loss: 1.6040, Train Accuracy: 52.6486%\n",
      "Epoch: 8620, Train Loss: 1.6039, Train Accuracy: 52.6486%\n",
      "Epoch: 8630, Train Loss: 1.6038, Train Accuracy: 52.6486%\n",
      "Epoch: 8640, Train Loss: 1.6036, Train Accuracy: 52.6486%\n",
      "Epoch: 8650, Train Loss: 1.6035, Train Accuracy: 52.6486%\n",
      "Epoch: 8660, Train Loss: 1.6034, Train Accuracy: 52.7568%\n",
      "Epoch: 8670, Train Loss: 1.6033, Train Accuracy: 52.7568%\n",
      "Epoch: 8680, Train Loss: 1.6031, Train Accuracy: 52.7568%\n",
      "Epoch: 8690, Train Loss: 1.6030, Train Accuracy: 52.7568%\n",
      "Epoch: 8700, Train Loss: 1.6029, Train Accuracy: 52.7568%\n",
      "Epoch: 8710, Train Loss: 1.6027, Train Accuracy: 52.7568%\n",
      "Epoch: 8720, Train Loss: 1.6026, Train Accuracy: 52.7568%\n",
      "Epoch: 8730, Train Loss: 1.6025, Train Accuracy: 52.7568%\n",
      "Epoch: 8740, Train Loss: 1.6023, Train Accuracy: 52.7568%\n",
      "Epoch: 8750, Train Loss: 1.6022, Train Accuracy: 52.7568%\n",
      "Epoch: 8760, Train Loss: 1.6021, Train Accuracy: 52.8649%\n",
      "Epoch: 8770, Train Loss: 1.6020, Train Accuracy: 52.8649%\n",
      "Epoch: 8780, Train Loss: 1.6018, Train Accuracy: 52.8649%\n",
      "Epoch: 8790, Train Loss: 1.6017, Train Accuracy: 52.8649%\n",
      "Epoch: 8800, Train Loss: 1.6016, Train Accuracy: 52.8649%\n",
      "Epoch: 8810, Train Loss: 1.6014, Train Accuracy: 52.8649%\n",
      "Epoch: 8820, Train Loss: 1.6013, Train Accuracy: 52.8649%\n",
      "Epoch: 8830, Train Loss: 1.6012, Train Accuracy: 52.8649%\n",
      "Epoch: 8840, Train Loss: 1.6011, Train Accuracy: 52.8649%\n",
      "Epoch: 8850, Train Loss: 1.6009, Train Accuracy: 52.8649%\n",
      "Epoch: 8860, Train Loss: 1.6008, Train Accuracy: 52.8649%\n",
      "Epoch: 8870, Train Loss: 1.6007, Train Accuracy: 52.8649%\n",
      "Epoch: 8880, Train Loss: 1.6005, Train Accuracy: 52.8649%\n",
      "Epoch: 8890, Train Loss: 1.6004, Train Accuracy: 52.8649%\n",
      "Epoch: 8900, Train Loss: 1.6003, Train Accuracy: 52.8649%\n",
      "Epoch: 8910, Train Loss: 1.6002, Train Accuracy: 52.8649%\n",
      "Epoch: 8920, Train Loss: 1.6000, Train Accuracy: 52.8649%\n",
      "Epoch: 8930, Train Loss: 1.5999, Train Accuracy: 52.8649%\n",
      "Epoch: 8940, Train Loss: 1.5998, Train Accuracy: 52.8649%\n",
      "Epoch: 8950, Train Loss: 1.5997, Train Accuracy: 52.8649%\n",
      "Epoch: 8960, Train Loss: 1.5995, Train Accuracy: 52.8649%\n",
      "Epoch: 8970, Train Loss: 1.5994, Train Accuracy: 52.8649%\n",
      "Epoch: 8980, Train Loss: 1.5993, Train Accuracy: 52.8649%\n",
      "Epoch: 8990, Train Loss: 1.5992, Train Accuracy: 52.8649%\n",
      "Epoch: 9000, Train Loss: 1.5990, Train Accuracy: 52.8649%\n",
      "Epoch: 9010, Train Loss: 1.5989, Train Accuracy: 52.8649%\n",
      "Epoch: 9020, Train Loss: 1.5988, Train Accuracy: 52.8649%\n",
      "Epoch: 9030, Train Loss: 1.5986, Train Accuracy: 52.8649%\n",
      "Epoch: 9040, Train Loss: 1.5985, Train Accuracy: 52.8649%\n",
      "Epoch: 9050, Train Loss: 1.5984, Train Accuracy: 52.8649%\n",
      "Epoch: 9060, Train Loss: 1.5983, Train Accuracy: 52.8649%\n",
      "Epoch: 9070, Train Loss: 1.5981, Train Accuracy: 52.8649%\n",
      "Epoch: 9080, Train Loss: 1.5980, Train Accuracy: 52.8649%\n",
      "Epoch: 9090, Train Loss: 1.5979, Train Accuracy: 52.8649%\n",
      "Epoch: 9100, Train Loss: 1.5978, Train Accuracy: 52.8649%\n",
      "Epoch: 9110, Train Loss: 1.5976, Train Accuracy: 52.8649%\n",
      "Epoch: 9120, Train Loss: 1.5975, Train Accuracy: 52.8649%\n",
      "Epoch: 9130, Train Loss: 1.5974, Train Accuracy: 52.8649%\n",
      "Epoch: 9140, Train Loss: 1.5973, Train Accuracy: 52.8649%\n",
      "Epoch: 9150, Train Loss: 1.5971, Train Accuracy: 52.8649%\n",
      "Epoch: 9160, Train Loss: 1.5970, Train Accuracy: 52.8649%\n",
      "Epoch: 9170, Train Loss: 1.5969, Train Accuracy: 52.8649%\n",
      "Epoch: 9180, Train Loss: 1.5968, Train Accuracy: 52.8649%\n",
      "Epoch: 9190, Train Loss: 1.5967, Train Accuracy: 52.8649%\n",
      "Epoch: 9200, Train Loss: 1.5965, Train Accuracy: 52.8649%\n",
      "Epoch: 9210, Train Loss: 1.5964, Train Accuracy: 52.8649%\n",
      "Epoch: 9220, Train Loss: 1.5963, Train Accuracy: 52.8649%\n",
      "Epoch: 9230, Train Loss: 1.5962, Train Accuracy: 52.7568%\n",
      "Epoch: 9240, Train Loss: 1.5960, Train Accuracy: 52.7568%\n",
      "Epoch: 9250, Train Loss: 1.5959, Train Accuracy: 52.7568%\n",
      "Epoch: 9260, Train Loss: 1.5958, Train Accuracy: 52.7568%\n",
      "Epoch: 9270, Train Loss: 1.5957, Train Accuracy: 52.7568%\n",
      "Epoch: 9280, Train Loss: 1.5955, Train Accuracy: 52.7568%\n",
      "Epoch: 9290, Train Loss: 1.5954, Train Accuracy: 52.7568%\n",
      "Epoch: 9300, Train Loss: 1.5953, Train Accuracy: 52.7568%\n",
      "Epoch: 9310, Train Loss: 1.5952, Train Accuracy: 52.7568%\n",
      "Epoch: 9320, Train Loss: 1.5951, Train Accuracy: 52.7568%\n",
      "Epoch: 9330, Train Loss: 1.5949, Train Accuracy: 52.7568%\n",
      "Epoch: 9340, Train Loss: 1.5948, Train Accuracy: 52.7568%\n",
      "Epoch: 9350, Train Loss: 1.5947, Train Accuracy: 52.7568%\n",
      "Epoch: 9360, Train Loss: 1.5946, Train Accuracy: 52.7568%\n",
      "Epoch: 9370, Train Loss: 1.5944, Train Accuracy: 52.7568%\n",
      "Epoch: 9380, Train Loss: 1.5943, Train Accuracy: 52.7568%\n",
      "Epoch: 9390, Train Loss: 1.5942, Train Accuracy: 52.7568%\n",
      "Epoch: 9400, Train Loss: 1.5941, Train Accuracy: 52.7568%\n",
      "Epoch: 9410, Train Loss: 1.5940, Train Accuracy: 52.7568%\n",
      "Epoch: 9420, Train Loss: 1.5938, Train Accuracy: 52.7568%\n",
      "Epoch: 9430, Train Loss: 1.5937, Train Accuracy: 52.7568%\n",
      "Epoch: 9440, Train Loss: 1.5936, Train Accuracy: 52.7568%\n",
      "Epoch: 9450, Train Loss: 1.5935, Train Accuracy: 52.7568%\n",
      "Epoch: 9460, Train Loss: 1.5934, Train Accuracy: 52.7568%\n",
      "Epoch: 9470, Train Loss: 1.5932, Train Accuracy: 52.7568%\n",
      "Epoch: 9480, Train Loss: 1.5931, Train Accuracy: 52.7568%\n",
      "Epoch: 9490, Train Loss: 1.5930, Train Accuracy: 52.7568%\n",
      "Epoch: 9500, Train Loss: 1.5929, Train Accuracy: 52.7568%\n",
      "Epoch: 9510, Train Loss: 1.5928, Train Accuracy: 52.7568%\n",
      "Epoch: 9520, Train Loss: 1.5926, Train Accuracy: 52.7568%\n",
      "Epoch: 9530, Train Loss: 1.5925, Train Accuracy: 52.7568%\n",
      "Epoch: 9540, Train Loss: 1.5924, Train Accuracy: 52.7568%\n",
      "Epoch: 9550, Train Loss: 1.5923, Train Accuracy: 52.7568%\n",
      "Epoch: 9560, Train Loss: 1.5922, Train Accuracy: 52.7568%\n",
      "Epoch: 9570, Train Loss: 1.5920, Train Accuracy: 52.7568%\n",
      "Epoch: 9580, Train Loss: 1.5919, Train Accuracy: 52.7568%\n",
      "Epoch: 9590, Train Loss: 1.5918, Train Accuracy: 52.7568%\n",
      "Epoch: 9600, Train Loss: 1.5917, Train Accuracy: 52.6486%\n",
      "Epoch: 9610, Train Loss: 1.5916, Train Accuracy: 52.6486%\n",
      "Epoch: 9620, Train Loss: 1.5915, Train Accuracy: 52.6486%\n",
      "Epoch: 9630, Train Loss: 1.5913, Train Accuracy: 52.6486%\n",
      "Epoch: 9640, Train Loss: 1.5912, Train Accuracy: 52.6486%\n",
      "Epoch: 9650, Train Loss: 1.5911, Train Accuracy: 52.6486%\n",
      "Epoch: 9660, Train Loss: 1.5910, Train Accuracy: 52.6486%\n",
      "Epoch: 9670, Train Loss: 1.5909, Train Accuracy: 52.6486%\n",
      "Epoch: 9680, Train Loss: 1.5907, Train Accuracy: 52.5405%\n",
      "Epoch: 9690, Train Loss: 1.5906, Train Accuracy: 52.5405%\n",
      "Epoch: 9700, Train Loss: 1.5905, Train Accuracy: 52.4324%\n",
      "Epoch: 9710, Train Loss: 1.5904, Train Accuracy: 52.4324%\n",
      "Epoch: 9720, Train Loss: 1.5903, Train Accuracy: 52.4324%\n",
      "Epoch: 9730, Train Loss: 1.5902, Train Accuracy: 52.4324%\n",
      "Epoch: 9740, Train Loss: 1.5900, Train Accuracy: 52.4324%\n",
      "Epoch: 9750, Train Loss: 1.5899, Train Accuracy: 52.4324%\n",
      "Epoch: 9760, Train Loss: 1.5898, Train Accuracy: 52.4324%\n",
      "Epoch: 9770, Train Loss: 1.5897, Train Accuracy: 52.4324%\n",
      "Epoch: 9780, Train Loss: 1.5896, Train Accuracy: 52.4324%\n",
      "Epoch: 9790, Train Loss: 1.5895, Train Accuracy: 52.4324%\n",
      "Epoch: 9800, Train Loss: 1.5893, Train Accuracy: 52.4324%\n",
      "Epoch: 9810, Train Loss: 1.5892, Train Accuracy: 52.4324%\n",
      "Epoch: 9820, Train Loss: 1.5891, Train Accuracy: 52.4324%\n",
      "Epoch: 9830, Train Loss: 1.5890, Train Accuracy: 52.4324%\n",
      "Epoch: 9840, Train Loss: 1.5889, Train Accuracy: 52.4324%\n",
      "Epoch: 9850, Train Loss: 1.5888, Train Accuracy: 52.4324%\n",
      "Epoch: 9860, Train Loss: 1.5886, Train Accuracy: 52.4324%\n",
      "Epoch: 9870, Train Loss: 1.5885, Train Accuracy: 52.4324%\n",
      "Epoch: 9880, Train Loss: 1.5884, Train Accuracy: 52.4324%\n",
      "Epoch: 9890, Train Loss: 1.5883, Train Accuracy: 52.4324%\n",
      "Epoch: 9900, Train Loss: 1.5882, Train Accuracy: 52.4324%\n",
      "Epoch: 9910, Train Loss: 1.5881, Train Accuracy: 52.4324%\n",
      "Epoch: 9920, Train Loss: 1.5880, Train Accuracy: 52.4324%\n",
      "Epoch: 9930, Train Loss: 1.5878, Train Accuracy: 52.4324%\n",
      "Epoch: 9940, Train Loss: 1.5877, Train Accuracy: 52.5405%\n",
      "Epoch: 9950, Train Loss: 1.5876, Train Accuracy: 52.5405%\n",
      "Epoch: 9960, Train Loss: 1.5875, Train Accuracy: 52.5405%\n",
      "Epoch: 9970, Train Loss: 1.5874, Train Accuracy: 52.5405%\n",
      "Epoch: 9980, Train Loss: 1.5873, Train Accuracy: 52.5405%\n",
      "Epoch: 9990, Train Loss: 1.5872, Train Accuracy: 52.5405%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:btdc8o80) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▂▂▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▃▄▄▅▅▆▆▆▇▆▆▇▇▇▇▇██▇▆▆</td></tr><tr><td>train_loss</td><td>███▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>███████▄▄▄▄▄▄▄▄▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▄▁▁▁▁</td></tr><tr><td>val_loss</td><td>███▇▇▇▇▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.52541</td></tr><tr><td>train_loss</td><td>1.58705</td></tr><tr><td>val_accuracy</td><td>0.53398</td></tr><tr><td>val_loss</td><td>1.5874</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.0002</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/btdc8o80' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/btdc8o80</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190322-btdc8o80/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:btdc8o80). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190341-gfnwlpp6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/gfnwlpp6' target=\"_blank\">Logistic Regression lr=0.3</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/gfnwlpp6' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/gfnwlpp6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.5378, Train Accuracy: 52.9730%\n",
      "Epoch: 20, Train Loss: 1.4769, Train Accuracy: 53.5135%\n",
      "Epoch: 30, Train Loss: 1.4535, Train Accuracy: 54.3784%\n",
      "Epoch: 40, Train Loss: 1.4416, Train Accuracy: 55.1351%\n",
      "Epoch: 50, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 60, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 70, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 80, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 90, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 100, Train Loss: 1.4199, Train Accuracy: 55.2432%\n",
      "Epoch: 110, Train Loss: 1.4186, Train Accuracy: 55.3514%\n",
      "Epoch: 120, Train Loss: 1.4175, Train Accuracy: 55.6757%\n",
      "Epoch: 130, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 140, Train Loss: 1.4158, Train Accuracy: 56.3243%\n",
      "Epoch: 150, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 160, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 170, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 180, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 190, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 200, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 210, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 220, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 230, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 240, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 250, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 260, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 270, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 280, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 290, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 300, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 310, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 320, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 330, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 340, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 350, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 360, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 370, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 380, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 390, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 400, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 410, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 420, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 430, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 440, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 450, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 460, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 470, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 480, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 490, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 500, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 510, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 520, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 530, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 540, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 550, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 560, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 570, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 580, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 590, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 600, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 610, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 620, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 630, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 640, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 650, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 660, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 670, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 680, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 690, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 700, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 710, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 720, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 730, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 740, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 750, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 760, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 770, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 780, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 790, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 800, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 810, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 820, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 830, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 840, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 850, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 860, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 870, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 880, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 890, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 900, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 910, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 920, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 930, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 940, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 950, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 960, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 970, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 980, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 990, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1000, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1010, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1020, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1030, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1040, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1050, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1060, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1070, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1080, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1090, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1100, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1110, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1120, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1130, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1140, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1150, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1160, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1170, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1180, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1190, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1200, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1210, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1220, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1230, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1240, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1250, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1260, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1270, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1280, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1290, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1300, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1310, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1320, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1330, Train Loss: 1.4098, Train Accuracy: 56.8649%\n",
      "Epoch: 1340, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1350, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1360, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1370, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1380, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1390, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1400, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 1410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 1990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 2990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 3990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 4990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 5990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 6990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 7990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 8990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9000, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9010, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9020, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9030, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9040, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9050, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9060, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9070, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9080, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9090, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9100, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9110, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9120, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9130, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9140, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9150, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9160, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9170, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9180, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9190, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9200, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9210, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9220, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9230, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9240, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9250, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9260, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9270, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9280, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9290, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9300, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9310, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9320, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9330, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9340, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9350, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9360, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9370, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9380, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9390, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9400, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9410, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9420, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9430, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9440, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9450, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9460, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9470, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9480, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9490, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9500, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9510, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9520, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9530, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9540, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9550, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9560, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9570, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9580, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9590, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9600, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9610, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9620, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9630, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9640, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9650, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9660, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9670, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9680, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9690, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9700, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9710, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9720, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9730, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9740, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9750, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9760, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9770, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9780, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9790, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9800, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9810, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9820, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9830, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9840, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9850, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9860, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9870, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9880, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9890, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9900, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9910, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9920, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9930, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9940, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9950, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9960, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9970, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9980, Train Loss: 1.4097, Train Accuracy: 56.7568%\n",
      "Epoch: 9990, Train Loss: 1.4097, Train Accuracy: 56.7568%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:gfnwlpp6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁█▇▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆</td></tr><tr><td>train_loss</td><td>█▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▅█████████████████████████████████████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56757</td></tr><tr><td>train_loss</td><td>1.40974</td></tr><tr><td>val_accuracy</td><td>0.61165</td></tr><tr><td>val_loss</td><td>1.34033</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.3</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/gfnwlpp6' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/gfnwlpp6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190341-gfnwlpp6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:gfnwlpp6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190402-hccms2mr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/hccms2mr' target=\"_blank\">Logistic Regression lr=0.03</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/hccms2mr' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/hccms2mr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7443, Train Accuracy: 51.6757%\n",
      "Epoch: 20, Train Loss: 1.7046, Train Accuracy: 51.7838%\n",
      "Epoch: 30, Train Loss: 1.6712, Train Accuracy: 51.6757%\n",
      "Epoch: 40, Train Loss: 1.6430, Train Accuracy: 52.3243%\n",
      "Epoch: 50, Train Loss: 1.6190, Train Accuracy: 52.4324%\n",
      "Epoch: 60, Train Loss: 1.5986, Train Accuracy: 52.8649%\n",
      "Epoch: 70, Train Loss: 1.5810, Train Accuracy: 52.7568%\n",
      "Epoch: 80, Train Loss: 1.5659, Train Accuracy: 52.7568%\n",
      "Epoch: 90, Train Loss: 1.5528, Train Accuracy: 52.8649%\n",
      "Epoch: 100, Train Loss: 1.5414, Train Accuracy: 53.1892%\n",
      "Epoch: 110, Train Loss: 1.5313, Train Accuracy: 52.8649%\n",
      "Epoch: 120, Train Loss: 1.5225, Train Accuracy: 52.9730%\n",
      "Epoch: 130, Train Loss: 1.5147, Train Accuracy: 53.0811%\n",
      "Epoch: 140, Train Loss: 1.5077, Train Accuracy: 52.9730%\n",
      "Epoch: 150, Train Loss: 1.5015, Train Accuracy: 53.4054%\n",
      "Epoch: 160, Train Loss: 1.4960, Train Accuracy: 53.4054%\n",
      "Epoch: 170, Train Loss: 1.4910, Train Accuracy: 53.4054%\n",
      "Epoch: 180, Train Loss: 1.4864, Train Accuracy: 53.5135%\n",
      "Epoch: 190, Train Loss: 1.4823, Train Accuracy: 53.5135%\n",
      "Epoch: 200, Train Loss: 1.4786, Train Accuracy: 53.5135%\n",
      "Epoch: 210, Train Loss: 1.4752, Train Accuracy: 53.6216%\n",
      "Epoch: 220, Train Loss: 1.4721, Train Accuracy: 53.7297%\n",
      "Epoch: 230, Train Loss: 1.4692, Train Accuracy: 53.9459%\n",
      "Epoch: 240, Train Loss: 1.4666, Train Accuracy: 53.9459%\n",
      "Epoch: 250, Train Loss: 1.4641, Train Accuracy: 53.7297%\n",
      "Epoch: 260, Train Loss: 1.4619, Train Accuracy: 53.7297%\n",
      "Epoch: 270, Train Loss: 1.4598, Train Accuracy: 53.9459%\n",
      "Epoch: 280, Train Loss: 1.4578, Train Accuracy: 54.0541%\n",
      "Epoch: 290, Train Loss: 1.4560, Train Accuracy: 54.1622%\n",
      "Epoch: 300, Train Loss: 1.4543, Train Accuracy: 54.3784%\n",
      "Epoch: 310, Train Loss: 1.4527, Train Accuracy: 54.7027%\n",
      "Epoch: 320, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 330, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 340, Train Loss: 1.4486, Train Accuracy: 54.3784%\n",
      "Epoch: 350, Train Loss: 1.4473, Train Accuracy: 54.3784%\n",
      "Epoch: 360, Train Loss: 1.4462, Train Accuracy: 54.4865%\n",
      "Epoch: 370, Train Loss: 1.4451, Train Accuracy: 54.4865%\n",
      "Epoch: 380, Train Loss: 1.4440, Train Accuracy: 54.5946%\n",
      "Epoch: 390, Train Loss: 1.4430, Train Accuracy: 54.9189%\n",
      "Epoch: 400, Train Loss: 1.4421, Train Accuracy: 55.0270%\n",
      "Epoch: 410, Train Loss: 1.4412, Train Accuracy: 54.9189%\n",
      "Epoch: 420, Train Loss: 1.4403, Train Accuracy: 54.9189%\n",
      "Epoch: 430, Train Loss: 1.4395, Train Accuracy: 54.9189%\n",
      "Epoch: 440, Train Loss: 1.4387, Train Accuracy: 55.0270%\n",
      "Epoch: 450, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 460, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 470, Train Loss: 1.4366, Train Accuracy: 55.1351%\n",
      "Epoch: 480, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 490, Train Loss: 1.4353, Train Accuracy: 55.0270%\n",
      "Epoch: 500, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 510, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 520, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 530, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 540, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 550, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 560, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 570, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 580, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 590, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 600, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 610, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 620, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 630, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 640, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 650, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 660, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 670, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 680, Train Loss: 1.4270, Train Accuracy: 55.3514%\n",
      "Epoch: 690, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 700, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 710, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 720, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 730, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 740, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 750, Train Loss: 1.4250, Train Accuracy: 55.2432%\n",
      "Epoch: 760, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 770, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 780, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 790, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 800, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 810, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 820, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 830, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 840, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 850, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 860, Train Loss: 1.4224, Train Accuracy: 55.0270%\n",
      "Epoch: 870, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 880, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 890, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 900, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 910, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 920, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 930, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 940, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 950, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 960, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 970, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 980, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 990, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 1000, Train Loss: 1.4200, Train Accuracy: 55.2432%\n",
      "Epoch: 1010, Train Loss: 1.4199, Train Accuracy: 55.2432%\n",
      "Epoch: 1020, Train Loss: 1.4197, Train Accuracy: 55.2432%\n",
      "Epoch: 1030, Train Loss: 1.4196, Train Accuracy: 55.2432%\n",
      "Epoch: 1040, Train Loss: 1.4195, Train Accuracy: 55.2432%\n",
      "Epoch: 1050, Train Loss: 1.4193, Train Accuracy: 55.2432%\n",
      "Epoch: 1060, Train Loss: 1.4192, Train Accuracy: 55.3514%\n",
      "Epoch: 1070, Train Loss: 1.4191, Train Accuracy: 55.3514%\n",
      "Epoch: 1080, Train Loss: 1.4189, Train Accuracy: 55.3514%\n",
      "Epoch: 1090, Train Loss: 1.4188, Train Accuracy: 55.3514%\n",
      "Epoch: 1100, Train Loss: 1.4187, Train Accuracy: 55.3514%\n",
      "Epoch: 1110, Train Loss: 1.4186, Train Accuracy: 55.3514%\n",
      "Epoch: 1120, Train Loss: 1.4185, Train Accuracy: 55.3514%\n",
      "Epoch: 1130, Train Loss: 1.4183, Train Accuracy: 55.4595%\n",
      "Epoch: 1140, Train Loss: 1.4182, Train Accuracy: 55.4595%\n",
      "Epoch: 1150, Train Loss: 1.4181, Train Accuracy: 55.4595%\n",
      "Epoch: 1160, Train Loss: 1.4180, Train Accuracy: 55.4595%\n",
      "Epoch: 1170, Train Loss: 1.4179, Train Accuracy: 55.4595%\n",
      "Epoch: 1180, Train Loss: 1.4178, Train Accuracy: 55.4595%\n",
      "Epoch: 1190, Train Loss: 1.4177, Train Accuracy: 55.6757%\n",
      "Epoch: 1200, Train Loss: 1.4176, Train Accuracy: 55.6757%\n",
      "Epoch: 1210, Train Loss: 1.4175, Train Accuracy: 55.7838%\n",
      "Epoch: 1220, Train Loss: 1.4174, Train Accuracy: 55.7838%\n",
      "Epoch: 1230, Train Loss: 1.4173, Train Accuracy: 56.0000%\n",
      "Epoch: 1240, Train Loss: 1.4172, Train Accuracy: 56.0000%\n",
      "Epoch: 1250, Train Loss: 1.4171, Train Accuracy: 56.0000%\n",
      "Epoch: 1260, Train Loss: 1.4170, Train Accuracy: 56.0000%\n",
      "Epoch: 1270, Train Loss: 1.4169, Train Accuracy: 56.0000%\n",
      "Epoch: 1280, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 1290, Train Loss: 1.4168, Train Accuracy: 55.8919%\n",
      "Epoch: 1300, Train Loss: 1.4167, Train Accuracy: 56.0000%\n",
      "Epoch: 1310, Train Loss: 1.4166, Train Accuracy: 56.0000%\n",
      "Epoch: 1320, Train Loss: 1.4165, Train Accuracy: 56.1081%\n",
      "Epoch: 1330, Train Loss: 1.4164, Train Accuracy: 56.1081%\n",
      "Epoch: 1340, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 1350, Train Loss: 1.4163, Train Accuracy: 56.2162%\n",
      "Epoch: 1360, Train Loss: 1.4162, Train Accuracy: 56.2162%\n",
      "Epoch: 1370, Train Loss: 1.4161, Train Accuracy: 56.2162%\n",
      "Epoch: 1380, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 1390, Train Loss: 1.4160, Train Accuracy: 56.2162%\n",
      "Epoch: 1400, Train Loss: 1.4159, Train Accuracy: 56.2162%\n",
      "Epoch: 1410, Train Loss: 1.4158, Train Accuracy: 56.4324%\n",
      "Epoch: 1420, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 1430, Train Loss: 1.4157, Train Accuracy: 56.4324%\n",
      "Epoch: 1440, Train Loss: 1.4156, Train Accuracy: 56.4324%\n",
      "Epoch: 1450, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 1460, Train Loss: 1.4155, Train Accuracy: 56.4324%\n",
      "Epoch: 1470, Train Loss: 1.4154, Train Accuracy: 56.4324%\n",
      "Epoch: 1480, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 1490, Train Loss: 1.4153, Train Accuracy: 56.4324%\n",
      "Epoch: 1500, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 1510, Train Loss: 1.4152, Train Accuracy: 56.4324%\n",
      "Epoch: 1520, Train Loss: 1.4151, Train Accuracy: 56.5405%\n",
      "Epoch: 1530, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 1540, Train Loss: 1.4150, Train Accuracy: 56.6486%\n",
      "Epoch: 1550, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 1560, Train Loss: 1.4149, Train Accuracy: 56.6486%\n",
      "Epoch: 1570, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 1580, Train Loss: 1.4148, Train Accuracy: 56.6486%\n",
      "Epoch: 1590, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 1600, Train Loss: 1.4147, Train Accuracy: 56.6486%\n",
      "Epoch: 1610, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 1620, Train Loss: 1.4146, Train Accuracy: 56.6486%\n",
      "Epoch: 1630, Train Loss: 1.4145, Train Accuracy: 56.6486%\n",
      "Epoch: 1640, Train Loss: 1.4145, Train Accuracy: 56.7568%\n",
      "Epoch: 1650, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 1660, Train Loss: 1.4144, Train Accuracy: 56.7568%\n",
      "Epoch: 1670, Train Loss: 1.4143, Train Accuracy: 56.8649%\n",
      "Epoch: 1680, Train Loss: 1.4143, Train Accuracy: 56.9730%\n",
      "Epoch: 1690, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 1700, Train Loss: 1.4142, Train Accuracy: 56.9730%\n",
      "Epoch: 1710, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 1720, Train Loss: 1.4141, Train Accuracy: 56.9730%\n",
      "Epoch: 1730, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 1740, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 1750, Train Loss: 1.4140, Train Accuracy: 57.0811%\n",
      "Epoch: 1760, Train Loss: 1.4139, Train Accuracy: 57.0811%\n",
      "Epoch: 1770, Train Loss: 1.4139, Train Accuracy: 56.9730%\n",
      "Epoch: 1780, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 1790, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 1800, Train Loss: 1.4138, Train Accuracy: 56.9730%\n",
      "Epoch: 1810, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 1820, Train Loss: 1.4137, Train Accuracy: 56.9730%\n",
      "Epoch: 1830, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 1840, Train Loss: 1.4136, Train Accuracy: 56.9730%\n",
      "Epoch: 1850, Train Loss: 1.4136, Train Accuracy: 56.8649%\n",
      "Epoch: 1860, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 1870, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 1880, Train Loss: 1.4135, Train Accuracy: 56.8649%\n",
      "Epoch: 1890, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 1900, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 1910, Train Loss: 1.4134, Train Accuracy: 56.7568%\n",
      "Epoch: 1920, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 1930, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 1940, Train Loss: 1.4133, Train Accuracy: 56.7568%\n",
      "Epoch: 1950, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 1960, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 1970, Train Loss: 1.4132, Train Accuracy: 56.7568%\n",
      "Epoch: 1980, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 1990, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 2000, Train Loss: 1.4131, Train Accuracy: 56.7568%\n",
      "Epoch: 2010, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 2020, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 2030, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 2040, Train Loss: 1.4130, Train Accuracy: 56.7568%\n",
      "Epoch: 2050, Train Loss: 1.4129, Train Accuracy: 56.7568%\n",
      "Epoch: 2060, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 2070, Train Loss: 1.4129, Train Accuracy: 56.8649%\n",
      "Epoch: 2080, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 2090, Train Loss: 1.4128, Train Accuracy: 56.8649%\n",
      "Epoch: 2100, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 2110, Train Loss: 1.4128, Train Accuracy: 56.7568%\n",
      "Epoch: 2120, Train Loss: 1.4127, Train Accuracy: 56.7568%\n",
      "Epoch: 2130, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 2140, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 2150, Train Loss: 1.4127, Train Accuracy: 56.8649%\n",
      "Epoch: 2160, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 2170, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 2180, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 2190, Train Loss: 1.4126, Train Accuracy: 56.8649%\n",
      "Epoch: 2200, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 2210, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 2220, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 2230, Train Loss: 1.4125, Train Accuracy: 56.8649%\n",
      "Epoch: 2240, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 2250, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 2260, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 2270, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 2280, Train Loss: 1.4124, Train Accuracy: 56.8649%\n",
      "Epoch: 2290, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 2300, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 2310, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 2320, Train Loss: 1.4123, Train Accuracy: 56.8649%\n",
      "Epoch: 2330, Train Loss: 1.4123, Train Accuracy: 56.9730%\n",
      "Epoch: 2340, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 2350, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 2360, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 2370, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 2380, Train Loss: 1.4122, Train Accuracy: 56.9730%\n",
      "Epoch: 2390, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2400, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2410, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2420, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2430, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2440, Train Loss: 1.4121, Train Accuracy: 57.0811%\n",
      "Epoch: 2450, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 2460, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 2470, Train Loss: 1.4120, Train Accuracy: 57.0811%\n",
      "Epoch: 2480, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 2490, Train Loss: 1.4120, Train Accuracy: 57.1892%\n",
      "Epoch: 2500, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2510, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2520, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2530, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2540, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2550, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2560, Train Loss: 1.4119, Train Accuracy: 57.1892%\n",
      "Epoch: 2570, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2580, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2590, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2600, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2610, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2620, Train Loss: 1.4118, Train Accuracy: 57.1892%\n",
      "Epoch: 2630, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2640, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2650, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2660, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2670, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2680, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2690, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2700, Train Loss: 1.4117, Train Accuracy: 57.1892%\n",
      "Epoch: 2710, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 2720, Train Loss: 1.4116, Train Accuracy: 57.1892%\n",
      "Epoch: 2730, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 2740, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 2750, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 2760, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 2770, Train Loss: 1.4116, Train Accuracy: 57.2973%\n",
      "Epoch: 2780, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 2790, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 2800, Train Loss: 1.4115, Train Accuracy: 57.2973%\n",
      "Epoch: 2810, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2820, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2830, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2840, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2850, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2860, Train Loss: 1.4115, Train Accuracy: 57.1892%\n",
      "Epoch: 2870, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2880, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2890, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2900, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2910, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2920, Train Loss: 1.4114, Train Accuracy: 57.1892%\n",
      "Epoch: 2930, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 2940, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 2950, Train Loss: 1.4114, Train Accuracy: 56.9730%\n",
      "Epoch: 2960, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 2970, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 2980, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 2990, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3000, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3010, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3020, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3030, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3040, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3050, Train Loss: 1.4113, Train Accuracy: 56.9730%\n",
      "Epoch: 3060, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3070, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3080, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3090, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3100, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3110, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3120, Train Loss: 1.4112, Train Accuracy: 56.9730%\n",
      "Epoch: 3130, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 3140, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 3150, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 3160, Train Loss: 1.4112, Train Accuracy: 56.8649%\n",
      "Epoch: 3170, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3180, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3190, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3200, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3210, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3220, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3230, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3240, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3250, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3260, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3270, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3280, Train Loss: 1.4111, Train Accuracy: 56.8649%\n",
      "Epoch: 3290, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 3300, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 3310, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 3320, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 3330, Train Loss: 1.4110, Train Accuracy: 56.8649%\n",
      "Epoch: 3340, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 3350, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 3360, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 3370, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 3380, Train Loss: 1.4110, Train Accuracy: 56.9730%\n",
      "Epoch: 3390, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 3400, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 3410, Train Loss: 1.4110, Train Accuracy: 57.0811%\n",
      "Epoch: 3420, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 3430, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 3440, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 3450, Train Loss: 1.4109, Train Accuracy: 57.0811%\n",
      "Epoch: 3460, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3470, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3480, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3490, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3500, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3510, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3520, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3530, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3540, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3550, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3560, Train Loss: 1.4109, Train Accuracy: 57.1892%\n",
      "Epoch: 3570, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3580, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3590, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3600, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3610, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3620, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3630, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3640, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3650, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3660, Train Loss: 1.4108, Train Accuracy: 57.1892%\n",
      "Epoch: 3670, Train Loss: 1.4108, Train Accuracy: 57.0811%\n",
      "Epoch: 3680, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3690, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3700, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3710, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3720, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3730, Train Loss: 1.4108, Train Accuracy: 56.9730%\n",
      "Epoch: 3740, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3750, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3760, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3770, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3780, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3790, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3800, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3810, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3820, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3830, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3840, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3850, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3860, Train Loss: 1.4107, Train Accuracy: 56.9730%\n",
      "Epoch: 3870, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 3880, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 3890, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 3900, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 3910, Train Loss: 1.4107, Train Accuracy: 57.0811%\n",
      "Epoch: 3920, Train Loss: 1.4107, Train Accuracy: 57.1892%\n",
      "Epoch: 3930, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3940, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3950, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3960, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3970, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3980, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 3990, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4000, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4010, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4020, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4030, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4040, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4050, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4060, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4070, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4080, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4090, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4100, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4110, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4120, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4130, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4140, Train Loss: 1.4106, Train Accuracy: 57.1892%\n",
      "Epoch: 4150, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4160, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4170, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4180, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4190, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4200, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4210, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4220, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4230, Train Loss: 1.4105, Train Accuracy: 57.1892%\n",
      "Epoch: 4240, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4250, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4260, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4270, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4280, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4290, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4300, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4310, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4320, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4330, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4340, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4350, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4360, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4370, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4380, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4390, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4400, Train Loss: 1.4105, Train Accuracy: 57.2973%\n",
      "Epoch: 4410, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4420, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4430, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4440, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4450, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4460, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4470, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4480, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4490, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4500, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4510, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4520, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4530, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4540, Train Loss: 1.4104, Train Accuracy: 57.2973%\n",
      "Epoch: 4550, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 4560, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4570, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4580, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4590, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4600, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4610, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4620, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4630, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4640, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4650, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4660, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4670, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4680, Train Loss: 1.4104, Train Accuracy: 57.1892%\n",
      "Epoch: 4690, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 4700, Train Loss: 1.4104, Train Accuracy: 57.0811%\n",
      "Epoch: 4710, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4720, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4730, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4740, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4750, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4760, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4770, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4780, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4790, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4800, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4810, Train Loss: 1.4103, Train Accuracy: 57.0811%\n",
      "Epoch: 4820, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4830, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4840, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4850, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4860, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4870, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4880, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4890, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4900, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4910, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4920, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4930, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4940, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4950, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4960, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4970, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4980, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 4990, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5000, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5010, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5020, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5030, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5040, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5050, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5060, Train Loss: 1.4103, Train Accuracy: 56.9730%\n",
      "Epoch: 5070, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5080, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5090, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5100, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5110, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5120, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5130, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5140, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5150, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5160, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5170, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5180, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5190, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5200, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5210, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5220, Train Loss: 1.4102, Train Accuracy: 56.9730%\n",
      "Epoch: 5230, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5240, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5250, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5260, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5270, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5280, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5290, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5300, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5310, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5320, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5330, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5340, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5350, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5360, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5370, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5380, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5390, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5400, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5410, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5420, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5430, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5440, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5450, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5460, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5470, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5480, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5490, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5500, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5510, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5520, Train Loss: 1.4102, Train Accuracy: 56.8649%\n",
      "Epoch: 5530, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5540, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5550, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5560, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5570, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5580, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5590, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5600, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5610, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5620, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5630, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5640, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5650, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5660, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5670, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5680, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5690, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5700, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5710, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5720, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5730, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5740, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5750, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5760, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5770, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5780, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5790, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5800, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5810, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5820, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5830, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5840, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5850, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5860, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5870, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5880, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5890, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5900, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5910, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5920, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5930, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5940, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5950, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5960, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5970, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5980, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 5990, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6000, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6010, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6020, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6030, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6040, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6050, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6060, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6070, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6080, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6090, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6100, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6110, Train Loss: 1.4101, Train Accuracy: 56.8649%\n",
      "Epoch: 6120, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6130, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6140, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6150, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6160, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6170, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6180, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6190, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6200, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6210, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6220, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6230, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6240, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6250, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6260, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6270, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6280, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6290, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6300, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6310, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6320, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6330, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6340, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6350, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6360, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6370, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6380, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6390, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6400, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6410, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6420, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6430, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6440, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6450, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6460, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6470, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6480, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6490, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6500, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6510, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6520, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6530, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6540, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6550, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6560, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6570, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6580, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6590, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6600, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6610, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6620, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6630, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6640, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6650, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6660, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6670, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6680, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6690, Train Loss: 1.4100, Train Accuracy: 56.8649%\n",
      "Epoch: 6700, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6710, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6720, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6730, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6740, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6750, Train Loss: 1.4100, Train Accuracy: 56.7568%\n",
      "Epoch: 6760, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6770, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6780, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6790, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6800, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6810, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6820, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6830, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6840, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6850, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6860, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6870, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6880, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6890, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6900, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6910, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6920, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6930, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6940, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6950, Train Loss: 1.4100, Train Accuracy: 56.6486%\n",
      "Epoch: 6960, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 6970, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 6980, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 6990, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7000, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7010, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7020, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7030, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7040, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7050, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7060, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7070, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7080, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7090, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7100, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7110, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7120, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7130, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7140, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7150, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7160, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7170, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7180, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7190, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7200, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7210, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7220, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7230, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7240, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7250, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7260, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7270, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7280, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7290, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7300, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7310, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7320, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7330, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7340, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7350, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7360, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7370, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7380, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7390, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7400, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7410, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7420, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7430, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7440, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7450, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7460, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7470, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7480, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7490, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7500, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7510, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7520, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7530, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7540, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7550, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7560, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7570, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7580, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7590, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7600, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7610, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7620, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7630, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7640, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7650, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7660, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7670, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7680, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7690, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7700, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7710, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7720, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7730, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7740, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7750, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7760, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7770, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7780, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7790, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7800, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7810, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7820, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7830, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7840, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7850, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7860, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7870, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7880, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7890, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7900, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7910, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7920, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7930, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7940, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7950, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7960, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7970, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7980, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 7990, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8000, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8010, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8020, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8030, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8040, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8050, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8060, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8070, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8080, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8090, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8100, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8110, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8120, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8130, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8140, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8150, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8160, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8170, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8180, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8190, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8200, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8210, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8220, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8230, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8240, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8250, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8260, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8270, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8280, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8290, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8300, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8310, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8320, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8330, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8340, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8350, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8360, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8370, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8380, Train Loss: 1.4099, Train Accuracy: 56.6486%\n",
      "Epoch: 8390, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8400, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8410, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8420, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8430, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8440, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8450, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8460, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8470, Train Loss: 1.4098, Train Accuracy: 56.6486%\n",
      "Epoch: 8480, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8490, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8500, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8510, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8520, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8530, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8540, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8550, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8560, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8570, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8580, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8590, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8600, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8610, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8620, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8630, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8640, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8650, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8660, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8670, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8680, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8690, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8700, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8710, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8720, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8730, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8740, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8750, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8760, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8770, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8780, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8790, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8800, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8810, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8820, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8830, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8840, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8850, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8860, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8870, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8880, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8890, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8900, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8910, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8920, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8930, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8940, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8950, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8960, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8970, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8980, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 8990, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9000, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9010, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9020, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9030, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9040, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9050, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9060, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9070, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9080, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9090, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9100, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9110, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9120, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9130, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9140, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9150, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9160, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9170, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9180, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9190, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9200, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9210, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9220, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9230, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9240, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9250, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9260, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9270, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9280, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9290, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9300, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9310, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9320, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9330, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9340, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9350, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9360, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9370, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9380, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9390, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9400, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9410, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9420, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9430, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9440, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9450, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9460, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9470, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9480, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9490, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9500, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9510, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9520, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9530, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9540, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9550, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9560, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9570, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9580, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9590, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9600, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9610, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9620, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9630, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9640, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9650, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9660, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9670, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9680, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9690, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9700, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9710, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9720, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9730, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9740, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9750, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9760, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9770, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9780, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9790, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9800, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9810, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9820, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9830, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9840, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9850, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9860, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9870, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9880, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9890, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9900, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9910, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9920, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9930, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9940, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9950, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9960, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9970, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9980, Train Loss: 1.4098, Train Accuracy: 56.7568%\n",
      "Epoch: 9990, Train Loss: 1.4098, Train Accuracy: 56.7568%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:hccms2mr) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▂▅▅▅▆▇▇▇▇██▇▇█▇███▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▃▃▄▄▄▅▆▆▆▆▆▆▇▇▇▆▆▆▆▆▆▆▆▆▆▇▇███████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.56757</td></tr><tr><td>train_loss</td><td>1.40979</td></tr><tr><td>val_accuracy</td><td>0.61165</td></tr><tr><td>val_loss</td><td>1.34065</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.03</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/hccms2mr' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/hccms2mr</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190402-hccms2mr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:hccms2mr). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190424-swrzphem</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/swrzphem' target=\"_blank\">Logistic Regression lr=0.003</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/swrzphem' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/swrzphem</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7866, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7767, Train Accuracy: 51.6757%\n",
      "Epoch: 40, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 50, Train Loss: 1.7671, Train Accuracy: 51.6757%\n",
      "Epoch: 60, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 70, Train Loss: 1.7578, Train Accuracy: 51.6757%\n",
      "Epoch: 80, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 90, Train Loss: 1.7488, Train Accuracy: 51.6757%\n",
      "Epoch: 100, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 110, Train Loss: 1.7402, Train Accuracy: 51.6757%\n",
      "Epoch: 120, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 130, Train Loss: 1.7319, Train Accuracy: 51.6757%\n",
      "Epoch: 140, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 150, Train Loss: 1.7238, Train Accuracy: 51.6757%\n",
      "Epoch: 160, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 170, Train Loss: 1.7160, Train Accuracy: 51.6757%\n",
      "Epoch: 180, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 190, Train Loss: 1.7085, Train Accuracy: 51.7838%\n",
      "Epoch: 200, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 210, Train Loss: 1.7013, Train Accuracy: 51.8919%\n",
      "Epoch: 220, Train Loss: 1.6977, Train Accuracy: 51.7838%\n",
      "Epoch: 230, Train Loss: 1.6943, Train Accuracy: 51.6757%\n",
      "Epoch: 240, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 250, Train Loss: 1.6875, Train Accuracy: 51.6757%\n",
      "Epoch: 260, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 270, Train Loss: 1.6810, Train Accuracy: 51.6757%\n",
      "Epoch: 280, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 290, Train Loss: 1.6746, Train Accuracy: 51.6757%\n",
      "Epoch: 300, Train Loss: 1.6715, Train Accuracy: 51.7838%\n",
      "Epoch: 310, Train Loss: 1.6685, Train Accuracy: 51.7838%\n",
      "Epoch: 320, Train Loss: 1.6655, Train Accuracy: 51.8919%\n",
      "Epoch: 330, Train Loss: 1.6626, Train Accuracy: 52.0000%\n",
      "Epoch: 340, Train Loss: 1.6597, Train Accuracy: 52.0000%\n",
      "Epoch: 350, Train Loss: 1.6569, Train Accuracy: 52.2162%\n",
      "Epoch: 360, Train Loss: 1.6541, Train Accuracy: 52.2162%\n",
      "Epoch: 370, Train Loss: 1.6513, Train Accuracy: 52.3243%\n",
      "Epoch: 380, Train Loss: 1.6486, Train Accuracy: 52.3243%\n",
      "Epoch: 390, Train Loss: 1.6460, Train Accuracy: 52.3243%\n",
      "Epoch: 400, Train Loss: 1.6434, Train Accuracy: 52.4324%\n",
      "Epoch: 410, Train Loss: 1.6408, Train Accuracy: 52.4324%\n",
      "Epoch: 420, Train Loss: 1.6383, Train Accuracy: 52.4324%\n",
      "Epoch: 430, Train Loss: 1.6358, Train Accuracy: 52.4324%\n",
      "Epoch: 440, Train Loss: 1.6333, Train Accuracy: 52.5405%\n",
      "Epoch: 450, Train Loss: 1.6309, Train Accuracy: 52.5405%\n",
      "Epoch: 460, Train Loss: 1.6285, Train Accuracy: 52.6486%\n",
      "Epoch: 470, Train Loss: 1.6262, Train Accuracy: 52.6486%\n",
      "Epoch: 480, Train Loss: 1.6239, Train Accuracy: 52.5405%\n",
      "Epoch: 490, Train Loss: 1.6216, Train Accuracy: 52.4324%\n",
      "Epoch: 500, Train Loss: 1.6194, Train Accuracy: 52.5405%\n",
      "Epoch: 510, Train Loss: 1.6172, Train Accuracy: 52.5405%\n",
      "Epoch: 520, Train Loss: 1.6151, Train Accuracy: 52.7568%\n",
      "Epoch: 530, Train Loss: 1.6130, Train Accuracy: 52.6486%\n",
      "Epoch: 540, Train Loss: 1.6109, Train Accuracy: 52.6486%\n",
      "Epoch: 550, Train Loss: 1.6088, Train Accuracy: 52.6486%\n",
      "Epoch: 560, Train Loss: 1.6068, Train Accuracy: 52.6486%\n",
      "Epoch: 570, Train Loss: 1.6048, Train Accuracy: 52.6486%\n",
      "Epoch: 580, Train Loss: 1.6028, Train Accuracy: 52.7568%\n",
      "Epoch: 590, Train Loss: 1.6009, Train Accuracy: 52.8649%\n",
      "Epoch: 600, Train Loss: 1.5990, Train Accuracy: 52.8649%\n",
      "Epoch: 610, Train Loss: 1.5971, Train Accuracy: 52.8649%\n",
      "Epoch: 620, Train Loss: 1.5953, Train Accuracy: 52.7568%\n",
      "Epoch: 630, Train Loss: 1.5934, Train Accuracy: 52.7568%\n",
      "Epoch: 640, Train Loss: 1.5916, Train Accuracy: 52.7568%\n",
      "Epoch: 650, Train Loss: 1.5899, Train Accuracy: 52.4324%\n",
      "Epoch: 660, Train Loss: 1.5881, Train Accuracy: 52.4324%\n",
      "Epoch: 670, Train Loss: 1.5864, Train Accuracy: 52.6486%\n",
      "Epoch: 680, Train Loss: 1.5847, Train Accuracy: 52.7568%\n",
      "Epoch: 690, Train Loss: 1.5831, Train Accuracy: 52.7568%\n",
      "Epoch: 700, Train Loss: 1.5814, Train Accuracy: 52.7568%\n",
      "Epoch: 710, Train Loss: 1.5798, Train Accuracy: 52.7568%\n",
      "Epoch: 720, Train Loss: 1.5782, Train Accuracy: 52.7568%\n",
      "Epoch: 730, Train Loss: 1.5767, Train Accuracy: 52.7568%\n",
      "Epoch: 740, Train Loss: 1.5751, Train Accuracy: 52.7568%\n",
      "Epoch: 750, Train Loss: 1.5736, Train Accuracy: 52.7568%\n",
      "Epoch: 760, Train Loss: 1.5721, Train Accuracy: 52.7568%\n",
      "Epoch: 770, Train Loss: 1.5706, Train Accuracy: 52.7568%\n",
      "Epoch: 780, Train Loss: 1.5692, Train Accuracy: 52.7568%\n",
      "Epoch: 790, Train Loss: 1.5677, Train Accuracy: 52.7568%\n",
      "Epoch: 800, Train Loss: 1.5663, Train Accuracy: 52.7568%\n",
      "Epoch: 810, Train Loss: 1.5649, Train Accuracy: 52.7568%\n",
      "Epoch: 820, Train Loss: 1.5635, Train Accuracy: 52.7568%\n",
      "Epoch: 830, Train Loss: 1.5622, Train Accuracy: 52.7568%\n",
      "Epoch: 840, Train Loss: 1.5608, Train Accuracy: 52.7568%\n",
      "Epoch: 850, Train Loss: 1.5595, Train Accuracy: 52.7568%\n",
      "Epoch: 860, Train Loss: 1.5582, Train Accuracy: 52.7568%\n",
      "Epoch: 870, Train Loss: 1.5569, Train Accuracy: 52.7568%\n",
      "Epoch: 880, Train Loss: 1.5556, Train Accuracy: 52.7568%\n",
      "Epoch: 890, Train Loss: 1.5544, Train Accuracy: 52.8649%\n",
      "Epoch: 900, Train Loss: 1.5532, Train Accuracy: 52.8649%\n",
      "Epoch: 910, Train Loss: 1.5519, Train Accuracy: 52.9730%\n",
      "Epoch: 920, Train Loss: 1.5507, Train Accuracy: 52.9730%\n",
      "Epoch: 930, Train Loss: 1.5496, Train Accuracy: 52.9730%\n",
      "Epoch: 940, Train Loss: 1.5484, Train Accuracy: 52.9730%\n",
      "Epoch: 950, Train Loss: 1.5472, Train Accuracy: 52.9730%\n",
      "Epoch: 960, Train Loss: 1.5461, Train Accuracy: 53.0811%\n",
      "Epoch: 970, Train Loss: 1.5450, Train Accuracy: 53.1892%\n",
      "Epoch: 980, Train Loss: 1.5439, Train Accuracy: 53.1892%\n",
      "Epoch: 990, Train Loss: 1.5428, Train Accuracy: 53.1892%\n",
      "Epoch: 1000, Train Loss: 1.5417, Train Accuracy: 53.2973%\n",
      "Epoch: 1010, Train Loss: 1.5406, Train Accuracy: 52.9730%\n",
      "Epoch: 1020, Train Loss: 1.5396, Train Accuracy: 52.7568%\n",
      "Epoch: 1030, Train Loss: 1.5386, Train Accuracy: 52.8649%\n",
      "Epoch: 1040, Train Loss: 1.5375, Train Accuracy: 52.8649%\n",
      "Epoch: 1050, Train Loss: 1.5365, Train Accuracy: 52.8649%\n",
      "Epoch: 1060, Train Loss: 1.5355, Train Accuracy: 52.8649%\n",
      "Epoch: 1070, Train Loss: 1.5345, Train Accuracy: 52.8649%\n",
      "Epoch: 1080, Train Loss: 1.5336, Train Accuracy: 52.8649%\n",
      "Epoch: 1090, Train Loss: 1.5326, Train Accuracy: 52.8649%\n",
      "Epoch: 1100, Train Loss: 1.5317, Train Accuracy: 52.8649%\n",
      "Epoch: 1110, Train Loss: 1.5307, Train Accuracy: 52.9730%\n",
      "Epoch: 1120, Train Loss: 1.5298, Train Accuracy: 52.9730%\n",
      "Epoch: 1130, Train Loss: 1.5289, Train Accuracy: 52.9730%\n",
      "Epoch: 1140, Train Loss: 1.5280, Train Accuracy: 53.0811%\n",
      "Epoch: 1150, Train Loss: 1.5271, Train Accuracy: 53.0811%\n",
      "Epoch: 1160, Train Loss: 1.5262, Train Accuracy: 52.9730%\n",
      "Epoch: 1170, Train Loss: 1.5253, Train Accuracy: 52.9730%\n",
      "Epoch: 1180, Train Loss: 1.5245, Train Accuracy: 52.9730%\n",
      "Epoch: 1190, Train Loss: 1.5236, Train Accuracy: 52.9730%\n",
      "Epoch: 1200, Train Loss: 1.5228, Train Accuracy: 52.9730%\n",
      "Epoch: 1210, Train Loss: 1.5220, Train Accuracy: 52.9730%\n",
      "Epoch: 1220, Train Loss: 1.5212, Train Accuracy: 52.9730%\n",
      "Epoch: 1230, Train Loss: 1.5204, Train Accuracy: 52.9730%\n",
      "Epoch: 1240, Train Loss: 1.5196, Train Accuracy: 52.9730%\n",
      "Epoch: 1250, Train Loss: 1.5188, Train Accuracy: 53.0811%\n",
      "Epoch: 1260, Train Loss: 1.5180, Train Accuracy: 53.0811%\n",
      "Epoch: 1270, Train Loss: 1.5172, Train Accuracy: 53.0811%\n",
      "Epoch: 1280, Train Loss: 1.5165, Train Accuracy: 53.0811%\n",
      "Epoch: 1290, Train Loss: 1.5157, Train Accuracy: 53.0811%\n",
      "Epoch: 1300, Train Loss: 1.5150, Train Accuracy: 53.0811%\n",
      "Epoch: 1310, Train Loss: 1.5142, Train Accuracy: 53.0811%\n",
      "Epoch: 1320, Train Loss: 1.5135, Train Accuracy: 52.9730%\n",
      "Epoch: 1330, Train Loss: 1.5128, Train Accuracy: 52.9730%\n",
      "Epoch: 1340, Train Loss: 1.5121, Train Accuracy: 53.0811%\n",
      "Epoch: 1350, Train Loss: 1.5114, Train Accuracy: 53.0811%\n",
      "Epoch: 1360, Train Loss: 1.5107, Train Accuracy: 53.0811%\n",
      "Epoch: 1370, Train Loss: 1.5100, Train Accuracy: 53.0811%\n",
      "Epoch: 1380, Train Loss: 1.5093, Train Accuracy: 52.9730%\n",
      "Epoch: 1390, Train Loss: 1.5087, Train Accuracy: 52.9730%\n",
      "Epoch: 1400, Train Loss: 1.5080, Train Accuracy: 52.9730%\n",
      "Epoch: 1410, Train Loss: 1.5073, Train Accuracy: 53.0811%\n",
      "Epoch: 1420, Train Loss: 1.5067, Train Accuracy: 53.0811%\n",
      "Epoch: 1430, Train Loss: 1.5061, Train Accuracy: 53.0811%\n",
      "Epoch: 1440, Train Loss: 1.5054, Train Accuracy: 53.0811%\n",
      "Epoch: 1450, Train Loss: 1.5048, Train Accuracy: 53.0811%\n",
      "Epoch: 1460, Train Loss: 1.5042, Train Accuracy: 53.0811%\n",
      "Epoch: 1470, Train Loss: 1.5036, Train Accuracy: 53.1892%\n",
      "Epoch: 1480, Train Loss: 1.5030, Train Accuracy: 53.2973%\n",
      "Epoch: 1490, Train Loss: 1.5024, Train Accuracy: 53.4054%\n",
      "Epoch: 1500, Train Loss: 1.5018, Train Accuracy: 53.4054%\n",
      "Epoch: 1510, Train Loss: 1.5012, Train Accuracy: 53.4054%\n",
      "Epoch: 1520, Train Loss: 1.5006, Train Accuracy: 53.4054%\n",
      "Epoch: 1530, Train Loss: 1.5000, Train Accuracy: 53.4054%\n",
      "Epoch: 1540, Train Loss: 1.4995, Train Accuracy: 53.4054%\n",
      "Epoch: 1550, Train Loss: 1.4989, Train Accuracy: 53.4054%\n",
      "Epoch: 1560, Train Loss: 1.4984, Train Accuracy: 53.4054%\n",
      "Epoch: 1570, Train Loss: 1.4978, Train Accuracy: 53.4054%\n",
      "Epoch: 1580, Train Loss: 1.4973, Train Accuracy: 53.4054%\n",
      "Epoch: 1590, Train Loss: 1.4967, Train Accuracy: 53.4054%\n",
      "Epoch: 1600, Train Loss: 1.4962, Train Accuracy: 53.4054%\n",
      "Epoch: 1610, Train Loss: 1.4957, Train Accuracy: 53.2973%\n",
      "Epoch: 1620, Train Loss: 1.4951, Train Accuracy: 53.2973%\n",
      "Epoch: 1630, Train Loss: 1.4946, Train Accuracy: 53.2973%\n",
      "Epoch: 1640, Train Loss: 1.4941, Train Accuracy: 53.2973%\n",
      "Epoch: 1650, Train Loss: 1.4936, Train Accuracy: 53.2973%\n",
      "Epoch: 1660, Train Loss: 1.4931, Train Accuracy: 53.2973%\n",
      "Epoch: 1670, Train Loss: 1.4926, Train Accuracy: 53.2973%\n",
      "Epoch: 1680, Train Loss: 1.4921, Train Accuracy: 53.2973%\n",
      "Epoch: 1690, Train Loss: 1.4916, Train Accuracy: 53.2973%\n",
      "Epoch: 1700, Train Loss: 1.4912, Train Accuracy: 53.4054%\n",
      "Epoch: 1710, Train Loss: 1.4907, Train Accuracy: 53.4054%\n",
      "Epoch: 1720, Train Loss: 1.4902, Train Accuracy: 53.5135%\n",
      "Epoch: 1730, Train Loss: 1.4898, Train Accuracy: 53.6216%\n",
      "Epoch: 1740, Train Loss: 1.4893, Train Accuracy: 53.5135%\n",
      "Epoch: 1750, Train Loss: 1.4888, Train Accuracy: 53.5135%\n",
      "Epoch: 1760, Train Loss: 1.4884, Train Accuracy: 53.5135%\n",
      "Epoch: 1770, Train Loss: 1.4879, Train Accuracy: 53.5135%\n",
      "Epoch: 1780, Train Loss: 1.4875, Train Accuracy: 53.5135%\n",
      "Epoch: 1790, Train Loss: 1.4871, Train Accuracy: 53.5135%\n",
      "Epoch: 1800, Train Loss: 1.4866, Train Accuracy: 53.5135%\n",
      "Epoch: 1810, Train Loss: 1.4862, Train Accuracy: 53.5135%\n",
      "Epoch: 1820, Train Loss: 1.4858, Train Accuracy: 53.5135%\n",
      "Epoch: 1830, Train Loss: 1.4853, Train Accuracy: 53.5135%\n",
      "Epoch: 1840, Train Loss: 1.4849, Train Accuracy: 53.6216%\n",
      "Epoch: 1850, Train Loss: 1.4845, Train Accuracy: 53.5135%\n",
      "Epoch: 1860, Train Loss: 1.4841, Train Accuracy: 53.6216%\n",
      "Epoch: 1870, Train Loss: 1.4837, Train Accuracy: 53.6216%\n",
      "Epoch: 1880, Train Loss: 1.4833, Train Accuracy: 53.6216%\n",
      "Epoch: 1890, Train Loss: 1.4829, Train Accuracy: 53.6216%\n",
      "Epoch: 1900, Train Loss: 1.4825, Train Accuracy: 53.5135%\n",
      "Epoch: 1910, Train Loss: 1.4821, Train Accuracy: 53.5135%\n",
      "Epoch: 1920, Train Loss: 1.4817, Train Accuracy: 53.5135%\n",
      "Epoch: 1930, Train Loss: 1.4813, Train Accuracy: 53.5135%\n",
      "Epoch: 1940, Train Loss: 1.4810, Train Accuracy: 53.5135%\n",
      "Epoch: 1950, Train Loss: 1.4806, Train Accuracy: 53.5135%\n",
      "Epoch: 1960, Train Loss: 1.4802, Train Accuracy: 53.5135%\n",
      "Epoch: 1970, Train Loss: 1.4799, Train Accuracy: 53.5135%\n",
      "Epoch: 1980, Train Loss: 1.4795, Train Accuracy: 53.5135%\n",
      "Epoch: 1990, Train Loss: 1.4791, Train Accuracy: 53.5135%\n",
      "Epoch: 2000, Train Loss: 1.4788, Train Accuracy: 53.5135%\n",
      "Epoch: 2010, Train Loss: 1.4784, Train Accuracy: 53.5135%\n",
      "Epoch: 2020, Train Loss: 1.4781, Train Accuracy: 53.5135%\n",
      "Epoch: 2030, Train Loss: 1.4777, Train Accuracy: 53.6216%\n",
      "Epoch: 2040, Train Loss: 1.4774, Train Accuracy: 53.6216%\n",
      "Epoch: 2050, Train Loss: 1.4770, Train Accuracy: 53.6216%\n",
      "Epoch: 2060, Train Loss: 1.4767, Train Accuracy: 53.6216%\n",
      "Epoch: 2070, Train Loss: 1.4763, Train Accuracy: 53.6216%\n",
      "Epoch: 2080, Train Loss: 1.4760, Train Accuracy: 53.6216%\n",
      "Epoch: 2090, Train Loss: 1.4757, Train Accuracy: 53.6216%\n",
      "Epoch: 2100, Train Loss: 1.4753, Train Accuracy: 53.6216%\n",
      "Epoch: 2110, Train Loss: 1.4750, Train Accuracy: 53.7297%\n",
      "Epoch: 2120, Train Loss: 1.4747, Train Accuracy: 53.6216%\n",
      "Epoch: 2130, Train Loss: 1.4744, Train Accuracy: 53.6216%\n",
      "Epoch: 2140, Train Loss: 1.4741, Train Accuracy: 53.6216%\n",
      "Epoch: 2150, Train Loss: 1.4737, Train Accuracy: 53.6216%\n",
      "Epoch: 2160, Train Loss: 1.4734, Train Accuracy: 53.6216%\n",
      "Epoch: 2170, Train Loss: 1.4731, Train Accuracy: 53.5135%\n",
      "Epoch: 2180, Train Loss: 1.4728, Train Accuracy: 53.6216%\n",
      "Epoch: 2190, Train Loss: 1.4725, Train Accuracy: 53.7297%\n",
      "Epoch: 2200, Train Loss: 1.4722, Train Accuracy: 53.7297%\n",
      "Epoch: 2210, Train Loss: 1.4719, Train Accuracy: 53.7297%\n",
      "Epoch: 2220, Train Loss: 1.4716, Train Accuracy: 53.7297%\n",
      "Epoch: 2230, Train Loss: 1.4713, Train Accuracy: 53.7297%\n",
      "Epoch: 2240, Train Loss: 1.4710, Train Accuracy: 53.7297%\n",
      "Epoch: 2250, Train Loss: 1.4707, Train Accuracy: 53.7297%\n",
      "Epoch: 2260, Train Loss: 1.4705, Train Accuracy: 53.7297%\n",
      "Epoch: 2270, Train Loss: 1.4702, Train Accuracy: 53.8378%\n",
      "Epoch: 2280, Train Loss: 1.4699, Train Accuracy: 53.8378%\n",
      "Epoch: 2290, Train Loss: 1.4696, Train Accuracy: 53.9459%\n",
      "Epoch: 2300, Train Loss: 1.4693, Train Accuracy: 53.9459%\n",
      "Epoch: 2310, Train Loss: 1.4691, Train Accuracy: 53.9459%\n",
      "Epoch: 2320, Train Loss: 1.4688, Train Accuracy: 53.9459%\n",
      "Epoch: 2330, Train Loss: 1.4685, Train Accuracy: 53.9459%\n",
      "Epoch: 2340, Train Loss: 1.4683, Train Accuracy: 53.9459%\n",
      "Epoch: 2350, Train Loss: 1.4680, Train Accuracy: 53.9459%\n",
      "Epoch: 2360, Train Loss: 1.4677, Train Accuracy: 53.9459%\n",
      "Epoch: 2370, Train Loss: 1.4675, Train Accuracy: 53.9459%\n",
      "Epoch: 2380, Train Loss: 1.4672, Train Accuracy: 53.9459%\n",
      "Epoch: 2390, Train Loss: 1.4669, Train Accuracy: 53.9459%\n",
      "Epoch: 2400, Train Loss: 1.4667, Train Accuracy: 53.9459%\n",
      "Epoch: 2410, Train Loss: 1.4664, Train Accuracy: 53.9459%\n",
      "Epoch: 2420, Train Loss: 1.4662, Train Accuracy: 53.9459%\n",
      "Epoch: 2430, Train Loss: 1.4659, Train Accuracy: 53.8378%\n",
      "Epoch: 2440, Train Loss: 1.4657, Train Accuracy: 53.9459%\n",
      "Epoch: 2450, Train Loss: 1.4654, Train Accuracy: 53.8378%\n",
      "Epoch: 2460, Train Loss: 1.4652, Train Accuracy: 53.8378%\n",
      "Epoch: 2470, Train Loss: 1.4650, Train Accuracy: 53.8378%\n",
      "Epoch: 2480, Train Loss: 1.4647, Train Accuracy: 53.8378%\n",
      "Epoch: 2490, Train Loss: 1.4645, Train Accuracy: 53.8378%\n",
      "Epoch: 2500, Train Loss: 1.4642, Train Accuracy: 53.7297%\n",
      "Epoch: 2510, Train Loss: 1.4640, Train Accuracy: 53.7297%\n",
      "Epoch: 2520, Train Loss: 1.4638, Train Accuracy: 53.7297%\n",
      "Epoch: 2530, Train Loss: 1.4636, Train Accuracy: 53.7297%\n",
      "Epoch: 2540, Train Loss: 1.4633, Train Accuracy: 53.7297%\n",
      "Epoch: 2550, Train Loss: 1.4631, Train Accuracy: 53.7297%\n",
      "Epoch: 2560, Train Loss: 1.4629, Train Accuracy: 53.7297%\n",
      "Epoch: 2570, Train Loss: 1.4626, Train Accuracy: 53.7297%\n",
      "Epoch: 2580, Train Loss: 1.4624, Train Accuracy: 53.7297%\n",
      "Epoch: 2590, Train Loss: 1.4622, Train Accuracy: 53.7297%\n",
      "Epoch: 2600, Train Loss: 1.4620, Train Accuracy: 53.7297%\n",
      "Epoch: 2610, Train Loss: 1.4618, Train Accuracy: 53.7297%\n",
      "Epoch: 2620, Train Loss: 1.4616, Train Accuracy: 53.8378%\n",
      "Epoch: 2630, Train Loss: 1.4613, Train Accuracy: 53.8378%\n",
      "Epoch: 2640, Train Loss: 1.4611, Train Accuracy: 53.8378%\n",
      "Epoch: 2650, Train Loss: 1.4609, Train Accuracy: 53.9459%\n",
      "Epoch: 2660, Train Loss: 1.4607, Train Accuracy: 53.9459%\n",
      "Epoch: 2670, Train Loss: 1.4605, Train Accuracy: 53.9459%\n",
      "Epoch: 2680, Train Loss: 1.4603, Train Accuracy: 53.9459%\n",
      "Epoch: 2690, Train Loss: 1.4601, Train Accuracy: 53.9459%\n",
      "Epoch: 2700, Train Loss: 1.4599, Train Accuracy: 53.9459%\n",
      "Epoch: 2710, Train Loss: 1.4597, Train Accuracy: 53.9459%\n",
      "Epoch: 2720, Train Loss: 1.4595, Train Accuracy: 53.9459%\n",
      "Epoch: 2730, Train Loss: 1.4593, Train Accuracy: 53.9459%\n",
      "Epoch: 2740, Train Loss: 1.4591, Train Accuracy: 53.9459%\n",
      "Epoch: 2750, Train Loss: 1.4589, Train Accuracy: 53.9459%\n",
      "Epoch: 2760, Train Loss: 1.4587, Train Accuracy: 54.0541%\n",
      "Epoch: 2770, Train Loss: 1.4585, Train Accuracy: 54.0541%\n",
      "Epoch: 2780, Train Loss: 1.4583, Train Accuracy: 54.0541%\n",
      "Epoch: 2790, Train Loss: 1.4581, Train Accuracy: 54.0541%\n",
      "Epoch: 2800, Train Loss: 1.4579, Train Accuracy: 54.0541%\n",
      "Epoch: 2810, Train Loss: 1.4577, Train Accuracy: 54.0541%\n",
      "Epoch: 2820, Train Loss: 1.4576, Train Accuracy: 54.1622%\n",
      "Epoch: 2830, Train Loss: 1.4574, Train Accuracy: 54.1622%\n",
      "Epoch: 2840, Train Loss: 1.4572, Train Accuracy: 54.1622%\n",
      "Epoch: 2850, Train Loss: 1.4570, Train Accuracy: 54.1622%\n",
      "Epoch: 2860, Train Loss: 1.4568, Train Accuracy: 54.1622%\n",
      "Epoch: 2870, Train Loss: 1.4567, Train Accuracy: 54.1622%\n",
      "Epoch: 2880, Train Loss: 1.4565, Train Accuracy: 54.1622%\n",
      "Epoch: 2890, Train Loss: 1.4563, Train Accuracy: 54.1622%\n",
      "Epoch: 2900, Train Loss: 1.4561, Train Accuracy: 54.1622%\n",
      "Epoch: 2910, Train Loss: 1.4559, Train Accuracy: 54.1622%\n",
      "Epoch: 2920, Train Loss: 1.4558, Train Accuracy: 54.1622%\n",
      "Epoch: 2930, Train Loss: 1.4556, Train Accuracy: 54.1622%\n",
      "Epoch: 2940, Train Loss: 1.4554, Train Accuracy: 54.1622%\n",
      "Epoch: 2950, Train Loss: 1.4553, Train Accuracy: 54.1622%\n",
      "Epoch: 2960, Train Loss: 1.4551, Train Accuracy: 54.1622%\n",
      "Epoch: 2970, Train Loss: 1.4549, Train Accuracy: 54.1622%\n",
      "Epoch: 2980, Train Loss: 1.4548, Train Accuracy: 54.2703%\n",
      "Epoch: 2990, Train Loss: 1.4546, Train Accuracy: 54.3784%\n",
      "Epoch: 3000, Train Loss: 1.4544, Train Accuracy: 54.3784%\n",
      "Epoch: 3010, Train Loss: 1.4543, Train Accuracy: 54.3784%\n",
      "Epoch: 3020, Train Loss: 1.4541, Train Accuracy: 54.3784%\n",
      "Epoch: 3030, Train Loss: 1.4539, Train Accuracy: 54.5946%\n",
      "Epoch: 3040, Train Loss: 1.4538, Train Accuracy: 54.5946%\n",
      "Epoch: 3050, Train Loss: 1.4536, Train Accuracy: 54.5946%\n",
      "Epoch: 3060, Train Loss: 1.4535, Train Accuracy: 54.7027%\n",
      "Epoch: 3070, Train Loss: 1.4533, Train Accuracy: 54.7027%\n",
      "Epoch: 3080, Train Loss: 1.4531, Train Accuracy: 54.7027%\n",
      "Epoch: 3090, Train Loss: 1.4530, Train Accuracy: 54.7027%\n",
      "Epoch: 3100, Train Loss: 1.4528, Train Accuracy: 54.7027%\n",
      "Epoch: 3110, Train Loss: 1.4527, Train Accuracy: 54.7027%\n",
      "Epoch: 3120, Train Loss: 1.4525, Train Accuracy: 54.7027%\n",
      "Epoch: 3130, Train Loss: 1.4524, Train Accuracy: 54.7027%\n",
      "Epoch: 3140, Train Loss: 1.4522, Train Accuracy: 54.7027%\n",
      "Epoch: 3150, Train Loss: 1.4521, Train Accuracy: 54.7027%\n",
      "Epoch: 3160, Train Loss: 1.4519, Train Accuracy: 54.7027%\n",
      "Epoch: 3170, Train Loss: 1.4518, Train Accuracy: 54.5946%\n",
      "Epoch: 3180, Train Loss: 1.4516, Train Accuracy: 54.5946%\n",
      "Epoch: 3190, Train Loss: 1.4515, Train Accuracy: 54.5946%\n",
      "Epoch: 3200, Train Loss: 1.4513, Train Accuracy: 54.5946%\n",
      "Epoch: 3210, Train Loss: 1.4512, Train Accuracy: 54.5946%\n",
      "Epoch: 3220, Train Loss: 1.4511, Train Accuracy: 54.5946%\n",
      "Epoch: 3230, Train Loss: 1.4509, Train Accuracy: 54.5946%\n",
      "Epoch: 3240, Train Loss: 1.4508, Train Accuracy: 54.5946%\n",
      "Epoch: 3250, Train Loss: 1.4506, Train Accuracy: 54.5946%\n",
      "Epoch: 3260, Train Loss: 1.4505, Train Accuracy: 54.5946%\n",
      "Epoch: 3270, Train Loss: 1.4504, Train Accuracy: 54.5946%\n",
      "Epoch: 3280, Train Loss: 1.4502, Train Accuracy: 54.5946%\n",
      "Epoch: 3290, Train Loss: 1.4501, Train Accuracy: 54.3784%\n",
      "Epoch: 3300, Train Loss: 1.4499, Train Accuracy: 54.3784%\n",
      "Epoch: 3310, Train Loss: 1.4498, Train Accuracy: 54.3784%\n",
      "Epoch: 3320, Train Loss: 1.4497, Train Accuracy: 54.3784%\n",
      "Epoch: 3330, Train Loss: 1.4495, Train Accuracy: 54.3784%\n",
      "Epoch: 3340, Train Loss: 1.4494, Train Accuracy: 54.3784%\n",
      "Epoch: 3350, Train Loss: 1.4493, Train Accuracy: 54.2703%\n",
      "Epoch: 3360, Train Loss: 1.4491, Train Accuracy: 54.2703%\n",
      "Epoch: 3370, Train Loss: 1.4490, Train Accuracy: 54.2703%\n",
      "Epoch: 3380, Train Loss: 1.4489, Train Accuracy: 54.2703%\n",
      "Epoch: 3390, Train Loss: 1.4488, Train Accuracy: 54.2703%\n",
      "Epoch: 3400, Train Loss: 1.4486, Train Accuracy: 54.3784%\n",
      "Epoch: 3410, Train Loss: 1.4485, Train Accuracy: 54.3784%\n",
      "Epoch: 3420, Train Loss: 1.4484, Train Accuracy: 54.3784%\n",
      "Epoch: 3430, Train Loss: 1.4482, Train Accuracy: 54.3784%\n",
      "Epoch: 3440, Train Loss: 1.4481, Train Accuracy: 54.3784%\n",
      "Epoch: 3450, Train Loss: 1.4480, Train Accuracy: 54.3784%\n",
      "Epoch: 3460, Train Loss: 1.4479, Train Accuracy: 54.3784%\n",
      "Epoch: 3470, Train Loss: 1.4478, Train Accuracy: 54.3784%\n",
      "Epoch: 3480, Train Loss: 1.4476, Train Accuracy: 54.3784%\n",
      "Epoch: 3490, Train Loss: 1.4475, Train Accuracy: 54.3784%\n",
      "Epoch: 3500, Train Loss: 1.4474, Train Accuracy: 54.3784%\n",
      "Epoch: 3510, Train Loss: 1.4473, Train Accuracy: 54.3784%\n",
      "Epoch: 3520, Train Loss: 1.4471, Train Accuracy: 54.3784%\n",
      "Epoch: 3530, Train Loss: 1.4470, Train Accuracy: 54.3784%\n",
      "Epoch: 3540, Train Loss: 1.4469, Train Accuracy: 54.3784%\n",
      "Epoch: 3550, Train Loss: 1.4468, Train Accuracy: 54.3784%\n",
      "Epoch: 3560, Train Loss: 1.4467, Train Accuracy: 54.3784%\n",
      "Epoch: 3570, Train Loss: 1.4466, Train Accuracy: 54.3784%\n",
      "Epoch: 3580, Train Loss: 1.4464, Train Accuracy: 54.3784%\n",
      "Epoch: 3590, Train Loss: 1.4463, Train Accuracy: 54.3784%\n",
      "Epoch: 3600, Train Loss: 1.4462, Train Accuracy: 54.4865%\n",
      "Epoch: 3610, Train Loss: 1.4461, Train Accuracy: 54.4865%\n",
      "Epoch: 3620, Train Loss: 1.4460, Train Accuracy: 54.4865%\n",
      "Epoch: 3630, Train Loss: 1.4459, Train Accuracy: 54.4865%\n",
      "Epoch: 3640, Train Loss: 1.4458, Train Accuracy: 54.4865%\n",
      "Epoch: 3650, Train Loss: 1.4457, Train Accuracy: 54.4865%\n",
      "Epoch: 3660, Train Loss: 1.4455, Train Accuracy: 54.4865%\n",
      "Epoch: 3670, Train Loss: 1.4454, Train Accuracy: 54.4865%\n",
      "Epoch: 3680, Train Loss: 1.4453, Train Accuracy: 54.4865%\n",
      "Epoch: 3690, Train Loss: 1.4452, Train Accuracy: 54.4865%\n",
      "Epoch: 3700, Train Loss: 1.4451, Train Accuracy: 54.4865%\n",
      "Epoch: 3710, Train Loss: 1.4450, Train Accuracy: 54.4865%\n",
      "Epoch: 3720, Train Loss: 1.4449, Train Accuracy: 54.4865%\n",
      "Epoch: 3730, Train Loss: 1.4448, Train Accuracy: 54.4865%\n",
      "Epoch: 3740, Train Loss: 1.4447, Train Accuracy: 54.4865%\n",
      "Epoch: 3750, Train Loss: 1.4446, Train Accuracy: 54.4865%\n",
      "Epoch: 3760, Train Loss: 1.4445, Train Accuracy: 54.4865%\n",
      "Epoch: 3770, Train Loss: 1.4444, Train Accuracy: 54.4865%\n",
      "Epoch: 3780, Train Loss: 1.4443, Train Accuracy: 54.4865%\n",
      "Epoch: 3790, Train Loss: 1.4442, Train Accuracy: 54.5946%\n",
      "Epoch: 3800, Train Loss: 1.4441, Train Accuracy: 54.5946%\n",
      "Epoch: 3810, Train Loss: 1.4440, Train Accuracy: 54.5946%\n",
      "Epoch: 3820, Train Loss: 1.4439, Train Accuracy: 54.5946%\n",
      "Epoch: 3830, Train Loss: 1.4438, Train Accuracy: 54.5946%\n",
      "Epoch: 3840, Train Loss: 1.4437, Train Accuracy: 54.5946%\n",
      "Epoch: 3850, Train Loss: 1.4436, Train Accuracy: 54.7027%\n",
      "Epoch: 3860, Train Loss: 1.4435, Train Accuracy: 54.7027%\n",
      "Epoch: 3870, Train Loss: 1.4434, Train Accuracy: 54.7027%\n",
      "Epoch: 3880, Train Loss: 1.4433, Train Accuracy: 54.7027%\n",
      "Epoch: 3890, Train Loss: 1.4432, Train Accuracy: 54.9189%\n",
      "Epoch: 3900, Train Loss: 1.4431, Train Accuracy: 54.9189%\n",
      "Epoch: 3910, Train Loss: 1.4430, Train Accuracy: 54.9189%\n",
      "Epoch: 3920, Train Loss: 1.4429, Train Accuracy: 54.9189%\n",
      "Epoch: 3930, Train Loss: 1.4428, Train Accuracy: 54.9189%\n",
      "Epoch: 3940, Train Loss: 1.4427, Train Accuracy: 54.9189%\n",
      "Epoch: 3950, Train Loss: 1.4426, Train Accuracy: 54.8108%\n",
      "Epoch: 3960, Train Loss: 1.4425, Train Accuracy: 54.8108%\n",
      "Epoch: 3970, Train Loss: 1.4424, Train Accuracy: 54.8108%\n",
      "Epoch: 3980, Train Loss: 1.4423, Train Accuracy: 54.8108%\n",
      "Epoch: 3990, Train Loss: 1.4422, Train Accuracy: 54.8108%\n",
      "Epoch: 4000, Train Loss: 1.4421, Train Accuracy: 54.9189%\n",
      "Epoch: 4010, Train Loss: 1.4420, Train Accuracy: 55.0270%\n",
      "Epoch: 4020, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 4030, Train Loss: 1.4419, Train Accuracy: 55.1351%\n",
      "Epoch: 4040, Train Loss: 1.4418, Train Accuracy: 55.1351%\n",
      "Epoch: 4050, Train Loss: 1.4417, Train Accuracy: 55.1351%\n",
      "Epoch: 4060, Train Loss: 1.4416, Train Accuracy: 55.1351%\n",
      "Epoch: 4070, Train Loss: 1.4415, Train Accuracy: 55.1351%\n",
      "Epoch: 4080, Train Loss: 1.4414, Train Accuracy: 55.0270%\n",
      "Epoch: 4090, Train Loss: 1.4413, Train Accuracy: 54.9189%\n",
      "Epoch: 4100, Train Loss: 1.4412, Train Accuracy: 54.9189%\n",
      "Epoch: 4110, Train Loss: 1.4411, Train Accuracy: 54.9189%\n",
      "Epoch: 4120, Train Loss: 1.4411, Train Accuracy: 54.9189%\n",
      "Epoch: 4130, Train Loss: 1.4410, Train Accuracy: 54.9189%\n",
      "Epoch: 4140, Train Loss: 1.4409, Train Accuracy: 54.9189%\n",
      "Epoch: 4150, Train Loss: 1.4408, Train Accuracy: 54.9189%\n",
      "Epoch: 4160, Train Loss: 1.4407, Train Accuracy: 54.9189%\n",
      "Epoch: 4170, Train Loss: 1.4406, Train Accuracy: 54.9189%\n",
      "Epoch: 4180, Train Loss: 1.4405, Train Accuracy: 54.9189%\n",
      "Epoch: 4190, Train Loss: 1.4405, Train Accuracy: 54.9189%\n",
      "Epoch: 4200, Train Loss: 1.4404, Train Accuracy: 54.9189%\n",
      "Epoch: 4210, Train Loss: 1.4403, Train Accuracy: 54.9189%\n",
      "Epoch: 4220, Train Loss: 1.4402, Train Accuracy: 54.9189%\n",
      "Epoch: 4230, Train Loss: 1.4401, Train Accuracy: 54.9189%\n",
      "Epoch: 4240, Train Loss: 1.4400, Train Accuracy: 54.9189%\n",
      "Epoch: 4250, Train Loss: 1.4400, Train Accuracy: 54.9189%\n",
      "Epoch: 4260, Train Loss: 1.4399, Train Accuracy: 54.9189%\n",
      "Epoch: 4270, Train Loss: 1.4398, Train Accuracy: 54.9189%\n",
      "Epoch: 4280, Train Loss: 1.4397, Train Accuracy: 54.9189%\n",
      "Epoch: 4290, Train Loss: 1.4396, Train Accuracy: 54.9189%\n",
      "Epoch: 4300, Train Loss: 1.4396, Train Accuracy: 54.9189%\n",
      "Epoch: 4310, Train Loss: 1.4395, Train Accuracy: 54.9189%\n",
      "Epoch: 4320, Train Loss: 1.4394, Train Accuracy: 55.0270%\n",
      "Epoch: 4330, Train Loss: 1.4393, Train Accuracy: 55.0270%\n",
      "Epoch: 4340, Train Loss: 1.4392, Train Accuracy: 55.0270%\n",
      "Epoch: 4350, Train Loss: 1.4392, Train Accuracy: 55.0270%\n",
      "Epoch: 4360, Train Loss: 1.4391, Train Accuracy: 55.0270%\n",
      "Epoch: 4370, Train Loss: 1.4390, Train Accuracy: 55.0270%\n",
      "Epoch: 4380, Train Loss: 1.4389, Train Accuracy: 55.0270%\n",
      "Epoch: 4390, Train Loss: 1.4389, Train Accuracy: 55.0270%\n",
      "Epoch: 4400, Train Loss: 1.4388, Train Accuracy: 55.0270%\n",
      "Epoch: 4410, Train Loss: 1.4387, Train Accuracy: 55.0270%\n",
      "Epoch: 4420, Train Loss: 1.4386, Train Accuracy: 54.9189%\n",
      "Epoch: 4430, Train Loss: 1.4386, Train Accuracy: 54.9189%\n",
      "Epoch: 4440, Train Loss: 1.4385, Train Accuracy: 54.9189%\n",
      "Epoch: 4450, Train Loss: 1.4384, Train Accuracy: 54.9189%\n",
      "Epoch: 4460, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 4470, Train Loss: 1.4383, Train Accuracy: 55.1351%\n",
      "Epoch: 4480, Train Loss: 1.4382, Train Accuracy: 55.1351%\n",
      "Epoch: 4490, Train Loss: 1.4381, Train Accuracy: 55.1351%\n",
      "Epoch: 4500, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 4510, Train Loss: 1.4380, Train Accuracy: 55.1351%\n",
      "Epoch: 4520, Train Loss: 1.4379, Train Accuracy: 55.1351%\n",
      "Epoch: 4530, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 4540, Train Loss: 1.4378, Train Accuracy: 55.1351%\n",
      "Epoch: 4550, Train Loss: 1.4377, Train Accuracy: 55.1351%\n",
      "Epoch: 4560, Train Loss: 1.4376, Train Accuracy: 55.1351%\n",
      "Epoch: 4570, Train Loss: 1.4375, Train Accuracy: 55.1351%\n",
      "Epoch: 4580, Train Loss: 1.4375, Train Accuracy: 55.1351%\n",
      "Epoch: 4590, Train Loss: 1.4374, Train Accuracy: 55.1351%\n",
      "Epoch: 4600, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 4610, Train Loss: 1.4373, Train Accuracy: 55.1351%\n",
      "Epoch: 4620, Train Loss: 1.4372, Train Accuracy: 55.1351%\n",
      "Epoch: 4630, Train Loss: 1.4371, Train Accuracy: 55.1351%\n",
      "Epoch: 4640, Train Loss: 1.4371, Train Accuracy: 55.2432%\n",
      "Epoch: 4650, Train Loss: 1.4370, Train Accuracy: 55.2432%\n",
      "Epoch: 4660, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 4670, Train Loss: 1.4369, Train Accuracy: 55.2432%\n",
      "Epoch: 4680, Train Loss: 1.4368, Train Accuracy: 55.2432%\n",
      "Epoch: 4690, Train Loss: 1.4367, Train Accuracy: 55.1351%\n",
      "Epoch: 4700, Train Loss: 1.4367, Train Accuracy: 55.1351%\n",
      "Epoch: 4710, Train Loss: 1.4366, Train Accuracy: 55.1351%\n",
      "Epoch: 4720, Train Loss: 1.4365, Train Accuracy: 55.1351%\n",
      "Epoch: 4730, Train Loss: 1.4365, Train Accuracy: 55.1351%\n",
      "Epoch: 4740, Train Loss: 1.4364, Train Accuracy: 55.1351%\n",
      "Epoch: 4750, Train Loss: 1.4363, Train Accuracy: 55.1351%\n",
      "Epoch: 4760, Train Loss: 1.4363, Train Accuracy: 55.1351%\n",
      "Epoch: 4770, Train Loss: 1.4362, Train Accuracy: 55.1351%\n",
      "Epoch: 4780, Train Loss: 1.4361, Train Accuracy: 55.1351%\n",
      "Epoch: 4790, Train Loss: 1.4361, Train Accuracy: 55.1351%\n",
      "Epoch: 4800, Train Loss: 1.4360, Train Accuracy: 55.1351%\n",
      "Epoch: 4810, Train Loss: 1.4359, Train Accuracy: 55.1351%\n",
      "Epoch: 4820, Train Loss: 1.4359, Train Accuracy: 55.1351%\n",
      "Epoch: 4830, Train Loss: 1.4358, Train Accuracy: 55.1351%\n",
      "Epoch: 4840, Train Loss: 1.4357, Train Accuracy: 55.1351%\n",
      "Epoch: 4850, Train Loss: 1.4357, Train Accuracy: 55.1351%\n",
      "Epoch: 4860, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 4870, Train Loss: 1.4356, Train Accuracy: 55.1351%\n",
      "Epoch: 4880, Train Loss: 1.4355, Train Accuracy: 55.0270%\n",
      "Epoch: 4890, Train Loss: 1.4354, Train Accuracy: 55.0270%\n",
      "Epoch: 4900, Train Loss: 1.4354, Train Accuracy: 55.0270%\n",
      "Epoch: 4910, Train Loss: 1.4353, Train Accuracy: 55.0270%\n",
      "Epoch: 4920, Train Loss: 1.4353, Train Accuracy: 55.1351%\n",
      "Epoch: 4930, Train Loss: 1.4352, Train Accuracy: 55.1351%\n",
      "Epoch: 4940, Train Loss: 1.4351, Train Accuracy: 55.2432%\n",
      "Epoch: 4950, Train Loss: 1.4351, Train Accuracy: 55.2432%\n",
      "Epoch: 4960, Train Loss: 1.4350, Train Accuracy: 55.3514%\n",
      "Epoch: 4970, Train Loss: 1.4350, Train Accuracy: 55.3514%\n",
      "Epoch: 4980, Train Loss: 1.4349, Train Accuracy: 55.3514%\n",
      "Epoch: 4990, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 5000, Train Loss: 1.4348, Train Accuracy: 55.3514%\n",
      "Epoch: 5010, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 5020, Train Loss: 1.4347, Train Accuracy: 55.3514%\n",
      "Epoch: 5030, Train Loss: 1.4346, Train Accuracy: 55.3514%\n",
      "Epoch: 5040, Train Loss: 1.4345, Train Accuracy: 55.3514%\n",
      "Epoch: 5050, Train Loss: 1.4345, Train Accuracy: 55.3514%\n",
      "Epoch: 5060, Train Loss: 1.4344, Train Accuracy: 55.3514%\n",
      "Epoch: 5070, Train Loss: 1.4344, Train Accuracy: 55.4595%\n",
      "Epoch: 5080, Train Loss: 1.4343, Train Accuracy: 55.4595%\n",
      "Epoch: 5090, Train Loss: 1.4343, Train Accuracy: 55.4595%\n",
      "Epoch: 5100, Train Loss: 1.4342, Train Accuracy: 55.4595%\n",
      "Epoch: 5110, Train Loss: 1.4341, Train Accuracy: 55.3514%\n",
      "Epoch: 5120, Train Loss: 1.4341, Train Accuracy: 55.3514%\n",
      "Epoch: 5130, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 5140, Train Loss: 1.4340, Train Accuracy: 55.3514%\n",
      "Epoch: 5150, Train Loss: 1.4339, Train Accuracy: 55.3514%\n",
      "Epoch: 5160, Train Loss: 1.4339, Train Accuracy: 55.3514%\n",
      "Epoch: 5170, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 5180, Train Loss: 1.4338, Train Accuracy: 55.3514%\n",
      "Epoch: 5190, Train Loss: 1.4337, Train Accuracy: 55.3514%\n",
      "Epoch: 5200, Train Loss: 1.4337, Train Accuracy: 55.3514%\n",
      "Epoch: 5210, Train Loss: 1.4336, Train Accuracy: 55.3514%\n",
      "Epoch: 5220, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 5230, Train Loss: 1.4335, Train Accuracy: 55.3514%\n",
      "Epoch: 5240, Train Loss: 1.4334, Train Accuracy: 55.4595%\n",
      "Epoch: 5250, Train Loss: 1.4334, Train Accuracy: 55.4595%\n",
      "Epoch: 5260, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 5270, Train Loss: 1.4333, Train Accuracy: 55.4595%\n",
      "Epoch: 5280, Train Loss: 1.4332, Train Accuracy: 55.4595%\n",
      "Epoch: 5290, Train Loss: 1.4332, Train Accuracy: 55.4595%\n",
      "Epoch: 5300, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 5310, Train Loss: 1.4331, Train Accuracy: 55.4595%\n",
      "Epoch: 5320, Train Loss: 1.4330, Train Accuracy: 55.4595%\n",
      "Epoch: 5330, Train Loss: 1.4330, Train Accuracy: 55.4595%\n",
      "Epoch: 5340, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 5350, Train Loss: 1.4329, Train Accuracy: 55.4595%\n",
      "Epoch: 5360, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 5370, Train Loss: 1.4328, Train Accuracy: 55.4595%\n",
      "Epoch: 5380, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 5390, Train Loss: 1.4327, Train Accuracy: 55.4595%\n",
      "Epoch: 5400, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 5410, Train Loss: 1.4326, Train Accuracy: 55.3514%\n",
      "Epoch: 5420, Train Loss: 1.4325, Train Accuracy: 55.3514%\n",
      "Epoch: 5430, Train Loss: 1.4325, Train Accuracy: 55.3514%\n",
      "Epoch: 5440, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 5450, Train Loss: 1.4324, Train Accuracy: 55.3514%\n",
      "Epoch: 5460, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 5470, Train Loss: 1.4323, Train Accuracy: 55.3514%\n",
      "Epoch: 5480, Train Loss: 1.4322, Train Accuracy: 55.3514%\n",
      "Epoch: 5490, Train Loss: 1.4322, Train Accuracy: 55.3514%\n",
      "Epoch: 5500, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 5510, Train Loss: 1.4321, Train Accuracy: 55.3514%\n",
      "Epoch: 5520, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 5530, Train Loss: 1.4320, Train Accuracy: 55.3514%\n",
      "Epoch: 5540, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 5550, Train Loss: 1.4319, Train Accuracy: 55.3514%\n",
      "Epoch: 5560, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 5570, Train Loss: 1.4318, Train Accuracy: 55.3514%\n",
      "Epoch: 5580, Train Loss: 1.4317, Train Accuracy: 55.3514%\n",
      "Epoch: 5590, Train Loss: 1.4317, Train Accuracy: 55.3514%\n",
      "Epoch: 5600, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 5610, Train Loss: 1.4316, Train Accuracy: 55.3514%\n",
      "Epoch: 5620, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 5630, Train Loss: 1.4315, Train Accuracy: 55.3514%\n",
      "Epoch: 5640, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 5650, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 5660, Train Loss: 1.4314, Train Accuracy: 55.3514%\n",
      "Epoch: 5670, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 5680, Train Loss: 1.4313, Train Accuracy: 55.3514%\n",
      "Epoch: 5690, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 5700, Train Loss: 1.4312, Train Accuracy: 55.3514%\n",
      "Epoch: 5710, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 5720, Train Loss: 1.4311, Train Accuracy: 55.3514%\n",
      "Epoch: 5730, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 5740, Train Loss: 1.4310, Train Accuracy: 55.3514%\n",
      "Epoch: 5750, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 5760, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 5770, Train Loss: 1.4309, Train Accuracy: 55.3514%\n",
      "Epoch: 5780, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 5790, Train Loss: 1.4308, Train Accuracy: 55.3514%\n",
      "Epoch: 5800, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 5810, Train Loss: 1.4307, Train Accuracy: 55.3514%\n",
      "Epoch: 5820, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 5830, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 5840, Train Loss: 1.4306, Train Accuracy: 55.3514%\n",
      "Epoch: 5850, Train Loss: 1.4305, Train Accuracy: 55.3514%\n",
      "Epoch: 5860, Train Loss: 1.4305, Train Accuracy: 55.4595%\n",
      "Epoch: 5870, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 5880, Train Loss: 1.4304, Train Accuracy: 55.4595%\n",
      "Epoch: 5890, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 5900, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 5910, Train Loss: 1.4303, Train Accuracy: 55.4595%\n",
      "Epoch: 5920, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 5930, Train Loss: 1.4302, Train Accuracy: 55.4595%\n",
      "Epoch: 5940, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 5950, Train Loss: 1.4301, Train Accuracy: 55.4595%\n",
      "Epoch: 5960, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 5970, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 5980, Train Loss: 1.4300, Train Accuracy: 55.4595%\n",
      "Epoch: 5990, Train Loss: 1.4299, Train Accuracy: 55.4595%\n",
      "Epoch: 6000, Train Loss: 1.4299, Train Accuracy: 55.5676%\n",
      "Epoch: 6010, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 6020, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 6030, Train Loss: 1.4298, Train Accuracy: 55.5676%\n",
      "Epoch: 6040, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 6050, Train Loss: 1.4297, Train Accuracy: 55.5676%\n",
      "Epoch: 6060, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 6070, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 6080, Train Loss: 1.4296, Train Accuracy: 55.5676%\n",
      "Epoch: 6090, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 6100, Train Loss: 1.4295, Train Accuracy: 55.5676%\n",
      "Epoch: 6110, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 6120, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 6130, Train Loss: 1.4294, Train Accuracy: 55.5676%\n",
      "Epoch: 6140, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 6150, Train Loss: 1.4293, Train Accuracy: 55.5676%\n",
      "Epoch: 6160, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 6170, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 6180, Train Loss: 1.4292, Train Accuracy: 55.5676%\n",
      "Epoch: 6190, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 6200, Train Loss: 1.4291, Train Accuracy: 55.5676%\n",
      "Epoch: 6210, Train Loss: 1.4291, Train Accuracy: 55.4595%\n",
      "Epoch: 6220, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 6230, Train Loss: 1.4290, Train Accuracy: 55.3514%\n",
      "Epoch: 6240, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 6250, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 6260, Train Loss: 1.4289, Train Accuracy: 55.3514%\n",
      "Epoch: 6270, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 6280, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 6290, Train Loss: 1.4288, Train Accuracy: 55.3514%\n",
      "Epoch: 6300, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 6310, Train Loss: 1.4287, Train Accuracy: 55.3514%\n",
      "Epoch: 6320, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 6330, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 6340, Train Loss: 1.4286, Train Accuracy: 55.3514%\n",
      "Epoch: 6350, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 6360, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 6370, Train Loss: 1.4285, Train Accuracy: 55.3514%\n",
      "Epoch: 6380, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 6390, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 6400, Train Loss: 1.4284, Train Accuracy: 55.3514%\n",
      "Epoch: 6410, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 6420, Train Loss: 1.4283, Train Accuracy: 55.3514%\n",
      "Epoch: 6430, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 6440, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 6450, Train Loss: 1.4282, Train Accuracy: 55.3514%\n",
      "Epoch: 6460, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 6470, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 6480, Train Loss: 1.4281, Train Accuracy: 55.3514%\n",
      "Epoch: 6490, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 6500, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 6510, Train Loss: 1.4280, Train Accuracy: 55.3514%\n",
      "Epoch: 6520, Train Loss: 1.4279, Train Accuracy: 55.3514%\n",
      "Epoch: 6530, Train Loss: 1.4279, Train Accuracy: 55.3514%\n",
      "Epoch: 6540, Train Loss: 1.4279, Train Accuracy: 55.2432%\n",
      "Epoch: 6550, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 6560, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 6570, Train Loss: 1.4278, Train Accuracy: 55.2432%\n",
      "Epoch: 6580, Train Loss: 1.4277, Train Accuracy: 55.1351%\n",
      "Epoch: 6590, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 6600, Train Loss: 1.4277, Train Accuracy: 55.2432%\n",
      "Epoch: 6610, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 6620, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 6630, Train Loss: 1.4276, Train Accuracy: 55.2432%\n",
      "Epoch: 6640, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 6650, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 6660, Train Loss: 1.4275, Train Accuracy: 55.2432%\n",
      "Epoch: 6670, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 6680, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 6690, Train Loss: 1.4274, Train Accuracy: 55.2432%\n",
      "Epoch: 6700, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 6710, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 6720, Train Loss: 1.4273, Train Accuracy: 55.3514%\n",
      "Epoch: 6730, Train Loss: 1.4272, Train Accuracy: 55.3514%\n",
      "Epoch: 6740, Train Loss: 1.4272, Train Accuracy: 55.4595%\n",
      "Epoch: 6750, Train Loss: 1.4272, Train Accuracy: 55.4595%\n",
      "Epoch: 6760, Train Loss: 1.4271, Train Accuracy: 55.4595%\n",
      "Epoch: 6770, Train Loss: 1.4271, Train Accuracy: 55.4595%\n",
      "Epoch: 6780, Train Loss: 1.4271, Train Accuracy: 55.4595%\n",
      "Epoch: 6790, Train Loss: 1.4270, Train Accuracy: 55.4595%\n",
      "Epoch: 6800, Train Loss: 1.4270, Train Accuracy: 55.3514%\n",
      "Epoch: 6810, Train Loss: 1.4270, Train Accuracy: 55.3514%\n",
      "Epoch: 6820, Train Loss: 1.4269, Train Accuracy: 55.3514%\n",
      "Epoch: 6830, Train Loss: 1.4269, Train Accuracy: 55.3514%\n",
      "Epoch: 6840, Train Loss: 1.4269, Train Accuracy: 55.3514%\n",
      "Epoch: 6850, Train Loss: 1.4268, Train Accuracy: 55.3514%\n",
      "Epoch: 6860, Train Loss: 1.4268, Train Accuracy: 55.3514%\n",
      "Epoch: 6870, Train Loss: 1.4268, Train Accuracy: 55.3514%\n",
      "Epoch: 6880, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 6890, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 6900, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 6910, Train Loss: 1.4267, Train Accuracy: 55.3514%\n",
      "Epoch: 6920, Train Loss: 1.4266, Train Accuracy: 55.3514%\n",
      "Epoch: 6930, Train Loss: 1.4266, Train Accuracy: 55.3514%\n",
      "Epoch: 6940, Train Loss: 1.4266, Train Accuracy: 55.3514%\n",
      "Epoch: 6950, Train Loss: 1.4265, Train Accuracy: 55.3514%\n",
      "Epoch: 6960, Train Loss: 1.4265, Train Accuracy: 55.3514%\n",
      "Epoch: 6970, Train Loss: 1.4265, Train Accuracy: 55.3514%\n",
      "Epoch: 6980, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 6990, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 7000, Train Loss: 1.4264, Train Accuracy: 55.3514%\n",
      "Epoch: 7010, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 7020, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 7030, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 7040, Train Loss: 1.4263, Train Accuracy: 55.3514%\n",
      "Epoch: 7050, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 7060, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 7070, Train Loss: 1.4262, Train Accuracy: 55.3514%\n",
      "Epoch: 7080, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 7090, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 7100, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 7110, Train Loss: 1.4261, Train Accuracy: 55.3514%\n",
      "Epoch: 7120, Train Loss: 1.4260, Train Accuracy: 55.3514%\n",
      "Epoch: 7130, Train Loss: 1.4260, Train Accuracy: 55.3514%\n",
      "Epoch: 7140, Train Loss: 1.4260, Train Accuracy: 55.3514%\n",
      "Epoch: 7150, Train Loss: 1.4259, Train Accuracy: 55.3514%\n",
      "Epoch: 7160, Train Loss: 1.4259, Train Accuracy: 55.3514%\n",
      "Epoch: 7170, Train Loss: 1.4259, Train Accuracy: 55.3514%\n",
      "Epoch: 7180, Train Loss: 1.4259, Train Accuracy: 55.3514%\n",
      "Epoch: 7190, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 7200, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 7210, Train Loss: 1.4258, Train Accuracy: 55.3514%\n",
      "Epoch: 7220, Train Loss: 1.4257, Train Accuracy: 55.3514%\n",
      "Epoch: 7230, Train Loss: 1.4257, Train Accuracy: 55.3514%\n",
      "Epoch: 7240, Train Loss: 1.4257, Train Accuracy: 55.3514%\n",
      "Epoch: 7250, Train Loss: 1.4257, Train Accuracy: 55.3514%\n",
      "Epoch: 7260, Train Loss: 1.4256, Train Accuracy: 55.3514%\n",
      "Epoch: 7270, Train Loss: 1.4256, Train Accuracy: 55.3514%\n",
      "Epoch: 7280, Train Loss: 1.4256, Train Accuracy: 55.3514%\n",
      "Epoch: 7290, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 7300, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 7310, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 7320, Train Loss: 1.4255, Train Accuracy: 55.3514%\n",
      "Epoch: 7330, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 7340, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 7350, Train Loss: 1.4254, Train Accuracy: 55.3514%\n",
      "Epoch: 7360, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 7370, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 7380, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 7390, Train Loss: 1.4253, Train Accuracy: 55.3514%\n",
      "Epoch: 7400, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 7410, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 7420, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 7430, Train Loss: 1.4252, Train Accuracy: 55.3514%\n",
      "Epoch: 7440, Train Loss: 1.4251, Train Accuracy: 55.3514%\n",
      "Epoch: 7450, Train Loss: 1.4251, Train Accuracy: 55.2432%\n",
      "Epoch: 7460, Train Loss: 1.4251, Train Accuracy: 55.2432%\n",
      "Epoch: 7470, Train Loss: 1.4251, Train Accuracy: 55.2432%\n",
      "Epoch: 7480, Train Loss: 1.4250, Train Accuracy: 55.2432%\n",
      "Epoch: 7490, Train Loss: 1.4250, Train Accuracy: 55.2432%\n",
      "Epoch: 7500, Train Loss: 1.4250, Train Accuracy: 55.2432%\n",
      "Epoch: 7510, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 7520, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 7530, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 7540, Train Loss: 1.4249, Train Accuracy: 55.2432%\n",
      "Epoch: 7550, Train Loss: 1.4248, Train Accuracy: 55.2432%\n",
      "Epoch: 7560, Train Loss: 1.4248, Train Accuracy: 55.2432%\n",
      "Epoch: 7570, Train Loss: 1.4248, Train Accuracy: 55.2432%\n",
      "Epoch: 7580, Train Loss: 1.4248, Train Accuracy: 55.2432%\n",
      "Epoch: 7590, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 7600, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 7610, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 7620, Train Loss: 1.4247, Train Accuracy: 55.2432%\n",
      "Epoch: 7630, Train Loss: 1.4246, Train Accuracy: 55.2432%\n",
      "Epoch: 7640, Train Loss: 1.4246, Train Accuracy: 55.2432%\n",
      "Epoch: 7650, Train Loss: 1.4246, Train Accuracy: 55.2432%\n",
      "Epoch: 7660, Train Loss: 1.4246, Train Accuracy: 55.2432%\n",
      "Epoch: 7670, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 7680, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 7690, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 7700, Train Loss: 1.4245, Train Accuracy: 55.2432%\n",
      "Epoch: 7710, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 7720, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 7730, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 7740, Train Loss: 1.4244, Train Accuracy: 55.2432%\n",
      "Epoch: 7750, Train Loss: 1.4243, Train Accuracy: 55.1351%\n",
      "Epoch: 7760, Train Loss: 1.4243, Train Accuracy: 55.1351%\n",
      "Epoch: 7770, Train Loss: 1.4243, Train Accuracy: 55.1351%\n",
      "Epoch: 7780, Train Loss: 1.4243, Train Accuracy: 55.1351%\n",
      "Epoch: 7790, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 7800, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 7810, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 7820, Train Loss: 1.4242, Train Accuracy: 55.1351%\n",
      "Epoch: 7830, Train Loss: 1.4241, Train Accuracy: 55.1351%\n",
      "Epoch: 7840, Train Loss: 1.4241, Train Accuracy: 55.1351%\n",
      "Epoch: 7850, Train Loss: 1.4241, Train Accuracy: 55.1351%\n",
      "Epoch: 7860, Train Loss: 1.4241, Train Accuracy: 55.1351%\n",
      "Epoch: 7870, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 7880, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 7890, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 7900, Train Loss: 1.4240, Train Accuracy: 55.1351%\n",
      "Epoch: 7910, Train Loss: 1.4239, Train Accuracy: 55.1351%\n",
      "Epoch: 7920, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 7930, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 7940, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 7950, Train Loss: 1.4239, Train Accuracy: 55.0270%\n",
      "Epoch: 7960, Train Loss: 1.4238, Train Accuracy: 55.0270%\n",
      "Epoch: 7970, Train Loss: 1.4238, Train Accuracy: 55.0270%\n",
      "Epoch: 7980, Train Loss: 1.4238, Train Accuracy: 55.0270%\n",
      "Epoch: 7990, Train Loss: 1.4238, Train Accuracy: 55.0270%\n",
      "Epoch: 8000, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 8010, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 8020, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 8030, Train Loss: 1.4237, Train Accuracy: 55.0270%\n",
      "Epoch: 8040, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 8050, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 8060, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 8070, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 8080, Train Loss: 1.4236, Train Accuracy: 54.9189%\n",
      "Epoch: 8090, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 8100, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 8110, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 8120, Train Loss: 1.4235, Train Accuracy: 54.9189%\n",
      "Epoch: 8130, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 8140, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 8150, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 8160, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 8170, Train Loss: 1.4234, Train Accuracy: 54.9189%\n",
      "Epoch: 8180, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 8190, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 8200, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 8210, Train Loss: 1.4233, Train Accuracy: 54.9189%\n",
      "Epoch: 8220, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 8230, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 8240, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 8250, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 8260, Train Loss: 1.4232, Train Accuracy: 54.9189%\n",
      "Epoch: 8270, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 8280, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 8290, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 8300, Train Loss: 1.4231, Train Accuracy: 54.9189%\n",
      "Epoch: 8310, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 8320, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 8330, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 8340, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 8350, Train Loss: 1.4230, Train Accuracy: 54.9189%\n",
      "Epoch: 8360, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 8370, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 8380, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 8390, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 8400, Train Loss: 1.4229, Train Accuracy: 54.9189%\n",
      "Epoch: 8410, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 8420, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 8430, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 8440, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 8450, Train Loss: 1.4228, Train Accuracy: 54.9189%\n",
      "Epoch: 8460, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 8470, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 8480, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 8490, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 8500, Train Loss: 1.4227, Train Accuracy: 55.0270%\n",
      "Epoch: 8510, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 8520, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 8530, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 8540, Train Loss: 1.4226, Train Accuracy: 55.0270%\n",
      "Epoch: 8550, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 8560, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 8570, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 8580, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 8590, Train Loss: 1.4225, Train Accuracy: 55.0270%\n",
      "Epoch: 8600, Train Loss: 1.4224, Train Accuracy: 55.0270%\n",
      "Epoch: 8610, Train Loss: 1.4224, Train Accuracy: 55.0270%\n",
      "Epoch: 8620, Train Loss: 1.4224, Train Accuracy: 55.1351%\n",
      "Epoch: 8630, Train Loss: 1.4224, Train Accuracy: 55.1351%\n",
      "Epoch: 8640, Train Loss: 1.4224, Train Accuracy: 55.1351%\n",
      "Epoch: 8650, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 8660, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 8670, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 8680, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 8690, Train Loss: 1.4223, Train Accuracy: 55.1351%\n",
      "Epoch: 8700, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8710, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8720, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8730, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8740, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8750, Train Loss: 1.4222, Train Accuracy: 55.1351%\n",
      "Epoch: 8760, Train Loss: 1.4221, Train Accuracy: 55.1351%\n",
      "Epoch: 8770, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 8780, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 8790, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 8800, Train Loss: 1.4221, Train Accuracy: 55.2432%\n",
      "Epoch: 8810, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 8820, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 8830, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 8840, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 8850, Train Loss: 1.4220, Train Accuracy: 55.2432%\n",
      "Epoch: 8860, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 8870, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 8880, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 8890, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 8900, Train Loss: 1.4219, Train Accuracy: 55.2432%\n",
      "Epoch: 8910, Train Loss: 1.4218, Train Accuracy: 55.2432%\n",
      "Epoch: 8920, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 8930, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 8940, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 8950, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 8960, Train Loss: 1.4218, Train Accuracy: 55.3514%\n",
      "Epoch: 8970, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 8980, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 8990, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 9000, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 9010, Train Loss: 1.4217, Train Accuracy: 55.3514%\n",
      "Epoch: 9020, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9030, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9040, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9050, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9060, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9070, Train Loss: 1.4216, Train Accuracy: 55.3514%\n",
      "Epoch: 9080, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 9090, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 9100, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 9110, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 9120, Train Loss: 1.4215, Train Accuracy: 55.3514%\n",
      "Epoch: 9130, Train Loss: 1.4214, Train Accuracy: 55.3514%\n",
      "Epoch: 9140, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 9150, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 9160, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 9170, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 9180, Train Loss: 1.4214, Train Accuracy: 55.2432%\n",
      "Epoch: 9190, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9200, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9210, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9220, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9230, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9240, Train Loss: 1.4213, Train Accuracy: 55.2432%\n",
      "Epoch: 9250, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9260, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9270, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9280, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9290, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9300, Train Loss: 1.4212, Train Accuracy: 55.2432%\n",
      "Epoch: 9310, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 9320, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 9330, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 9340, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 9350, Train Loss: 1.4211, Train Accuracy: 55.2432%\n",
      "Epoch: 9360, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9370, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9380, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9390, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9400, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9410, Train Loss: 1.4210, Train Accuracy: 55.2432%\n",
      "Epoch: 9420, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9430, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9440, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9450, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9460, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9470, Train Loss: 1.4209, Train Accuracy: 55.2432%\n",
      "Epoch: 9480, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9490, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9500, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9510, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9520, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9530, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9540, Train Loss: 1.4208, Train Accuracy: 55.2432%\n",
      "Epoch: 9550, Train Loss: 1.4207, Train Accuracy: 55.2432%\n",
      "Epoch: 9560, Train Loss: 1.4207, Train Accuracy: 55.2432%\n",
      "Epoch: 9570, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 9580, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 9590, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 9600, Train Loss: 1.4207, Train Accuracy: 55.1351%\n",
      "Epoch: 9610, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9620, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9630, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9640, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9650, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9660, Train Loss: 1.4206, Train Accuracy: 55.1351%\n",
      "Epoch: 9670, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9680, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9690, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9700, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9710, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9720, Train Loss: 1.4205, Train Accuracy: 55.1351%\n",
      "Epoch: 9730, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9740, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9750, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9760, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9770, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9780, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9790, Train Loss: 1.4204, Train Accuracy: 55.1351%\n",
      "Epoch: 9800, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9810, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9820, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9830, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9840, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9850, Train Loss: 1.4203, Train Accuracy: 55.1351%\n",
      "Epoch: 9860, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9870, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9880, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9890, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9900, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9910, Train Loss: 1.4202, Train Accuracy: 55.1351%\n",
      "Epoch: 9920, Train Loss: 1.4202, Train Accuracy: 55.2432%\n",
      "Epoch: 9930, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9940, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9950, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9960, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9970, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9980, Train Loss: 1.4201, Train Accuracy: 55.2432%\n",
      "Epoch: 9990, Train Loss: 1.4201, Train Accuracy: 55.2432%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:swrzphem) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_accuracy</td><td>▁▁▃▃▃▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇██████▇███▇▇▇▇▇█▇▇▇▇</td></tr><tr><td>train_loss</td><td>█▇▅▄▄▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▄▄▃▃▃▁▃▄▄▄▆▆▆▄▄▄▄▄▄▄▄▆▆█▆▆▆▆▆▆▆█████████</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>9999</td></tr><tr><td>train_accuracy</td><td>0.55243</td></tr><tr><td>train_loss</td><td>1.42004</td></tr><tr><td>val_accuracy</td><td>0.56311</td></tr><tr><td>val_loss</td><td>1.37661</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Logistic Regression lr=0.003</strong> at: <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/swrzphem' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/swrzphem</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231012_190424-swrzphem/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:swrzphem). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/arjundosajh/IIITH/Sem 5/SMAI/assignment-3-ArjunDosajh/wandb/run-20231012_190444-0hy1b05h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/0hy1b05h' target=\"_blank\">Logistic Regression lr=0.0003</a></strong> to <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/0hy1b05h' target=\"_blank\">https://wandb.ai/arjundosajh/SMAI-Assignment%203/runs/0hy1b05h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train Loss: 1.7918, Train Accuracy: 0.5405%\n",
      "Epoch: 10, Train Loss: 1.7912, Train Accuracy: 51.5676%\n",
      "Epoch: 20, Train Loss: 1.7907, Train Accuracy: 51.5676%\n",
      "Epoch: 30, Train Loss: 1.7902, Train Accuracy: 51.5676%\n",
      "Epoch: 40, Train Loss: 1.7897, Train Accuracy: 51.5676%\n",
      "Epoch: 50, Train Loss: 1.7892, Train Accuracy: 51.5676%\n",
      "Epoch: 60, Train Loss: 1.7887, Train Accuracy: 51.5676%\n",
      "Epoch: 70, Train Loss: 1.7882, Train Accuracy: 51.5676%\n",
      "Epoch: 80, Train Loss: 1.7877, Train Accuracy: 51.5676%\n",
      "Epoch: 90, Train Loss: 1.7872, Train Accuracy: 51.5676%\n",
      "Epoch: 100, Train Loss: 1.7866, Train Accuracy: 51.5676%\n",
      "Epoch: 110, Train Loss: 1.7861, Train Accuracy: 51.5676%\n",
      "Epoch: 120, Train Loss: 1.7856, Train Accuracy: 51.5676%\n",
      "Epoch: 130, Train Loss: 1.7851, Train Accuracy: 51.5676%\n",
      "Epoch: 140, Train Loss: 1.7846, Train Accuracy: 51.5676%\n",
      "Epoch: 150, Train Loss: 1.7841, Train Accuracy: 51.5676%\n",
      "Epoch: 160, Train Loss: 1.7836, Train Accuracy: 51.5676%\n",
      "Epoch: 170, Train Loss: 1.7831, Train Accuracy: 51.5676%\n",
      "Epoch: 180, Train Loss: 1.7826, Train Accuracy: 51.5676%\n",
      "Epoch: 190, Train Loss: 1.7821, Train Accuracy: 51.5676%\n",
      "Epoch: 200, Train Loss: 1.7816, Train Accuracy: 51.5676%\n",
      "Epoch: 210, Train Loss: 1.7811, Train Accuracy: 51.5676%\n",
      "Epoch: 220, Train Loss: 1.7806, Train Accuracy: 51.5676%\n",
      "Epoch: 230, Train Loss: 1.7801, Train Accuracy: 51.5676%\n",
      "Epoch: 240, Train Loss: 1.7796, Train Accuracy: 51.5676%\n",
      "Epoch: 250, Train Loss: 1.7791, Train Accuracy: 51.5676%\n",
      "Epoch: 260, Train Loss: 1.7786, Train Accuracy: 51.5676%\n",
      "Epoch: 270, Train Loss: 1.7782, Train Accuracy: 51.5676%\n",
      "Epoch: 280, Train Loss: 1.7777, Train Accuracy: 51.5676%\n",
      "Epoch: 290, Train Loss: 1.7772, Train Accuracy: 51.6757%\n",
      "Epoch: 300, Train Loss: 1.7767, Train Accuracy: 51.6757%\n",
      "Epoch: 310, Train Loss: 1.7762, Train Accuracy: 51.6757%\n",
      "Epoch: 320, Train Loss: 1.7757, Train Accuracy: 51.6757%\n",
      "Epoch: 330, Train Loss: 1.7752, Train Accuracy: 51.6757%\n",
      "Epoch: 340, Train Loss: 1.7747, Train Accuracy: 51.6757%\n",
      "Epoch: 350, Train Loss: 1.7743, Train Accuracy: 51.6757%\n",
      "Epoch: 360, Train Loss: 1.7738, Train Accuracy: 51.6757%\n",
      "Epoch: 370, Train Loss: 1.7733, Train Accuracy: 51.6757%\n",
      "Epoch: 380, Train Loss: 1.7728, Train Accuracy: 51.6757%\n",
      "Epoch: 390, Train Loss: 1.7723, Train Accuracy: 51.6757%\n",
      "Epoch: 400, Train Loss: 1.7718, Train Accuracy: 51.6757%\n",
      "Epoch: 410, Train Loss: 1.7714, Train Accuracy: 51.6757%\n",
      "Epoch: 420, Train Loss: 1.7709, Train Accuracy: 51.6757%\n",
      "Epoch: 430, Train Loss: 1.7704, Train Accuracy: 51.6757%\n",
      "Epoch: 440, Train Loss: 1.7699, Train Accuracy: 51.6757%\n",
      "Epoch: 450, Train Loss: 1.7694, Train Accuracy: 51.6757%\n",
      "Epoch: 460, Train Loss: 1.7690, Train Accuracy: 51.6757%\n",
      "Epoch: 470, Train Loss: 1.7685, Train Accuracy: 51.6757%\n",
      "Epoch: 480, Train Loss: 1.7680, Train Accuracy: 51.6757%\n",
      "Epoch: 490, Train Loss: 1.7676, Train Accuracy: 51.6757%\n",
      "Epoch: 500, Train Loss: 1.7671, Train Accuracy: 51.6757%\n",
      "Epoch: 510, Train Loss: 1.7666, Train Accuracy: 51.6757%\n",
      "Epoch: 520, Train Loss: 1.7661, Train Accuracy: 51.6757%\n",
      "Epoch: 530, Train Loss: 1.7657, Train Accuracy: 51.6757%\n",
      "Epoch: 540, Train Loss: 1.7652, Train Accuracy: 51.6757%\n",
      "Epoch: 550, Train Loss: 1.7647, Train Accuracy: 51.6757%\n",
      "Epoch: 560, Train Loss: 1.7643, Train Accuracy: 51.6757%\n",
      "Epoch: 570, Train Loss: 1.7638, Train Accuracy: 51.6757%\n",
      "Epoch: 580, Train Loss: 1.7633, Train Accuracy: 51.6757%\n",
      "Epoch: 590, Train Loss: 1.7629, Train Accuracy: 51.6757%\n",
      "Epoch: 600, Train Loss: 1.7624, Train Accuracy: 51.6757%\n",
      "Epoch: 610, Train Loss: 1.7619, Train Accuracy: 51.6757%\n",
      "Epoch: 620, Train Loss: 1.7615, Train Accuracy: 51.6757%\n",
      "Epoch: 630, Train Loss: 1.7610, Train Accuracy: 51.6757%\n",
      "Epoch: 640, Train Loss: 1.7606, Train Accuracy: 51.6757%\n",
      "Epoch: 650, Train Loss: 1.7601, Train Accuracy: 51.6757%\n",
      "Epoch: 660, Train Loss: 1.7596, Train Accuracy: 51.6757%\n",
      "Epoch: 670, Train Loss: 1.7592, Train Accuracy: 51.6757%\n",
      "Epoch: 680, Train Loss: 1.7587, Train Accuracy: 51.6757%\n",
      "Epoch: 690, Train Loss: 1.7583, Train Accuracy: 51.6757%\n",
      "Epoch: 700, Train Loss: 1.7578, Train Accuracy: 51.6757%\n",
      "Epoch: 710, Train Loss: 1.7574, Train Accuracy: 51.6757%\n",
      "Epoch: 720, Train Loss: 1.7569, Train Accuracy: 51.6757%\n",
      "Epoch: 730, Train Loss: 1.7564, Train Accuracy: 51.6757%\n",
      "Epoch: 740, Train Loss: 1.7560, Train Accuracy: 51.6757%\n",
      "Epoch: 750, Train Loss: 1.7555, Train Accuracy: 51.6757%\n",
      "Epoch: 760, Train Loss: 1.7551, Train Accuracy: 51.6757%\n",
      "Epoch: 770, Train Loss: 1.7546, Train Accuracy: 51.6757%\n",
      "Epoch: 780, Train Loss: 1.7542, Train Accuracy: 51.6757%\n",
      "Epoch: 790, Train Loss: 1.7537, Train Accuracy: 51.6757%\n",
      "Epoch: 800, Train Loss: 1.7533, Train Accuracy: 51.6757%\n",
      "Epoch: 810, Train Loss: 1.7529, Train Accuracy: 51.6757%\n",
      "Epoch: 820, Train Loss: 1.7524, Train Accuracy: 51.6757%\n",
      "Epoch: 830, Train Loss: 1.7520, Train Accuracy: 51.6757%\n",
      "Epoch: 840, Train Loss: 1.7515, Train Accuracy: 51.6757%\n",
      "Epoch: 850, Train Loss: 1.7511, Train Accuracy: 51.6757%\n",
      "Epoch: 860, Train Loss: 1.7506, Train Accuracy: 51.6757%\n",
      "Epoch: 870, Train Loss: 1.7502, Train Accuracy: 51.6757%\n",
      "Epoch: 880, Train Loss: 1.7497, Train Accuracy: 51.6757%\n",
      "Epoch: 890, Train Loss: 1.7493, Train Accuracy: 51.6757%\n",
      "Epoch: 900, Train Loss: 1.7489, Train Accuracy: 51.6757%\n",
      "Epoch: 910, Train Loss: 1.7484, Train Accuracy: 51.6757%\n",
      "Epoch: 920, Train Loss: 1.7480, Train Accuracy: 51.6757%\n",
      "Epoch: 930, Train Loss: 1.7475, Train Accuracy: 51.6757%\n",
      "Epoch: 940, Train Loss: 1.7471, Train Accuracy: 51.6757%\n",
      "Epoch: 950, Train Loss: 1.7467, Train Accuracy: 51.6757%\n",
      "Epoch: 960, Train Loss: 1.7462, Train Accuracy: 51.6757%\n",
      "Epoch: 970, Train Loss: 1.7458, Train Accuracy: 51.6757%\n",
      "Epoch: 980, Train Loss: 1.7454, Train Accuracy: 51.6757%\n",
      "Epoch: 990, Train Loss: 1.7449, Train Accuracy: 51.6757%\n",
      "Epoch: 1000, Train Loss: 1.7445, Train Accuracy: 51.6757%\n",
      "Epoch: 1010, Train Loss: 1.7441, Train Accuracy: 51.6757%\n",
      "Epoch: 1020, Train Loss: 1.7436, Train Accuracy: 51.6757%\n",
      "Epoch: 1030, Train Loss: 1.7432, Train Accuracy: 51.6757%\n",
      "Epoch: 1040, Train Loss: 1.7428, Train Accuracy: 51.6757%\n",
      "Epoch: 1050, Train Loss: 1.7424, Train Accuracy: 51.6757%\n",
      "Epoch: 1060, Train Loss: 1.7419, Train Accuracy: 51.6757%\n",
      "Epoch: 1070, Train Loss: 1.7415, Train Accuracy: 51.6757%\n",
      "Epoch: 1080, Train Loss: 1.7411, Train Accuracy: 51.6757%\n",
      "Epoch: 1090, Train Loss: 1.7407, Train Accuracy: 51.6757%\n",
      "Epoch: 1100, Train Loss: 1.7402, Train Accuracy: 51.6757%\n",
      "Epoch: 1110, Train Loss: 1.7398, Train Accuracy: 51.6757%\n",
      "Epoch: 1120, Train Loss: 1.7394, Train Accuracy: 51.6757%\n",
      "Epoch: 1130, Train Loss: 1.7390, Train Accuracy: 51.6757%\n",
      "Epoch: 1140, Train Loss: 1.7385, Train Accuracy: 51.6757%\n",
      "Epoch: 1150, Train Loss: 1.7381, Train Accuracy: 51.6757%\n",
      "Epoch: 1160, Train Loss: 1.7377, Train Accuracy: 51.6757%\n",
      "Epoch: 1170, Train Loss: 1.7373, Train Accuracy: 51.6757%\n",
      "Epoch: 1180, Train Loss: 1.7369, Train Accuracy: 51.6757%\n",
      "Epoch: 1190, Train Loss: 1.7364, Train Accuracy: 51.6757%\n",
      "Epoch: 1200, Train Loss: 1.7360, Train Accuracy: 51.6757%\n",
      "Epoch: 1210, Train Loss: 1.7356, Train Accuracy: 51.6757%\n",
      "Epoch: 1220, Train Loss: 1.7352, Train Accuracy: 51.6757%\n",
      "Epoch: 1230, Train Loss: 1.7348, Train Accuracy: 51.6757%\n",
      "Epoch: 1240, Train Loss: 1.7344, Train Accuracy: 51.6757%\n",
      "Epoch: 1250, Train Loss: 1.7339, Train Accuracy: 51.6757%\n",
      "Epoch: 1260, Train Loss: 1.7335, Train Accuracy: 51.6757%\n",
      "Epoch: 1270, Train Loss: 1.7331, Train Accuracy: 51.6757%\n",
      "Epoch: 1280, Train Loss: 1.7327, Train Accuracy: 51.6757%\n",
      "Epoch: 1290, Train Loss: 1.7323, Train Accuracy: 51.6757%\n",
      "Epoch: 1300, Train Loss: 1.7319, Train Accuracy: 51.6757%\n",
      "Epoch: 1310, Train Loss: 1.7315, Train Accuracy: 51.6757%\n",
      "Epoch: 1320, Train Loss: 1.7311, Train Accuracy: 51.6757%\n",
      "Epoch: 1330, Train Loss: 1.7307, Train Accuracy: 51.6757%\n",
      "Epoch: 1340, Train Loss: 1.7303, Train Accuracy: 51.6757%\n",
      "Epoch: 1350, Train Loss: 1.7299, Train Accuracy: 51.6757%\n",
      "Epoch: 1360, Train Loss: 1.7294, Train Accuracy: 51.6757%\n",
      "Epoch: 1370, Train Loss: 1.7290, Train Accuracy: 51.6757%\n",
      "Epoch: 1380, Train Loss: 1.7286, Train Accuracy: 51.6757%\n",
      "Epoch: 1390, Train Loss: 1.7282, Train Accuracy: 51.6757%\n",
      "Epoch: 1400, Train Loss: 1.7278, Train Accuracy: 51.6757%\n",
      "Epoch: 1410, Train Loss: 1.7274, Train Accuracy: 51.6757%\n",
      "Epoch: 1420, Train Loss: 1.7270, Train Accuracy: 51.6757%\n",
      "Epoch: 1430, Train Loss: 1.7266, Train Accuracy: 51.6757%\n",
      "Epoch: 1440, Train Loss: 1.7262, Train Accuracy: 51.6757%\n",
      "Epoch: 1450, Train Loss: 1.7258, Train Accuracy: 51.6757%\n",
      "Epoch: 1460, Train Loss: 1.7254, Train Accuracy: 51.6757%\n",
      "Epoch: 1470, Train Loss: 1.7250, Train Accuracy: 51.6757%\n",
      "Epoch: 1480, Train Loss: 1.7246, Train Accuracy: 51.6757%\n",
      "Epoch: 1490, Train Loss: 1.7242, Train Accuracy: 51.6757%\n",
      "Epoch: 1500, Train Loss: 1.7238, Train Accuracy: 51.6757%\n",
      "Epoch: 1510, Train Loss: 1.7234, Train Accuracy: 51.6757%\n",
      "Epoch: 1520, Train Loss: 1.7231, Train Accuracy: 51.6757%\n",
      "Epoch: 1530, Train Loss: 1.7227, Train Accuracy: 51.6757%\n",
      "Epoch: 1540, Train Loss: 1.7223, Train Accuracy: 51.6757%\n",
      "Epoch: 1550, Train Loss: 1.7219, Train Accuracy: 51.6757%\n",
      "Epoch: 1560, Train Loss: 1.7215, Train Accuracy: 51.6757%\n",
      "Epoch: 1570, Train Loss: 1.7211, Train Accuracy: 51.6757%\n",
      "Epoch: 1580, Train Loss: 1.7207, Train Accuracy: 51.6757%\n",
      "Epoch: 1590, Train Loss: 1.7203, Train Accuracy: 51.6757%\n",
      "Epoch: 1600, Train Loss: 1.7199, Train Accuracy: 51.6757%\n",
      "Epoch: 1610, Train Loss: 1.7195, Train Accuracy: 51.6757%\n",
      "Epoch: 1620, Train Loss: 1.7191, Train Accuracy: 51.6757%\n",
      "Epoch: 1630, Train Loss: 1.7188, Train Accuracy: 51.6757%\n",
      "Epoch: 1640, Train Loss: 1.7184, Train Accuracy: 51.6757%\n",
      "Epoch: 1650, Train Loss: 1.7180, Train Accuracy: 51.6757%\n",
      "Epoch: 1660, Train Loss: 1.7176, Train Accuracy: 51.6757%\n",
      "Epoch: 1670, Train Loss: 1.7172, Train Accuracy: 51.6757%\n",
      "Epoch: 1680, Train Loss: 1.7168, Train Accuracy: 51.6757%\n",
      "Epoch: 1690, Train Loss: 1.7165, Train Accuracy: 51.6757%\n",
      "Epoch: 1700, Train Loss: 1.7161, Train Accuracy: 51.6757%\n",
      "Epoch: 1710, Train Loss: 1.7157, Train Accuracy: 51.6757%\n",
      "Epoch: 1720, Train Loss: 1.7153, Train Accuracy: 51.6757%\n",
      "Epoch: 1730, Train Loss: 1.7149, Train Accuracy: 51.6757%\n",
      "Epoch: 1740, Train Loss: 1.7145, Train Accuracy: 51.6757%\n",
      "Epoch: 1750, Train Loss: 1.7142, Train Accuracy: 51.6757%\n",
      "Epoch: 1760, Train Loss: 1.7138, Train Accuracy: 51.6757%\n",
      "Epoch: 1770, Train Loss: 1.7134, Train Accuracy: 51.6757%\n",
      "Epoch: 1780, Train Loss: 1.7130, Train Accuracy: 51.6757%\n",
      "Epoch: 1790, Train Loss: 1.7127, Train Accuracy: 51.6757%\n",
      "Epoch: 1800, Train Loss: 1.7123, Train Accuracy: 51.6757%\n",
      "Epoch: 1810, Train Loss: 1.7119, Train Accuracy: 51.6757%\n",
      "Epoch: 1820, Train Loss: 1.7115, Train Accuracy: 51.6757%\n",
      "Epoch: 1830, Train Loss: 1.7112, Train Accuracy: 51.6757%\n",
      "Epoch: 1840, Train Loss: 1.7108, Train Accuracy: 51.6757%\n",
      "Epoch: 1850, Train Loss: 1.7104, Train Accuracy: 51.6757%\n",
      "Epoch: 1860, Train Loss: 1.7100, Train Accuracy: 51.7838%\n",
      "Epoch: 1870, Train Loss: 1.7097, Train Accuracy: 51.7838%\n",
      "Epoch: 1880, Train Loss: 1.7093, Train Accuracy: 51.7838%\n",
      "Epoch: 1890, Train Loss: 1.7089, Train Accuracy: 51.7838%\n",
      "Epoch: 1900, Train Loss: 1.7086, Train Accuracy: 51.7838%\n",
      "Epoch: 1910, Train Loss: 1.7082, Train Accuracy: 51.7838%\n",
      "Epoch: 1920, Train Loss: 1.7078, Train Accuracy: 51.7838%\n",
      "Epoch: 1930, Train Loss: 1.7075, Train Accuracy: 51.7838%\n",
      "Epoch: 1940, Train Loss: 1.7071, Train Accuracy: 51.8919%\n",
      "Epoch: 1950, Train Loss: 1.7067, Train Accuracy: 51.8919%\n",
      "Epoch: 1960, Train Loss: 1.7064, Train Accuracy: 51.8919%\n",
      "Epoch: 1970, Train Loss: 1.7060, Train Accuracy: 51.8919%\n",
      "Epoch: 1980, Train Loss: 1.7056, Train Accuracy: 51.8919%\n",
      "Epoch: 1990, Train Loss: 1.7053, Train Accuracy: 51.8919%\n",
      "Epoch: 2000, Train Loss: 1.7049, Train Accuracy: 51.8919%\n",
      "Epoch: 2010, Train Loss: 1.7045, Train Accuracy: 51.8919%\n",
      "Epoch: 2020, Train Loss: 1.7042, Train Accuracy: 51.8919%\n",
      "Epoch: 2030, Train Loss: 1.7038, Train Accuracy: 51.8919%\n",
      "Epoch: 2040, Train Loss: 1.7035, Train Accuracy: 51.8919%\n",
      "Epoch: 2050, Train Loss: 1.7031, Train Accuracy: 51.8919%\n",
      "Epoch: 2060, Train Loss: 1.7027, Train Accuracy: 51.8919%\n",
      "Epoch: 2070, Train Loss: 1.7024, Train Accuracy: 51.8919%\n",
      "Epoch: 2080, Train Loss: 1.7020, Train Accuracy: 51.8919%\n",
      "Epoch: 2090, Train Loss: 1.7017, Train Accuracy: 51.8919%\n",
      "Epoch: 2100, Train Loss: 1.7013, Train Accuracy: 51.8919%\n",
      "Epoch: 2110, Train Loss: 1.7010, Train Accuracy: 51.8919%\n",
      "Epoch: 2120, Train Loss: 1.7006, Train Accuracy: 51.8919%\n",
      "Epoch: 2130, Train Loss: 1.7002, Train Accuracy: 51.8919%\n",
      "Epoch: 2140, Train Loss: 1.6999, Train Accuracy: 51.8919%\n",
      "Epoch: 2150, Train Loss: 1.6995, Train Accuracy: 51.8919%\n",
      "Epoch: 2160, Train Loss: 1.6992, Train Accuracy: 51.8919%\n",
      "Epoch: 2170, Train Loss: 1.6988, Train Accuracy: 51.8919%\n",
      "Epoch: 2180, Train Loss: 1.6985, Train Accuracy: 51.7838%\n",
      "Epoch: 2190, Train Loss: 1.6981, Train Accuracy: 51.7838%\n",
      "Epoch: 2200, Train Loss: 1.6978, Train Accuracy: 51.7838%\n",
      "Epoch: 2210, Train Loss: 1.6974, Train Accuracy: 51.7838%\n",
      "Epoch: 2220, Train Loss: 1.6971, Train Accuracy: 51.7838%\n",
      "Epoch: 2230, Train Loss: 1.6967, Train Accuracy: 51.7838%\n",
      "Epoch: 2240, Train Loss: 1.6964, Train Accuracy: 51.7838%\n",
      "Epoch: 2250, Train Loss: 1.6960, Train Accuracy: 51.7838%\n",
      "Epoch: 2260, Train Loss: 1.6957, Train Accuracy: 51.7838%\n",
      "Epoch: 2270, Train Loss: 1.6953, Train Accuracy: 51.7838%\n",
      "Epoch: 2280, Train Loss: 1.6950, Train Accuracy: 51.7838%\n",
      "Epoch: 2290, Train Loss: 1.6946, Train Accuracy: 51.7838%\n",
      "Epoch: 2300, Train Loss: 1.6943, Train Accuracy: 51.6757%\n",
      "Epoch: 2310, Train Loss: 1.6940, Train Accuracy: 51.6757%\n",
      "Epoch: 2320, Train Loss: 1.6936, Train Accuracy: 51.6757%\n",
      "Epoch: 2330, Train Loss: 1.6933, Train Accuracy: 51.6757%\n",
      "Epoch: 2340, Train Loss: 1.6929, Train Accuracy: 51.6757%\n",
      "Epoch: 2350, Train Loss: 1.6926, Train Accuracy: 51.6757%\n",
      "Epoch: 2360, Train Loss: 1.6922, Train Accuracy: 51.6757%\n",
      "Epoch: 2370, Train Loss: 1.6919, Train Accuracy: 51.6757%\n",
      "Epoch: 2380, Train Loss: 1.6916, Train Accuracy: 51.6757%\n",
      "Epoch: 2390, Train Loss: 1.6912, Train Accuracy: 51.6757%\n",
      "Epoch: 2400, Train Loss: 1.6909, Train Accuracy: 51.6757%\n",
      "Epoch: 2410, Train Loss: 1.6906, Train Accuracy: 51.6757%\n",
      "Epoch: 2420, Train Loss: 1.6902, Train Accuracy: 51.6757%\n",
      "Epoch: 2430, Train Loss: 1.6899, Train Accuracy: 51.6757%\n",
      "Epoch: 2440, Train Loss: 1.6895, Train Accuracy: 51.6757%\n",
      "Epoch: 2450, Train Loss: 1.6892, Train Accuracy: 51.6757%\n",
      "Epoch: 2460, Train Loss: 1.6889, Train Accuracy: 51.6757%\n",
      "Epoch: 2470, Train Loss: 1.6885, Train Accuracy: 51.6757%\n",
      "Epoch: 2480, Train Loss: 1.6882, Train Accuracy: 51.6757%\n",
      "Epoch: 2490, Train Loss: 1.6879, Train Accuracy: 51.6757%\n",
      "Epoch: 2500, Train Loss: 1.6875, Train Accuracy: 51.6757%\n",
      "Epoch: 2510, Train Loss: 1.6872, Train Accuracy: 51.6757%\n",
      "Epoch: 2520, Train Loss: 1.6869, Train Accuracy: 51.6757%\n",
      "Epoch: 2530, Train Loss: 1.6865, Train Accuracy: 51.6757%\n",
      "Epoch: 2540, Train Loss: 1.6862, Train Accuracy: 51.5676%\n",
      "Epoch: 2550, Train Loss: 1.6859, Train Accuracy: 51.5676%\n",
      "Epoch: 2560, Train Loss: 1.6855, Train Accuracy: 51.6757%\n",
      "Epoch: 2570, Train Loss: 1.6852, Train Accuracy: 51.6757%\n",
      "Epoch: 2580, Train Loss: 1.6849, Train Accuracy: 51.6757%\n",
      "Epoch: 2590, Train Loss: 1.6846, Train Accuracy: 51.6757%\n",
      "Epoch: 2600, Train Loss: 1.6842, Train Accuracy: 51.6757%\n",
      "Epoch: 2610, Train Loss: 1.6839, Train Accuracy: 51.6757%\n",
      "Epoch: 2620, Train Loss: 1.6836, Train Accuracy: 51.6757%\n",
      "Epoch: 2630, Train Loss: 1.6833, Train Accuracy: 51.6757%\n",
      "Epoch: 2640, Train Loss: 1.6829, Train Accuracy: 51.6757%\n",
      "Epoch: 2650, Train Loss: 1.6826, Train Accuracy: 51.6757%\n",
      "Epoch: 2660, Train Loss: 1.6823, Train Accuracy: 51.6757%\n",
      "Epoch: 2670, Train Loss: 1.6820, Train Accuracy: 51.6757%\n",
      "Epoch: 2680, Train Loss: 1.6816, Train Accuracy: 51.6757%\n",
      "Epoch: 2690, Train Loss: 1.6813, Train Accuracy: 51.6757%\n",
      "Epoch: 2700, Train Loss: 1.6810, Train Accuracy: 51.6757%\n",
      "Epoch: 2710, Train Loss: 1.6807, Train Accuracy: 51.6757%\n",
      "Epoch: 2720, Train Loss: 1.6803, Train Accuracy: 51.6757%\n",
      "Epoch: 2730, Train Loss: 1.6800, Train Accuracy: 51.6757%\n",
      "Epoch: 2740, Train Loss: 1.6797, Train Accuracy: 51.6757%\n",
      "Epoch: 2750, Train Loss: 1.6794, Train Accuracy: 51.6757%\n",
      "Epoch: 2760, Train Loss: 1.6791, Train Accuracy: 51.6757%\n",
      "Epoch: 2770, Train Loss: 1.6787, Train Accuracy: 51.6757%\n",
      "Epoch: 2780, Train Loss: 1.6784, Train Accuracy: 51.6757%\n",
      "Epoch: 2790, Train Loss: 1.6781, Train Accuracy: 51.6757%\n",
      "Epoch: 2800, Train Loss: 1.6778, Train Accuracy: 51.6757%\n",
      "Epoch: 2810, Train Loss: 1.6775, Train Accuracy: 51.6757%\n",
      "Epoch: 2820, Train Loss: 1.6772, Train Accuracy: 51.6757%\n",
      "Epoch: 2830, Train Loss: 1.6769, Train Accuracy: 51.6757%\n",
      "Epoch: 2840, Train Loss: 1.6765, Train Accuracy: 51.6757%\n",
      "Epoch: 2850, Train Loss: 1.6762, Train Accuracy: 51.6757%\n",
      "Epoch: 2860, Train Loss: 1.6759, Train Accuracy: 51.6757%\n",
      "Epoch: 2870, Train Loss: 1.6756, Train Accuracy: 51.6757%\n",
      "Epoch: 2880, Train Loss: 1.6753, Train Accuracy: 51.6757%\n",
      "Epoch: 2890, Train Loss: 1.6750, Train Accuracy: 51.6757%\n",
      "Epoch: 2900, Train Loss: 1.6747, Train Accuracy: 51.6757%\n",
      "Epoch: 2910, Train Loss: 1.6744, Train Accuracy: 51.6757%\n",
      "Epoch: 2920, Train Loss: 1.6740, Train Accuracy: 51.6757%\n",
      "Epoch: 2930, Train Loss: 1.6737, Train Accuracy: 51.6757%\n",
      "Epoch: 2940, Train Loss: 1.6734, Train Accuracy: 51.6757%\n",
      "Epoch: 2950, Train Loss: 1.6731, Train Accuracy: 51.6757%\n",
      "Epoch: 2960, Train Loss: 1.6728, Train Accuracy: 51.6757%\n",
      "Epoch: 2970, Train Loss: 1.6725, Train Accuracy: 51.6757%\n",
      "Epoch: 2980, Train Loss: 1.6722, Train Accuracy: 51.6757%\n",
      "Epoch: 2990, Train Loss: 1.6719, Train Accuracy: 51.7838%\n",
      "Epoch: 3000, Train Loss: 1.6716, Train Accuracy: 51.7838%\n",
      "Epoch: 3010, Train Loss: 1.6713, Train Accuracy: 51.7838%\n",
      "Epoch: 3020, Train Loss: 1.6710, Train Accuracy: 51.7838%\n",
      "Epoch: 3030, Train Loss: 1.6707, Train Accuracy: 51.7838%\n",
      "Epoch: 3040, Train Loss: 1.6704, Train Accuracy: 51.7838%\n",
      "Epoch: 3050, Train Loss: 1.6701, Train Accuracy: 51.7838%\n",
      "Epoch: 3060, Train Loss: 1.6698, Train Accuracy: 51.7838%\n",
      "Epoch: 3070, Train Loss: 1.6694, Train Accuracy: 51.7838%\n",
      "Epoch: 3080, Train Loss: 1.6691, Train Accuracy: 51.7838%\n",
      "Epoch: 3090, Train Loss: 1.6688, Train Accuracy: 51.7838%\n",
      "Epoch: 3100, Train Loss: 1.6685, Train Accuracy: 51.7838%\n",
      "Epoch: 3110, Train Loss: 1.6682, Train Accuracy: 51.7838%\n",
      "Epoch: 3120, Train Loss: 1.6679, Train Accuracy: 51.7838%\n",
      "Epoch: 3130, Train Loss: 1.6676, Train Accuracy: 51.7838%\n",
      "Epoch: 3140, Train Loss: 1.6673, Train Accuracy: 51.7838%\n",
      "Epoch: 3150, Train Loss: 1.6670, Train Accuracy: 51.7838%\n",
      "Epoch: 3160, Train Loss: 1.6667, Train Accuracy: 51.7838%\n",
      "Epoch: 3170, Train Loss: 1.6665, Train Accuracy: 51.7838%\n",
      "Epoch: 3180, Train Loss: 1.6662, Train Accuracy: 51.7838%\n",
      "Epoch: 3190, Train Loss: 1.6659, Train Accuracy: 51.7838%\n",
      "Epoch: 3200, Train Loss: 1.6656, Train Accuracy: 51.8919%\n",
      "Epoch: 3210, Train Loss: 1.6653, Train Accuracy: 51.8919%\n",
      "Epoch: 3220, Train Loss: 1.6650, Train Accuracy: 51.8919%\n",
      "Epoch: 3230, Train Loss: 1.6647, Train Accuracy: 52.0000%\n",
      "Epoch: 3240, Train Loss: 1.6644, Train Accuracy: 52.0000%\n",
      "Epoch: 3250, Train Loss: 1.6641, Train Accuracy: 52.0000%\n",
      "Epoch: 3260, Train Loss: 1.6638, Train Accuracy: 52.0000%\n",
      "Epoch: 3270, Train Loss: 1.6635, Train Accuracy: 52.0000%\n",
      "Epoch: 3280, Train Loss: 1.6632, Train Accuracy: 52.0000%\n",
      "Epoch: 3290, Train Loss: 1.6629, Train Accuracy: 52.0000%\n",
      "Epoch: 3300, Train Loss: 1.6626, Train Accuracy: 52.0000%\n",
      "Epoch: 3310, Train Loss: 1.6623, Train Accuracy: 52.0000%\n",
      "Epoch: 3320, Train Loss: 1.6620, Train Accuracy: 52.0000%\n",
      "Epoch: 3330, Train Loss: 1.6618, Train Accuracy: 52.0000%\n",
      "Epoch: 3340, Train Loss: 1.6615, Train Accuracy: 52.0000%\n",
      "Epoch: 3350, Train Loss: 1.6612, Train Accuracy: 52.0000%\n",
      "Epoch: 3360, Train Loss: 1.6609, Train Accuracy: 52.0000%\n",
      "Epoch: 3370, Train Loss: 1.6606, Train Accuracy: 52.0000%\n",
      "Epoch: 3380, Train Loss: 1.6603, Train Accuracy: 52.0000%\n",
      "Epoch: 3390, Train Loss: 1.6600, Train Accuracy: 52.0000%\n",
      "Epoch: 3400, Train Loss: 1.6597, Train Accuracy: 52.0000%\n",
      "Epoch: 3410, Train Loss: 1.6595, Train Accuracy: 52.1081%\n",
      "Epoch: 3420, Train Loss: 1.6592, Train Accuracy: 52.1081%\n",
      "Epoch: 3430, Train Loss: 1.6589, Train Accuracy: 52.1081%\n",
      "Epoch: 3440, Train Loss: 1.6586, Train Accuracy: 52.1081%\n",
      "Epoch: 3450, Train Loss: 1.6583, Train Accuracy: 52.1081%\n",
      "Epoch: 3460, Train Loss: 1.6580, Train Accuracy: 52.2162%\n",
      "Epoch: 3470, Train Loss: 1.6578, Train Accuracy: 52.2162%\n",
      "Epoch: 3480, Train Loss: 1.6575, Train Accuracy: 52.2162%\n",
      "Epoch: 3490, Train Loss: 1.6572, Train Accuracy: 52.2162%\n",
      "Epoch: 3500, Train Loss: 1.6569, Train Accuracy: 52.2162%\n",
      "Epoch: 3510, Train Loss: 1.6566, Train Accuracy: 52.2162%\n",
      "Epoch: 3520, Train Loss: 1.6563, Train Accuracy: 52.2162%\n",
      "Epoch: 3530, Train Loss: 1.6561, Train Accuracy: 52.2162%\n",
      "Epoch: 3540, Train Loss: 1.6558, Train Accuracy: 52.2162%\n",
      "Epoch: 3550, Train Loss: 1.6555, Train Accuracy: 52.2162%\n",
      "Epoch: 3560, Train Loss: 1.6552, Train Accuracy: 52.2162%\n",
      "Epoch: 3570, Train Loss: 1.6549, Train Accuracy: 52.2162%\n",
      "Epoch: 3580, Train Loss: 1.6547, Train Accuracy: 52.2162%\n",
      "Epoch: 3590, Train Loss: 1.6544, Train Accuracy: 52.2162%\n",
      "Epoch: 3600, Train Loss: 1.6541, Train Accuracy: 52.2162%\n",
      "Epoch: 3610, Train Loss: 1.6538, Train Accuracy: 52.2162%\n",
      "Epoch: 3620, Train Loss: 1.6536, Train Accuracy: 52.2162%\n",
      "Epoch: 3630, Train Loss: 1.6533, Train Accuracy: 52.2162%\n",
      "Epoch: 3640, Train Loss: 1.6530, Train Accuracy: 52.2162%\n",
      "Epoch: 3650, Train Loss: 1.6527, Train Accuracy: 52.2162%\n",
      "Epoch: 3660, Train Loss: 1.6525, Train Accuracy: 52.1081%\n",
      "Epoch: 3670, Train Loss: 1.6522, Train Accuracy: 52.2162%\n",
      "Epoch: 3680, Train Loss: 1.6519, Train Accuracy: 52.3243%\n",
      "Epoch: 3690, Train Loss: 1.6516, Train Accuracy: 52.3243%\n",
      "Epoch: 3700, Train Loss: 1.6514, Train Accuracy: 52.3243%\n",
      "Epoch: 3710, Train Loss: 1.6511, Train Accuracy: 52.3243%\n",
      "Epoch: 3720, Train Loss: 1.6508, Train Accuracy: 52.3243%\n",
      "Epoch: 3730, Train Loss: 1.6506, Train Accuracy: 52.3243%\n",
      "Epoch: 3740, Train Loss: 1.6503, Train Accuracy: 52.3243%\n",
      "Epoch: 3750, Train Loss: 1.6500, Train Accuracy: 52.3243%\n",
      "Epoch: 3760, Train Loss: 1.6497, Train Accuracy: 52.3243%\n",
      "Epoch: 3770, Train Loss: 1.6495, Train Accuracy: 52.3243%\n",
      "Epoch: 3780, Train Loss: 1.6492, Train Accuracy: 52.3243%\n",
      "Epoch: 3790, Train Loss: 1.6489, Train Accuracy: 52.3243%\n",
      "Epoch: 3800, Train Loss: 1.6487, Train Accuracy: 52.3243%\n",
      "Epoch: 3810, Train Loss: 1.6484, Train Accuracy: 52.3243%\n",
      "Epoch: 3820, Train Loss: 1.6481, Train Accuracy: 52.3243%\n",
      "Epoch: 3830, Train Loss: 1.6479, Train Accuracy: 52.3243%\n",
      "Epoch: 3840, Train Loss: 1.6476, Train Accuracy: 52.3243%\n",
      "Epoch: 3850, Train Loss: 1.6473, Train Accuracy: 52.3243%\n",
      "Epoch: 3860, Train Loss: 1.6471, Train Accuracy: 52.3243%\n",
      "Epoch: 3870, Train Loss: 1.6468, Train Accuracy: 52.3243%\n",
      "Epoch: 3880, Train Loss: 1.6465, Train Accuracy: 52.3243%\n",
      "Epoch: 3890, Train Loss: 1.6463, Train Accuracy: 52.3243%\n",
      "Epoch: 3900, Train Loss: 1.6460, Train Accuracy: 52.3243%\n",
      "Epoch: 3910, Train Loss: 1.6457, Train Accuracy: 52.3243%\n",
      "Epoch: 3920, Train Loss: 1.6455, Train Accuracy: 52.3243%\n",
      "Epoch: 3930, Train Loss: 1.6452, Train Accuracy: 52.3243%\n",
      "Epoch: 3940, Train Loss: 1.6450, Train Accuracy: 52.3243%\n",
      "Epoch: 3950, Train Loss: 1.6447, Train Accuracy: 52.3243%\n",
      "Epoch: 3960, Train Loss: 1.6444, Train Accuracy: 52.4324%\n",
      "Epoch: 3970, Train Loss: 1.6442, Train Accuracy: 52.4324%\n",
      "Epoch: 3980, Train Loss: 1.6439, Train Accuracy: 52.4324%\n",
      "Epoch: 3990, Train Loss: 1.6437, Train Accuracy: 52.4324%\n",
      "Epoch: 4000, Train Loss: 1.6434, Train Accuracy: 52.4324%\n",
      "Epoch: 4010, Train Loss: 1.6431, Train Accuracy: 52.4324%\n",
      "Epoch: 4020, Train Loss: 1.6429, Train Accuracy: 52.5405%\n",
      "Epoch: 4030, Train Loss: 1.6426, Train Accuracy: 52.4324%\n",
      "Epoch: 4040, Train Loss: 1.6424, Train Accuracy: 52.4324%\n",
      "Epoch: 4050, Train Loss: 1.6421, Train Accuracy: 52.4324%\n",
      "Epoch: 4060, Train Loss: 1.6419, Train Accuracy: 52.4324%\n",
      "Epoch: 4070, Train Loss: 1.6416, Train Accuracy: 52.4324%\n",
      "Epoch: 4080, Train Loss: 1.6413, Train Accuracy: 52.4324%\n",
      "Epoch: 4090, Train Loss: 1.6411, Train Accuracy: 52.4324%\n",
      "Epoch: 4100, Train Loss: 1.6408, Train Accuracy: 52.4324%\n",
      "Epoch: 4110, Train Loss: 1.6406, Train Accuracy: 52.4324%\n",
      "Epoch: 4120, Train Loss: 1.6403, Train Accuracy: 52.4324%\n",
      "Epoch: 4130, Train Loss: 1.6401, Train Accuracy: 52.4324%\n",
      "Epoch: 4140, Train Loss: 1.6398, Train Accuracy: 52.4324%\n",
      "Epoch: 4150, Train Loss: 1.6396, Train Accuracy: 52.4324%\n",
      "Epoch: 4160, Train Loss: 1.6393, Train Accuracy: 52.4324%\n",
      "Epoch: 4170, Train Loss: 1.6391, Train Accuracy: 52.4324%\n",
      "Epoch: 4180, Train Loss: 1.6388, Train Accuracy: 52.4324%\n",
      "Epoch: 4190, Train Loss: 1.6385, Train Accuracy: 52.4324%\n",
      "Epoch: 4200, Train Loss: 1.6383, Train Accuracy: 52.4324%\n",
      "Epoch: 4210, Train Loss: 1.6380, Train Accuracy: 52.4324%\n",
      "Epoch: 4220, Train Loss: 1.6378, Train Accuracy: 52.4324%\n",
      "Epoch: 4230, Train Loss: 1.6375, Train Accuracy: 52.4324%\n",
      "Epoch: 4240, Train Loss: 1.6373, Train Accuracy: 52.4324%\n",
      "Epoch: 4250, Train Loss: 1.6370, Train Accuracy: 52.4324%\n",
      "Epoch: 4260, Train Loss: 1.6368, Train Accuracy: 52.4324%\n",
      "Epoch: 4270, Train Loss: 1.6366, Train Accuracy: 52.4324%\n",
      "Epoch: 4280, Train Loss: 1.6363, Train Accuracy: 52.4324%\n",
      "Epoch: 4290, Train Loss: 1.6361, Train Accuracy: 52.4324%\n",
      "Epoch: 4300, Train Loss: 1.6358, Train Accuracy: 52.4324%\n",
      "Epoch: 4310, Train Loss: 1.6356, Train Accuracy: 52.4324%\n",
      "Epoch: 4320, Train Loss: 1.6353, Train Accuracy: 52.5405%\n",
      "Epoch: 4330, Train Loss: 1.6351, Train Accuracy: 52.5405%\n",
      "Epoch: 4340, Train Loss: 1.6348, Train Accuracy: 52.5405%\n",
      "Epoch: 4350, Train Loss: 1.6346, Train Accuracy: 52.5405%\n",
      "Epoch: 4360, Train Loss: 1.6343, Train Accuracy: 52.5405%\n",
      "Epoch: 4370, Train Loss: 1.6341, Train Accuracy: 52.5405%\n",
      "Epoch: 4380, Train Loss: 1.6338, Train Accuracy: 52.5405%\n",
      "Epoch: 4390, Train Loss: 1.6336, Train Accuracy: 52.5405%\n",
      "Epoch: 4400, Train Loss: 1.6334, Train Accuracy: 52.5405%\n",
      "Epoch: 4410, Train Loss: 1.6331, Train Accuracy: 52.5405%\n",
      "Epoch: 4420, Train Loss: 1.6329, Train Accuracy: 52.5405%\n",
      "Epoch: 4430, Train Loss: 1.6326, Train Accuracy: 52.5405%\n",
      "Epoch: 4440, Train Loss: 1.6324, Train Accuracy: 52.5405%\n",
      "Epoch: 4450, Train Loss: 1.6322, Train Accuracy: 52.5405%\n",
      "Epoch: 4460, Train Loss: 1.6319, Train Accuracy: 52.5405%\n",
      "Epoch: 4470, Train Loss: 1.6317, Train Accuracy: 52.5405%\n",
      "Epoch: 4480, Train Loss: 1.6314, Train Accuracy: 52.5405%\n",
      "Epoch: 4490, Train Loss: 1.6312, Train Accuracy: 52.5405%\n",
      "Epoch: 4500, Train Loss: 1.6310, Train Accuracy: 52.5405%\n",
      "Epoch: 4510, Train Loss: 1.6307, Train Accuracy: 52.5405%\n",
      "Epoch: 4520, Train Loss: 1.6305, Train Accuracy: 52.5405%\n",
      "Epoch: 4530, Train Loss: 1.6302, Train Accuracy: 52.5405%\n",
      "Epoch: 4540, Train Loss: 1.6300, Train Accuracy: 52.6486%\n",
      "Epoch: 4550, Train Loss: 1.6298, Train Accuracy: 52.6486%\n",
      "Epoch: 4560, Train Loss: 1.6295, Train Accuracy: 52.6486%\n",
      "Epoch: 4570, Train Loss: 1.6293, Train Accuracy: 52.6486%\n",
      "Epoch: 4580, Train Loss: 1.6291, Train Accuracy: 52.6486%\n",
      "Epoch: 4590, Train Loss: 1.6288, Train Accuracy: 52.6486%\n",
      "Epoch: 4600, Train Loss: 1.6286, Train Accuracy: 52.6486%\n",
      "Epoch: 4610, Train Loss: 1.6283, Train Accuracy: 52.6486%\n",
      "Epoch: 4620, Train Loss: 1.6281, Train Accuracy: 52.6486%\n",
      "Epoch: 4630, Train Loss: 1.6279, Train Accuracy: 52.6486%\n",
      "Epoch: 4640, Train Loss: 1.6276, Train Accuracy: 52.6486%\n",
      "Epoch: 4650, Train Loss: 1.6274, Train Accuracy: 52.6486%\n",
      "Epoch: 4660, Train Loss: 1.6272, Train Accuracy: 52.6486%\n",
      "Epoch: 4670, Train Loss: 1.6269, Train Accuracy: 52.6486%\n",
      "Epoch: 4680, Train Loss: 1.6267, Train Accuracy: 52.6486%\n",
      "Epoch: 4690, Train Loss: 1.6265, Train Accuracy: 52.6486%\n",
      "Epoch: 4700, Train Loss: 1.6262, Train Accuracy: 52.6486%\n",
      "Epoch: 4710, Train Loss: 1.6260, Train Accuracy: 52.6486%\n",
      "Epoch: 4720, Train Loss: 1.6258, Train Accuracy: 52.6486%\n",
      "Epoch: 4730, Train Loss: 1.6256, Train Accuracy: 52.6486%\n",
      "Epoch: 4740, Train Loss: 1.6253, Train Accuracy: 52.6486%\n",
      "Epoch: 4750, Train Loss: 1.6251, Train Accuracy: 52.6486%\n",
      "Epoch: 4760, Train Loss: 1.6249, Train Accuracy: 52.6486%\n",
      "Epoch: 4770, Train Loss: 1.6246, Train Accuracy: 52.6486%\n",
      "Epoch: 4780, Train Loss: 1.6244, Train Accuracy: 52.5405%\n",
      "Epoch: 4790, Train Loss: 1.6242, Train Accuracy: 52.5405%\n",
      "Epoch: 4800, Train Loss: 1.6239, Train Accuracy: 52.5405%\n",
      "Epoch: 4810, Train Loss: 1.6237, Train Accuracy: 52.5405%\n",
      "Epoch: 4820, Train Loss: 1.6235, Train Accuracy: 52.5405%\n",
      "Epoch: 4830, Train Loss: 1.6233, Train Accuracy: 52.4324%\n",
      "Epoch: 4840, Train Loss: 1.6230, Train Accuracy: 52.4324%\n",
      "Epoch: 4850, Train Loss: 1.6228, Train Accuracy: 52.4324%\n",
      "Epoch: 4860, Train Loss: 1.6226, Train Accuracy: 52.4324%\n",
      "Epoch: 4870, Train Loss: 1.6224, Train Accuracy: 52.4324%\n",
      "Epoch: 4880, Train Loss: 1.6221, Train Accuracy: 52.4324%\n",
      "Epoch: 4890, Train Loss: 1.6219, Train Accuracy: 52.4324%\n",
      "Epoch: 4900, Train Loss: 1.6217, Train Accuracy: 52.4324%\n",
      "Epoch: 4910, Train Loss: 1.6215, Train Accuracy: 52.4324%\n",
      "Epoch: 4920, Train Loss: 1.6212, Train Accuracy: 52.4324%\n",
      "Epoch: 4930, Train Loss: 1.6210, Train Accuracy: 52.4324%\n",
      "Epoch: 4940, Train Loss: 1.6208, Train Accuracy: 52.4324%\n",
      "Epoch: 4950, Train Loss: 1.6206, Train Accuracy: 52.4324%\n",
      "Epoch: 4960, Train Loss: 1.6203, Train Accuracy: 52.4324%\n",
      "Epoch: 4970, Train Loss: 1.6201, Train Accuracy: 52.5405%\n",
      "Epoch: 4980, Train Loss: 1.6199, Train Accuracy: 52.5405%\n",
      "Epoch: 4990, Train Loss: 1.6197, Train Accuracy: 52.5405%\n",
      "Epoch: 5000, Train Loss: 1.6195, Train Accuracy: 52.5405%\n",
      "Epoch: 5010, Train Loss: 1.6192, Train Accuracy: 52.5405%\n",
      "Epoch: 5020, Train Loss: 1.6190, Train Accuracy: 52.5405%\n",
      "Epoch: 5030, Train Loss: 1.6188, Train Accuracy: 52.5405%\n",
      "Epoch: 5040, Train Loss: 1.6186, Train Accuracy: 52.5405%\n",
      "Epoch: 5050, Train Loss: 1.6184, Train Accuracy: 52.5405%\n",
      "Epoch: 5060, Train Loss: 1.6181, Train Accuracy: 52.5405%\n",
      "Epoch: 5070, Train Loss: 1.6179, Train Accuracy: 52.5405%\n",
      "Epoch: 5080, Train Loss: 1.6177, Train Accuracy: 52.5405%\n",
      "Epoch: 5090, Train Loss: 1.6175, Train Accuracy: 52.5405%\n",
      "Epoch: 5100, Train Loss: 1.6173, Train Accuracy: 52.5405%\n",
      "Epoch: 5110, Train Loss: 1.6171, Train Accuracy: 52.6486%\n",
      "Epoch: 5120, Train Loss: 1.6168, Train Accuracy: 52.6486%\n",
      "Epoch: 5130, Train Loss: 1.6166, Train Accuracy: 52.6486%\n",
      "Epoch: 5140, Train Loss: 1.6164, Train Accuracy: 52.7568%\n",
      "Epoch: 5150, Train Loss: 1.6162, Train Accuracy: 52.7568%\n",
      "Epoch: 5160, Train Loss: 1.6160, Train Accuracy: 52.7568%\n",
      "Epoch: 5170, Train Loss: 1.6158, Train Accuracy: 52.7568%\n",
      "Epoch: 5180, Train Loss: 1.6155, Train Accuracy: 52.7568%\n",
      "Epoch: 5190, Train Loss: 1.6153, Train Accuracy: 52.7568%\n",
      "Epoch: 5200, Train Loss: 1.6151, Train Accuracy: 52.7568%\n",
      "Epoch: 5210, Train Loss: 1.6149, Train Accuracy: 52.7568%\n",
      "Epoch: 5220, Train Loss: 1.6147, Train Accuracy: 52.7568%\n",
      "Epoch: 5230, Train Loss: 1.6145, Train Accuracy: 52.7568%\n",
      "Epoch: 5240, Train Loss: 1.6143, Train Accuracy: 52.7568%\n",
      "Epoch: 5250, Train Loss: 1.6141, Train Accuracy: 52.7568%\n",
      "Epoch: 5260, Train Loss: 1.6138, Train Accuracy: 52.7568%\n",
      "Epoch: 5270, Train Loss: 1.6136, Train Accuracy: 52.7568%\n",
      "Epoch: 5280, Train Loss: 1.6134, Train Accuracy: 52.6486%\n",
      "Epoch: 5290, Train Loss: 1.6132, Train Accuracy: 52.6486%\n",
      "Epoch: 5300, Train Loss: 1.6130, Train Accuracy: 52.6486%\n",
      "Epoch: 5310, Train Loss: 1.6128, Train Accuracy: 52.6486%\n",
      "Epoch: 5320, Train Loss: 1.6126, Train Accuracy: 52.6486%\n",
      "Epoch: 5330, Train Loss: 1.6124, Train Accuracy: 52.6486%\n",
      "Epoch: 5340, Train Loss: 1.6122, Train Accuracy: 52.6486%\n",
      "Epoch: 5350, Train Loss: 1.6119, Train Accuracy: 52.6486%\n",
      "Epoch: 5360, Train Loss: 1.6117, Train Accuracy: 52.6486%\n",
      "Epoch: 5370, Train Loss: 1.6115, Train Accuracy: 52.6486%\n",
      "Epoch: 5380, Train Loss: 1.6113, Train Accuracy: 52.6486%\n",
      "Epoch: 5390, Train Loss: 1.6111, Train Accuracy: 52.6486%\n",
      "Epoch: 5400, Train Loss: 1.6109, Train Accuracy: 52.6486%\n",
      "Epoch: 5410, Train Loss: 1.6107, Train Accuracy: 52.6486%\n",
      "Epoch: 5420, Train Loss: 1.6105, Train Accuracy: 52.6486%\n",
      "Epoch: 5430, Train Loss: 1.6103, Train Accuracy: 52.6486%\n",
      "Epoch: 5440, Train Loss: 1.6101, Train Accuracy: 52.6486%\n",
      "Epoch: 5450, Train Loss: 1.6099, Train Accuracy: 52.6486%\n",
      "Epoch: 5460, Train Loss: 1.6097, Train Accuracy: 52.6486%\n",
      "Epoch: 5470, Train Loss: 1.6095, Train Accuracy: 52.6486%\n",
      "Epoch: 5480, Train Loss: 1.6093, Train Accuracy: 52.6486%\n",
      "Epoch: 5490, Train Loss: 1.6091, Train Accuracy: 52.6486%\n",
      "Epoch: 5500, Train Loss: 1.6088, Train Accuracy: 52.6486%\n",
      "Epoch: 5510, Train Loss: 1.6086, Train Accuracy: 52.6486%\n",
      "Epoch: 5520, Train Loss: 1.6084, Train Accuracy: 52.6486%\n",
      "Epoch: 5530, Train Loss: 1.6082, Train Accuracy: 52.6486%\n",
      "Epoch: 5540, Train Loss: 1.6080, Train Accuracy: 52.6486%\n",
      "Epoch: 5550, Train Loss: 1.6078, Train Accuracy: 52.6486%\n",
      "Epoch: 5560, Train Loss: 1.6076, Train Accuracy: 52.6486%\n",
      "Epoch: 5570, Train Loss: 1.6074, Train Accuracy: 52.6486%\n",
      "Epoch: 5580, Train Loss: 1.6072, Train Accuracy: 52.6486%\n",
      "Epoch: 5590, Train Loss: 1.6070, Train Accuracy: 52.6486%\n",
      "Epoch: 5600, Train Loss: 1.6068, Train Accuracy: 52.6486%\n",
      "Epoch: 5610, Train Loss: 1.6066, Train Accuracy: 52.6486%\n",
      "Epoch: 5620, Train Loss: 1.6064, Train Accuracy: 52.6486%\n",
      "Epoch: 5630, Train Loss: 1.6062, Train Accuracy: 52.6486%\n",
      "Epoch: 5640, Train Loss: 1.6060, Train Accuracy: 52.6486%\n",
      "Epoch: 5650, Train Loss: 1.6058, Train Accuracy: 52.6486%\n",
      "Epoch: 5660, Train Loss: 1.6056, Train Accuracy: 52.6486%\n",
      "Epoch: 5670, Train Loss: 1.6054, Train Accuracy: 52.6486%\n",
      "Epoch: 5680, Train Loss: 1.6052, Train Accuracy: 52.6486%\n",
      "Epoch: 5690, Train Loss: 1.6050, Train Accuracy: 52.6486%\n",
      "Epoch: 5700, Train Loss: 1.6048, Train Accuracy: 52.6486%\n",
      "Epoch: 5710, Train Loss: 1.6046, Train Accuracy: 52.6486%\n",
      "Epoch: 5720, Train Loss: 1.6044, Train Accuracy: 52.6486%\n",
      "Epoch: 5730, Train Loss: 1.6042, Train Accuracy: 52.6486%\n",
      "Epoch: 5740, Train Loss: 1.6040, Train Accuracy: 52.6486%\n",
      "Epoch: 5750, Train Loss: 1.6038, Train Accuracy: 52.6486%\n",
      "Epoch: 5760, Train Loss: 1.6036, Train Accuracy: 52.6486%\n",
      "Epoch: 5770, Train Loss: 1.6034, Train Accuracy: 52.7568%\n",
      "Epoch: 5780, Train Loss: 1.6033, Train Accuracy: 52.7568%\n",
      "Epoch: 5790, Train Loss: 1.6031, Train Accuracy: 52.7568%\n",
      "Epoch: 5800, Train Loss: 1.6029, Train Accuracy: 52.7568%\n",
      "Epoch: 5810, Train Loss: 1.6027, Train Accuracy: 52.7568%\n",
      "Epoch: 5820, Train Loss: 1.6025, Train Accuracy: 52.7568%\n",
      "Epoch: 5830, Train Loss: 1.6023, Train Accuracy: 52.7568%\n",
      "Epoch: 5840, Train Loss: 1.6021, Train Accuracy: 52.8649%\n",
      "Epoch: 5850, Train Loss: 1.6019, Train Accuracy: 52.8649%\n",
      "Epoch: 5860, Train Loss: 1.6017, Train Accuracy: 52.8649%\n",
      "Epoch: 5870, Train Loss: 1.6015, Train Accuracy: 52.8649%\n",
      "Epoch: 5880, Train Loss: 1.6013, Train Accuracy: 52.8649%\n",
      "Epoch: 5890, Train Loss: 1.6011, Train Accuracy: 52.8649%\n",
      "Epoch: 5900, Train Loss: 1.6009, Train Accuracy: 52.8649%\n",
      "Epoch: 5910, Train Loss: 1.6007, Train Accuracy: 52.8649%\n",
      "Epoch: 5920, Train Loss: 1.6005, Train Accuracy: 52.8649%\n",
      "Epoch: 5930, Train Loss: 1.6004, Train Accuracy: 52.8649%\n",
      "Epoch: 5940, Train Loss: 1.6002, Train Accuracy: 52.8649%\n",
      "Epoch: 5950, Train Loss: 1.6000, Train Accuracy: 52.8649%\n",
      "Epoch: 5960, Train Loss: 1.5998, Train Accuracy: 52.8649%\n",
      "Epoch: 5970, Train Loss: 1.5996, Train Accuracy: 52.8649%\n",
      "Epoch: 5980, Train Loss: 1.5994, Train Accuracy: 52.8649%\n",
      "Epoch: 5990, Train Loss: 1.5992, Train Accuracy: 52.8649%\n",
      "Epoch: 6000, Train Loss: 1.5990, Train Accuracy: 52.8649%\n",
      "Epoch: 6010, Train Loss: 1.5988, Train Accuracy: 52.8649%\n",
      "Epoch: 6020, Train Loss: 1.5986, Train Accuracy: 52.8649%\n",
      "Epoch: 6030, Train Loss: 1.5985, Train Accuracy: 52.8649%\n",
      "Epoch: 6040, Train Loss: 1.5983, Train Accuracy: 52.8649%\n",
      "Epoch: 6050, Train Loss: 1.5981, Train Accuracy: 52.8649%\n",
      "Epoch: 6060, Train Loss: 1.5979, Train Accuracy: 52.8649%\n",
      "Epoch: 6070, Train Loss: 1.5977, Train Accuracy: 52.8649%\n",
      "Epoch: 6080, Train Loss: 1.5975, Train Accuracy: 52.8649%\n",
      "Epoch: 6090, Train Loss: 1.5973, Train Accuracy: 52.8649%\n",
      "Epoch: 6100, Train Loss: 1.5971, Train Accuracy: 52.8649%\n",
      "Epoch: 6110, Train Loss: 1.5970, Train Accuracy: 52.8649%\n",
      "Epoch: 6120, Train Loss: 1.5968, Train Accuracy: 52.8649%\n",
      "Epoch: 6130, Train Loss: 1.5966, Train Accuracy: 52.8649%\n",
      "Epoch: 6140, Train Loss: 1.5964, Train Accuracy: 52.8649%\n",
      "Epoch: 6150, Train Loss: 1.5962, Train Accuracy: 52.7568%\n",
      "Epoch: 6160, Train Loss: 1.5960, Train Accuracy: 52.7568%\n",
      "Epoch: 6170, Train Loss: 1.5959, Train Accuracy: 52.7568%\n",
      "Epoch: 6180, Train Loss: 1.5957, Train Accuracy: 52.7568%\n",
      "Epoch: 6190, Train Loss: 1.5955, Train Accuracy: 52.7568%\n",
      "Epoch: 6200, Train Loss: 1.5953, Train Accuracy: 52.7568%\n",
      "Epoch: 6210, Train Loss: 1.5951, Train Accuracy: 52.7568%\n",
      "Epoch: 6220, Train Loss: 1.5949, Train Accuracy: 52.7568%\n",
      "Epoch: 6230, Train Loss: 1.5948, Train Accuracy: 52.7568%\n",
      "Epoch: 6240, Train Loss: 1.5946, Train Accuracy: 52.7568%\n",
      "Epoch: 6250, Train Loss: 1.5944, Train Accuracy: 52.7568%\n",
      "Epoch: 6260, Train Loss: 1.5942, Train Accuracy: 52.7568%\n",
      "Epoch: 6270, Train Loss: 1.5940, Train Accuracy: 52.7568%\n",
      "Epoch: 6280, Train Loss: 1.5938, Train Accuracy: 52.7568%\n",
      "Epoch: 6290, Train Loss: 1.5937, Train Accuracy: 52.7568%\n",
      "Epoch: 6300, Train Loss: 1.5935, Train Accuracy: 52.7568%\n",
      "Epoch: 6310, Train Loss: 1.5933, Train Accuracy: 52.7568%\n",
      "Epoch: 6320, Train Loss: 1.5931, Train Accuracy: 52.7568%\n",
      "Epoch: 6330, Train Loss: 1.5929, Train Accuracy: 52.7568%\n",
      "Epoch: 6340, Train Loss: 1.5928, Train Accuracy: 52.7568%\n",
      "Epoch: 6350, Train Loss: 1.5926, Train Accuracy: 52.7568%\n",
      "Epoch: 6360, Train Loss: 1.5924, Train Accuracy: 52.7568%\n",
      "Epoch: 6370, Train Loss: 1.5922, Train Accuracy: 52.7568%\n",
      "Epoch: 6380, Train Loss: 1.5920, Train Accuracy: 52.7568%\n",
      "Epoch: 6390, Train Loss: 1.5919, Train Accuracy: 52.7568%\n",
      "Epoch: 6400, Train Loss: 1.5917, Train Accuracy: 52.6486%\n",
      "Epoch: 6410, Train Loss: 1.5915, Train Accuracy: 52.6486%\n",
      "Epoch: 6420, Train Loss: 1.5913, Train Accuracy: 52.6486%\n",
      "Epoch: 6430, Train Loss: 1.5912, Train Accuracy: 52.6486%\n",
      "Epoch: 6440, Train Loss: 1.5910, Train Accuracy: 52.6486%\n",
      "Epoch: 6450, Train Loss: 1.5908, Train Accuracy: 52.6486%\n",
      "Epoch: 6460, Train Loss: 1.5906, Train Accuracy: 52.5405%\n",
      "Epoch: 6470, Train Loss: 1.5904, Train Accuracy: 52.4324%\n",
      "Epoch: 6480, Train Loss: 1.5903, Train Accuracy: 52.4324%\n",
      "Epoch: 6490, Train Loss: 1.5901, Train Accuracy: 52.4324%\n",
      "Epoch: 6500, Train Loss: 1.5899, Train Accuracy: 52.4324%\n",
      "Epoch: 6510, Train Loss: 1.5897, Train Accuracy: 52.4324%\n",
      "Epoch: 6520, Train Loss: 1.5896, Train Accuracy: 52.4324%\n",
      "Epoch: 6530, Train Loss: 1.5894, Train Accuracy: 52.4324%\n",
      "Epoch: 6540, Train Loss: 1.5892, Train Accuracy: 52.4324%\n",
      "Epoch: 6550, Train Loss: 1.5890, Train Accuracy: 52.4324%\n",
      "Epoch: 6560, Train Loss: 1.5889, Train Accuracy: 52.4324%\n",
      "Epoch: 6570, Train Loss: 1.5887, Train Accuracy: 52.4324%\n",
      "Epoch: 6580, Train Loss: 1.5885, Train Accuracy: 52.4324%\n",
      "Epoch: 6590, Train Loss: 1.5884, Train Accuracy: 52.4324%\n",
      "Epoch: 6600, Train Loss: 1.5882, Train Accuracy: 52.4324%\n",
      "Epoch: 6610, Train Loss: 1.5880, Train Accuracy: 52.4324%\n",
      "Epoch: 6620, Train Loss: 1.5878, Train Accuracy: 52.4324%\n",
      "Epoch: 6630, Train Loss: 1.5877, Train Accuracy: 52.5405%\n",
      "Epoch: 6640, Train Loss: 1.5875, Train Accuracy: 52.5405%\n",
      "Epoch: 6650, Train Loss: 1.5873, Train Accuracy: 52.5405%\n",
      "Epoch: 6660, Train Loss: 1.5872, Train Accuracy: 52.5405%\n",
      "Epoch: 6670, Train Loss: 1.5870, Train Accuracy: 52.5405%\n",
      "Epoch: 6680, Train Loss: 1.5868, Train Accuracy: 52.5405%\n",
      "Epoch: 6690, Train Loss: 1.5866, Train Accuracy: 52.6486%\n",
      "Epoch: 6700, Train Loss: 1.5865, Train Accuracy: 52.6486%\n",
      "Epoch: 6710, Train Loss: 1.5863, Train Accuracy: 52.6486%\n",
      "Epoch: 6720, Train Loss: 1.5861, Train Accuracy: 52.7568%\n",
      "Epoch: 6730, Train Loss: 1.5860, Train Accuracy: 52.7568%\n",
      "Epoch: 6740, Train Loss: 1.5858, Train Accuracy: 52.7568%\n",
      "Epoch: 6750, Train Loss: 1.5856, Train Accuracy: 52.7568%\n",
      "Epoch: 6760, Train Loss: 1.5855, Train Accuracy: 52.7568%\n",
      "Epoch: 6770, Train Loss: 1.5853, Train Accuracy: 52.7568%\n",
      "Epoch: 6780, Train Loss: 1.5851, Train Accuracy: 52.7568%\n",
      "Epoch: 6790, Train Loss: 1.5849, Train Accuracy: 52.7568%\n",
      "Epoch: 6800, Train Loss: 1.5848, Train Accuracy: 52.7568%\n",
      "Epoch: 6810, Train Loss: 1.5846, Train Accuracy: 52.7568%\n",
      "Epoch: 6820, Train Loss: 1.5844, Train Accuracy: 52.7568%\n",
      "Epoch: 6830, Train Loss: 1.5843, Train Accuracy: 52.7568%\n",
      "Epoch: 6840, Train Loss: 1.5841, Train Accuracy: 52.7568%\n",
      "Epoch: 6850, Train Loss: 1.5839, Train Accuracy: 52.7568%\n",
      "Epoch: 6860, Train Loss: 1.5838, Train Accuracy: 52.7568%\n",
      "Epoch: 6870, Train Loss: 1.5836, Train Accuracy: 52.7568%\n",
      "Epoch: 6880, Train Loss: 1.5834, Train Accuracy: 52.7568%\n",
      "Epoch: 6890, Train Loss: 1.5833, Train Accuracy: 52.7568%\n",
      "Epoch: 6900, Train Loss: 1.5831, Train Accuracy: 52.7568%\n",
      "Epoch: 6910, Train Loss: 1.5830, Train Accuracy: 52.7568%\n",
      "Epoch: 6920, Train Loss: 1.5828, Train Accuracy: 52.7568%\n",
      "Epoch: 6930, Train Loss: 1.5826, Train Accuracy: 52.7568%\n",
      "Epoch: 6940, Train Loss: 1.5825, Train Accuracy: 52.7568%\n",
      "Epoch: 6950, Train Loss: 1.5823, Train Accuracy: 52.7568%\n",
      "Epoch: 6960, Train Loss: 1.5821, Train Accuracy: 52.7568%\n",
      "Epoch: 6970, Train Loss: 1.5820, Train Accuracy: 52.7568%\n",
      "Epoch: 6980, Train Loss: 1.5818, Train Accuracy: 52.7568%\n",
      "Epoch: 6990, Train Loss: 1.5816, Train Accuracy: 52.7568%\n",
      "Epoch: 7000, Train Loss: 1.5815, Train Accuracy: 52.7568%\n",
      "Epoch: 7010, Train Loss: 1.5813, Train Accuracy: 52.7568%\n",
      "Epoch: 7020, Train Loss: 1.5812, Train Accuracy: 52.7568%\n",
      "Epoch: 7030, Train Loss: 1.5810, Train Accuracy: 52.7568%\n",
      "Epoch: 7040, Train Loss: 1.5808, Train Accuracy: 52.7568%\n",
      "Epoch: 7050, Train Loss: 1.5807, Train Accuracy: 52.7568%\n",
      "Epoch: 7060, Train Loss: 1.5805, Train Accuracy: 52.7568%\n",
      "Epoch: 7070, Train Loss: 1.5803, Train Accuracy: 52.7568%\n",
      "Epoch: 7080, Train Loss: 1.5802, Train Accuracy: 52.7568%\n",
      "Epoch: 7090, Train Loss: 1.5800, Train Accuracy: 52.7568%\n",
      "Epoch: 7100, Train Loss: 1.5799, Train Accuracy: 52.7568%\n",
      "Epoch: 7110, Train Loss: 1.5797, Train Accuracy: 52.7568%\n",
      "Epoch: 7120, Train Loss: 1.5795, Train Accuracy: 52.7568%\n",
      "Epoch: 7130, Train Loss: 1.5794, Train Accuracy: 52.7568%\n",
      "Epoch: 7140, Train Loss: 1.5792, Train Accuracy: 52.7568%\n",
      "Epoch: 7150, Train Loss: 1.5791, Train Accuracy: 52.7568%\n",
      "Epoch: 7160, Train Loss: 1.5789, Train Accuracy: 52.7568%\n",
      "Epoch: 7170, Train Loss: 1.5787, Train Accuracy: 52.7568%\n",
      "Epoch: 7180, Train Loss: 1.5786, Train Accuracy: 52.7568%\n",
      "Epoch: 7190, Train Loss: 1.5784, Train Accuracy: 52.7568%\n",
      "Epoch: 7200, Train Loss: 1.5783, Train Accuracy: 52.7568%\n",
      "Epoch: 7210, Train Loss: 1.5781, Train Accuracy: 52.7568%\n",
      "Epoch: 7220, Train Loss: 1.5780, Train Accuracy: 52.7568%\n",
      "Epoch: 7230, Train Loss: 1.5778, Train Accuracy: 52.7568%\n",
      "Epoch: 7240, Train Loss: 1.5776, Train Accuracy: 52.7568%\n",
      "Epoch: 7250, Train Loss: 1.5775, Train Accuracy: 52.7568%\n",
      "Epoch: 7260, Train Loss: 1.5773, Train Accuracy: 52.7568%\n",
      "Epoch: 7270, Train Loss: 1.5772, Train Accuracy: 52.7568%\n",
      "Epoch: 7280, Train Loss: 1.5770, Train Accuracy: 52.7568%\n",
      "Epoch: 7290, Train Loss: 1.5769, Train Accuracy: 52.7568%\n",
      "Epoch: 7300, Train Loss: 1.5767, Train Accuracy: 52.7568%\n",
      "Epoch: 7310, Train Loss: 1.5765, Train Accuracy: 52.7568%\n",
      "Epoch: 7320, Train Loss: 1.5764, Train Accuracy: 52.7568%\n",
      "Epoch: 7330, Train Loss: 1.5762, Train Accuracy: 52.7568%\n",
      "Epoch: 7340, Train Loss: 1.5761, Train Accuracy: 52.7568%\n",
      "Epoch: 7350, Train Loss: 1.5759, Train Accuracy: 52.7568%\n",
      "Epoch: 7360, Train Loss: 1.5758, Train Accuracy: 52.7568%\n",
      "Epoch: 7370, Train Loss: 1.5756, Train Accuracy: 52.7568%\n",
      "Epoch: 7380, Train Loss: 1.5755, Train Accuracy: 52.7568%\n",
      "Epoch: 7390, Train Loss: 1.5753, Train Accuracy: 52.7568%\n",
      "Epoch: 7400, Train Loss: 1.5752, Train Accuracy: 52.7568%\n",
      "Epoch: 7410, Train Loss: 1.5750, Train Accuracy: 52.7568%\n",
      "Epoch: 7420, Train Loss: 1.5749, Train Accuracy: 52.7568%\n",
      "Epoch: 7430, Train Loss: 1.5747, Train Accuracy: 52.7568%\n",
      "Epoch: 7440, Train Loss: 1.5745, Train Accuracy: 52.7568%\n",
      "Epoch: 7450, Train Loss: 1.5744, Train Accuracy: 52.7568%\n",
      "Epoch: 7460, Train Loss: 1.5742, Train Accuracy: 52.7568%\n",
      "Epoch: 7470, Train Loss: 1.5741, Train Accuracy: 52.7568%\n",
      "Epoch: 7480, Train Loss: 1.5739, Train Accuracy: 52.7568%\n",
      "Epoch: 7490, Train Loss: 1.5738, Train Accuracy: 52.7568%\n",
      "Epoch: 7500, Train Loss: 1.5736, Train Accuracy: 52.7568%\n",
      "Epoch: 7510, Train Loss: 1.5735, Train Accuracy: 52.7568%\n",
      "Epoch: 7520, Train Loss: 1.5733, Train Accuracy: 52.7568%\n",
      "Epoch: 7530, Train Loss: 1.5732, Train Accuracy: 52.7568%\n",
      "Epoch: 7540, Train Loss: 1.5730, Train Accuracy: 52.7568%\n",
      "Epoch: 7550, Train Loss: 1.5729, Train Accuracy: 52.7568%\n",
      "Epoch: 7560, Train Loss: 1.5727, Train Accuracy: 52.7568%\n",
      "Epoch: 7570, Train Loss: 1.5726, Train Accuracy: 52.7568%\n",
      "Epoch: 7580, Train Loss: 1.5724, Train Accuracy: 52.7568%\n",
      "Epoch: 7590, Train Loss: 1.5723, Train Accuracy: 52.7568%\n",
      "Epoch: 7600, Train Loss: 1.5721, Train Accuracy: 52.7568%\n",
      "Epoch: 7610, Train Loss: 1.5720, Train Accuracy: 52.7568%\n",
      "Epoch: 7620, Train Loss: 1.5718, Train Accuracy: 52.7568%\n",
      "Epoch: 7630, Train Loss: 1.5717, Train Accuracy: 52.7568%\n",
      "Epoch: 7640, Train Loss: 1.5715, Train Accuracy: 52.7568%\n",
      "Epoch: 7650, Train Loss: 1.5714, Train Accuracy: 52.7568%\n",
      "Epoch: 7660, Train Loss: 1.5712, Train Accuracy: 52.7568%\n",
      "Epoch: 7670, Train Loss: 1.5711, Train Accuracy: 52.7568%\n",
      "Epoch: 7680, Train Loss: 1.5709, Train Accuracy: 52.7568%\n",
      "Epoch: 7690, Train Loss: 1.5708, Train Accuracy: 52.7568%\n",
      "Epoch: 7700, Train Loss: 1.5707, Train Accuracy: 52.7568%\n",
      "Epoch: 7710, Train Loss: 1.5705, Train Accuracy: 52.7568%\n",
      "Epoch: 7720, Train Loss: 1.5704, Train Accuracy: 52.7568%\n",
      "Epoch: 7730, Train Loss: 1.5702, Train Accuracy: 52.7568%\n",
      "Epoch: 7740, Train Loss: 1.5701, Train Accuracy: 52.7568%\n",
      "Epoch: 7750, Train Loss: 1.5699, Train Accuracy: 52.7568%\n",
      "Epoch: 7760, Train Loss: 1.5698, Train Accuracy: 52.7568%\n",
      "Epoch: 7770, Train Loss: 1.5696, Train Accuracy: 52.7568%\n",
      "Epoch: 7780, Train Loss: 1.5695, Train Accuracy: 52.7568%\n",
      "Epoch: 7790, Train Loss: 1.5693, Train Accuracy: 52.7568%\n",
      "Epoch: 7800, Train Loss: 1.5692, Train Accuracy: 52.7568%\n",
      "Epoch: 7810, Train Loss: 1.5690, Train Accuracy: 52.7568%\n",
      "Epoch: 7820, Train Loss: 1.5689, Train Accuracy: 52.7568%\n",
      "Epoch: 7830, Train Loss: 1.5688, Train Accuracy: 52.7568%\n",
      "Epoch: 7840, Train Loss: 1.5686, Train Accuracy: 52.7568%\n",
      "Epoch: 7850, Train Loss: 1.5685, Train Accuracy: 52.7568%\n",
      "Epoch: 7860, Train Loss: 1.5683, Train Accuracy: 52.7568%\n",
      "Epoch: 7870, Train Loss: 1.5682, Train Accuracy: 52.7568%\n",
      "Epoch: 7880, Train Loss: 1.5680, Train Accuracy: 52.7568%\n",
      "Epoch: 7890, Train Loss: 1.5679, Train Accuracy: 52.7568%\n",
      "Epoch: 7900, Train Loss: 1.5678, Train Accuracy: 52.7568%\n",
      "Epoch: 7910, Train Loss: 1.5676, Train Accuracy: 52.7568%\n",
      "Epoch: 7920, Train Loss: 1.5675, Train Accuracy: 52.7568%\n",
      "Epoch: 7930, Train Loss: 1.5673, Train Accuracy: 52.7568%\n",
      "Epoch: 7940, Train Loss: 1.5672, Train Accuracy: 52.7568%\n",
      "Epoch: 7950, Train Loss: 1.5670, Train Accuracy: 52.7568%\n",
      "Epoch: 7960, Train Loss: 1.5669, Train Accuracy: 52.7568%\n",
      "Epoch: 7970, Train Loss: 1.5668, Train Accuracy: 52.7568%\n",
      "Epoch: 7980, Train Loss: 1.5666, Train Accuracy: 52.7568%\n",
      "Epoch: 7990, Train Loss: 1.5665, Train Accuracy: 52.7568%\n",
      "Epoch: 8000, Train Loss: 1.5663, Train Accuracy: 52.7568%\n",
      "Epoch: 8010, Train Loss: 1.5662, Train Accuracy: 52.7568%\n",
      "Epoch: 8020, Train Loss: 1.5661, Train Accuracy: 52.7568%\n",
      "Epoch: 8030, Train Loss: 1.5659, Train Accuracy: 52.7568%\n",
      "Epoch: 8040, Train Loss: 1.5658, Train Accuracy: 52.7568%\n",
      "Epoch: 8050, Train Loss: 1.5656, Train Accuracy: 52.7568%\n",
      "Epoch: 8060, Train Loss: 1.5655, Train Accuracy: 52.7568%\n",
      "Epoch: 8070, Train Loss: 1.5654, Train Accuracy: 52.7568%\n",
      "Epoch: 8080, Train Loss: 1.5652, Train Accuracy: 52.7568%\n",
      "Epoch: 8090, Train Loss: 1.5651, Train Accuracy: 52.7568%\n",
      "Epoch: 8100, Train Loss: 1.5649, Train Accuracy: 52.7568%\n",
      "Epoch: 8110, Train Loss: 1.5648, Train Accuracy: 52.7568%\n",
      "Epoch: 8120, Train Loss: 1.5647, Train Accuracy: 52.7568%\n",
      "Epoch: 8130, Train Loss: 1.5645, Train Accuracy: 52.7568%\n",
      "Epoch: 8140, Train Loss: 1.5644, Train Accuracy: 52.7568%\n",
      "Epoch: 8150, Train Loss: 1.5642, Train Accuracy: 52.7568%\n",
      "Epoch: 8160, Train Loss: 1.5641, Train Accuracy: 52.7568%\n",
      "Epoch: 8170, Train Loss: 1.5640, Train Accuracy: 52.7568%\n",
      "Epoch: 8180, Train Loss: 1.5638, Train Accuracy: 52.7568%\n",
      "Epoch: 8190, Train Loss: 1.5637, Train Accuracy: 52.7568%\n",
      "Epoch: 8200, Train Loss: 1.5636, Train Accuracy: 52.7568%\n",
      "Epoch: 8210, Train Loss: 1.5634, Train Accuracy: 52.7568%\n",
      "Epoch: 8220, Train Loss: 1.5633, Train Accuracy: 52.7568%\n",
      "Epoch: 8230, Train Loss: 1.5632, Train Accuracy: 52.7568%\n",
      "Epoch: 8240, Train Loss: 1.5630, Train Accuracy: 52.7568%\n",
      "Epoch: 8250, Train Loss: 1.5629, Train Accuracy: 52.7568%\n",
      "Epoch: 8260, Train Loss: 1.5627, Train Accuracy: 52.7568%\n",
      "Epoch: 8270, Train Loss: 1.5626, Train Accuracy: 52.7568%\n",
      "Epoch: 8280, Train Loss: 1.5625, Train Accuracy: 52.7568%\n",
      "Epoch: 8290, Train Loss: 1.5623, Train Accuracy: 52.7568%\n",
      "Epoch: 8300, Train Loss: 1.5622, Train Accuracy: 52.7568%\n",
      "Epoch: 8310, Train Loss: 1.5621, Train Accuracy: 52.7568%\n",
      "Epoch: 8320, Train Loss: 1.5619, Train Accuracy: 52.7568%\n",
      "Epoch: 8330, Train Loss: 1.5618, Train Accuracy: 52.7568%\n",
      "Epoch: 8340, Train Loss: 1.5617, Train Accuracy: 52.7568%\n",
      "Epoch: 8350, Train Loss: 1.5615, Train Accuracy: 52.7568%\n",
      "Epoch: 8360, Train Loss: 1.5614, Train Accuracy: 52.7568%\n",
      "Epoch: 8370, Train Loss: 1.5613, Train Accuracy: 52.7568%\n",
      "Epoch: 8380, Train Loss: 1.5611, Train Accuracy: 52.7568%\n",
      "Epoch: 8390, Train Loss: 1.5610, Train Accuracy: 52.7568%\n",
      "Epoch: 8400, Train Loss: 1.5609, Train Accuracy: 52.7568%\n",
      "Epoch: 8410, Train Loss: 1.5607, Train Accuracy: 52.7568%\n",
      "Epoch: 8420, Train Loss: 1.5606, Train Accuracy: 52.7568%\n",
      "Epoch: 8430, Train Loss: 1.5605, Train Accuracy: 52.7568%\n",
      "Epoch: 8440, Train Loss: 1.5603, Train Accuracy: 52.7568%\n",
      "Epoch: 8450, Train Loss: 1.5602, Train Accuracy: 52.7568%\n",
      "Epoch: 8460, Train Loss: 1.5601, Train Accuracy: 52.7568%\n",
      "Epoch: 8470, Train Loss: 1.5599, Train Accuracy: 52.7568%\n",
      "Epoch: 8480, Train Loss: 1.5598, Train Accuracy: 52.7568%\n",
      "Epoch: 8490, Train Loss: 1.5597, Train Accuracy: 52.7568%\n",
      "Epoch: 8500, Train Loss: 1.5595, Train Accuracy: 52.7568%\n",
      "Epoch: 8510, Train Loss: 1.5594, Train Accuracy: 52.7568%\n",
      "Epoch: 8520, Train Loss: 1.5593, Train Accuracy: 52.7568%\n",
      "Epoch: 8530, Train Loss: 1.5591, Train Accuracy: 52.7568%\n",
      "Epoch: 8540, Train Loss: 1.5590, Train Accuracy: 52.7568%\n",
      "Epoch: 8550, Train Loss: 1.5589, Train Accuracy: 52.7568%\n",
      "Epoch: 8560, Train Loss: 1.5588, Train Accuracy: 52.7568%\n",
      "Epoch: 8570, Train Loss: 1.5586, Train Accuracy: 52.7568%\n",
      "Epoch: 8580, Train Loss: 1.5585, Train Accuracy: 52.7568%\n",
      "Epoch: 8590, Train Loss: 1.5584, Train Accuracy: 52.7568%\n",
      "Epoch: 8600, Train Loss: 1.5582, Train Accuracy: 52.7568%\n",
      "Epoch: 8610, Train Loss: 1.5581, Train Accuracy: 52.7568%\n",
      "Epoch: 8620, Train Loss: 1.5580, Train Accuracy: 52.7568%\n",
      "Epoch: 8630, Train Loss: 1.5578, Train Accuracy: 52.7568%\n",
      "Epoch: 8640, Train Loss: 1.5577, Train Accuracy: 52.7568%\n",
      "Epoch: 8650, Train Loss: 1.5576, Train Accuracy: 52.7568%\n",
      "Epoch: 8660, Train Loss: 1.5575, Train Accuracy: 52.7568%\n",
      "Epoch: 8670, Train Loss: 1.5573, Train Accuracy: 52.7568%\n",
      "Epoch: 8680, Train Loss: 1.5572, Train Accuracy: 52.7568%\n",
      "Epoch: 8690, Train Loss: 1.5571, Train Accuracy: 52.7568%\n",
      "Epoch: 8700, Train Loss: 1.5569, Train Accuracy: 52.7568%\n",
      "Epoch: 8710, Train Loss: 1.5568, Train Accuracy: 52.7568%\n",
      "Epoch: 8720, Train Loss: 1.5567, Train Accuracy: 52.7568%\n",
      "Epoch: 8730, Train Loss: 1.5566, Train Accuracy: 52.7568%\n",
      "Epoch: 8740, Train Loss: 1.5564, Train Accuracy: 52.7568%\n",
      "Epoch: 8750, Train Loss: 1.5563, Train Accuracy: 52.7568%\n",
      "Epoch: 8760, Train Loss: 1.5562, Train Accuracy: 52.7568%\n",
      "Epoch: 8770, Train Loss: 1.5561, Train Accuracy: 52.7568%\n",
      "Epoch: 8780, Train Loss: 1.5559, Train Accuracy: 52.7568%\n",
      "Epoch: 8790, Train Loss: 1.5558, Train Accuracy: 52.7568%\n",
      "Epoch: 8800, Train Loss: 1.5557, Train Accuracy: 52.8649%\n",
      "Epoch: 8810, Train Loss: 1.5556, Train Accuracy: 52.8649%\n",
      "Epoch: 8820, Train Loss: 1.5554, Train Accuracy: 52.8649%\n",
      "Epoch: 8830, Train Loss: 1.5553, Train Accuracy: 52.8649%\n",
      "Epoch: 8840, Train Loss: 1.5552, Train Accuracy: 52.8649%\n",
      "Epoch: 8850, Train Loss: 1.5551, Train Accuracy: 52.8649%\n",
      "Epoch: 8860, Train Loss: 1.5549, Train Accuracy: 52.8649%\n",
      "Epoch: 8870, Train Loss: 1.5548, Train Accuracy: 52.8649%\n",
      "Epoch: 8880, Train Loss: 1.5547, Train Accuracy: 52.8649%\n",
      "Epoch: 8890, Train Loss: 1.5546, Train Accuracy: 52.8649%\n",
      "Epoch: 8900, Train Loss: 1.5544, Train Accuracy: 52.8649%\n",
      "Epoch: 8910, Train Loss: 1.5543, Train Accuracy: 52.8649%\n",
      "Epoch: 8920, Train Loss: 1.5542, Train Accuracy: 52.8649%\n",
      "Epoch: 8930, Train Loss: 1.5541, Train Accuracy: 52.8649%\n",
      "Epoch: 8940, Train Loss: 1.5539, Train Accuracy: 52.8649%\n",
      "Epoch: 8950, Train Loss: 1.5538, Train Accuracy: 52.8649%\n",
      "Epoch: 8960, Train Loss: 1.5537, Train Accuracy: 52.8649%\n",
      "Epoch: 8970, Train Loss: 1.5536, Train Accuracy: 52.8649%\n",
      "Epoch: 8980, Train Loss: 1.5534, Train Accuracy: 52.8649%\n",
      "Epoch: 8990, Train Loss: 1.5533, Train Accuracy: 52.8649%\n",
      "Epoch: 9000, Train Loss: 1.5532, Train Accuracy: 52.8649%\n",
      "Epoch: 9010, Train Loss: 1.5531, Train Accuracy: 52.8649%\n",
      "Epoch: 9020, Train Loss: 1.5530, Train Accuracy: 52.8649%\n",
      "Epoch: 9030, Train Loss: 1.5528, Train Accuracy: 52.9730%\n",
      "Epoch: 9040, Train Loss: 1.5527, Train Accuracy: 52.9730%\n",
      "Epoch: 9050, Train Loss: 1.5526, Train Accuracy: 52.9730%\n",
      "Epoch: 9060, Train Loss: 1.5525, Train Accuracy: 52.9730%\n",
      "Epoch: 9070, Train Loss: 1.5523, Train Accuracy: 52.9730%\n",
      "Epoch: 9080, Train Loss: 1.5522, Train Accuracy: 52.9730%\n",
      "Epoch: 9090, Train Loss: 1.5521, Train Accuracy: 52.9730%\n",
      "Epoch: 9100, Train Loss: 1.5520, Train Accuracy: 52.9730%\n",
      "Epoch: 9110, Train Loss: 1.5519, Train Accuracy: 52.9730%\n",
      "Epoch: 9120, Train Loss: 1.5517, Train Accuracy: 52.9730%\n",
      "Epoch: 9130, Train Loss: 1.5516, Train Accuracy: 52.9730%\n",
      "Epoch: 9140, Train Loss: 1.5515, Train Accuracy: 52.9730%\n",
      "Epoch: 9150, Train Loss: 1.5514, Train Accuracy: 52.9730%\n",
      "Epoch: 9160, Train Loss: 1.5513, Train Accuracy: 52.9730%\n",
      "Epoch: 9170, Train Loss: 1.5511, Train Accuracy: 52.9730%\n",
      "Epoch: 9180, Train Loss: 1.5510, Train Accuracy: 52.9730%\n",
      "Epoch: 9190, Train Loss: 1.5509, Train Accuracy: 52.9730%\n",
      "Epoch: 9200, Train Loss: 1.5508, Train Accuracy: 52.9730%\n",
      "Epoch: 9210, Train Loss: 1.5507, Train Accuracy: 52.9730%\n",
      "Epoch: 9220, Train Loss: 1.5505, Train Accuracy: 52.9730%\n",
      "Epoch: 9230, Train Loss: 1.5504, Train Accuracy: 52.9730%\n",
      "Epoch: 9240, Train Loss: 1.5503, Train Accuracy: 52.9730%\n",
      "Epoch: 9250, Train Loss: 1.5502, Train Accuracy: 52.9730%\n",
      "Epoch: 9260, Train Loss: 1.5501, Train Accuracy: 52.9730%\n",
      "Epoch: 9270, Train Loss: 1.5500, Train Accuracy: 52.9730%\n",
      "Epoch: 9280, Train Loss: 1.5498, Train Accuracy: 52.9730%\n",
      "Epoch: 9290, Train Loss: 1.5497, Train Accuracy: 52.9730%\n",
      "Epoch: 9300, Train Loss: 1.5496, Train Accuracy: 52.9730%\n",
      "Epoch: 9310, Train Loss: 1.5495, Train Accuracy: 52.9730%\n",
      "Epoch: 9320, Train Loss: 1.5494, Train Accuracy: 52.9730%\n",
      "Epoch: 9330, Train Loss: 1.5492, Train Accuracy: 52.9730%\n",
      "Epoch: 9340, Train Loss: 1.5491, Train Accuracy: 52.9730%\n",
      "Epoch: 9350, Train Loss: 1.5490, Train Accuracy: 52.9730%\n",
      "Epoch: 9360, Train Loss: 1.5489, Train Accuracy: 52.9730%\n",
      "Epoch: 9370, Train Loss: 1.5488, Train Accuracy: 52.9730%\n",
      "Epoch: 9380, Train Loss: 1.5487, Train Accuracy: 52.9730%\n",
      "Epoch: 9390, Train Loss: 1.5485, Train Accuracy: 52.9730%\n",
      "Epoch: 9400, Train Loss: 1.5484, Train Accuracy: 52.9730%\n",
      "Epoch: 9410, Train Loss: 1.5483, Train Accuracy: 52.9730%\n",
      "Epoch: 9420, Train Loss: 1.5482, Train Accuracy: 52.9730%\n",
      "Epoch: 9430, Train Loss: 1.5481, Train Accuracy: 52.9730%\n",
      "Epoch: 9440, Train Loss: 1.5480, Train Accuracy: 52.9730%\n",
      "Epoch: 9450, Train Loss: 1.5478, Train Accuracy: 52.9730%\n",
      "Epoch: 9460, Train Loss: 1.5477, Train Accuracy: 52.9730%\n",
      "Epoch: 9470, Train Loss: 1.5476, Train Accuracy: 52.9730%\n",
      "Epoch: 9480, Train Loss: 1.5475, Train Accuracy: 52.9730%\n",
      "Epoch: 9490, Train Loss: 1.5474, Train Accuracy: 52.9730%\n",
      "Epoch: 9500, Train Loss: 1.5473, Train Accuracy: 52.9730%\n",
      "Epoch: 9510, Train Loss: 1.5472, Train Accuracy: 52.9730%\n",
      "Epoch: 9520, Train Loss: 1.5470, Train Accuracy: 52.9730%\n",
      "Epoch: 9530, Train Loss: 1.5469, Train Accuracy: 52.9730%\n",
      "Epoch: 9540, Train Loss: 1.5468, Train Accuracy: 52.9730%\n",
      "Epoch: 9550, Train Loss: 1.5467, Train Accuracy: 52.9730%\n",
      "Epoch: 9560, Train Loss: 1.5466, Train Accuracy: 53.0811%\n",
      "Epoch: 9570, Train Loss: 1.5465, Train Accuracy: 53.0811%\n",
      "Epoch: 9580, Train Loss: 1.5464, Train Accuracy: 53.0811%\n",
      "Epoch: 9590, Train Loss: 1.5463, Train Accuracy: 53.0811%\n",
      "Epoch: 9600, Train Loss: 1.5461, Train Accuracy: 53.0811%\n",
      "Epoch: 9610, Train Loss: 1.5460, Train Accuracy: 53.0811%\n",
      "Epoch: 9620, Train Loss: 1.5459, Train Accuracy: 53.0811%\n",
      "Epoch: 9630, Train Loss: 1.5458, Train Accuracy: 53.0811%\n",
      "Epoch: 9640, Train Loss: 1.5457, Train Accuracy: 53.0811%\n",
      "Epoch: 9650, Train Loss: 1.5456, Train Accuracy: 53.0811%\n",
      "Epoch: 9660, Train Loss: 1.5455, Train Accuracy: 53.1892%\n",
      "Epoch: 9670, Train Loss: 1.5454, Train Accuracy: 53.1892%\n",
      "Epoch: 9680, Train Loss: 1.5452, Train Accuracy: 53.1892%\n",
      "Epoch: 9690, Train Loss: 1.5451, Train Accuracy: 53.1892%\n",
      "Epoch: 9700, Train Loss: 1.5450, Train Accuracy: 53.1892%\n",
      "Epoch: 9710, Train Loss: 1.5449, Train Accuracy: 53.1892%\n",
      "Epoch: 9720, Train Loss: 1.5448, Train Accuracy: 53.1892%\n",
      "Epoch: 9730, Train Loss: 1.5447, Train Accuracy: 53.1892%\n",
      "Epoch: 9740, Train Loss: 1.5446, Train Accuracy: 53.1892%\n",
      "Epoch: 9750, Train Loss: 1.5445, Train Accuracy: 53.1892%\n",
      "Epoch: 9760, Train Loss: 1.5443, Train Accuracy: 53.1892%\n",
      "Epoch: 9770, Train Loss: 1.5442, Train Accuracy: 53.1892%\n",
      "Epoch: 9780, Train Loss: 1.5441, Train Accuracy: 53.1892%\n",
      "Epoch: 9790, Train Loss: 1.5440, Train Accuracy: 53.1892%\n",
      "Epoch: 9800, Train Loss: 1.5439, Train Accuracy: 53.1892%\n",
      "Epoch: 9810, Train Loss: 1.5438, Train Accuracy: 53.1892%\n",
      "Epoch: 9820, Train Loss: 1.5437, Train Accuracy: 53.1892%\n",
      "Epoch: 9830, Train Loss: 1.5436, Train Accuracy: 53.1892%\n",
      "Epoch: 9840, Train Loss: 1.5435, Train Accuracy: 53.1892%\n",
      "Epoch: 9850, Train Loss: 1.5434, Train Accuracy: 53.1892%\n",
      "Epoch: 9860, Train Loss: 1.5433, Train Accuracy: 53.1892%\n",
      "Epoch: 9870, Train Loss: 1.5431, Train Accuracy: 53.1892%\n",
      "Epoch: 9880, Train Loss: 1.5430, Train Accuracy: 53.1892%\n",
      "Epoch: 9890, Train Loss: 1.5429, Train Accuracy: 53.1892%\n",
      "Epoch: 9900, Train Loss: 1.5428, Train Accuracy: 53.1892%\n",
      "Epoch: 9910, Train Loss: 1.5427, Train Accuracy: 53.1892%\n",
      "Epoch: 9920, Train Loss: 1.5426, Train Accuracy: 53.1892%\n",
      "Epoch: 9930, Train Loss: 1.5425, Train Accuracy: 53.1892%\n",
      "Epoch: 9940, Train Loss: 1.5424, Train Accuracy: 53.1892%\n",
      "Epoch: 9950, Train Loss: 1.5423, Train Accuracy: 53.1892%\n",
      "Epoch: 9960, Train Loss: 1.5422, Train Accuracy: 53.2973%\n",
      "Epoch: 9970, Train Loss: 1.5421, Train Accuracy: 53.2973%\n",
      "Epoch: 9980, Train Loss: 1.5420, Train Accuracy: 53.2973%\n",
      "Epoch: 9990, Train Loss: 1.5418, Train Accuracy: 53.2973%\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001, 0.0001, 0.2, 0.02, 0.002, 0.0002, 0.3, 0.03, 0.003, 0.0003]\n",
    "\n",
    "for lr in learning_rates:\n",
    "    wandb.init(project='SMAI-Assignment 3', name=f\"Logistic Regression lr={lr}\", config={\n",
    "        'Model': 'Multinomial Logistic Regression',\n",
    "        'Epochs': 10000,\n",
    "        'Learning Rate': lr\n",
    "    })\n",
    "    model = MultinomialLogisticRegression(learning_rate=lr, epochs=10000, X_train=X_train, y_train=y_train, X_val=X_val, y_val=y_val)\n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
